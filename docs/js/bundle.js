/******/ (() => { // webpackBootstrap
/******/ 	"use strict";
/******/ 	var __webpack_modules__ = ({

/***/ "../../../AppData/Roaming/npm/node_modules/mediabunny/dist/bundles/mediabunny.cjs":
/*!****************************************************************************************!*\
  !*** ../../../AppData/Roaming/npm/node_modules/mediabunny/dist/bundles/mediabunny.cjs ***!
  \****************************************************************************************/
/***/ ((module) => {

/*!
 * Copyright (c) 2025-present, Vanilagy and contributors
 *
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */

var Mediabunny = (() => {
  var __defProp = Object.defineProperty;
  var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
  var __getOwnPropNames = Object.getOwnPropertyNames;
  var __hasOwnProp = Object.prototype.hasOwnProperty;
  var __export = (target, all) => {
    for (var name in all)
      __defProp(target, name, { get: all[name], enumerable: true });
  };
  var __copyProps = (to, from, except, desc) => {
    if (from && typeof from === "object" || typeof from === "function") {
      for (let key of __getOwnPropNames(from))
        if (!__hasOwnProp.call(to, key) && key !== except)
          __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
    }
    return to;
  };
  var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);

  // src/index.ts
  var index_exports = {};
  __export(index_exports, {
    ALL_FORMATS: () => ALL_FORMATS,
    ALL_TRACK_TYPES: () => ALL_TRACK_TYPES,
    AUDIO_CODECS: () => AUDIO_CODECS,
    AudioBufferSink: () => AudioBufferSink,
    AudioBufferSource: () => AudioBufferSource,
    AudioSample: () => AudioSample,
    AudioSampleSink: () => AudioSampleSink,
    AudioSampleSource: () => AudioSampleSource,
    AudioSource: () => AudioSource,
    BaseMediaSampleSink: () => BaseMediaSampleSink,
    BlobSource: () => BlobSource,
    BufferSource: () => BufferSource,
    BufferTarget: () => BufferTarget,
    CanvasSink: () => CanvasSink,
    CanvasSource: () => CanvasSource,
    Conversion: () => Conversion,
    CustomAudioDecoder: () => CustomAudioDecoder,
    CustomAudioEncoder: () => CustomAudioEncoder,
    CustomVideoDecoder: () => CustomVideoDecoder,
    CustomVideoEncoder: () => CustomVideoEncoder,
    EncodedAudioPacketSource: () => EncodedAudioPacketSource,
    EncodedPacket: () => EncodedPacket,
    EncodedPacketSink: () => EncodedPacketSink,
    EncodedVideoPacketSource: () => EncodedVideoPacketSource,
    Input: () => Input,
    InputAudioTrack: () => InputAudioTrack,
    InputFormat: () => InputFormat,
    InputTrack: () => InputTrack,
    InputVideoTrack: () => InputVideoTrack,
    IsobmffInputFormat: () => IsobmffInputFormat,
    IsobmffOutputFormat: () => IsobmffOutputFormat2,
    MATROSKA: () => MATROSKA,
    MP3: () => MP3,
    MP4: () => MP4,
    MatroskaInputFormat: () => MatroskaInputFormat,
    MediaSource: () => MediaSource,
    MediaStreamAudioTrackSource: () => MediaStreamAudioTrackSource,
    MediaStreamVideoTrackSource: () => MediaStreamVideoTrackSource,
    MkvOutputFormat: () => MkvOutputFormat2,
    MovOutputFormat: () => MovOutputFormat,
    Mp3InputFormat: () => Mp3InputFormat,
    Mp3OutputFormat: () => Mp3OutputFormat,
    Mp4InputFormat: () => Mp4InputFormat,
    Mp4OutputFormat: () => Mp4OutputFormat,
    NON_PCM_AUDIO_CODECS: () => NON_PCM_AUDIO_CODECS,
    OGG: () => OGG,
    OggInputFormat: () => OggInputFormat,
    OggOutputFormat: () => OggOutputFormat,
    Output: () => Output,
    OutputFormat: () => OutputFormat,
    PCM_AUDIO_CODECS: () => PCM_AUDIO_CODECS,
    QTFF: () => QTFF,
    QUALITY_HIGH: () => QUALITY_HIGH,
    QUALITY_LOW: () => QUALITY_LOW,
    QUALITY_MEDIUM: () => QUALITY_MEDIUM,
    QUALITY_VERY_HIGH: () => QUALITY_VERY_HIGH,
    QUALITY_VERY_LOW: () => QUALITY_VERY_LOW,
    Quality: () => Quality,
    QuickTimeInputFormat: () => QuickTimeInputFormat,
    SUBTITLE_CODECS: () => SUBTITLE_CODECS,
    Source: () => Source,
    StreamSource: () => StreamSource,
    StreamTarget: () => StreamTarget,
    SubtitleSource: () => SubtitleSource,
    Target: () => Target,
    TextSubtitleSource: () => TextSubtitleSource,
    UrlSource: () => UrlSource,
    VIDEO_CODECS: () => VIDEO_CODECS,
    VideoSample: () => VideoSample,
    VideoSampleSink: () => VideoSampleSink,
    VideoSampleSource: () => VideoSampleSource,
    VideoSource: () => VideoSource,
    WAVE: () => WAVE,
    WEBM: () => WEBM,
    WavOutputFormat: () => WavOutputFormat,
    WaveInputFormat: () => WaveInputFormat,
    WebMInputFormat: () => WebMInputFormat,
    WebMOutputFormat: () => WebMOutputFormat,
    canEncode: () => canEncode,
    canEncodeAudio: () => canEncodeAudio,
    canEncodeSubtitles: () => canEncodeSubtitles,
    canEncodeVideo: () => canEncodeVideo,
    getEncodableAudioCodecs: () => getEncodableAudioCodecs,
    getEncodableCodecs: () => getEncodableCodecs,
    getEncodableSubtitleCodecs: () => getEncodableSubtitleCodecs,
    getEncodableVideoCodecs: () => getEncodableVideoCodecs,
    getFirstEncodableAudioCodec: () => getFirstEncodableAudioCodec,
    getFirstEncodableSubtitleCodec: () => getFirstEncodableSubtitleCodec,
    getFirstEncodableVideoCodec: () => getFirstEncodableVideoCodec,
    registerDecoder: () => registerDecoder,
    registerEncoder: () => registerEncoder
  });

  // src/misc.ts
  function assert(x) {
    if (!x) {
      throw new Error("Assertion failed.");
    }
  }
  var normalizeRotation = (rotation) => {
    const mappedRotation = (rotation % 360 + 360) % 360;
    if (mappedRotation === 0 || mappedRotation === 90 || mappedRotation === 180 || mappedRotation === 270) {
      return mappedRotation;
    } else {
      throw new Error(`Invalid rotation ${rotation}.`);
    }
  };
  var last = (arr) => {
    return arr && arr[arr.length - 1];
  };
  var isU32 = (value) => {
    return value >= 0 && value < 2 ** 32;
  };
  var Bitstream = class _Bitstream {
    constructor(bytes2) {
      this.bytes = bytes2;
      /** Current offset in bits. */
      this.pos = 0;
    }
    seekToByte(byteOffset) {
      this.pos = 8 * byteOffset;
    }
    readBit() {
      const byteIndex = Math.floor(this.pos / 8);
      const byte = this.bytes[byteIndex] ?? 0;
      const bitIndex = 7 - (this.pos & 7);
      const bit = (byte & 1 << bitIndex) >> bitIndex;
      this.pos++;
      return bit;
    }
    readBits(n) {
      if (n === 1) {
        return this.readBit();
      }
      let result = 0;
      for (let i = 0; i < n; i++) {
        result <<= 1;
        result |= this.readBit();
      }
      return result;
    }
    readAlignedByte() {
      if (this.pos % 8 !== 0) {
        throw new Error("Bitstream is not byte-aligned.");
      }
      const byteIndex = this.pos / 8;
      const byte = this.bytes[byteIndex] ?? 0;
      this.pos += 8;
      return byte;
    }
    skipBits(n) {
      this.pos += n;
    }
    getBitsLeft() {
      return this.bytes.length * 8 - this.pos;
    }
    clone() {
      const clone = new _Bitstream(this.bytes);
      clone.pos = this.pos;
      return clone;
    }
  };
  var readExpGolomb = (bitstream) => {
    let leadingZeroBits = 0;
    while (bitstream.readBits(1) === 0 && leadingZeroBits < 32) {
      leadingZeroBits++;
    }
    if (leadingZeroBits >= 32) {
      throw new Error("Invalid exponential-Golomb code.");
    }
    const result = (1 << leadingZeroBits) - 1 + bitstream.readBits(leadingZeroBits);
    return result;
  };
  var readSignedExpGolomb = (bitstream) => {
    const codeNum = readExpGolomb(bitstream);
    return (codeNum & 1) === 0 ? -(codeNum >> 1) : codeNum + 1 >> 1;
  };
  var writeBits = (bytes2, start, end, value) => {
    for (let i = start; i < end; i++) {
      const byteIndex = Math.floor(i / 8);
      let byte = bytes2[byteIndex];
      const bitIndex = 7 - (i & 7);
      byte &= ~(1 << bitIndex);
      byte |= (value & 1 << end - i - 1) >> end - i - 1 << bitIndex;
      bytes2[byteIndex] = byte;
    }
  };
  var toUint8Array = (source) => {
    if (source instanceof Uint8Array) {
      return source;
    } else if (source instanceof ArrayBuffer) {
      return new Uint8Array(source);
    } else {
      return new Uint8Array(source.buffer, source.byteOffset, source.byteLength);
    }
  };
  var toDataView = (source) => {
    if (source instanceof DataView) {
      return source;
    } else if (source instanceof ArrayBuffer) {
      return new DataView(source);
    } else {
      return new DataView(source.buffer, source.byteOffset, source.byteLength);
    }
  };
  var textEncoder = new TextEncoder();
  var invertObject = (object) => {
    return Object.fromEntries(Object.entries(object).map(([key, value]) => [value, key]));
  };
  var COLOR_PRIMARIES_MAP = {
    bt709: 1,
    // ITU-R BT.709
    bt470bg: 5,
    // ITU-R BT.470BG
    smpte170m: 6,
    // ITU-R BT.601 525 - SMPTE 170M
    bt2020: 9,
    // ITU-R BT.202
    smpte432: 12
    // SMPTE EG 432-1
  };
  var COLOR_PRIMARIES_MAP_INVERSE = invertObject(COLOR_PRIMARIES_MAP);
  var TRANSFER_CHARACTERISTICS_MAP = {
    "bt709": 1,
    // ITU-R BT.709
    "smpte170m": 6,
    // SMPTE 170M
    "linear": 8,
    // Linear transfer characteristics
    "iec61966-2-1": 13,
    // IEC 61966-2-1
    "pg": 16,
    // Rec. ITU-R BT.2100-2 perceptual quantization (PQ) system
    "hlg": 18
    // Rec. ITU-R BT.2100-2 hybrid loggamma (HLG) system
  };
  var TRANSFER_CHARACTERISTICS_MAP_INVERSE = invertObject(TRANSFER_CHARACTERISTICS_MAP);
  var MATRIX_COEFFICIENTS_MAP = {
    "rgb": 0,
    // Identity
    "bt709": 1,
    // ITU-R BT.709
    "bt470bg": 5,
    // ITU-R BT.470BG
    "smpte170m": 6,
    // SMPTE 170M
    "bt2020-ncl": 9
    // ITU-R BT.2020-2 (non-constant luminance)
  };
  var MATRIX_COEFFICIENTS_MAP_INVERSE = invertObject(MATRIX_COEFFICIENTS_MAP);
  var colorSpaceIsComplete = (colorSpace) => {
    return !!colorSpace && !!colorSpace.primaries && !!colorSpace.transfer && !!colorSpace.matrix && colorSpace.fullRange !== void 0;
  };
  var isAllowSharedBufferSource = (x) => {
    return x instanceof ArrayBuffer || typeof SharedArrayBuffer !== "undefined" && x instanceof SharedArrayBuffer || ArrayBuffer.isView(x);
  };
  var AsyncMutex = class {
    constructor() {
      this.currentPromise = Promise.resolve();
    }
    async acquire() {
      let resolver;
      const nextPromise = new Promise((resolve) => {
        resolver = resolve;
      });
      const currentPromiseAlias = this.currentPromise;
      this.currentPromise = nextPromise;
      await currentPromiseAlias;
      return resolver;
    }
  };
  var bytesToHexString = (bytes2) => {
    return [...bytes2].map((x) => x.toString(16).padStart(2, "0")).join("");
  };
  var reverseBitsU32 = (x) => {
    x = x >> 1 & 1431655765 | (x & 1431655765) << 1;
    x = x >> 2 & 858993459 | (x & 858993459) << 2;
    x = x >> 4 & 252645135 | (x & 252645135) << 4;
    x = x >> 8 & 16711935 | (x & 16711935) << 8;
    x = x >> 16 & 65535 | (x & 65535) << 16;
    return x >>> 0;
  };
  var binarySearchExact = (arr, key, valueGetter) => {
    let low = 0;
    let high = arr.length - 1;
    let ans = -1;
    while (low <= high) {
      const mid = low + high >> 1;
      const midVal = valueGetter(arr[mid]);
      if (midVal === key) {
        ans = mid;
        high = mid - 1;
      } else if (midVal < key) {
        low = mid + 1;
      } else {
        high = mid - 1;
      }
    }
    return ans;
  };
  var binarySearchLessOrEqual = (arr, key, valueGetter) => {
    let low = 0;
    let high = arr.length - 1;
    let ans = -1;
    while (low <= high) {
      const mid = low + (high - low + 1) / 2 | 0;
      const midVal = valueGetter(arr[mid]);
      if (midVal <= key) {
        ans = mid;
        low = mid + 1;
      } else {
        high = mid - 1;
      }
    }
    return ans;
  };
  var insertSorted = (arr, item, valueGetter) => {
    const insertionIndex = binarySearchLessOrEqual(arr, valueGetter(item), valueGetter);
    arr.splice(insertionIndex + 1, 0, item);
  };
  var promiseWithResolvers = () => {
    let resolve;
    let reject;
    const promise = new Promise((res, rej) => {
      resolve = res;
      reject = rej;
    });
    return { promise, resolve, reject };
  };
  var removeItem = (arr, item) => {
    const index = arr.indexOf(item);
    if (index !== -1) {
      arr.splice(index, 1);
    }
  };
  var findLast = (arr, predicate) => {
    for (let i = arr.length - 1; i >= 0; i--) {
      if (predicate(arr[i])) {
        return arr[i];
      }
    }
    return void 0;
  };
  var findLastIndex = (arr, predicate) => {
    for (let i = arr.length - 1; i >= 0; i--) {
      if (predicate(arr[i])) {
        return i;
      }
    }
    return -1;
  };
  var toAsyncIterator = async function* (source) {
    if (Symbol.iterator in source) {
      yield* source[Symbol.iterator]();
    } else {
      yield* source[Symbol.asyncIterator]();
    }
  };
  var validateAnyIterable = (iterable) => {
    if (!(Symbol.iterator in iterable) && !(Symbol.asyncIterator in iterable)) {
      throw new TypeError("Argument must be an iterable or async iterable.");
    }
  };
  var assertNever = (x) => {
    throw new Error(`Unexpected value: ${x}`);
  };
  var getUint24 = (view2, byteOffset, littleEndian) => {
    const byte1 = view2.getUint8(byteOffset);
    const byte2 = view2.getUint8(byteOffset + 1);
    const byte3 = view2.getUint8(byteOffset + 2);
    if (littleEndian) {
      return byte1 | byte2 << 8 | byte3 << 16;
    } else {
      return byte1 << 16 | byte2 << 8 | byte3;
    }
  };
  var getInt24 = (view2, byteOffset, littleEndian) => {
    return getUint24(view2, byteOffset, littleEndian) << 8 >> 8;
  };
  var setUint24 = (view2, byteOffset, value, littleEndian) => {
    value = value >>> 0;
    value = value & 16777215;
    if (littleEndian) {
      view2.setUint8(byteOffset, value & 255);
      view2.setUint8(byteOffset + 1, value >>> 8 & 255);
      view2.setUint8(byteOffset + 2, value >>> 16 & 255);
    } else {
      view2.setUint8(byteOffset, value >>> 16 & 255);
      view2.setUint8(byteOffset + 1, value >>> 8 & 255);
      view2.setUint8(byteOffset + 2, value & 255);
    }
  };
  var setInt24 = (view2, byteOffset, value, littleEndian) => {
    value = clamp(value, -8388608, 8388607);
    if (value < 0) {
      value = value + 16777216 & 16777215;
    }
    setUint24(view2, byteOffset, value, littleEndian);
  };
  var setInt64 = (view2, byteOffset, value, littleEndian) => {
    if (littleEndian) {
      view2.setUint32(byteOffset + 0, value, true);
      view2.setInt32(byteOffset + 4, Math.floor(value / 2 ** 32), true);
    } else {
      view2.setInt32(byteOffset + 0, Math.floor(value / 2 ** 32), true);
      view2.setUint32(byteOffset + 4, value, true);
    }
  };
  var mapAsyncGenerator = (generator, map) => {
    return {
      async next() {
        const result = await generator.next();
        if (result.done) {
          return { value: void 0, done: true };
        } else {
          return { value: map(result.value), done: false };
        }
      },
      return() {
        return generator.return();
      },
      throw(error) {
        return generator.throw(error);
      },
      [Symbol.asyncIterator]() {
        return this;
      }
    };
  };
  var clamp = (value, min, max) => {
    return Math.max(min, Math.min(max, value));
  };
  var UNDETERMINED_LANGUAGE = "und";
  var roundToPrecision = (value, digits) => {
    const factor = 10 ** digits;
    return Math.round(value * factor) / factor;
  };
  var roundToMultiple = (value, multiple) => {
    return Math.round(value / multiple) * multiple;
  };
  var ilog = (x) => {
    let ret = 0;
    while (x) {
      ret++;
      x >>= 1;
    }
    return ret;
  };
  var ISO_639_2_REGEX = /^[a-z]{3}$/;
  var isIso639Dash2LanguageCode = (x) => {
    return ISO_639_2_REGEX.test(x);
  };
  var SECOND_TO_MICROSECOND_FACTOR = 1e6 * (1 + Number.EPSILON);
  var mergeObjectsDeeply = (a, b) => {
    const result = { ...a };
    for (const key in b) {
      if (typeof a[key] === "object" && a[key] !== null && typeof b[key] === "object" && b[key] !== null) {
        result[key] = mergeObjectsDeeply(
          a[key],
          b[key]
        );
      } else {
        result[key] = b[key];
      }
    }
    return result;
  };
  var retriedFetch = async (url2, requestInit, getRetryDelay) => {
    let attempts = 0;
    while (true) {
      try {
        return await fetch(url2, requestInit);
      } catch (error) {
        attempts++;
        const retryDelayInSeconds = getRetryDelay(attempts);
        if (retryDelayInSeconds === null) {
          throw error;
        }
        console.error("Retrying failed fetch. Error:", error);
        if (!Number.isFinite(retryDelayInSeconds) || retryDelayInSeconds < 0) {
          throw new TypeError("Retry delay must be a non-negative finite number.");
        }
        if (retryDelayInSeconds > 0) {
          await new Promise((resolve) => setTimeout(resolve, 1e3 * retryDelayInSeconds));
        }
      }
    }
  };
  var computeRationalApproximation = (x, maxDenominator) => {
    const sign = x < 0 ? -1 : 1;
    x = Math.abs(x);
    let prevNumerator = 0, prevDenominator = 1;
    let currNumerator = 1, currDenominator = 0;
    let remainder = x;
    while (true) {
      const integer = Math.floor(remainder);
      const nextNumerator = integer * currNumerator + prevNumerator;
      const nextDenominator = integer * currDenominator + prevDenominator;
      if (nextDenominator > maxDenominator) {
        return {
          numerator: sign * currNumerator,
          denominator: currDenominator
        };
      }
      prevNumerator = currNumerator;
      prevDenominator = currDenominator;
      currNumerator = nextNumerator;
      currDenominator = nextDenominator;
      remainder = 1 / (remainder - integer);
      if (!isFinite(remainder)) {
        break;
      }
    }
    return {
      numerator: sign * currNumerator,
      denominator: currDenominator
    };
  };
  var CallSerializer = class {
    constructor() {
      this.currentPromise = Promise.resolve();
    }
    call(fn) {
      return this.currentPromise = this.currentPromise.then(fn);
    }
  };
  var isSafariCache = null;
  var isSafari = () => {
    if (isSafariCache !== null) {
      return isSafariCache;
    }
    const result = !!(typeof navigator !== "undefined" && navigator.vendor?.match(/apple/i) && !navigator.userAgent?.match(/crios/i) && !navigator.userAgent?.match(/fxios/i) && !navigator.userAgent?.match(/Opera|OPT\//));
    isSafariCache = result;
    return result;
  };

  // src/custom-coder.ts
  var CustomVideoDecoder = class {
    /** Returns true iff the decoder can decode the given codec configuration. */
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    static supports(codec, config) {
      return false;
    }
  };
  var CustomAudioDecoder = class {
    /** Returns true iff the decoder can decode the given codec configuration. */
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    static supports(codec, config) {
      return false;
    }
  };
  var CustomVideoEncoder = class {
    /** Returns true iff the encoder can encode the given codec configuration. */
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    static supports(codec, config) {
      return false;
    }
  };
  var CustomAudioEncoder = class {
    /** Returns true iff the encoder can encode the given codec configuration. */
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    static supports(codec, config) {
      return false;
    }
  };
  var customVideoDecoders = [];
  var customAudioDecoders = [];
  var customVideoEncoders = [];
  var customAudioEncoders = [];
  var registerDecoder = (decoder) => {
    if (decoder.prototype instanceof CustomVideoDecoder) {
      const casted = decoder;
      if (customVideoDecoders.includes(casted)) {
        console.warn("Video decoder already registered.");
        return;
      }
      customVideoDecoders.push(casted);
    } else if (decoder.prototype instanceof CustomAudioDecoder) {
      const casted = decoder;
      if (customAudioDecoders.includes(casted)) {
        console.warn("Audio decoder already registered.");
        return;
      }
      customAudioDecoders.push(casted);
    } else {
      throw new TypeError("Decoder must be a CustomVideoDecoder or CustomAudioDecoder.");
    }
  };
  var registerEncoder = (encoder) => {
    if (encoder.prototype instanceof CustomVideoEncoder) {
      const casted = encoder;
      if (customVideoEncoders.includes(casted)) {
        console.warn("Video encoder already registered.");
        return;
      }
      customVideoEncoders.push(casted);
    } else if (encoder.prototype instanceof CustomAudioEncoder) {
      const casted = encoder;
      if (customAudioEncoders.includes(casted)) {
        console.warn("Audio encoder already registered.");
        return;
      }
      customAudioEncoders.push(casted);
    } else {
      throw new TypeError("Encoder must be a CustomVideoEncoder or CustomAudioEncoder.");
    }
  };

  // src/codec.ts
  var VIDEO_CODECS = [
    "avc",
    "hevc",
    "vp9",
    "av1",
    "vp8"
  ];
  var PCM_AUDIO_CODECS = [
    "pcm-s16",
    // We don't prefix 'le' so we're compatible with the WebCodecs-registered PCM codec strings
    "pcm-s16be",
    "pcm-s24",
    "pcm-s24be",
    "pcm-s32",
    "pcm-s32be",
    "pcm-f32",
    "pcm-f32be",
    "pcm-f64",
    "pcm-f64be",
    "pcm-u8",
    "pcm-s8",
    "ulaw",
    "alaw"
  ];
  var NON_PCM_AUDIO_CODECS = [
    "aac",
    "opus",
    "mp3",
    "vorbis",
    "flac"
  ];
  var AUDIO_CODECS = [
    ...NON_PCM_AUDIO_CODECS,
    ...PCM_AUDIO_CODECS
  ];
  var SUBTITLE_CODECS = [
    "webvtt"
  ];
  var AVC_LEVEL_TABLE = [
    { maxMacroblocks: 99, maxBitrate: 64e3, level: 10 },
    // Level 1
    { maxMacroblocks: 396, maxBitrate: 192e3, level: 11 },
    // Level 1.1
    { maxMacroblocks: 396, maxBitrate: 384e3, level: 12 },
    // Level 1.2
    { maxMacroblocks: 396, maxBitrate: 768e3, level: 13 },
    // Level 1.3
    { maxMacroblocks: 396, maxBitrate: 2e6, level: 20 },
    // Level 2
    { maxMacroblocks: 792, maxBitrate: 4e6, level: 21 },
    // Level 2.1
    { maxMacroblocks: 1620, maxBitrate: 4e6, level: 22 },
    // Level 2.2
    { maxMacroblocks: 1620, maxBitrate: 1e7, level: 30 },
    // Level 3
    { maxMacroblocks: 3600, maxBitrate: 14e6, level: 31 },
    // Level 3.1
    { maxMacroblocks: 5120, maxBitrate: 2e7, level: 32 },
    // Level 3.2
    { maxMacroblocks: 8192, maxBitrate: 2e7, level: 40 },
    // Level 4
    { maxMacroblocks: 8192, maxBitrate: 5e7, level: 41 },
    // Level 4.1
    { maxMacroblocks: 8704, maxBitrate: 5e7, level: 42 },
    // Level 4.2
    { maxMacroblocks: 22080, maxBitrate: 135e6, level: 50 },
    // Level 5
    { maxMacroblocks: 36864, maxBitrate: 24e7, level: 51 },
    // Level 5.1
    { maxMacroblocks: 36864, maxBitrate: 24e7, level: 52 },
    // Level 5.2
    { maxMacroblocks: 139264, maxBitrate: 24e7, level: 60 },
    // Level 6
    { maxMacroblocks: 139264, maxBitrate: 48e7, level: 61 },
    // Level 6.1
    { maxMacroblocks: 139264, maxBitrate: 8e8, level: 62 }
    // Level 6.2
  ];
  var HEVC_LEVEL_TABLE = [
    { maxPictureSize: 36864, maxBitrate: 128e3, tier: "L", level: 30 },
    // Level 1 (Low Tier)
    { maxPictureSize: 122880, maxBitrate: 15e5, tier: "L", level: 60 },
    // Level 2 (Low Tier)
    { maxPictureSize: 245760, maxBitrate: 3e6, tier: "L", level: 63 },
    // Level 2.1 (Low Tier)
    { maxPictureSize: 552960, maxBitrate: 6e6, tier: "L", level: 90 },
    // Level 3 (Low Tier)
    { maxPictureSize: 983040, maxBitrate: 1e7, tier: "L", level: 93 },
    // Level 3.1 (Low Tier)
    { maxPictureSize: 2228224, maxBitrate: 12e6, tier: "L", level: 120 },
    // Level 4 (Low Tier)
    { maxPictureSize: 2228224, maxBitrate: 3e7, tier: "H", level: 120 },
    // Level 4 (High Tier)
    { maxPictureSize: 2228224, maxBitrate: 2e7, tier: "L", level: 123 },
    // Level 4.1 (Low Tier)
    { maxPictureSize: 2228224, maxBitrate: 5e7, tier: "H", level: 123 },
    // Level 4.1 (High Tier)
    { maxPictureSize: 8912896, maxBitrate: 25e6, tier: "L", level: 150 },
    // Level 5 (Low Tier)
    { maxPictureSize: 8912896, maxBitrate: 1e8, tier: "H", level: 150 },
    // Level 5 (High Tier)
    { maxPictureSize: 8912896, maxBitrate: 4e7, tier: "L", level: 153 },
    // Level 5.1 (Low Tier)
    { maxPictureSize: 8912896, maxBitrate: 16e7, tier: "H", level: 153 },
    // Level 5.1 (High Tier)
    { maxPictureSize: 8912896, maxBitrate: 6e7, tier: "L", level: 156 },
    // Level 5.2 (Low Tier)
    { maxPictureSize: 8912896, maxBitrate: 24e7, tier: "H", level: 156 },
    // Level 5.2 (High Tier)
    { maxPictureSize: 35651584, maxBitrate: 6e7, tier: "L", level: 180 },
    // Level 6 (Low Tier)
    { maxPictureSize: 35651584, maxBitrate: 24e7, tier: "H", level: 180 },
    // Level 6 (High Tier)
    { maxPictureSize: 35651584, maxBitrate: 12e7, tier: "L", level: 183 },
    // Level 6.1 (Low Tier)
    { maxPictureSize: 35651584, maxBitrate: 48e7, tier: "H", level: 183 },
    // Level 6.1 (High Tier)
    { maxPictureSize: 35651584, maxBitrate: 24e7, tier: "L", level: 186 },
    // Level 6.2 (Low Tier)
    { maxPictureSize: 35651584, maxBitrate: 8e8, tier: "H", level: 186 }
    // Level 6.2 (High Tier)
  ];
  var VP9_LEVEL_TABLE = [
    { maxPictureSize: 36864, maxBitrate: 2e5, level: 10 },
    // Level 1
    { maxPictureSize: 73728, maxBitrate: 8e5, level: 11 },
    // Level 1.1
    { maxPictureSize: 122880, maxBitrate: 18e5, level: 20 },
    // Level 2
    { maxPictureSize: 245760, maxBitrate: 36e5, level: 21 },
    // Level 2.1
    { maxPictureSize: 552960, maxBitrate: 72e5, level: 30 },
    // Level 3
    { maxPictureSize: 983040, maxBitrate: 12e6, level: 31 },
    // Level 3.1
    { maxPictureSize: 2228224, maxBitrate: 18e6, level: 40 },
    // Level 4
    { maxPictureSize: 2228224, maxBitrate: 3e7, level: 41 },
    // Level 4.1
    { maxPictureSize: 8912896, maxBitrate: 6e7, level: 50 },
    // Level 5
    { maxPictureSize: 8912896, maxBitrate: 12e7, level: 51 },
    // Level 5.1
    { maxPictureSize: 8912896, maxBitrate: 18e7, level: 52 },
    // Level 5.2
    { maxPictureSize: 35651584, maxBitrate: 18e7, level: 60 },
    // Level 6
    { maxPictureSize: 35651584, maxBitrate: 24e7, level: 61 },
    // Level 6.1
    { maxPictureSize: 35651584, maxBitrate: 48e7, level: 62 }
    // Level 6.2
  ];
  var AV1_LEVEL_TABLE = [
    { maxPictureSize: 147456, maxBitrate: 15e5, tier: "M", level: 0 },
    // Level 2.0 (Main Tier)
    { maxPictureSize: 278784, maxBitrate: 3e6, tier: "M", level: 1 },
    // Level 2.1 (Main Tier)
    { maxPictureSize: 665856, maxBitrate: 6e6, tier: "M", level: 4 },
    // Level 3.0 (Main Tier)
    { maxPictureSize: 1065024, maxBitrate: 1e7, tier: "M", level: 5 },
    // Level 3.1 (Main Tier)
    { maxPictureSize: 2359296, maxBitrate: 12e6, tier: "M", level: 8 },
    // Level 4.0 (Main Tier)
    { maxPictureSize: 2359296, maxBitrate: 3e7, tier: "H", level: 8 },
    // Level 4.0 (High Tier)
    { maxPictureSize: 2359296, maxBitrate: 2e7, tier: "M", level: 9 },
    // Level 4.1 (Main Tier)
    { maxPictureSize: 2359296, maxBitrate: 5e7, tier: "H", level: 9 },
    // Level 4.1 (High Tier)
    { maxPictureSize: 8912896, maxBitrate: 3e7, tier: "M", level: 12 },
    // Level 5.0 (Main Tier)
    { maxPictureSize: 8912896, maxBitrate: 1e8, tier: "H", level: 12 },
    // Level 5.0 (High Tier)
    { maxPictureSize: 8912896, maxBitrate: 4e7, tier: "M", level: 13 },
    // Level 5.1 (Main Tier)
    { maxPictureSize: 8912896, maxBitrate: 16e7, tier: "H", level: 13 },
    // Level 5.1 (High Tier)
    { maxPictureSize: 8912896, maxBitrate: 6e7, tier: "M", level: 14 },
    // Level 5.2 (Main Tier)
    { maxPictureSize: 8912896, maxBitrate: 24e7, tier: "H", level: 14 },
    // Level 5.2 (High Tier)
    { maxPictureSize: 35651584, maxBitrate: 6e7, tier: "M", level: 15 },
    // Level 5.3 (Main Tier)
    { maxPictureSize: 35651584, maxBitrate: 24e7, tier: "H", level: 15 },
    // Level 5.3 (High Tier)
    { maxPictureSize: 35651584, maxBitrate: 6e7, tier: "M", level: 16 },
    // Level 6.0 (Main Tier)
    { maxPictureSize: 35651584, maxBitrate: 24e7, tier: "H", level: 16 },
    // Level 6.0 (High Tier)
    { maxPictureSize: 35651584, maxBitrate: 1e8, tier: "M", level: 17 },
    // Level 6.1 (Main Tier)
    { maxPictureSize: 35651584, maxBitrate: 48e7, tier: "H", level: 17 },
    // Level 6.1 (High Tier)
    { maxPictureSize: 35651584, maxBitrate: 16e7, tier: "M", level: 18 },
    // Level 6.2 (Main Tier)
    { maxPictureSize: 35651584, maxBitrate: 8e8, tier: "H", level: 18 },
    // Level 6.2 (High Tier)
    { maxPictureSize: 35651584, maxBitrate: 16e7, tier: "M", level: 19 },
    // Level 6.3 (Main Tier)
    { maxPictureSize: 35651584, maxBitrate: 8e8, tier: "H", level: 19 }
    // Level 6.3 (High Tier)
  ];
  var VP9_DEFAULT_SUFFIX = ".01.01.01.01.00";
  var AV1_DEFAULT_SUFFIX = ".0.110.01.01.01.0";
  var buildVideoCodecString = (codec, width, height, bitrate) => {
    if (codec === "avc") {
      const profileIndication = 100;
      const totalMacroblocks = Math.ceil(width / 16) * Math.ceil(height / 16);
      const levelInfo = AVC_LEVEL_TABLE.find(
        (level) => totalMacroblocks <= level.maxMacroblocks && bitrate <= level.maxBitrate
      ) ?? last(AVC_LEVEL_TABLE);
      const levelIndication = levelInfo ? levelInfo.level : 0;
      const hexProfileIndication = profileIndication.toString(16).padStart(2, "0");
      const hexProfileCompatibility = "00";
      const hexLevelIndication = levelIndication.toString(16).padStart(2, "0");
      return `avc1.${hexProfileIndication}${hexProfileCompatibility}${hexLevelIndication}`;
    } else if (codec === "hevc") {
      const profilePrefix = "";
      const profileIdc = 1;
      const compatibilityFlags = "6";
      const pictureSize = width * height;
      const levelInfo = HEVC_LEVEL_TABLE.find(
        (level) => pictureSize <= level.maxPictureSize && bitrate <= level.maxBitrate
      ) ?? last(HEVC_LEVEL_TABLE);
      const constraintFlags = "B0";
      return `hev1.${profilePrefix}${profileIdc}.${compatibilityFlags}.${levelInfo.tier}${levelInfo.level}.${constraintFlags}`;
    } else if (codec === "vp8") {
      return "vp8";
    } else if (codec === "vp9") {
      const profile = "00";
      const pictureSize = width * height;
      const levelInfo = VP9_LEVEL_TABLE.find(
        (level) => pictureSize <= level.maxPictureSize && bitrate <= level.maxBitrate
      ) ?? last(VP9_LEVEL_TABLE);
      const bitDepth = "08";
      return `vp09.${profile}.${levelInfo.level.toString().padStart(2, "0")}.${bitDepth}`;
    } else if (codec === "av1") {
      const profile = 0;
      const pictureSize = width * height;
      const levelInfo = AV1_LEVEL_TABLE.find(
        (level2) => pictureSize <= level2.maxPictureSize && bitrate <= level2.maxBitrate
      ) ?? last(AV1_LEVEL_TABLE);
      const level = levelInfo.level.toString().padStart(2, "0");
      const bitDepth = "08";
      return `av01.${profile}.${level}${levelInfo.tier}.${bitDepth}`;
    }
    throw new TypeError(`Unhandled codec '${codec}'.`);
  };
  var generateVp9CodecConfigurationFromCodecString = (codecString) => {
    const parts = codecString.split(".");
    const profile = Number(parts[1]);
    const level = Number(parts[2]);
    const bitDepth = Number(parts[3]);
    const chromaSubsampling = parts[4] ? Number(parts[4]) : 1;
    return [
      1,
      1,
      profile,
      2,
      1,
      level,
      3,
      1,
      bitDepth,
      4,
      1,
      chromaSubsampling
    ];
  };
  var generateAv1CodecConfigurationFromCodecString = (codecString) => {
    const parts = codecString.split(".");
    const marker = 1;
    const version = 1;
    const firstByte = (marker << 7) + version;
    const profile = Number(parts[1]);
    const levelAndTier = parts[2];
    const level = Number(levelAndTier.slice(0, -1));
    const secondByte = (profile << 5) + level;
    const tier = levelAndTier.slice(-1) === "H" ? 1 : 0;
    const bitDepth = Number(parts[3]);
    const highBitDepth = bitDepth === 8 ? 0 : 1;
    const twelveBit = 0;
    const monochrome = parts[4] ? Number(parts[4]) : 0;
    const chromaSubsamplingX = parts[5] ? Number(parts[5][0]) : 1;
    const chromaSubsamplingY = parts[5] ? Number(parts[5][1]) : 1;
    const chromaSamplePosition = parts[5] ? Number(parts[5][2]) : 0;
    const thirdByte = (tier << 7) + (highBitDepth << 6) + (twelveBit << 5) + (monochrome << 4) + (chromaSubsamplingX << 3) + (chromaSubsamplingY << 2) + chromaSamplePosition;
    const initialPresentationDelayPresent = 0;
    const fourthByte = initialPresentationDelayPresent;
    return [firstByte, secondByte, thirdByte, fourthByte];
  };
  var extractVideoCodecString = (trackInfo) => {
    const { codec, codecDescription, colorSpace, avcCodecInfo, hevcCodecInfo, vp9CodecInfo, av1CodecInfo } = trackInfo;
    if (codec === "avc") {
      if (avcCodecInfo) {
        const bytes2 = new Uint8Array([
          avcCodecInfo.avcProfileIndication,
          avcCodecInfo.profileCompatibility,
          avcCodecInfo.avcLevelIndication
        ]);
        return `avc1.${bytesToHexString(bytes2)}`;
      }
      if (!codecDescription || codecDescription.byteLength < 4) {
        throw new TypeError("AVC decoder description is not provided or is not at least 4 bytes long.");
      }
      return `avc1.${bytesToHexString(codecDescription.subarray(1, 4))}`;
    } else if (codec === "hevc") {
      let generalProfileSpace;
      let generalProfileIdc;
      let compatibilityFlags;
      let generalTierFlag;
      let generalLevelIdc;
      let constraintFlags;
      if (hevcCodecInfo) {
        generalProfileSpace = hevcCodecInfo.generalProfileSpace;
        generalProfileIdc = hevcCodecInfo.generalProfileIdc;
        compatibilityFlags = reverseBitsU32(hevcCodecInfo.generalProfileCompatibilityFlags);
        generalTierFlag = hevcCodecInfo.generalTierFlag;
        generalLevelIdc = hevcCodecInfo.generalLevelIdc;
        constraintFlags = [...hevcCodecInfo.generalConstraintIndicatorFlags];
      } else {
        if (!codecDescription || codecDescription.byteLength < 23) {
          throw new TypeError("HEVC decoder description is not provided or is not at least 23 bytes long.");
        }
        const view2 = toDataView(codecDescription);
        const profileByte = view2.getUint8(1);
        generalProfileSpace = profileByte >> 6 & 3;
        generalProfileIdc = profileByte & 31;
        compatibilityFlags = reverseBitsU32(view2.getUint32(2));
        generalTierFlag = profileByte >> 5 & 1;
        generalLevelIdc = view2.getUint8(12);
        constraintFlags = [];
        for (let i = 0; i < 6; i++) {
          constraintFlags.push(view2.getUint8(6 + i));
        }
      }
      let codecString = "hev1.";
      codecString += ["", "A", "B", "C"][generalProfileSpace] + generalProfileIdc;
      codecString += ".";
      codecString += compatibilityFlags.toString(16).toUpperCase();
      codecString += ".";
      codecString += generalTierFlag === 0 ? "L" : "H";
      codecString += generalLevelIdc;
      while (constraintFlags.length > 0 && constraintFlags[constraintFlags.length - 1] === 0) {
        constraintFlags.pop();
      }
      if (constraintFlags.length > 0) {
        codecString += ".";
        codecString += constraintFlags.map((x) => x.toString(16).toUpperCase()).join(".");
      }
      return codecString;
    } else if (codec === "vp8") {
      return "vp8";
    } else if (codec === "vp9") {
      if (!vp9CodecInfo) {
        const pictureSize = trackInfo.width * trackInfo.height;
        let level2 = last(VP9_LEVEL_TABLE).level;
        for (const entry of VP9_LEVEL_TABLE) {
          if (pictureSize <= entry.maxPictureSize) {
            level2 = entry.level;
            break;
          }
        }
        return `vp09.00.${level2.toString().padStart(2, "0")}.08`;
      }
      const profile = vp9CodecInfo.profile.toString().padStart(2, "0");
      const level = vp9CodecInfo.level.toString().padStart(2, "0");
      const bitDepth = vp9CodecInfo.bitDepth.toString().padStart(2, "0");
      const chromaSubsampling = vp9CodecInfo.chromaSubsampling.toString().padStart(2, "0");
      const colourPrimaries = vp9CodecInfo.colourPrimaries.toString().padStart(2, "0");
      const transferCharacteristics = vp9CodecInfo.transferCharacteristics.toString().padStart(2, "0");
      const matrixCoefficients = vp9CodecInfo.matrixCoefficients.toString().padStart(2, "0");
      const videoFullRangeFlag = vp9CodecInfo.videoFullRangeFlag.toString().padStart(2, "0");
      let string = `vp09.${profile}.${level}.${bitDepth}.${chromaSubsampling}`;
      string += `.${colourPrimaries}.${transferCharacteristics}.${matrixCoefficients}.${videoFullRangeFlag}`;
      if (string.endsWith(VP9_DEFAULT_SUFFIX)) {
        string = string.slice(0, -VP9_DEFAULT_SUFFIX.length);
      }
      return string;
    } else if (codec === "av1") {
      if (!av1CodecInfo) {
        const pictureSize = trackInfo.width * trackInfo.height;
        let level2 = last(VP9_LEVEL_TABLE).level;
        for (const entry of VP9_LEVEL_TABLE) {
          if (pictureSize <= entry.maxPictureSize) {
            level2 = entry.level;
            break;
          }
        }
        return `av01.0.${level2.toString().padStart(2, "0")}M.08`;
      }
      const profile = av1CodecInfo.profile;
      const level = av1CodecInfo.level.toString().padStart(2, "0");
      const tier = av1CodecInfo.tier ? "H" : "M";
      const bitDepth = av1CodecInfo.bitDepth.toString().padStart(2, "0");
      const monochrome = av1CodecInfo.monochrome ? "1" : "0";
      const chromaSubsampling = 100 * av1CodecInfo.chromaSubsamplingX + 10 * av1CodecInfo.chromaSubsamplingY + 1 * (av1CodecInfo.chromaSubsamplingX && av1CodecInfo.chromaSubsamplingY ? av1CodecInfo.chromaSamplePosition : 0);
      const colorPrimaries = colorSpace?.primaries ? COLOR_PRIMARIES_MAP[colorSpace.primaries] : 1;
      const transferCharacteristics = colorSpace?.transfer ? TRANSFER_CHARACTERISTICS_MAP[colorSpace.transfer] : 1;
      const matrixCoefficients = colorSpace?.matrix ? MATRIX_COEFFICIENTS_MAP[colorSpace.matrix] : 1;
      const videoFullRangeFlag = colorSpace?.fullRange ? 1 : 0;
      let string = `av01.${profile}.${level}${tier}.${bitDepth}`;
      string += `.${monochrome}.${chromaSubsampling.toString().padStart(3, "0")}`;
      string += `.${colorPrimaries.toString().padStart(2, "0")}`;
      string += `.${transferCharacteristics.toString().padStart(2, "0")}`;
      string += `.${matrixCoefficients.toString().padStart(2, "0")}`;
      string += `.${videoFullRangeFlag}`;
      if (string.endsWith(AV1_DEFAULT_SUFFIX)) {
        string = string.slice(0, -AV1_DEFAULT_SUFFIX.length);
      }
      return string;
    }
    throw new TypeError(`Unhandled codec '${codec}'.`);
  };
  var buildAudioCodecString = (codec, numberOfChannels, sampleRate) => {
    if (codec === "aac") {
      if (numberOfChannels >= 2 && sampleRate <= 24e3) {
        return "mp4a.40.29";
      }
      if (sampleRate <= 24e3) {
        return "mp4a.40.5";
      }
      return "mp4a.40.2";
    } else if (codec === "mp3") {
      return "mp3";
    } else if (codec === "opus") {
      return "opus";
    } else if (codec === "vorbis") {
      return "vorbis";
    } else if (codec === "flac") {
      return "flac";
    } else if (PCM_AUDIO_CODECS.includes(codec)) {
      return codec;
    }
    throw new TypeError(`Unhandled codec '${codec}'.`);
  };
  var extractAudioCodecString = (trackInfo) => {
    const { codec, codecDescription, aacCodecInfo } = trackInfo;
    if (codec === "aac") {
      if (!aacCodecInfo) {
        throw new TypeError("AAC codec info must be provided.");
      }
      if (aacCodecInfo.isMpeg2) {
        return "mp4a.67";
      } else {
        const audioSpecificConfig = parseAacAudioSpecificConfig(codecDescription);
        return `mp4a.40.${audioSpecificConfig.objectType}`;
      }
    } else if (codec === "mp3") {
      return "mp3";
    } else if (codec === "opus") {
      return "opus";
    } else if (codec === "vorbis") {
      return "vorbis";
    } else if (codec === "flac") {
      return "flac";
    } else if (codec && PCM_AUDIO_CODECS.includes(codec)) {
      return codec;
    }
    throw new TypeError(`Unhandled codec '${codec}'.`);
  };
  var parseAacAudioSpecificConfig = (bytes2) => {
    if (!bytes2 || bytes2.byteLength < 2) {
      throw new TypeError("AAC description must be at least 2 bytes long.");
    }
    const bitstream = new Bitstream(bytes2);
    let objectType = bitstream.readBits(5);
    if (objectType === 31) {
      objectType = 32 + bitstream.readBits(6);
    }
    const frequencyIndex = bitstream.readBits(4);
    let sampleRate = null;
    if (frequencyIndex === 15) {
      sampleRate = bitstream.readBits(24);
    } else {
      const freqTable = [
        96e3,
        88200,
        64e3,
        48e3,
        44100,
        32e3,
        24e3,
        22050,
        16e3,
        12e3,
        11025,
        8e3,
        7350
      ];
      if (frequencyIndex < freqTable.length) {
        sampleRate = freqTable[frequencyIndex];
      }
    }
    const channelConfiguration = bitstream.readBits(4);
    let numberOfChannels = null;
    if (channelConfiguration >= 1 && channelConfiguration <= 7) {
      const channelMap = {
        1: 1,
        2: 2,
        3: 3,
        4: 4,
        5: 5,
        6: 6,
        7: 8
      };
      numberOfChannels = channelMap[channelConfiguration];
    }
    return {
      objectType,
      frequencyIndex,
      sampleRate,
      channelConfiguration,
      numberOfChannels
    };
  };
  var OPUS_INTERNAL_SAMPLE_RATE = 48e3;
  var PCM_CODEC_REGEX = /^pcm-([usf])(\d+)+(be)?$/;
  var parsePcmCodec = (codec) => {
    assert(PCM_AUDIO_CODECS.includes(codec));
    if (codec === "ulaw") {
      return { dataType: "ulaw", sampleSize: 1, littleEndian: true, silentValue: 255 };
    } else if (codec === "alaw") {
      return { dataType: "alaw", sampleSize: 1, littleEndian: true, silentValue: 213 };
    }
    const match = PCM_CODEC_REGEX.exec(codec);
    assert(match);
    let dataType;
    if (match[1] === "u") {
      dataType = "unsigned";
    } else if (match[1] === "s") {
      dataType = "signed";
    } else {
      dataType = "float";
    }
    const sampleSize = Number(match[2]) / 8;
    const littleEndian = match[3] !== "be";
    const silentValue = codec === "pcm-u8" ? 2 ** 7 : 0;
    return { dataType, sampleSize, littleEndian, silentValue };
  };
  var inferCodecFromCodecString = (codecString) => {
    if (codecString.startsWith("avc1") || codecString.startsWith("avc3")) {
      return "avc";
    } else if (codecString.startsWith("hev1") || codecString.startsWith("hvc1")) {
      return "hevc";
    } else if (codecString === "vp8") {
      return "vp8";
    } else if (codecString.startsWith("vp09")) {
      return "vp9";
    } else if (codecString.startsWith("av01")) {
      return "av1";
    }
    if (codecString.startsWith("mp4a.40") || codecString === "mp4a.67") {
      return "aac";
    } else if (codecString === "mp3" || codecString === "mp4a.69" || codecString === "mp4a.6B" || codecString === "mp4a.6b") {
      return "mp3";
    } else if (codecString === "opus") {
      return "opus";
    } else if (codecString === "vorbis") {
      return "vorbis";
    } else if (codecString === "flac") {
      return "flac";
    } else if (codecString === "ulaw") {
      return "ulaw";
    } else if (codecString === "alaw") {
      return "alaw";
    } else if (PCM_CODEC_REGEX.test(codecString)) {
      return codecString;
    }
    if (codecString === "webvtt") {
      return "webvtt";
    }
    return null;
  };
  var getVideoEncoderConfigExtension = (codec) => {
    if (codec === "avc") {
      return {
        avc: {
          format: "avc"
          // Ensure the format is not Annex B
        }
      };
    } else if (codec === "hevc") {
      return {
        hevc: {
          format: "hevc"
          // Ensure the format is not Annex B
        }
      };
    }
    return {};
  };
  var getAudioEncoderConfigExtension = (codec) => {
    if (codec === "aac") {
      return {
        aac: {
          format: "aac"
          // Ensure the format is not ADTS
        }
      };
    } else if (codec === "opus") {
      return {
        opus: {
          format: "opus"
        }
      };
    }
    return {};
  };
  var Quality = class {
    /** @internal */
    constructor(factor) {
      this._factor = factor;
    }
    /** @internal */
    _toVideoBitrate(codec, width, height) {
      const pixels = width * height;
      const codecEfficiencyFactors = {
        avc: 1,
        // H.264/AVC (baseline)
        hevc: 0.6,
        // H.265/HEVC (~40% more efficient than AVC)
        vp9: 0.6,
        // Similar to HEVC
        av1: 0.4,
        // ~60% more efficient than AVC
        vp8: 1.2
        // Slightly less efficient than AVC
      };
      const referencePixels = 1920 * 1080;
      const referenceBitrate = 3e6;
      const scaleFactor = Math.pow(pixels / referencePixels, 0.95);
      const baseBitrate = referenceBitrate * scaleFactor;
      const codecAdjustedBitrate = baseBitrate * codecEfficiencyFactors[codec];
      const finalBitrate = codecAdjustedBitrate * this._factor;
      return Math.ceil(finalBitrate / 1e3) * 1e3;
    }
    /** @internal */
    _toAudioBitrate(codec) {
      if (PCM_AUDIO_CODECS.includes(codec) || codec === "flac") {
        return void 0;
      }
      const baseRates = {
        aac: 128e3,
        // 128kbps base for AAC
        opus: 64e3,
        // 64kbps base for Opus
        mp3: 16e4,
        // 160kbps base for MP3
        vorbis: 64e3
        // 64kbps base for Vorbis
      };
      const baseBitrate = baseRates[codec];
      if (!baseBitrate) {
        throw new Error(`Unhandled codec: ${codec}`);
      }
      let finalBitrate = baseBitrate * this._factor;
      if (codec === "aac") {
        const validRates = [96e3, 128e3, 16e4, 192e3];
        finalBitrate = validRates.reduce(
          (prev, curr) => Math.abs(curr - finalBitrate) < Math.abs(prev - finalBitrate) ? curr : prev
        );
      } else if (codec === "opus" || codec === "vorbis") {
        finalBitrate = Math.max(6e3, finalBitrate);
      } else if (codec === "mp3") {
        const validRates = [
          8e3,
          16e3,
          24e3,
          32e3,
          4e4,
          48e3,
          64e3,
          8e4,
          96e3,
          112e3,
          128e3,
          16e4,
          192e3,
          224e3,
          256e3,
          32e4
        ];
        finalBitrate = validRates.reduce(
          (prev, curr) => Math.abs(curr - finalBitrate) < Math.abs(prev - finalBitrate) ? curr : prev
        );
      }
      return Math.round(finalBitrate / 1e3) * 1e3;
    }
  };
  var QUALITY_VERY_LOW = new Quality(0.3);
  var QUALITY_LOW = new Quality(0.6);
  var QUALITY_MEDIUM = new Quality(1);
  var QUALITY_HIGH = new Quality(2);
  var QUALITY_VERY_HIGH = new Quality(4);
  var VALID_VIDEO_CODEC_STRING_PREFIXES = ["avc1", "avc3", "hev1", "hvc1", "vp8", "vp09", "av01"];
  var AVC_CODEC_STRING_REGEX = /^(avc1|avc3)\.[0-9a-fA-F]{6}$/;
  var HEVC_CODEC_STRING_REGEX = /^(hev1|hvc1)\.(?:[ABC]?\d+)\.[0-9a-fA-F]{1,8}\.[LH]\d+(?:\.[0-9a-fA-F]{1,2}){0,6}$/;
  var VP9_CODEC_STRING_REGEX = /^vp09(?:\.\d{2}){3}(?:(?:\.\d{2}){5})?$/;
  var AV1_CODEC_STRING_REGEX = /^av01\.\d\.\d{2}[MH]\.\d{2}(?:\.\d\.\d{3}\.\d{2}\.\d{2}\.\d{2}\.\d)?$/;
  var validateVideoChunkMetadata = (metadata) => {
    if (!metadata) {
      throw new TypeError("Video chunk metadata must be provided.");
    }
    if (typeof metadata !== "object") {
      throw new TypeError("Video chunk metadata must be an object.");
    }
    if (!metadata.decoderConfig) {
      throw new TypeError("Video chunk metadata must include a decoder configuration.");
    }
    if (typeof metadata.decoderConfig !== "object") {
      throw new TypeError("Video chunk metadata decoder configuration must be an object.");
    }
    if (typeof metadata.decoderConfig.codec !== "string") {
      throw new TypeError("Video chunk metadata decoder configuration must specify a codec string.");
    }
    if (!VALID_VIDEO_CODEC_STRING_PREFIXES.some((prefix) => metadata.decoderConfig.codec.startsWith(prefix))) {
      throw new TypeError(
        "Video chunk metadata decoder configuration codec string must be a valid video codec string as specified in the WebCodecs Codec Registry."
      );
    }
    if (!Number.isInteger(metadata.decoderConfig.codedWidth) || metadata.decoderConfig.codedWidth <= 0) {
      throw new TypeError(
        "Video chunk metadata decoder configuration must specify a valid codedWidth (positive integer)."
      );
    }
    if (!Number.isInteger(metadata.decoderConfig.codedHeight) || metadata.decoderConfig.codedHeight <= 0) {
      throw new TypeError(
        "Video chunk metadata decoder configuration must specify a valid codedHeight (positive integer)."
      );
    }
    if (metadata.decoderConfig.description !== void 0) {
      if (!isAllowSharedBufferSource(metadata.decoderConfig.description)) {
        throw new TypeError(
          "Video chunk metadata decoder configuration description, when defined, must be an ArrayBuffer or an ArrayBuffer view."
        );
      }
    }
    if (metadata.decoderConfig.colorSpace !== void 0) {
      const { colorSpace } = metadata.decoderConfig;
      if (typeof colorSpace !== "object") {
        throw new TypeError(
          "Video chunk metadata decoder configuration colorSpace, when provided, must be an object."
        );
      }
      const primariesValues = Object.keys(COLOR_PRIMARIES_MAP);
      if (colorSpace.primaries != null && !primariesValues.includes(colorSpace.primaries)) {
        throw new TypeError(
          `Video chunk metadata decoder configuration colorSpace primaries, when defined, must be one of ${primariesValues.join(", ")}.`
        );
      }
      const transferValues = Object.keys(TRANSFER_CHARACTERISTICS_MAP);
      if (colorSpace.transfer != null && !transferValues.includes(colorSpace.transfer)) {
        throw new TypeError(
          `Video chunk metadata decoder configuration colorSpace transfer, when defined, must be one of ${transferValues.join(", ")}.`
        );
      }
      const matrixValues = Object.keys(MATRIX_COEFFICIENTS_MAP);
      if (colorSpace.matrix != null && !matrixValues.includes(colorSpace.matrix)) {
        throw new TypeError(
          `Video chunk metadata decoder configuration colorSpace matrix, when defined, must be one of ${matrixValues.join(", ")}.`
        );
      }
      if (colorSpace.fullRange != null && typeof colorSpace.fullRange !== "boolean") {
        throw new TypeError(
          "Video chunk metadata decoder configuration colorSpace fullRange, when defined, must be a boolean."
        );
      }
    }
    if (metadata.decoderConfig.codec.startsWith("avc1") || metadata.decoderConfig.codec.startsWith("avc3")) {
      if (!AVC_CODEC_STRING_REGEX.test(metadata.decoderConfig.codec)) {
        throw new TypeError(
          "Video chunk metadata decoder configuration codec string for AVC must be a valid AVC codec string as specified in Section 3.4 of RFC 6381."
        );
      }
    } else if (metadata.decoderConfig.codec.startsWith("hev1") || metadata.decoderConfig.codec.startsWith("hvc1")) {
      if (!HEVC_CODEC_STRING_REGEX.test(metadata.decoderConfig.codec)) {
        throw new TypeError(
          "Video chunk metadata decoder configuration codec string for HEVC must be a valid HEVC codec string as specified in Section E.3 of ISO 14496-15."
        );
      }
    } else if (metadata.decoderConfig.codec.startsWith("vp8")) {
      if (metadata.decoderConfig.codec !== "vp8") {
        throw new TypeError('Video chunk metadata decoder configuration codec string for VP8 must be "vp8".');
      }
    } else if (metadata.decoderConfig.codec.startsWith("vp09")) {
      if (!VP9_CODEC_STRING_REGEX.test(metadata.decoderConfig.codec)) {
        throw new TypeError(
          'Video chunk metadata decoder configuration codec string for VP9 must be a valid VP9 codec string as specified in Section "Codecs Parameter String" of https://www.webmproject.org/vp9/mp4/.'
        );
      }
    } else if (metadata.decoderConfig.codec.startsWith("av01")) {
      if (!AV1_CODEC_STRING_REGEX.test(metadata.decoderConfig.codec)) {
        throw new TypeError(
          'Video chunk metadata decoder configuration codec string for AV1 must be a valid AV1 codec string as specified in Section "Codecs Parameter String" of https://aomediacodec.github.io/av1-isobmff/.'
        );
      }
    }
  };
  var VALID_AUDIO_CODEC_STRING_PREFIXES = ["mp4a", "mp3", "opus", "vorbis", "flac", "ulaw", "alaw", "pcm"];
  var validateAudioChunkMetadata = (metadata) => {
    if (!metadata) {
      throw new TypeError("Audio chunk metadata must be provided.");
    }
    if (typeof metadata !== "object") {
      throw new TypeError("Audio chunk metadata must be an object.");
    }
    if (!metadata.decoderConfig) {
      throw new TypeError("Audio chunk metadata must include a decoder configuration.");
    }
    if (typeof metadata.decoderConfig !== "object") {
      throw new TypeError("Audio chunk metadata decoder configuration must be an object.");
    }
    if (typeof metadata.decoderConfig.codec !== "string") {
      throw new TypeError("Audio chunk metadata decoder configuration must specify a codec string.");
    }
    if (!VALID_AUDIO_CODEC_STRING_PREFIXES.some((prefix) => metadata.decoderConfig.codec.startsWith(prefix))) {
      throw new TypeError(
        "Audio chunk metadata decoder configuration codec string must be a valid audio codec string as specified in the WebCodecs Codec Registry."
      );
    }
    if (!Number.isInteger(metadata.decoderConfig.sampleRate) || metadata.decoderConfig.sampleRate <= 0) {
      throw new TypeError(
        "Audio chunk metadata decoder configuration must specify a valid sampleRate (positive integer)."
      );
    }
    if (!Number.isInteger(metadata.decoderConfig.numberOfChannels) || metadata.decoderConfig.numberOfChannels <= 0) {
      throw new TypeError(
        "Audio chunk metadata decoder configuration must specify a valid numberOfChannels (positive integer)."
      );
    }
    if (metadata.decoderConfig.description !== void 0) {
      if (!isAllowSharedBufferSource(metadata.decoderConfig.description)) {
        throw new TypeError(
          "Audio chunk metadata decoder configuration description, when defined, must be an ArrayBuffer or an ArrayBuffer view."
        );
      }
    }
    if (metadata.decoderConfig.codec.startsWith("mp4a") && metadata.decoderConfig.codec !== "mp4a.69" && metadata.decoderConfig.codec !== "mp4a.6B" && metadata.decoderConfig.codec !== "mp4a.6b") {
      const validStrings = ["mp4a.40.2", "mp4a.40.02", "mp4a.40.5", "mp4a.40.05", "mp4a.40.29", "mp4a.67"];
      if (!validStrings.includes(metadata.decoderConfig.codec)) {
        throw new TypeError(
          "Audio chunk metadata decoder configuration codec string for AAC must be a valid AAC codec string as specified in https://www.w3.org/TR/webcodecs-aac-codec-registration/."
        );
      }
      if (!metadata.decoderConfig.description) {
        throw new TypeError(
          "Audio chunk metadata decoder configuration for AAC must include a description, which is expected to be an AudioSpecificConfig as specified in ISO 14496-3."
        );
      }
    } else if (metadata.decoderConfig.codec.startsWith("mp3") || metadata.decoderConfig.codec.startsWith("mp4a")) {
      if (metadata.decoderConfig.codec !== "mp3" && metadata.decoderConfig.codec !== "mp4a.69" && metadata.decoderConfig.codec !== "mp4a.6B" && metadata.decoderConfig.codec !== "mp4a.6b") {
        throw new TypeError(
          'Audio chunk metadata decoder configuration codec string for MP3 must be "mp3", "mp4a.69" or "mp4a.6B".'
        );
      }
    } else if (metadata.decoderConfig.codec.startsWith("opus")) {
      if (metadata.decoderConfig.codec !== "opus") {
        throw new TypeError('Audio chunk metadata decoder configuration codec string for Opus must be "opus".');
      }
      if (metadata.decoderConfig.description && metadata.decoderConfig.description.byteLength < 18) {
        throw new TypeError(
          "Audio chunk metadata decoder configuration description, when specified, is expected to be an Identification Header as specified in Section 5.1 of RFC 7845."
        );
      }
    } else if (metadata.decoderConfig.codec.startsWith("vorbis")) {
      if (metadata.decoderConfig.codec !== "vorbis") {
        throw new TypeError('Audio chunk metadata decoder configuration codec string for Vorbis must be "vorbis".');
      }
      if (!metadata.decoderConfig.description) {
        throw new TypeError(
          "Audio chunk metadata decoder configuration for Vorbis must include a description, which is expected to adhere to the format described in https://www.w3.org/TR/webcodecs-vorbis-codec-registration/."
        );
      }
    } else if (metadata.decoderConfig.codec.startsWith("flac")) {
      if (metadata.decoderConfig.codec !== "flac") {
        throw new TypeError('Audio chunk metadata decoder configuration codec string for FLAC must be "flac".');
      }
      const minDescriptionSize = 4 + 4 + 34;
      if (!metadata.decoderConfig.description || metadata.decoderConfig.description.byteLength < minDescriptionSize) {
        throw new TypeError(
          "Audio chunk metadata decoder configuration for FLAC must include a description, which is expected to adhere to the format described in https://www.w3.org/TR/webcodecs-flac-codec-registration/."
        );
      }
    } else if (metadata.decoderConfig.codec.startsWith("pcm") || metadata.decoderConfig.codec.startsWith("ulaw") || metadata.decoderConfig.codec.startsWith("alaw")) {
      if (!PCM_AUDIO_CODECS.includes(metadata.decoderConfig.codec)) {
        throw new TypeError(
          `Audio chunk metadata decoder configuration codec string for PCM must be one of the supported PCM codecs (${PCM_AUDIO_CODECS.join(", ")}).`
        );
      }
    }
  };
  var validateSubtitleMetadata = (metadata) => {
    if (!metadata) {
      throw new TypeError("Subtitle metadata must be provided.");
    }
    if (typeof metadata !== "object") {
      throw new TypeError("Subtitle metadata must be an object.");
    }
    if (!metadata.config) {
      throw new TypeError("Subtitle metadata must include a config object.");
    }
    if (typeof metadata.config !== "object") {
      throw new TypeError("Subtitle metadata config must be an object.");
    }
    if (typeof metadata.config.description !== "string") {
      throw new TypeError("Subtitle metadata config description must be a string.");
    }
  };
  var canEncode = (codec) => {
    if (VIDEO_CODECS.includes(codec)) {
      return canEncodeVideo(codec);
    } else if (AUDIO_CODECS.includes(codec)) {
      return canEncodeAudio(codec);
    } else if (SUBTITLE_CODECS.includes(codec)) {
      return canEncodeSubtitles(codec);
    }
    throw new TypeError(`Unknown codec '${codec}'.`);
  };
  var canEncodeVideo = async (codec, { width = 1280, height = 720, bitrate = 1e6 } = {}) => {
    if (!VIDEO_CODECS.includes(codec)) {
      return false;
    }
    if (!Number.isInteger(width) || width <= 0) {
      throw new TypeError("width must be a positive integer.");
    }
    if (!Number.isInteger(height) || height <= 0) {
      throw new TypeError("height must be a positive integer.");
    }
    if (!(bitrate instanceof Quality) && (!Number.isInteger(bitrate) || bitrate <= 0)) {
      throw new TypeError("bitrate must be a positive integer or a quality.");
    }
    const resolvedBitrate = bitrate instanceof Quality ? bitrate._toVideoBitrate(codec, width, height) : bitrate;
    if (customVideoEncoders.length > 0) {
      const encoderConfig = {
        codec: buildVideoCodecString(
          codec,
          width,
          height,
          resolvedBitrate
        ),
        width,
        height,
        bitrate: resolvedBitrate,
        ...getVideoEncoderConfigExtension(codec)
      };
      if (customVideoEncoders.some((x) => x.supports(codec, encoderConfig))) {
        return true;
      }
    }
    if (typeof VideoEncoder === "undefined") {
      return false;
    }
    const support = await VideoEncoder.isConfigSupported({
      codec: buildVideoCodecString(codec, width, height, resolvedBitrate),
      width,
      height,
      bitrate: resolvedBitrate,
      ...getVideoEncoderConfigExtension(codec)
    });
    return support.supported === true;
  };
  var canEncodeAudio = async (codec, { numberOfChannels = 2, sampleRate = 48e3, bitrate = 128e3 } = {}) => {
    if (!AUDIO_CODECS.includes(codec)) {
      return false;
    }
    if (!Number.isInteger(numberOfChannels) || numberOfChannels <= 0) {
      throw new TypeError("numberOfChannels must be a positive integer.");
    }
    if (!Number.isInteger(sampleRate) || sampleRate <= 0) {
      throw new TypeError("sampleRate must be a positive integer.");
    }
    if (!(bitrate instanceof Quality) && (!Number.isInteger(bitrate) || bitrate <= 0)) {
      throw new TypeError("bitrate must be a positive integer.");
    }
    const resolvedBitrate = bitrate instanceof Quality ? bitrate._toAudioBitrate(codec) : bitrate;
    if (customAudioEncoders.length > 0) {
      const encoderConfig = {
        codec: buildAudioCodecString(
          codec,
          numberOfChannels,
          sampleRate
        ),
        numberOfChannels,
        sampleRate,
        bitrate: resolvedBitrate,
        ...getAudioEncoderConfigExtension(codec)
      };
      if (customAudioEncoders.some((x) => x.supports(codec, encoderConfig))) {
        return true;
      }
    }
    if (PCM_AUDIO_CODECS.includes(codec)) {
      return true;
    }
    if (typeof AudioEncoder === "undefined") {
      return false;
    }
    const support = await AudioEncoder.isConfigSupported({
      codec: buildAudioCodecString(codec, numberOfChannels, sampleRate),
      numberOfChannels,
      sampleRate,
      bitrate: resolvedBitrate,
      ...getAudioEncoderConfigExtension(codec)
    });
    return support.supported === true;
  };
  var canEncodeSubtitles = async (codec) => {
    if (!SUBTITLE_CODECS.includes(codec)) {
      return false;
    }
    return true;
  };
  var getEncodableCodecs = async () => {
    const [videoCodecs, audioCodecs, subtitleCodecs] = await Promise.all([
      getEncodableVideoCodecs(),
      getEncodableAudioCodecs(),
      getEncodableSubtitleCodecs()
    ]);
    return [...videoCodecs, ...audioCodecs, ...subtitleCodecs];
  };
  var getEncodableVideoCodecs = async (checkedCodecs = VIDEO_CODECS, options) => {
    const bools = await Promise.all(checkedCodecs.map((codec) => canEncodeVideo(codec, options)));
    return checkedCodecs.filter((_, i) => bools[i]);
  };
  var getEncodableAudioCodecs = async (checkedCodecs = AUDIO_CODECS, options) => {
    const bools = await Promise.all(checkedCodecs.map((codec) => canEncodeAudio(codec, options)));
    return checkedCodecs.filter((_, i) => bools[i]);
  };
  var getEncodableSubtitleCodecs = async (checkedCodecs = SUBTITLE_CODECS) => {
    const bools = await Promise.all(checkedCodecs.map(canEncodeSubtitles));
    return checkedCodecs.filter((_, i) => bools[i]);
  };
  var getFirstEncodableVideoCodec = async (checkedCodecs, options) => {
    for (const codec of checkedCodecs) {
      if (await canEncodeVideo(codec, options)) {
        return codec;
      }
    }
    return null;
  };
  var getFirstEncodableAudioCodec = async (checkedCodecs, options) => {
    for (const codec of checkedCodecs) {
      if (await canEncodeAudio(codec, options)) {
        return codec;
      }
    }
    return null;
  };
  var getFirstEncodableSubtitleCodec = async (checkedCodecs) => {
    for (const codec of checkedCodecs) {
      if (await canEncodeSubtitles(codec)) {
        return codec;
      }
    }
    return null;
  };

  // src/subtitles.ts
  var cueBlockHeaderRegex = /(?:(.+?)\n)?((?:\d{2}:)?\d{2}:\d{2}.\d{3})\s+-->\s+((?:\d{2}:)?\d{2}:\d{2}.\d{3})/g;
  var preambleStartRegex = /^WEBVTT(.|\n)*?\n{2}/;
  var inlineTimestampRegex = /<(?:(\d{2}):)?(\d{2}):(\d{2}).(\d{3})>/g;
  var SubtitleParser = class {
    constructor(options) {
      this.preambleText = null;
      this.preambleEmitted = false;
      this.options = options;
    }
    parse(text) {
      text = text.replaceAll("\r\n", "\n").replaceAll("\r", "\n");
      cueBlockHeaderRegex.lastIndex = 0;
      let match;
      if (!this.preambleText) {
        if (!preambleStartRegex.test(text)) {
          throw new Error("WebVTT preamble incorrect.");
        }
        match = cueBlockHeaderRegex.exec(text);
        const preamble = text.slice(0, match?.index ?? text.length).trimEnd();
        if (!preamble) {
          throw new Error("No WebVTT preamble provided.");
        }
        this.preambleText = preamble;
        if (match) {
          text = text.slice(match.index);
          cueBlockHeaderRegex.lastIndex = 0;
        }
      }
      while (match = cueBlockHeaderRegex.exec(text)) {
        const notes = text.slice(0, match.index);
        const cueIdentifier = match[1];
        const matchEnd = match.index + match[0].length;
        const bodyStart = text.indexOf("\n", matchEnd) + 1;
        const cueSettings = text.slice(matchEnd, bodyStart).trim();
        let bodyEnd = text.indexOf("\n\n", matchEnd);
        if (bodyEnd === -1) bodyEnd = text.length;
        const startTime = parseSubtitleTimestamp(match[2]);
        const endTime = parseSubtitleTimestamp(match[3]);
        const duration = endTime - startTime;
        const body = text.slice(bodyStart, bodyEnd).trim();
        text = text.slice(bodyEnd).trimStart();
        cueBlockHeaderRegex.lastIndex = 0;
        const cue = {
          timestamp: startTime / 1e3,
          duration: duration / 1e3,
          text: body,
          identifier: cueIdentifier,
          settings: cueSettings,
          notes
        };
        const meta = {};
        if (!this.preambleEmitted) {
          meta.config = {
            description: this.preambleText
          };
          this.preambleEmitted = true;
        }
        this.options.output(cue, meta);
      }
    }
  };
  var timestampRegex = /(?:(\d{2}):)?(\d{2}):(\d{2}).(\d{3})/;
  var parseSubtitleTimestamp = (string) => {
    const match = timestampRegex.exec(string);
    if (!match) throw new Error("Expected match.");
    return 60 * 60 * 1e3 * Number(match[1] || "0") + 60 * 1e3 * Number(match[2]) + 1e3 * Number(match[3]) + Number(match[4]);
  };
  var formatSubtitleTimestamp = (timestamp) => {
    const hours = Math.floor(timestamp / (60 * 60 * 1e3));
    const minutes = Math.floor(timestamp % (60 * 60 * 1e3) / (60 * 1e3));
    const seconds = Math.floor(timestamp % (60 * 1e3) / 1e3);
    const milliseconds = timestamp % 1e3;
    return hours.toString().padStart(2, "0") + ":" + minutes.toString().padStart(2, "0") + ":" + seconds.toString().padStart(2, "0") + "." + milliseconds.toString().padStart(3, "0");
  };

  // src/codec-data.ts
  var findNalUnitsInAnnexB = (packetData) => {
    const nalUnits = [];
    let i = 0;
    while (i < packetData.length) {
      let startCodePos = -1;
      let startCodeLength = 0;
      for (let j = i; j < packetData.length - 3; j++) {
        if (packetData[j] === 0 && packetData[j + 1] === 0 && packetData[j + 2] === 1) {
          startCodePos = j;
          startCodeLength = 3;
          break;
        }
        if (j < packetData.length - 4 && packetData[j] === 0 && packetData[j + 1] === 0 && packetData[j + 2] === 0 && packetData[j + 3] === 1) {
          startCodePos = j;
          startCodeLength = 4;
          break;
        }
      }
      if (startCodePos === -1) {
        break;
      }
      if (i > 0 && startCodePos > i) {
        const nalData = packetData.subarray(i, startCodePos);
        if (nalData.length > 0) {
          nalUnits.push(nalData);
        }
      }
      i = startCodePos + startCodeLength;
    }
    if (i < packetData.length) {
      const nalData = packetData.subarray(i);
      if (nalData.length > 0) {
        nalUnits.push(nalData);
      }
    }
    return nalUnits;
  };
  var findNalUnitsInLengthPrefixed = (packetData, lengthSize) => {
    const nalUnits = [];
    let offset = 0;
    const dataView = new DataView(packetData.buffer, packetData.byteOffset, packetData.byteLength);
    while (offset + lengthSize <= packetData.length) {
      let nalUnitLength;
      if (lengthSize === 1) {
        nalUnitLength = dataView.getUint8(offset);
      } else if (lengthSize === 2) {
        nalUnitLength = dataView.getUint16(offset, false);
      } else if (lengthSize === 3) {
        nalUnitLength = (dataView.getUint16(offset, false) << 8) + dataView.getUint8(offset + 2);
      } else if (lengthSize === 4) {
        nalUnitLength = dataView.getUint32(offset, false);
      } else {
        assertNever(lengthSize);
        assert(false);
      }
      offset += lengthSize;
      const nalUnit = packetData.subarray(offset, offset + nalUnitLength);
      nalUnits.push(nalUnit);
      offset += nalUnitLength;
    }
    return nalUnits;
  };
  var removeEmulationPreventionBytes = (data) => {
    const result = [];
    const len = data.length;
    for (let i = 0; i < len; i++) {
      if (i + 2 < len && data[i] === 0 && data[i + 1] === 0 && data[i + 2] === 3) {
        result.push(0, 0);
        i += 2;
      } else {
        result.push(data[i]);
      }
    }
    return new Uint8Array(result);
  };
  var transformAnnexBToLengthPrefixed = (packetData) => {
    const NAL_UNIT_LENGTH_SIZE = 4;
    const nalUnits = findNalUnitsInAnnexB(packetData);
    if (nalUnits.length === 0) {
      return null;
    }
    let totalSize = 0;
    for (const nalUnit of nalUnits) {
      totalSize += NAL_UNIT_LENGTH_SIZE + nalUnit.byteLength;
    }
    const avccData = new Uint8Array(totalSize);
    const dataView = new DataView(avccData.buffer);
    let offset = 0;
    for (const nalUnit of nalUnits) {
      const length = nalUnit.byteLength;
      dataView.setUint32(offset, length, false);
      offset += 4;
      avccData.set(nalUnit, offset);
      offset += nalUnit.byteLength;
    }
    return avccData;
  };
  var extractNalUnitTypeForAvc = (data) => {
    return data[0] & 31;
  };
  var extractAvcDecoderConfigurationRecord = (packetData) => {
    try {
      const nalUnits = findNalUnitsInAnnexB(packetData);
      const spsUnits = nalUnits.filter((unit) => extractNalUnitTypeForAvc(unit) === 7);
      const ppsUnits = nalUnits.filter((unit) => extractNalUnitTypeForAvc(unit) === 8);
      const spsExtUnits = nalUnits.filter((unit) => extractNalUnitTypeForAvc(unit) === 13);
      if (spsUnits.length === 0) {
        return null;
      }
      if (ppsUnits.length === 0) {
        return null;
      }
      const spsData = spsUnits[0];
      const bitstream = new Bitstream(removeEmulationPreventionBytes(spsData));
      bitstream.skipBits(1);
      bitstream.skipBits(2);
      const nal_unit_type = bitstream.readBits(5);
      if (nal_unit_type !== 7) {
        console.error("Invalid SPS NAL unit type");
        return null;
      }
      const profile_idc = bitstream.readAlignedByte();
      const constraint_flags = bitstream.readAlignedByte();
      const level_idc = bitstream.readAlignedByte();
      const record = {
        configurationVersion: 1,
        avcProfileIndication: profile_idc,
        profileCompatibility: constraint_flags,
        avcLevelIndication: level_idc,
        lengthSizeMinusOne: 3,
        // Typically 4 bytes for length field
        sequenceParameterSets: spsUnits,
        pictureParameterSets: ppsUnits,
        chromaFormat: null,
        bitDepthLumaMinus8: null,
        bitDepthChromaMinus8: null,
        sequenceParameterSetExt: null
      };
      if (profile_idc === 100 || profile_idc === 110 || profile_idc === 122 || profile_idc === 144) {
        readExpGolomb(bitstream);
        const chroma_format_idc = readExpGolomb(bitstream);
        if (chroma_format_idc === 3) {
          bitstream.skipBits(1);
        }
        const bit_depth_luma_minus8 = readExpGolomb(bitstream);
        const bit_depth_chroma_minus8 = readExpGolomb(bitstream);
        record.chromaFormat = chroma_format_idc;
        record.bitDepthLumaMinus8 = bit_depth_luma_minus8;
        record.bitDepthChromaMinus8 = bit_depth_chroma_minus8;
        record.sequenceParameterSetExt = spsExtUnits;
      }
      return record;
    } catch (error) {
      console.error("Error building AVC Decoder Configuration Record:", error);
      return null;
    }
  };
  var serializeAvcDecoderConfigurationRecord = (record) => {
    const bytes2 = [];
    bytes2.push(record.configurationVersion);
    bytes2.push(record.avcProfileIndication);
    bytes2.push(record.profileCompatibility);
    bytes2.push(record.avcLevelIndication);
    bytes2.push(252 | record.lengthSizeMinusOne & 3);
    bytes2.push(224 | record.sequenceParameterSets.length & 31);
    for (const sps of record.sequenceParameterSets) {
      const length = sps.byteLength;
      bytes2.push(length >> 8);
      bytes2.push(length & 255);
      for (let i = 0; i < length; i++) {
        bytes2.push(sps[i]);
      }
    }
    bytes2.push(record.pictureParameterSets.length);
    for (const pps of record.pictureParameterSets) {
      const length = pps.byteLength;
      bytes2.push(length >> 8);
      bytes2.push(length & 255);
      for (let i = 0; i < length; i++) {
        bytes2.push(pps[i]);
      }
    }
    if (record.avcProfileIndication === 100 || record.avcProfileIndication === 110 || record.avcProfileIndication === 122 || record.avcProfileIndication === 144) {
      assert(record.chromaFormat !== null);
      assert(record.bitDepthLumaMinus8 !== null);
      assert(record.bitDepthChromaMinus8 !== null);
      assert(record.sequenceParameterSetExt !== null);
      bytes2.push(252 | record.chromaFormat & 3);
      bytes2.push(248 | record.bitDepthLumaMinus8 & 7);
      bytes2.push(248 | record.bitDepthChromaMinus8 & 7);
      bytes2.push(record.sequenceParameterSetExt.length);
      for (const spsExt of record.sequenceParameterSetExt) {
        const length = spsExt.byteLength;
        bytes2.push(length >> 8);
        bytes2.push(length & 255);
        for (let i = 0; i < length; i++) {
          bytes2.push(spsExt[i]);
        }
      }
    }
    return new Uint8Array(bytes2);
  };
  var NALU_TYPE_VPS = 32;
  var NALU_TYPE_SPS = 33;
  var NALU_TYPE_PPS = 34;
  var NALU_TYPE_SEI_PREFIX = 39;
  var NALU_TYPE_SEI_SUFFIX = 40;
  var extractNalUnitTypeForHevc = (data) => {
    return data[0] >> 1 & 63;
  };
  var extractHevcDecoderConfigurationRecord = (packetData) => {
    try {
      const nalUnits = findNalUnitsInAnnexB(packetData);
      const vpsUnits = nalUnits.filter((unit) => extractNalUnitTypeForHevc(unit) === NALU_TYPE_VPS);
      const spsUnits = nalUnits.filter((unit) => extractNalUnitTypeForHevc(unit) === NALU_TYPE_SPS);
      const ppsUnits = nalUnits.filter((unit) => extractNalUnitTypeForHevc(unit) === NALU_TYPE_PPS);
      const seiUnits = nalUnits.filter(
        (unit) => extractNalUnitTypeForHevc(unit) === NALU_TYPE_SEI_PREFIX || extractNalUnitTypeForHevc(unit) === NALU_TYPE_SEI_SUFFIX
      );
      if (spsUnits.length === 0 || ppsUnits.length === 0) return null;
      const sps = spsUnits[0];
      const bitstream = new Bitstream(removeEmulationPreventionBytes(sps));
      bitstream.skipBits(16);
      bitstream.readBits(4);
      const sps_max_sub_layers_minus1 = bitstream.readBits(3);
      const sps_temporal_id_nesting_flag = bitstream.readBits(1);
      const {
        general_profile_space,
        general_tier_flag,
        general_profile_idc,
        general_profile_compatibility_flags,
        general_constraint_indicator_flags,
        general_level_idc
      } = parseProfileTierLevel(bitstream, sps_max_sub_layers_minus1);
      readExpGolomb(bitstream);
      const chroma_format_idc = readExpGolomb(bitstream);
      if (chroma_format_idc === 3) bitstream.skipBits(1);
      readExpGolomb(bitstream);
      readExpGolomb(bitstream);
      if (bitstream.readBits(1)) {
        readExpGolomb(bitstream);
        readExpGolomb(bitstream);
        readExpGolomb(bitstream);
        readExpGolomb(bitstream);
      }
      const bit_depth_luma_minus8 = readExpGolomb(bitstream);
      const bit_depth_chroma_minus8 = readExpGolomb(bitstream);
      readExpGolomb(bitstream);
      const sps_sub_layer_ordering_info_present_flag = bitstream.readBits(1);
      const maxNum = sps_sub_layer_ordering_info_present_flag ? 0 : sps_max_sub_layers_minus1;
      for (let i = maxNum; i <= sps_max_sub_layers_minus1; i++) {
        readExpGolomb(bitstream);
        readExpGolomb(bitstream);
        readExpGolomb(bitstream);
      }
      readExpGolomb(bitstream);
      readExpGolomb(bitstream);
      readExpGolomb(bitstream);
      readExpGolomb(bitstream);
      readExpGolomb(bitstream);
      readExpGolomb(bitstream);
      if (bitstream.readBits(1)) {
        if (bitstream.readBits(1)) {
          skipScalingListData(bitstream);
        }
      }
      bitstream.skipBits(1);
      bitstream.skipBits(1);
      if (bitstream.readBits(1)) {
        bitstream.skipBits(4);
        bitstream.skipBits(4);
        readExpGolomb(bitstream);
        readExpGolomb(bitstream);
        bitstream.skipBits(1);
      }
      const num_short_term_ref_pic_sets = readExpGolomb(bitstream);
      skipAllStRefPicSets(bitstream, num_short_term_ref_pic_sets);
      if (bitstream.readBits(1)) {
        const num_long_term_ref_pics_sps = readExpGolomb(bitstream);
        for (let i = 0; i < num_long_term_ref_pics_sps; i++) {
          readExpGolomb(bitstream);
          bitstream.skipBits(1);
        }
      }
      bitstream.skipBits(1);
      bitstream.skipBits(1);
      let min_spatial_segmentation_idc = 0;
      if (bitstream.readBits(1)) {
        min_spatial_segmentation_idc = parseVuiForMinSpatialSegmentationIdc(bitstream, sps_max_sub_layers_minus1);
      }
      let parallelismType = 0;
      if (ppsUnits.length > 0) {
        const pps = ppsUnits[0];
        const ppsBitstream = new Bitstream(removeEmulationPreventionBytes(pps));
        ppsBitstream.skipBits(16);
        readExpGolomb(ppsBitstream);
        readExpGolomb(ppsBitstream);
        ppsBitstream.skipBits(1);
        ppsBitstream.skipBits(1);
        ppsBitstream.skipBits(3);
        ppsBitstream.skipBits(1);
        ppsBitstream.skipBits(1);
        readExpGolomb(ppsBitstream);
        readExpGolomb(ppsBitstream);
        readSignedExpGolomb(ppsBitstream);
        ppsBitstream.skipBits(1);
        ppsBitstream.skipBits(1);
        if (ppsBitstream.readBits(1)) {
          readExpGolomb(ppsBitstream);
        }
        readSignedExpGolomb(ppsBitstream);
        readSignedExpGolomb(ppsBitstream);
        ppsBitstream.skipBits(1);
        ppsBitstream.skipBits(1);
        ppsBitstream.skipBits(1);
        ppsBitstream.skipBits(1);
        const tiles_enabled_flag = ppsBitstream.readBits(1);
        const entropy_coding_sync_enabled_flag = ppsBitstream.readBits(1);
        if (!tiles_enabled_flag && !entropy_coding_sync_enabled_flag) parallelismType = 0;
        else if (tiles_enabled_flag && !entropy_coding_sync_enabled_flag) parallelismType = 2;
        else if (!tiles_enabled_flag && entropy_coding_sync_enabled_flag) parallelismType = 3;
        else parallelismType = 0;
      }
      const arrays = [
        ...vpsUnits.length ? [
          {
            arrayCompleteness: 1,
            nalUnitType: NALU_TYPE_VPS,
            nalUnits: vpsUnits
          }
        ] : [],
        ...spsUnits.length ? [
          {
            arrayCompleteness: 1,
            nalUnitType: NALU_TYPE_SPS,
            nalUnits: spsUnits
          }
        ] : [],
        ...ppsUnits.length ? [
          {
            arrayCompleteness: 1,
            nalUnitType: NALU_TYPE_PPS,
            nalUnits: ppsUnits
          }
        ] : [],
        ...seiUnits.length ? [
          {
            arrayCompleteness: 1,
            nalUnitType: extractNalUnitTypeForHevc(seiUnits[0]),
            nalUnits: seiUnits
          }
        ] : []
      ];
      const record = {
        configurationVersion: 1,
        generalProfileSpace: general_profile_space,
        generalTierFlag: general_tier_flag,
        generalProfileIdc: general_profile_idc,
        generalProfileCompatibilityFlags: general_profile_compatibility_flags,
        generalConstraintIndicatorFlags: general_constraint_indicator_flags,
        generalLevelIdc: general_level_idc,
        minSpatialSegmentationIdc: min_spatial_segmentation_idc,
        parallelismType,
        chromaFormatIdc: chroma_format_idc,
        bitDepthLumaMinus8: bit_depth_luma_minus8,
        bitDepthChromaMinus8: bit_depth_chroma_minus8,
        avgFrameRate: 0,
        constantFrameRate: 0,
        numTemporalLayers: sps_max_sub_layers_minus1 + 1,
        temporalIdNested: sps_temporal_id_nesting_flag,
        lengthSizeMinusOne: 3,
        arrays
      };
      return record;
    } catch (error) {
      console.error("Error building HEVC Decoder Configuration Record:", error);
      return null;
    }
  };
  var parseProfileTierLevel = (bitstream, maxNumSubLayersMinus1) => {
    const general_profile_space = bitstream.readBits(2);
    const general_tier_flag = bitstream.readBits(1);
    const general_profile_idc = bitstream.readBits(5);
    let general_profile_compatibility_flags = 0;
    for (let i = 0; i < 32; i++) {
      general_profile_compatibility_flags = general_profile_compatibility_flags << 1 | bitstream.readBits(1);
    }
    const general_constraint_indicator_flags = new Uint8Array(6);
    for (let i = 0; i < 6; i++) {
      general_constraint_indicator_flags[i] = bitstream.readBits(8);
    }
    const general_level_idc = bitstream.readBits(8);
    const sub_layer_profile_present_flag = [];
    const sub_layer_level_present_flag = [];
    for (let i = 0; i < maxNumSubLayersMinus1; i++) {
      sub_layer_profile_present_flag.push(bitstream.readBits(1));
      sub_layer_level_present_flag.push(bitstream.readBits(1));
    }
    if (maxNumSubLayersMinus1 > 0) {
      for (let i = maxNumSubLayersMinus1; i < 8; i++) {
        bitstream.skipBits(2);
      }
    }
    for (let i = 0; i < maxNumSubLayersMinus1; i++) {
      if (sub_layer_profile_present_flag[i]) bitstream.skipBits(88);
      if (sub_layer_level_present_flag[i]) bitstream.skipBits(8);
    }
    return {
      general_profile_space,
      general_tier_flag,
      general_profile_idc,
      general_profile_compatibility_flags,
      general_constraint_indicator_flags,
      general_level_idc
    };
  };
  var skipScalingListData = (bitstream) => {
    for (let sizeId = 0; sizeId < 4; sizeId++) {
      for (let matrixId = 0; matrixId < (sizeId === 3 ? 2 : 6); matrixId++) {
        const scaling_list_pred_mode_flag = bitstream.readBits(1);
        if (!scaling_list_pred_mode_flag) {
          readExpGolomb(bitstream);
        } else {
          const coefNum = Math.min(64, 1 << 4 + (sizeId << 1));
          if (sizeId > 1) {
            readSignedExpGolomb(bitstream);
          }
          for (let i = 0; i < coefNum; i++) {
            readSignedExpGolomb(bitstream);
          }
        }
      }
    }
  };
  var skipAllStRefPicSets = (bitstream, num_short_term_ref_pic_sets) => {
    const NumDeltaPocs = [];
    for (let stRpsIdx = 0; stRpsIdx < num_short_term_ref_pic_sets; stRpsIdx++) {
      NumDeltaPocs[stRpsIdx] = skipStRefPicSet(bitstream, stRpsIdx, num_short_term_ref_pic_sets, NumDeltaPocs);
    }
  };
  var skipStRefPicSet = (bitstream, stRpsIdx, num_short_term_ref_pic_sets, NumDeltaPocs) => {
    let NumDeltaPocsThis = 0;
    let inter_ref_pic_set_prediction_flag = 0;
    let RefRpsIdx = 0;
    if (stRpsIdx !== 0) {
      inter_ref_pic_set_prediction_flag = bitstream.readBits(1);
    }
    if (inter_ref_pic_set_prediction_flag) {
      if (stRpsIdx === num_short_term_ref_pic_sets) {
        const delta_idx_minus1 = readExpGolomb(bitstream);
        RefRpsIdx = stRpsIdx - (delta_idx_minus1 + 1);
      } else {
        RefRpsIdx = stRpsIdx - 1;
      }
      bitstream.readBits(1);
      readExpGolomb(bitstream);
      const numDelta = NumDeltaPocs[RefRpsIdx] ?? 0;
      for (let j = 0; j <= numDelta; j++) {
        const used_by_curr_pic_flag = bitstream.readBits(1);
        if (!used_by_curr_pic_flag) {
          bitstream.readBits(1);
        }
      }
      NumDeltaPocsThis = NumDeltaPocs[RefRpsIdx];
    } else {
      const num_negative_pics = readExpGolomb(bitstream);
      const num_positive_pics = readExpGolomb(bitstream);
      for (let i = 0; i < num_negative_pics; i++) {
        readExpGolomb(bitstream);
        bitstream.readBits(1);
      }
      for (let i = 0; i < num_positive_pics; i++) {
        readExpGolomb(bitstream);
        bitstream.readBits(1);
      }
      NumDeltaPocsThis = num_negative_pics + num_positive_pics;
    }
    return NumDeltaPocsThis;
  };
  var parseVuiForMinSpatialSegmentationIdc = (bitstream, sps_max_sub_layers_minus1) => {
    if (bitstream.readBits(1)) {
      const aspect_ratio_idc = bitstream.readBits(8);
      if (aspect_ratio_idc === 255) {
        bitstream.readBits(16);
        bitstream.readBits(16);
      }
    }
    if (bitstream.readBits(1)) {
      bitstream.readBits(1);
    }
    if (bitstream.readBits(1)) {
      bitstream.readBits(3);
      bitstream.readBits(1);
      if (bitstream.readBits(1)) {
        bitstream.readBits(8);
        bitstream.readBits(8);
        bitstream.readBits(8);
      }
    }
    if (bitstream.readBits(1)) {
      readExpGolomb(bitstream);
      readExpGolomb(bitstream);
    }
    bitstream.readBits(1);
    bitstream.readBits(1);
    bitstream.readBits(1);
    if (bitstream.readBits(1)) {
      readExpGolomb(bitstream);
      readExpGolomb(bitstream);
      readExpGolomb(bitstream);
      readExpGolomb(bitstream);
    }
    if (bitstream.readBits(1)) {
      bitstream.readBits(32);
      bitstream.readBits(32);
      if (bitstream.readBits(1)) {
        readExpGolomb(bitstream);
      }
      if (bitstream.readBits(1)) {
        skipHrdParameters(bitstream, true, sps_max_sub_layers_minus1);
      }
    }
    if (bitstream.readBits(1)) {
      bitstream.readBits(1);
      bitstream.readBits(1);
      bitstream.readBits(1);
      const min_spatial_segmentation_idc = readExpGolomb(bitstream);
      readExpGolomb(bitstream);
      readExpGolomb(bitstream);
      readExpGolomb(bitstream);
      readExpGolomb(bitstream);
      return min_spatial_segmentation_idc;
    }
    return 0;
  };
  var skipHrdParameters = (bitstream, commonInfPresentFlag, maxNumSubLayersMinus1) => {
    let nal_hrd_parameters_present_flag = false;
    let vcl_hrd_parameters_present_flag = false;
    let sub_pic_hrd_params_present_flag = false;
    if (commonInfPresentFlag) {
      nal_hrd_parameters_present_flag = bitstream.readBits(1) === 1;
      vcl_hrd_parameters_present_flag = bitstream.readBits(1) === 1;
      if (nal_hrd_parameters_present_flag || vcl_hrd_parameters_present_flag) {
        sub_pic_hrd_params_present_flag = bitstream.readBits(1) === 1;
        if (sub_pic_hrd_params_present_flag) {
          bitstream.readBits(8);
          bitstream.readBits(5);
          bitstream.readBits(1);
          bitstream.readBits(5);
        }
        bitstream.readBits(4);
        bitstream.readBits(4);
        if (sub_pic_hrd_params_present_flag) {
          bitstream.readBits(4);
        }
        bitstream.readBits(5);
        bitstream.readBits(5);
        bitstream.readBits(5);
      }
    }
    for (let i = 0; i <= maxNumSubLayersMinus1; i++) {
      const fixed_pic_rate_general_flag = bitstream.readBits(1) === 1;
      let fixed_pic_rate_within_cvs_flag = true;
      if (!fixed_pic_rate_general_flag) {
        fixed_pic_rate_within_cvs_flag = bitstream.readBits(1) === 1;
      }
      let low_delay_hrd_flag = false;
      if (fixed_pic_rate_within_cvs_flag) {
        readExpGolomb(bitstream);
      } else {
        low_delay_hrd_flag = bitstream.readBits(1) === 1;
      }
      let CpbCnt = 1;
      if (!low_delay_hrd_flag) {
        const cpb_cnt_minus1 = readExpGolomb(bitstream);
        CpbCnt = cpb_cnt_minus1 + 1;
      }
      if (nal_hrd_parameters_present_flag) {
        skipSubLayerHrdParameters(bitstream, CpbCnt, sub_pic_hrd_params_present_flag);
      }
      if (vcl_hrd_parameters_present_flag) {
        skipSubLayerHrdParameters(bitstream, CpbCnt, sub_pic_hrd_params_present_flag);
      }
    }
  };
  var skipSubLayerHrdParameters = (bitstream, CpbCnt, sub_pic_hrd_params_present_flag) => {
    for (let i = 0; i < CpbCnt; i++) {
      readExpGolomb(bitstream);
      readExpGolomb(bitstream);
      if (sub_pic_hrd_params_present_flag) {
        readExpGolomb(bitstream);
        readExpGolomb(bitstream);
      }
      bitstream.readBits(1);
    }
  };
  var serializeHevcDecoderConfigurationRecord = (record) => {
    const bytes2 = [];
    bytes2.push(record.configurationVersion);
    bytes2.push(
      (record.generalProfileSpace & 3) << 6 | (record.generalTierFlag & 1) << 5 | record.generalProfileIdc & 31
    );
    bytes2.push(record.generalProfileCompatibilityFlags >>> 24 & 255);
    bytes2.push(record.generalProfileCompatibilityFlags >>> 16 & 255);
    bytes2.push(record.generalProfileCompatibilityFlags >>> 8 & 255);
    bytes2.push(record.generalProfileCompatibilityFlags & 255);
    bytes2.push(...record.generalConstraintIndicatorFlags);
    bytes2.push(record.generalLevelIdc & 255);
    bytes2.push(240 | record.minSpatialSegmentationIdc >> 8 & 15);
    bytes2.push(record.minSpatialSegmentationIdc & 255);
    bytes2.push(252 | record.parallelismType & 3);
    bytes2.push(252 | record.chromaFormatIdc & 3);
    bytes2.push(248 | record.bitDepthLumaMinus8 & 7);
    bytes2.push(248 | record.bitDepthChromaMinus8 & 7);
    bytes2.push(record.avgFrameRate >> 8 & 255);
    bytes2.push(record.avgFrameRate & 255);
    bytes2.push(
      (record.constantFrameRate & 3) << 6 | (record.numTemporalLayers & 7) << 3 | (record.temporalIdNested & 1) << 2 | record.lengthSizeMinusOne & 3
    );
    bytes2.push(record.arrays.length & 255);
    for (const arr of record.arrays) {
      bytes2.push(
        (arr.arrayCompleteness & 1) << 7 | 0 << 6 | arr.nalUnitType & 63
      );
      bytes2.push(arr.nalUnits.length >> 8 & 255);
      bytes2.push(arr.nalUnits.length & 255);
      for (const nal of arr.nalUnits) {
        bytes2.push(nal.length >> 8 & 255);
        bytes2.push(nal.length & 255);
        for (let i = 0; i < nal.length; i++) {
          bytes2.push(nal[i]);
        }
      }
    }
    return new Uint8Array(bytes2);
  };
  var extractVp9CodecInfoFromPacket = (packet) => {
    const bitstream = new Bitstream(packet);
    const frameMarker = bitstream.readBits(2);
    if (frameMarker !== 2) {
      return null;
    }
    const profileLowBit = bitstream.readBits(1);
    const profileHighBit = bitstream.readBits(1);
    const profile = (profileHighBit << 1) + profileLowBit;
    if (profile === 3) {
      bitstream.skipBits(1);
    }
    const showExistingFrame = bitstream.readBits(1);
    if (showExistingFrame === 1) {
      return null;
    }
    const frameType = bitstream.readBits(1);
    if (frameType !== 0) {
      return null;
    }
    bitstream.skipBits(2);
    const syncCode = bitstream.readBits(24);
    if (syncCode !== 4817730) {
      return null;
    }
    let bitDepth = 8;
    if (profile >= 2) {
      const tenOrTwelveBit = bitstream.readBits(1);
      bitDepth = tenOrTwelveBit ? 12 : 10;
    }
    const colorSpace = bitstream.readBits(3);
    let chromaSubsampling = 0;
    let videoFullRangeFlag = 0;
    if (colorSpace !== 7) {
      const colorRange = bitstream.readBits(1);
      videoFullRangeFlag = colorRange;
      if (profile === 1 || profile === 3) {
        const subsamplingX = bitstream.readBits(1);
        const subsamplingY = bitstream.readBits(1);
        chromaSubsampling = !subsamplingX && !subsamplingY ? 3 : subsamplingX && !subsamplingY ? 2 : 1;
        bitstream.skipBits(1);
      } else {
        chromaSubsampling = 1;
      }
    } else {
      chromaSubsampling = 3;
      videoFullRangeFlag = 1;
    }
    const widthMinusOne = bitstream.readBits(16);
    const heightMinusOne = bitstream.readBits(16);
    const width = widthMinusOne + 1;
    const height = heightMinusOne + 1;
    const pictureSize = width * height;
    let level = last(VP9_LEVEL_TABLE).level;
    for (const entry of VP9_LEVEL_TABLE) {
      if (pictureSize <= entry.maxPictureSize) {
        level = entry.level;
        break;
      }
    }
    const matrixCoefficients = colorSpace === 7 ? 0 : colorSpace === 2 ? 1 : colorSpace === 1 ? 6 : 2;
    const colourPrimaries = colorSpace === 2 ? 1 : colorSpace === 1 ? 6 : 2;
    const transferCharacteristics = colorSpace === 2 ? 1 : colorSpace === 1 ? 6 : 2;
    return {
      profile,
      level,
      bitDepth,
      chromaSubsampling,
      videoFullRangeFlag,
      colourPrimaries,
      transferCharacteristics,
      matrixCoefficients
    };
  };
  function* iterateAv1PacketObus(packet) {
    const bitstream = new Bitstream(packet);
    const readLeb128 = () => {
      let value = 0;
      for (let i = 0; i < 8; i++) {
        const byte = bitstream.readAlignedByte();
        value |= (byte & 127) << i * 7;
        if (!(byte & 128)) {
          break;
        }
        if (i === 7 && byte & 128) {
          return null;
        }
      }
      if (value >= 2 ** 32 - 1) {
        return null;
      }
      return value;
    };
    while (bitstream.getBitsLeft() >= 8) {
      bitstream.skipBits(1);
      const obuType = bitstream.readBits(4);
      const obuExtension = bitstream.readBits(1);
      const obuHasSizeField = bitstream.readBits(1);
      bitstream.skipBits(1);
      if (obuExtension) {
        bitstream.skipBits(8);
      }
      let obuSize;
      if (obuHasSizeField) {
        const obuSizeValue = readLeb128();
        if (obuSizeValue === null) return;
        obuSize = obuSizeValue;
      } else {
        obuSize = Math.floor(bitstream.getBitsLeft() / 8);
      }
      assert(bitstream.pos % 8 === 0);
      yield {
        type: obuType,
        data: packet.subarray(bitstream.pos / 8, bitstream.pos / 8 + obuSize)
      };
      bitstream.skipBits(obuSize * 8);
    }
  }
  var extractAv1CodecInfoFromPacket = (packet) => {
    for (const { type, data } of iterateAv1PacketObus(packet)) {
      if (type !== 1) {
        continue;
      }
      const bitstream = new Bitstream(data);
      const seqProfile = bitstream.readBits(3);
      const stillPicture = bitstream.readBits(1);
      const reducedStillPictureHeader = bitstream.readBits(1);
      let seqLevel = 0;
      let seqTier = 0;
      let bufferDelayLengthMinus1 = 0;
      if (reducedStillPictureHeader) {
        seqLevel = bitstream.readBits(5);
      } else {
        const timingInfoPresentFlag = bitstream.readBits(1);
        if (timingInfoPresentFlag) {
          bitstream.skipBits(32);
          bitstream.skipBits(32);
          const equalPictureInterval = bitstream.readBits(1);
          if (equalPictureInterval) {
            return null;
          }
        }
        const decoderModelInfoPresentFlag = bitstream.readBits(1);
        if (decoderModelInfoPresentFlag) {
          bufferDelayLengthMinus1 = bitstream.readBits(5);
          bitstream.skipBits(32);
          bitstream.skipBits(5);
          bitstream.skipBits(5);
        }
        const operatingPointsCntMinus1 = bitstream.readBits(5);
        for (let i = 0; i <= operatingPointsCntMinus1; i++) {
          bitstream.skipBits(12);
          const seqLevelIdx = bitstream.readBits(5);
          if (i === 0) {
            seqLevel = seqLevelIdx;
          }
          if (seqLevelIdx > 7) {
            const seqTierTemp = bitstream.readBits(1);
            if (i === 0) {
              seqTier = seqTierTemp;
            }
          }
          if (decoderModelInfoPresentFlag) {
            const decoderModelPresentForThisOp = bitstream.readBits(1);
            if (decoderModelPresentForThisOp) {
              const n = bufferDelayLengthMinus1 + 1;
              bitstream.skipBits(n);
              bitstream.skipBits(n);
              bitstream.skipBits(1);
            }
          }
          const initialDisplayDelayPresentFlag = bitstream.readBits(1);
          if (initialDisplayDelayPresentFlag) {
            bitstream.skipBits(4);
          }
        }
      }
      const highBitdepth = bitstream.readBits(1);
      let bitDepth = 8;
      if (seqProfile === 2 && highBitdepth) {
        const twelveBit = bitstream.readBits(1);
        bitDepth = twelveBit ? 12 : 10;
      } else if (seqProfile <= 2) {
        bitDepth = highBitdepth ? 10 : 8;
      }
      let monochrome = 0;
      if (seqProfile !== 1) {
        monochrome = bitstream.readBits(1);
      }
      let chromaSubsamplingX = 1;
      let chromaSubsamplingY = 1;
      let chromaSamplePosition = 0;
      if (!monochrome) {
        if (seqProfile === 0) {
          chromaSubsamplingX = 1;
          chromaSubsamplingY = 1;
        } else if (seqProfile === 1) {
          chromaSubsamplingX = 0;
          chromaSubsamplingY = 0;
        } else {
          if (bitDepth === 12) {
            chromaSubsamplingX = bitstream.readBits(1);
            if (chromaSubsamplingX) {
              chromaSubsamplingY = bitstream.readBits(1);
            }
          }
        }
        if (chromaSubsamplingX && chromaSubsamplingY) {
          chromaSamplePosition = bitstream.readBits(2);
        }
      }
      return {
        profile: seqProfile,
        level: seqLevel,
        tier: seqTier,
        bitDepth,
        monochrome,
        chromaSubsamplingX,
        chromaSubsamplingY,
        chromaSamplePosition
      };
    }
    return null;
  };
  var parseOpusIdentificationHeader = (bytes2) => {
    const view2 = toDataView(bytes2);
    const outputChannelCount = view2.getUint8(9);
    const preSkip = view2.getUint16(10, true);
    const inputSampleRate = view2.getUint32(12, true);
    const outputGain = view2.getInt16(16, true);
    const channelMappingFamily = view2.getUint8(18);
    let channelMappingTable = null;
    if (channelMappingFamily) {
      channelMappingTable = bytes2.subarray(19, 19 + 2 + outputChannelCount);
    }
    return {
      outputChannelCount,
      preSkip,
      inputSampleRate,
      outputGain,
      channelMappingFamily,
      channelMappingTable
    };
  };
  var OPUS_FRAME_DURATION_TABLE = [
    480,
    960,
    1920,
    2880,
    480,
    960,
    1920,
    2880,
    480,
    960,
    1920,
    2880,
    480,
    960,
    480,
    960,
    120,
    240,
    480,
    960,
    120,
    240,
    480,
    960,
    120,
    240,
    480,
    960,
    120,
    240,
    480,
    960
  ];
  var parseOpusTocByte = (packet) => {
    const config = packet[0] >> 3;
    return {
      durationInSamples: OPUS_FRAME_DURATION_TABLE[config]
    };
  };
  var parseModesFromVorbisSetupPacket = (setupHeader) => {
    if (setupHeader.length < 7) {
      throw new Error("Setup header is too short.");
    }
    if (setupHeader[0] !== 5) {
      throw new Error("Wrong packet type in Setup header.");
    }
    const signature = String.fromCharCode(...setupHeader.slice(1, 7));
    if (signature !== "vorbis") {
      throw new Error("Invalid packet signature in Setup header.");
    }
    const bufSize = setupHeader.length;
    const revBuffer = new Uint8Array(bufSize);
    for (let i = 0; i < bufSize; i++) {
      revBuffer[i] = setupHeader[bufSize - 1 - i];
    }
    const bitstream = new Bitstream(revBuffer);
    let gotFramingBit = 0;
    while (bitstream.getBitsLeft() > 97) {
      if (bitstream.readBits(1) === 1) {
        gotFramingBit = bitstream.pos;
        break;
      }
    }
    if (gotFramingBit === 0) {
      throw new Error("Invalid Setup header: framing bit not found.");
    }
    let modeCount = 0;
    let gotModeHeader = false;
    let lastModeCount = 0;
    while (bitstream.getBitsLeft() >= 97) {
      const tempPos = bitstream.pos;
      const a = bitstream.readBits(8);
      const b = bitstream.readBits(16);
      const c = bitstream.readBits(16);
      if (a > 63 || b !== 0 || c !== 0) {
        bitstream.pos = tempPos;
        break;
      }
      bitstream.skipBits(1);
      modeCount++;
      if (modeCount > 64) {
        break;
      }
      const bsClone = bitstream.clone();
      const candidate = bsClone.readBits(6) + 1;
      if (candidate === modeCount) {
        gotModeHeader = true;
        lastModeCount = modeCount;
      }
    }
    if (!gotModeHeader) {
      throw new Error("Invalid Setup header: mode header not found.");
    }
    if (lastModeCount > 63) {
      throw new Error(`Unsupported mode count: ${lastModeCount}.`);
    }
    const finalModeCount = lastModeCount;
    bitstream.pos = 0;
    bitstream.skipBits(gotFramingBit);
    const modeBlockflags = Array(finalModeCount).fill(0);
    for (let i = finalModeCount - 1; i >= 0; i--) {
      bitstream.skipBits(40);
      modeBlockflags[i] = bitstream.readBits(1);
    }
    return { modeBlockflags };
  };
  var determineVideoPacketType = async (videoTrack, packet) => {
    assert(videoTrack.codec);
    switch (videoTrack.codec) {
      case "avc":
        {
          const decoderConfig = await videoTrack.getDecoderConfig();
          assert(decoderConfig);
          let nalUnits;
          if (decoderConfig.description) {
            const bytes2 = toUint8Array(decoderConfig.description);
            const lengthSizeMinusOne = bytes2[4] & 3;
            const lengthSize = lengthSizeMinusOne + 1;
            nalUnits = findNalUnitsInLengthPrefixed(packet.data, lengthSize);
          } else {
            nalUnits = findNalUnitsInAnnexB(packet.data);
          }
          const isKeyframe = nalUnits.some((x) => extractNalUnitTypeForAvc(x) === 5);
          return isKeyframe ? "key" : "delta";
        }
        ;
      case "hevc":
        {
          const decoderConfig = await videoTrack.getDecoderConfig();
          assert(decoderConfig);
          let nalUnits;
          if (decoderConfig.description) {
            const bytes2 = toUint8Array(decoderConfig.description);
            const lengthSizeMinusOne = bytes2[21] & 3;
            const lengthSize = lengthSizeMinusOne + 1;
            nalUnits = findNalUnitsInLengthPrefixed(packet.data, lengthSize);
          } else {
            nalUnits = findNalUnitsInAnnexB(packet.data);
          }
          const isKeyframe = nalUnits.some((x) => {
            const type = extractNalUnitTypeForHevc(x);
            return 16 <= type && type <= 23;
          });
          return isKeyframe ? "key" : "delta";
        }
        ;
      case "vp8":
        {
          const frameType = packet.data[0] & 1;
          return frameType === 0 ? "key" : "delta";
        }
        ;
      case "vp9":
        {
          const bitstream = new Bitstream(packet.data);
          if (bitstream.readBits(2) !== 2) {
            return null;
          }
          ;
          const profileLowBit = bitstream.readBits(1);
          const profileHighBit = bitstream.readBits(1);
          const profile = (profileHighBit << 1) + profileLowBit;
          if (profile === 3) {
            bitstream.skipBits(1);
          }
          const showExistingFrame = bitstream.readBits(1);
          if (showExistingFrame) {
            return null;
          }
          const frameType = bitstream.readBits(1);
          return frameType === 0 ? "key" : "delta";
        }
        ;
      case "av1":
        {
          let reducedStillPictureHeader = false;
          for (const { type, data } of iterateAv1PacketObus(packet.data)) {
            if (type === 1) {
              const bitstream = new Bitstream(data);
              bitstream.skipBits(4);
              reducedStillPictureHeader = !!bitstream.readBits(1);
            } else if (type === 3 || type === 6 || type === 7) {
              if (reducedStillPictureHeader) {
                return "key";
              }
              const bitstream = new Bitstream(data);
              const showExistingFrame = bitstream.readBits(1);
              if (showExistingFrame) {
                return null;
              }
              const frameType = bitstream.readBits(2);
              return frameType === 0 ? "key" : "delta";
            }
          }
          return null;
        }
        ;
      default:
        {
          assertNever(videoTrack.codec);
          assert(false);
        }
        ;
    }
  };

  // src/isobmff/isobmff-boxes.ts
  var IsobmffBoxWriter = class {
    constructor(writer) {
      this.writer = writer;
      this.helper = new Uint8Array(8);
      this.helperView = new DataView(this.helper.buffer);
      /**
       * Stores the position from the start of the file to where boxes elements have been written. This is used to
       * rewrite/edit elements that were already added before, and to measure sizes of things.
       */
      this.offsets = /* @__PURE__ */ new WeakMap();
    }
    writeU32(value) {
      this.helperView.setUint32(0, value, false);
      this.writer.write(this.helper.subarray(0, 4));
    }
    writeU64(value) {
      this.helperView.setUint32(0, Math.floor(value / 2 ** 32), false);
      this.helperView.setUint32(4, value, false);
      this.writer.write(this.helper.subarray(0, 8));
    }
    writeAscii(text) {
      for (let i = 0; i < text.length; i++) {
        this.helperView.setUint8(i % 8, text.charCodeAt(i));
        if (i % 8 === 7) this.writer.write(this.helper);
      }
      if (text.length % 8 !== 0) {
        this.writer.write(this.helper.subarray(0, text.length % 8));
      }
    }
    writeBox(box2) {
      this.offsets.set(box2, this.writer.getPos());
      if (box2.contents && !box2.children) {
        this.writeBoxHeader(box2, box2.size ?? box2.contents.byteLength + 8);
        this.writer.write(box2.contents);
      } else {
        const startPos = this.writer.getPos();
        this.writeBoxHeader(box2, 0);
        if (box2.contents) this.writer.write(box2.contents);
        if (box2.children) {
          for (const child of box2.children) if (child) this.writeBox(child);
        }
        const endPos = this.writer.getPos();
        const size = box2.size ?? endPos - startPos;
        this.writer.seek(startPos);
        this.writeBoxHeader(box2, size);
        this.writer.seek(endPos);
      }
    }
    writeBoxHeader(box2, size) {
      this.writeU32(box2.largeSize ? 1 : size);
      this.writeAscii(box2.type);
      if (box2.largeSize) this.writeU64(size);
    }
    measureBoxHeader(box2) {
      return 8 + (box2.largeSize ? 8 : 0);
    }
    patchBox(box2) {
      const boxOffset = this.offsets.get(box2);
      assert(boxOffset !== void 0);
      const endPos = this.writer.getPos();
      this.writer.seek(boxOffset);
      this.writeBox(box2);
      this.writer.seek(endPos);
    }
    measureBox(box2) {
      if (box2.contents && !box2.children) {
        const headerSize = this.measureBoxHeader(box2);
        return headerSize + box2.contents.byteLength;
      } else {
        let result = this.measureBoxHeader(box2);
        if (box2.contents) result += box2.contents.byteLength;
        if (box2.children) {
          for (const child of box2.children) if (child) result += this.measureBox(child);
        }
        return result;
      }
    }
  };
  var bytes = new Uint8Array(8);
  var view = new DataView(bytes.buffer);
  var u8 = (value) => {
    return [(value % 256 + 256) % 256];
  };
  var u16 = (value) => {
    view.setUint16(0, value, false);
    return [bytes[0], bytes[1]];
  };
  var i16 = (value) => {
    view.setInt16(0, value, false);
    return [bytes[0], bytes[1]];
  };
  var u24 = (value) => {
    view.setUint32(0, value, false);
    return [bytes[1], bytes[2], bytes[3]];
  };
  var u32 = (value) => {
    view.setUint32(0, value, false);
    return [bytes[0], bytes[1], bytes[2], bytes[3]];
  };
  var i32 = (value) => {
    view.setInt32(0, value, false);
    return [bytes[0], bytes[1], bytes[2], bytes[3]];
  };
  var u64 = (value) => {
    view.setUint32(0, Math.floor(value / 2 ** 32), false);
    view.setUint32(4, value, false);
    return [bytes[0], bytes[1], bytes[2], bytes[3], bytes[4], bytes[5], bytes[6], bytes[7]];
  };
  var fixed_8_8 = (value) => {
    view.setInt16(0, 2 ** 8 * value, false);
    return [bytes[0], bytes[1]];
  };
  var fixed_16_16 = (value) => {
    view.setInt32(0, 2 ** 16 * value, false);
    return [bytes[0], bytes[1], bytes[2], bytes[3]];
  };
  var fixed_2_30 = (value) => {
    view.setInt32(0, 2 ** 30 * value, false);
    return [bytes[0], bytes[1], bytes[2], bytes[3]];
  };
  var variableUnsignedInt = (value, byteLength) => {
    const bytes2 = [];
    let remaining = value;
    do {
      let byte = remaining & 127;
      remaining >>= 7;
      if (bytes2.length > 0) {
        byte |= 128;
      }
      bytes2.push(byte);
      if (byteLength !== void 0) {
        byteLength--;
      }
    } while (remaining > 0 || byteLength);
    return bytes2.reverse();
  };
  var ascii = (text, nullTerminated = false) => {
    const bytes2 = Array(text.length).fill(null).map((_, i) => text.charCodeAt(i));
    if (nullTerminated) bytes2.push(0);
    return bytes2;
  };
  var lastPresentedSample = (samples) => {
    let result = null;
    for (const sample of samples) {
      if (!result || sample.timestamp > result.timestamp) {
        result = sample;
      }
    }
    return result;
  };
  var rotationMatrix = (rotationInDegrees) => {
    const theta = rotationInDegrees * (Math.PI / 180);
    const cosTheta = Math.round(Math.cos(theta));
    const sinTheta = Math.round(Math.sin(theta));
    return [
      cosTheta,
      sinTheta,
      0,
      -sinTheta,
      cosTheta,
      0,
      0,
      0,
      1
    ];
  };
  var IDENTITY_MATRIX = rotationMatrix(0);
  var matrixToBytes = (matrix) => {
    return [
      fixed_16_16(matrix[0]),
      fixed_16_16(matrix[1]),
      fixed_2_30(matrix[2]),
      fixed_16_16(matrix[3]),
      fixed_16_16(matrix[4]),
      fixed_2_30(matrix[5]),
      fixed_16_16(matrix[6]),
      fixed_16_16(matrix[7]),
      fixed_2_30(matrix[8])
    ];
  };
  var box = (type, contents, children) => ({
    type,
    contents: contents && new Uint8Array(contents.flat(10)),
    children
  });
  var fullBox = (type, version, flags, contents, children) => box(
    type,
    [u8(version), u24(flags), contents ?? []],
    children
  );
  var ftyp = (details) => {
    const minorVersion = 512;
    if (details.isQuickTime) {
      return box("ftyp", [
        ascii("qt  "),
        // Major brand
        u32(minorVersion),
        // Minor version
        // Compatible brands
        ascii("qt  ")
      ]);
    }
    if (details.fragmented) {
      return box("ftyp", [
        ascii("iso5"),
        // Major brand
        u32(minorVersion),
        // Minor version
        // Compatible brands
        ascii("iso5"),
        ascii("iso6"),
        ascii("mp41")
      ]);
    }
    return box("ftyp", [
      ascii("isom"),
      // Major brand
      u32(minorVersion),
      // Minor version
      // Compatible brands
      ascii("isom"),
      details.holdsAvc ? ascii("avc1") : [],
      ascii("mp41")
    ]);
  };
  var mdat = (reserveLargeSize) => ({ type: "mdat", largeSize: reserveLargeSize });
  var moov = (trackDatas, creationTime, fragmented = false) => box("moov", void 0, [
    mvhd(creationTime, trackDatas),
    ...trackDatas.map((x) => trak(x, creationTime)),
    fragmented ? mvex(trackDatas) : null
  ]);
  var mvhd = (creationTime, trackDatas) => {
    const duration = intoTimescale(Math.max(
      0,
      ...trackDatas.filter((x) => x.samples.length > 0).map((x) => {
        const lastSample = lastPresentedSample(x.samples);
        return lastSample.timestamp + lastSample.duration;
      })
    ), GLOBAL_TIMESCALE);
    const nextTrackId = Math.max(0, ...trackDatas.map((x) => x.track.id)) + 1;
    const needsU64 = !isU32(creationTime) || !isU32(duration);
    const u32OrU64 = needsU64 ? u64 : u32;
    return fullBox("mvhd", +needsU64, 0, [
      u32OrU64(creationTime),
      // Creation time
      u32OrU64(creationTime),
      // Modification time
      u32(GLOBAL_TIMESCALE),
      // Timescale
      u32OrU64(duration),
      // Duration
      fixed_16_16(1),
      // Preferred rate
      fixed_8_8(1),
      // Preferred volume
      Array(10).fill(0),
      // Reserved
      matrixToBytes(IDENTITY_MATRIX),
      // Matrix
      Array(24).fill(0),
      // Pre-defined
      u32(nextTrackId)
      // Next track ID
    ]);
  };
  var trak = (trackData, creationTime) => box("trak", void 0, [
    tkhd(trackData, creationTime),
    mdia(trackData, creationTime)
  ]);
  var tkhd = (trackData, creationTime) => {
    const lastSample = lastPresentedSample(trackData.samples);
    const durationInGlobalTimescale = intoTimescale(
      lastSample ? lastSample.timestamp + lastSample.duration : 0,
      GLOBAL_TIMESCALE
    );
    const needsU64 = !isU32(creationTime) || !isU32(durationInGlobalTimescale);
    const u32OrU64 = needsU64 ? u64 : u32;
    let matrix;
    if (trackData.type === "video") {
      const rotation = trackData.track.metadata.rotation;
      matrix = rotationMatrix(rotation ?? 0);
    } else {
      matrix = IDENTITY_MATRIX;
    }
    return fullBox("tkhd", +needsU64, 3, [
      u32OrU64(creationTime),
      // Creation time
      u32OrU64(creationTime),
      // Modification time
      u32(trackData.track.id),
      // Track ID
      u32(0),
      // Reserved
      u32OrU64(durationInGlobalTimescale),
      // Duration
      Array(8).fill(0),
      // Reserved
      u16(0),
      // Layer
      u16(trackData.track.id),
      // Alternate group
      fixed_8_8(trackData.type === "audio" ? 1 : 0),
      // Volume
      u16(0),
      // Reserved
      matrixToBytes(matrix),
      // Matrix
      fixed_16_16(trackData.type === "video" ? trackData.info.width : 0),
      // Track width
      fixed_16_16(trackData.type === "video" ? trackData.info.height : 0)
      // Track height
    ]);
  };
  var mdia = (trackData, creationTime) => box("mdia", void 0, [
    mdhd(trackData, creationTime),
    hdlr(trackData),
    minf(trackData)
  ]);
  var mdhd = (trackData, creationTime) => {
    const lastSample = lastPresentedSample(trackData.samples);
    const localDuration = intoTimescale(
      lastSample ? lastSample.timestamp + lastSample.duration : 0,
      trackData.timescale
    );
    const needsU64 = !isU32(creationTime) || !isU32(localDuration);
    const u32OrU64 = needsU64 ? u64 : u32;
    let language = 0;
    for (const character of trackData.track.metadata.languageCode ?? UNDETERMINED_LANGUAGE) {
      language <<= 5;
      language += character.charCodeAt(0) - 96;
    }
    return fullBox("mdhd", +needsU64, 0, [
      u32OrU64(creationTime),
      // Creation time
      u32OrU64(creationTime),
      // Modification time
      u32(trackData.timescale),
      // Timescale
      u32OrU64(localDuration),
      // Duration
      u16(language),
      // Language
      u16(0)
      // Quality
    ]);
  };
  var TRACK_TYPE_TO_COMPONENT_SUBTYPE = {
    video: "vide",
    audio: "soun",
    subtitle: "text"
  };
  var TRACK_TYPE_TO_HANDLER_NAME = {
    video: "MediabunnyVideoHandler",
    audio: "MediabunnySoundHandler",
    subtitle: "MediabunnyTextHandler"
  };
  var hdlr = (trackData) => fullBox("hdlr", 0, 0, [
    ascii("mhlr"),
    // Component type
    ascii(TRACK_TYPE_TO_COMPONENT_SUBTYPE[trackData.type]),
    // Component subtype
    u32(0),
    // Component manufacturer
    u32(0),
    // Component flags
    u32(0),
    // Component flags mask
    ascii(TRACK_TYPE_TO_HANDLER_NAME[trackData.type], true)
    // Component name
  ]);
  var minf = (trackData) => box("minf", void 0, [
    TRACK_TYPE_TO_HEADER_BOX[trackData.type](),
    dinf(),
    stbl(trackData)
  ]);
  var vmhd = () => fullBox("vmhd", 0, 1, [
    u16(0),
    // Graphics mode
    u16(0),
    // Opcolor R
    u16(0),
    // Opcolor G
    u16(0)
    // Opcolor B
  ]);
  var smhd = () => fullBox("smhd", 0, 0, [
    u16(0),
    // Balance
    u16(0)
    // Reserved
  ]);
  var nmhd = () => fullBox("nmhd", 0, 0);
  var TRACK_TYPE_TO_HEADER_BOX = {
    video: vmhd,
    audio: smhd,
    subtitle: nmhd
  };
  var dinf = () => box("dinf", void 0, [
    dref()
  ]);
  var dref = () => fullBox("dref", 0, 0, [
    u32(1)
    // Entry count
  ], [
    url()
  ]);
  var url = () => fullBox("url ", 0, 1);
  var stbl = (trackData) => {
    const needsCtts = trackData.compositionTimeOffsetTable.length > 1 || trackData.compositionTimeOffsetTable.some((x) => x.sampleCompositionTimeOffset !== 0);
    return box("stbl", void 0, [
      stsd(trackData),
      stts(trackData),
      needsCtts ? ctts(trackData) : null,
      needsCtts ? cslg(trackData) : null,
      stsc(trackData),
      stsz(trackData),
      stco(trackData),
      stss(trackData)
    ]);
  };
  var stsd = (trackData) => {
    let sampleDescription;
    if (trackData.type === "video") {
      sampleDescription = videoSampleDescription(
        VIDEO_CODEC_TO_BOX_NAME[trackData.track.source._codec],
        trackData
      );
    } else if (trackData.type === "audio") {
      const boxName = audioCodecToBoxName(trackData.track.source._codec, trackData.muxer.isQuickTime);
      assert(boxName);
      sampleDescription = soundSampleDescription(
        boxName,
        trackData
      );
    } else if (trackData.type === "subtitle") {
      sampleDescription = subtitleSampleDescription(
        SUBTITLE_CODEC_TO_BOX_NAME[trackData.track.source._codec],
        trackData
      );
    }
    assert(sampleDescription);
    return fullBox("stsd", 0, 0, [
      u32(1)
      // Entry count
    ], [
      sampleDescription
    ]);
  };
  var videoSampleDescription = (compressionType, trackData) => box(compressionType, [
    Array(6).fill(0),
    // Reserved
    u16(1),
    // Data reference index
    u16(0),
    // Pre-defined
    u16(0),
    // Reserved
    Array(12).fill(0),
    // Pre-defined
    u16(trackData.info.width),
    // Width
    u16(trackData.info.height),
    // Height
    u32(4718592),
    // Horizontal resolution
    u32(4718592),
    // Vertical resolution
    u32(0),
    // Reserved
    u16(1),
    // Frame count
    Array(32).fill(0),
    // Compressor name
    u16(24),
    // Depth
    i16(65535)
    // Pre-defined
  ], [
    VIDEO_CODEC_TO_CONFIGURATION_BOX[trackData.track.source._codec](trackData),
    colorSpaceIsComplete(trackData.info.decoderConfig.colorSpace) ? colr(trackData) : null
  ]);
  var colr = (trackData) => box("colr", [
    ascii("nclx"),
    // Colour type
    u16(COLOR_PRIMARIES_MAP[trackData.info.decoderConfig.colorSpace.primaries]),
    // Colour primaries
    u16(TRANSFER_CHARACTERISTICS_MAP[trackData.info.decoderConfig.colorSpace.transfer]),
    // Transfer characteristics
    u16(MATRIX_COEFFICIENTS_MAP[trackData.info.decoderConfig.colorSpace.matrix]),
    // Matrix coefficients
    u8((trackData.info.decoderConfig.colorSpace.fullRange ? 1 : 0) << 7)
    // Full range flag
  ]);
  var avcC = (trackData) => trackData.info.decoderConfig && box("avcC", [
    // For AVC, description is an AVCDecoderConfigurationRecord, so nothing else to do here
    ...toUint8Array(trackData.info.decoderConfig.description)
  ]);
  var hvcC = (trackData) => trackData.info.decoderConfig && box("hvcC", [
    // For HEVC, description is an HEVCDecoderConfigurationRecord, so nothing else to do here
    ...toUint8Array(trackData.info.decoderConfig.description)
  ]);
  var vpcC = (trackData) => {
    if (!trackData.info.decoderConfig) {
      return null;
    }
    const decoderConfig = trackData.info.decoderConfig;
    const parts = decoderConfig.codec.split(".");
    const profile = Number(parts[1]);
    const level = Number(parts[2]);
    const bitDepth = Number(parts[3]);
    const chromaSubsampling = parts[4] ? Number(parts[4]) : 1;
    const videoFullRangeFlag = parts[8] ? Number(parts[8]) : Number(decoderConfig.colorSpace?.fullRange ?? 0);
    const thirdByte = (bitDepth << 4) + (chromaSubsampling << 1) + videoFullRangeFlag;
    const colourPrimaries = parts[5] ? Number(parts[5]) : decoderConfig.colorSpace?.primaries ? COLOR_PRIMARIES_MAP[decoderConfig.colorSpace.primaries] : 2;
    const transferCharacteristics = parts[6] ? Number(parts[6]) : decoderConfig.colorSpace?.transfer ? TRANSFER_CHARACTERISTICS_MAP[decoderConfig.colorSpace.transfer] : 2;
    const matrixCoefficients = parts[7] ? Number(parts[7]) : decoderConfig.colorSpace?.matrix ? MATRIX_COEFFICIENTS_MAP[decoderConfig.colorSpace.matrix] : 2;
    return fullBox("vpcC", 1, 0, [
      u8(profile),
      // Profile
      u8(level),
      // Level
      u8(thirdByte),
      // Bit depth, chroma subsampling, full range
      u8(colourPrimaries),
      // Colour primaries
      u8(transferCharacteristics),
      // Transfer characteristics
      u8(matrixCoefficients),
      // Matrix coefficients
      u16(0)
      // Codec initialization data size
    ]);
  };
  var av1C = (trackData) => {
    return box("av1C", generateAv1CodecConfigurationFromCodecString(trackData.info.decoderConfig.codec));
  };
  var soundSampleDescription = (compressionType, trackData) => {
    let version = 0;
    let contents;
    let sampleSizeInBits = 16;
    if (PCM_AUDIO_CODECS.includes(trackData.track.source._codec)) {
      const codec = trackData.track.source._codec;
      const { sampleSize } = parsePcmCodec(codec);
      sampleSizeInBits = 8 * sampleSize;
      if (sampleSizeInBits > 16) {
        version = 1;
      }
    }
    if (version === 0) {
      contents = [
        Array(6).fill(0),
        // Reserved
        u16(1),
        // Data reference index
        u16(version),
        // Version
        u16(0),
        // Revision level
        u32(0),
        // Vendor
        u16(trackData.info.numberOfChannels),
        // Number of channels
        u16(sampleSizeInBits),
        // Sample size (bits)
        u16(0),
        // Compression ID
        u16(0),
        // Packet size
        u16(trackData.info.sampleRate < 2 ** 16 ? trackData.info.sampleRate : 0),
        // Sample rate (upper)
        u16(0)
        // Sample rate (lower)
      ];
    } else {
      contents = [
        Array(6).fill(0),
        // Reserved
        u16(1),
        // Data reference index
        u16(version),
        // Version
        u16(0),
        // Revision level
        u32(0),
        // Vendor
        u16(trackData.info.numberOfChannels),
        // Number of channels
        u16(Math.min(sampleSizeInBits, 16)),
        // Sample size (bits)
        u16(0),
        // Compression ID
        u16(0),
        // Packet size
        u16(trackData.info.sampleRate < 2 ** 16 ? trackData.info.sampleRate : 0),
        // Sample rate (upper)
        u16(0),
        // Sample rate (lower)
        u32(1),
        // Samples per packet (must be 1 for uncompressed formats)
        u32(sampleSizeInBits / 8),
        // Bytes per packet
        u32(trackData.info.numberOfChannels * sampleSizeInBits / 8),
        // Bytes per frame
        u32(2)
        // Bytes per sample (constant in FFmpeg)
      ];
    }
    return box(compressionType, contents, [
      audioCodecToConfigurationBox(trackData.track.source._codec, trackData.muxer.isQuickTime)?.(trackData) ?? null
    ]);
  };
  var esds = (trackData) => {
    let objectTypeIndication;
    switch (trackData.track.source._codec) {
      case "aac":
        {
          objectTypeIndication = 64;
        }
        ;
        break;
      case "mp3":
        {
          objectTypeIndication = 107;
        }
        ;
        break;
      case "vorbis":
        {
          objectTypeIndication = 221;
        }
        ;
        break;
      default:
        throw new Error(`Unhandled audio codec: ${trackData.track.source._codec}`);
    }
    let bytes2 = [
      ...u8(objectTypeIndication),
      // Object type indication
      ...u8(21),
      // stream type(6bits)=5 audio, flags(2bits)=1
      ...u24(0),
      // 24bit buffer size
      ...u32(0),
      // max bitrate
      ...u32(0)
      // avg bitrate
    ];
    if (trackData.info.decoderConfig.description) {
      const description = toUint8Array(trackData.info.decoderConfig.description);
      bytes2 = [
        ...bytes2,
        ...u8(5),
        // TAG(5) = DecoderSpecificInfo
        ...variableUnsignedInt(description.byteLength),
        ...description
      ];
    }
    bytes2 = [
      ...u16(1),
      // ES_ID = 1
      ...u8(0),
      // flags etc = 0
      ...u8(4),
      // TAG(4) = ES Descriptor
      ...variableUnsignedInt(bytes2.length),
      ...bytes2,
      ...u8(6),
      // TAG(6)
      ...u8(1),
      // length
      ...u8(2)
      // data
    ];
    bytes2 = [
      ...u8(3),
      // TAG(3) = Object Descriptor
      ...variableUnsignedInt(bytes2.length),
      ...bytes2
    ];
    return fullBox("esds", 0, 0, bytes2);
  };
  var wave = (trackData) => {
    return box("wave", void 0, [
      frma(trackData),
      enda(trackData),
      box("\0\0\0\0")
      // NULL tag at the end
    ]);
  };
  var frma = (trackData) => {
    return box("frma", [
      ascii(audioCodecToBoxName(trackData.track.source._codec, trackData.muxer.isQuickTime))
    ]);
  };
  var enda = (trackData) => {
    const { littleEndian } = parsePcmCodec(trackData.track.source._codec);
    return box("enda", [
      u16(+littleEndian)
    ]);
  };
  var dOps = (trackData) => {
    let outputChannelCount = trackData.info.numberOfChannels;
    let preSkip = 3840;
    let inputSampleRate = trackData.info.sampleRate;
    let outputGain = 0;
    let channelMappingFamily = 0;
    let channelMappingTable = new Uint8Array(0);
    const description = trackData.info.decoderConfig?.description;
    if (description) {
      assert(description.byteLength >= 18);
      const bytes2 = toUint8Array(description);
      const header = parseOpusIdentificationHeader(bytes2);
      outputChannelCount = header.outputChannelCount;
      preSkip = header.preSkip;
      inputSampleRate = header.inputSampleRate;
      outputGain = header.outputGain;
      channelMappingFamily = header.channelMappingFamily;
      if (header.channelMappingTable) {
        channelMappingTable = header.channelMappingTable;
      }
    }
    return box("dOps", [
      u8(0),
      // Version
      u8(outputChannelCount),
      // OutputChannelCount
      u16(preSkip),
      // PreSkip
      u32(inputSampleRate),
      // InputSampleRate
      i16(outputGain),
      // OutputGain
      u8(channelMappingFamily),
      // ChannelMappingFamily
      ...channelMappingTable
    ]);
  };
  var dfLa = (trackData) => {
    const description = trackData.info.decoderConfig?.description;
    assert(description);
    const bytes2 = toUint8Array(description);
    return fullBox("dfLa", 0, 0, [
      ...bytes2.subarray(4)
    ]);
  };
  var pcmC = (trackData) => {
    const { littleEndian, sampleSize } = parsePcmCodec(trackData.track.source._codec);
    const formatFlags = +littleEndian;
    return fullBox("pcmC", 0, 0, [
      u8(formatFlags),
      u8(8 * sampleSize)
    ]);
  };
  var subtitleSampleDescription = (compressionType, trackData) => box(compressionType, [
    Array(6).fill(0),
    // Reserved
    u16(1)
    // Data reference index
  ], [
    SUBTITLE_CODEC_TO_CONFIGURATION_BOX[trackData.track.source._codec](trackData)
  ]);
  var vttC = (trackData) => box("vttC", [
    ...textEncoder.encode(trackData.info.config.description)
  ]);
  var stts = (trackData) => {
    return fullBox("stts", 0, 0, [
      u32(trackData.timeToSampleTable.length),
      // Number of entries
      trackData.timeToSampleTable.map((x) => [
        // Time-to-sample table
        u32(x.sampleCount),
        // Sample count
        u32(x.sampleDelta)
        // Sample duration
      ])
    ]);
  };
  var stss = (trackData) => {
    if (trackData.samples.every((x) => x.type === "key")) return null;
    const keySamples = [...trackData.samples.entries()].filter(([, sample]) => sample.type === "key");
    return fullBox("stss", 0, 0, [
      u32(keySamples.length),
      // Number of entries
      keySamples.map(([index]) => u32(index + 1))
      // Sync sample table
    ]);
  };
  var stsc = (trackData) => {
    return fullBox("stsc", 0, 0, [
      u32(trackData.compactlyCodedChunkTable.length),
      // Number of entries
      trackData.compactlyCodedChunkTable.map((x) => [
        // Sample-to-chunk table
        u32(x.firstChunk),
        // First chunk
        u32(x.samplesPerChunk),
        // Samples per chunk
        u32(1)
        // Sample description index
      ])
    ]);
  };
  var stsz = (trackData) => {
    if (trackData.type === "audio" && trackData.info.requiresPcmTransformation) {
      const { sampleSize } = parsePcmCodec(trackData.track.source._codec);
      return fullBox("stsz", 0, 0, [
        u32(sampleSize * trackData.info.numberOfChannels),
        // Sample size
        u32(trackData.samples.reduce((acc, x) => acc + intoTimescale(x.duration, trackData.timescale), 0))
      ]);
    }
    return fullBox("stsz", 0, 0, [
      u32(0),
      // Sample size (0 means non-constant size)
      u32(trackData.samples.length),
      // Number of entries
      trackData.samples.map((x) => u32(x.size))
      // Sample size table
    ]);
  };
  var stco = (trackData) => {
    if (trackData.finalizedChunks.length > 0 && last(trackData.finalizedChunks).offset >= 2 ** 32) {
      return fullBox("co64", 0, 0, [
        u32(trackData.finalizedChunks.length),
        // Number of entries
        trackData.finalizedChunks.map((x) => u64(x.offset))
        // Chunk offset table
      ]);
    }
    return fullBox("stco", 0, 0, [
      u32(trackData.finalizedChunks.length),
      // Number of entries
      trackData.finalizedChunks.map((x) => u32(x.offset))
      // Chunk offset table
    ]);
  };
  var ctts = (trackData) => {
    return fullBox("ctts", 1, 0, [
      u32(trackData.compositionTimeOffsetTable.length),
      // Number of entries
      trackData.compositionTimeOffsetTable.map((x) => [
        // Time-to-sample table
        u32(x.sampleCount),
        // Sample count
        i32(x.sampleCompositionTimeOffset)
        // Sample offset
      ])
    ]);
  };
  var cslg = (trackData) => {
    let leastDecodeToDisplayDelta = Infinity;
    let greatestDecodeToDisplayDelta = -Infinity;
    let compositionStartTime = Infinity;
    let compositionEndTime = -Infinity;
    assert(trackData.compositionTimeOffsetTable.length > 0);
    assert(trackData.samples.length > 0);
    for (let i = 0; i < trackData.compositionTimeOffsetTable.length; i++) {
      const entry = trackData.compositionTimeOffsetTable[i];
      leastDecodeToDisplayDelta = Math.min(leastDecodeToDisplayDelta, entry.sampleCompositionTimeOffset);
      greatestDecodeToDisplayDelta = Math.max(greatestDecodeToDisplayDelta, entry.sampleCompositionTimeOffset);
    }
    for (let i = 0; i < trackData.samples.length; i++) {
      const sample = trackData.samples[i];
      compositionStartTime = Math.min(
        compositionStartTime,
        intoTimescale(sample.timestamp, trackData.timescale)
      );
      compositionEndTime = Math.max(
        compositionEndTime,
        intoTimescale(sample.timestamp + sample.duration, trackData.timescale)
      );
    }
    const compositionToDtsShift = Math.max(-leastDecodeToDisplayDelta, 0);
    if (compositionEndTime >= 2 ** 31) {
      return null;
    }
    return fullBox("cslg", 0, 0, [
      i32(compositionToDtsShift),
      // Composition to DTS shift
      i32(leastDecodeToDisplayDelta),
      // Least decode to display delta
      i32(greatestDecodeToDisplayDelta),
      // Greatest decode to display delta
      i32(compositionStartTime),
      // Composition start time
      i32(compositionEndTime)
      // Composition end time
    ]);
  };
  var mvex = (trackDatas) => {
    return box("mvex", void 0, trackDatas.map(trex));
  };
  var trex = (trackData) => {
    return fullBox("trex", 0, 0, [
      u32(trackData.track.id),
      // Track ID
      u32(1),
      // Default sample description index
      u32(0),
      // Default sample duration
      u32(0),
      // Default sample size
      u32(0)
      // Default sample flags
    ]);
  };
  var moof = (sequenceNumber, trackDatas) => {
    return box("moof", void 0, [
      mfhd(sequenceNumber),
      ...trackDatas.map(traf)
    ]);
  };
  var mfhd = (sequenceNumber) => {
    return fullBox("mfhd", 0, 0, [
      u32(sequenceNumber)
      // Sequence number
    ]);
  };
  var fragmentSampleFlags = (sample) => {
    let byte1 = 0;
    let byte2 = 0;
    const byte3 = 0;
    const byte4 = 0;
    const sampleIsDifferenceSample = sample.type === "delta";
    byte2 |= +sampleIsDifferenceSample;
    if (sampleIsDifferenceSample) {
      byte1 |= 1;
    } else {
      byte1 |= 2;
    }
    return byte1 << 24 | byte2 << 16 | byte3 << 8 | byte4;
  };
  var traf = (trackData) => {
    return box("traf", void 0, [
      tfhd(trackData),
      tfdt(trackData),
      trun(trackData)
    ]);
  };
  var tfhd = (trackData) => {
    assert(trackData.currentChunk);
    let tfFlags = 0;
    tfFlags |= 8;
    tfFlags |= 16;
    tfFlags |= 32;
    tfFlags |= 131072;
    const referenceSample = trackData.currentChunk.samples[1] ?? trackData.currentChunk.samples[0];
    const referenceSampleInfo = {
      duration: referenceSample.timescaleUnitsToNextSample,
      size: referenceSample.size,
      flags: fragmentSampleFlags(referenceSample)
    };
    return fullBox("tfhd", 0, tfFlags, [
      u32(trackData.track.id),
      // Track ID
      u32(referenceSampleInfo.duration),
      // Default sample duration
      u32(referenceSampleInfo.size),
      // Default sample size
      u32(referenceSampleInfo.flags)
      // Default sample flags
    ]);
  };
  var tfdt = (trackData) => {
    assert(trackData.currentChunk);
    return fullBox("tfdt", 1, 0, [
      u64(intoTimescale(trackData.currentChunk.startTimestamp, trackData.timescale))
      // Base Media Decode Time
    ]);
  };
  var trun = (trackData) => {
    assert(trackData.currentChunk);
    const allSampleDurations = trackData.currentChunk.samples.map((x) => x.timescaleUnitsToNextSample);
    const allSampleSizes = trackData.currentChunk.samples.map((x) => x.size);
    const allSampleFlags = trackData.currentChunk.samples.map(fragmentSampleFlags);
    const allSampleCompositionTimeOffsets = trackData.currentChunk.samples.map((x) => intoTimescale(x.timestamp - x.decodeTimestamp, trackData.timescale));
    const uniqueSampleDurations = new Set(allSampleDurations);
    const uniqueSampleSizes = new Set(allSampleSizes);
    const uniqueSampleFlags = new Set(allSampleFlags);
    const uniqueSampleCompositionTimeOffsets = new Set(allSampleCompositionTimeOffsets);
    const firstSampleFlagsPresent = uniqueSampleFlags.size === 2 && allSampleFlags[0] !== allSampleFlags[1];
    const sampleDurationPresent = uniqueSampleDurations.size > 1;
    const sampleSizePresent = uniqueSampleSizes.size > 1;
    const sampleFlagsPresent = !firstSampleFlagsPresent && uniqueSampleFlags.size > 1;
    const sampleCompositionTimeOffsetsPresent = uniqueSampleCompositionTimeOffsets.size > 1 || [...uniqueSampleCompositionTimeOffsets].some((x) => x !== 0);
    let flags = 0;
    flags |= 1;
    flags |= 4 * +firstSampleFlagsPresent;
    flags |= 256 * +sampleDurationPresent;
    flags |= 512 * +sampleSizePresent;
    flags |= 1024 * +sampleFlagsPresent;
    flags |= 2048 * +sampleCompositionTimeOffsetsPresent;
    return fullBox("trun", 1, flags, [
      u32(trackData.currentChunk.samples.length),
      // Sample count
      u32(trackData.currentChunk.offset - trackData.currentChunk.moofOffset || 0),
      // Data offset
      firstSampleFlagsPresent ? u32(allSampleFlags[0]) : [],
      trackData.currentChunk.samples.map((_, i) => [
        sampleDurationPresent ? u32(allSampleDurations[i]) : [],
        // Sample duration
        sampleSizePresent ? u32(allSampleSizes[i]) : [],
        // Sample size
        sampleFlagsPresent ? u32(allSampleFlags[i]) : [],
        // Sample flags
        // Sample composition time offsets
        sampleCompositionTimeOffsetsPresent ? i32(allSampleCompositionTimeOffsets[i]) : []
      ])
    ]);
  };
  var mfra = (trackDatas) => {
    return box("mfra", void 0, [
      ...trackDatas.map(tfra),
      mfro()
    ]);
  };
  var tfra = (trackData, trackIndex) => {
    const version = 1;
    return fullBox("tfra", version, 0, [
      u32(trackData.track.id),
      // Track ID
      u32(63),
      // This specifies that traf number, trun number and sample number are 32-bit ints
      u32(trackData.finalizedChunks.length),
      // Number of entries
      trackData.finalizedChunks.map((chunk) => [
        u64(intoTimescale(chunk.samples[0].timestamp, trackData.timescale)),
        // Time (in presentation time)
        u64(chunk.moofOffset),
        // moof offset
        u32(trackIndex + 1),
        // traf number
        u32(1),
        // trun number
        u32(1)
        // Sample number
      ])
    ]);
  };
  var mfro = () => {
    return fullBox("mfro", 0, 0, [
      // This value needs to be overwritten manually from the outside, where the actual size of the enclosing mfra box
      // is known
      u32(0)
      // Size
    ]);
  };
  var vtte = () => box("vtte");
  var vttc = (payload, timestamp, identifier, settings, sourceId) => box("vttc", void 0, [
    sourceId !== null ? box("vsid", [i32(sourceId)]) : null,
    identifier !== null ? box("iden", [...textEncoder.encode(identifier)]) : null,
    timestamp !== null ? box("ctim", [...textEncoder.encode(formatSubtitleTimestamp(timestamp))]) : null,
    settings !== null ? box("sttg", [...textEncoder.encode(settings)]) : null,
    box("payl", [...textEncoder.encode(payload)])
  ]);
  var vtta = (notes) => box("vtta", [...textEncoder.encode(notes)]);
  var VIDEO_CODEC_TO_BOX_NAME = {
    avc: "avc1",
    hevc: "hvc1",
    vp8: "vp08",
    vp9: "vp09",
    av1: "av01"
  };
  var VIDEO_CODEC_TO_CONFIGURATION_BOX = {
    avc: avcC,
    hevc: hvcC,
    vp8: vpcC,
    vp9: vpcC,
    av1: av1C
  };
  var audioCodecToBoxName = (codec, isQuickTime) => {
    switch (codec) {
      case "aac":
        return "mp4a";
      case "mp3":
        return "mp4a";
      case "opus":
        return "Opus";
      case "vorbis":
        return "mp4a";
      case "flac":
        return "fLaC";
      case "ulaw":
        return "ulaw";
      case "alaw":
        return "alaw";
      case "pcm-u8":
        return "raw ";
      case "pcm-s8":
        return "sowt";
    }
    if (isQuickTime) {
      switch (codec) {
        case "pcm-s16":
          return "sowt";
        case "pcm-s16be":
          return "twos";
        case "pcm-s24":
          return "in24";
        case "pcm-s24be":
          return "in24";
        case "pcm-s32":
          return "in32";
        case "pcm-s32be":
          return "in32";
        case "pcm-f32":
          return "fl32";
        case "pcm-f32be":
          return "fl32";
        case "pcm-f64":
          return "fl64";
        case "pcm-f64be":
          return "fl64";
      }
    } else {
      switch (codec) {
        case "pcm-s16":
          return "ipcm";
        case "pcm-s16be":
          return "ipcm";
        case "pcm-s24":
          return "ipcm";
        case "pcm-s24be":
          return "ipcm";
        case "pcm-s32":
          return "ipcm";
        case "pcm-s32be":
          return "ipcm";
        case "pcm-f32":
          return "fpcm";
        case "pcm-f32be":
          return "fpcm";
        case "pcm-f64":
          return "fpcm";
        case "pcm-f64be":
          return "fpcm";
      }
    }
  };
  var audioCodecToConfigurationBox = (codec, isQuickTime) => {
    switch (codec) {
      case "aac":
        return esds;
      case "mp3":
        return esds;
      case "opus":
        return dOps;
      case "vorbis":
        return esds;
      case "flac":
        return dfLa;
    }
    if (isQuickTime) {
      switch (codec) {
        case "pcm-s24":
          return wave;
        case "pcm-s24be":
          return wave;
        case "pcm-s32":
          return wave;
        case "pcm-s32be":
          return wave;
        case "pcm-f32":
          return wave;
        case "pcm-f32be":
          return wave;
        case "pcm-f64":
          return wave;
        case "pcm-f64be":
          return wave;
      }
    } else {
      switch (codec) {
        case "pcm-s16":
          return pcmC;
        case "pcm-s16be":
          return pcmC;
        case "pcm-s24":
          return pcmC;
        case "pcm-s24be":
          return pcmC;
        case "pcm-s32":
          return pcmC;
        case "pcm-s32be":
          return pcmC;
        case "pcm-f32":
          return pcmC;
        case "pcm-f32be":
          return pcmC;
        case "pcm-f64":
          return pcmC;
        case "pcm-f64be":
          return pcmC;
      }
    }
    return null;
  };
  var SUBTITLE_CODEC_TO_BOX_NAME = {
    webvtt: "wvtt"
  };
  var SUBTITLE_CODEC_TO_CONFIGURATION_BOX = {
    webvtt: vttC
  };

  // src/muxer.ts
  var Muxer = class {
    constructor(output) {
      this.mutex = new AsyncMutex();
      /**
       * This field is used to synchronize multiple MediaStreamTracks. They use the same time coordinate system across
       * tracks, and to ensure correct audio-video sync, we must use the same offset for all of them. The reason an offset
       * is needed at all is because the timestamps typically don't start at zero.
       */
      this.firstMediaStreamTimestamp = null;
      this.trackTimestampInfo = /* @__PURE__ */ new WeakMap();
      this.output = output;
    }
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    onTrackClose(track) {
    }
    validateAndNormalizeTimestamp(track, timestampInSeconds, isKeyFrame) {
      timestampInSeconds += track.source._timestampOffset;
      let timestampInfo = this.trackTimestampInfo.get(track);
      if (!timestampInfo) {
        if (!isKeyFrame) {
          throw new Error("First frame must be a key frame.");
        }
        timestampInfo = {
          maxTimestamp: timestampInSeconds,
          maxTimestampBeforeLastKeyFrame: timestampInSeconds
        };
        this.trackTimestampInfo.set(track, timestampInfo);
      }
      if (timestampInSeconds < 0) {
        throw new Error(`Timestamps must be non-negative (got ${timestampInSeconds}s).`);
      }
      if (isKeyFrame) {
        timestampInfo.maxTimestampBeforeLastKeyFrame = timestampInfo.maxTimestamp;
      }
      if (timestampInSeconds < timestampInfo.maxTimestampBeforeLastKeyFrame) {
        throw new Error(
          `Timestamps cannot be smaller than the highest timestamp of the previous run (a run begins with a key frame and ends right before the next key frame). Got ${timestampInSeconds}s, but highest timestamp is ${timestampInfo.maxTimestampBeforeLastKeyFrame}s.`
        );
      }
      timestampInfo.maxTimestamp = Math.max(timestampInfo.maxTimestamp, timestampInSeconds);
      return timestampInSeconds;
    }
  };

  // src/writer.ts
  var Writer = class {
    constructor() {
      /** Setting this to true will cause the writer to ensure data is written in a strictly monotonic, streamable way. */
      this.ensureMonotonicity = false;
      this.trackedWrites = null;
      this.trackedStart = -1;
      this.trackedEnd = -1;
    }
    start() {
    }
    maybeTrackWrites(data) {
      if (!this.trackedWrites) {
        return;
      }
      let pos = this.getPos();
      if (pos < this.trackedStart) {
        if (pos + data.byteLength <= this.trackedStart) {
          return;
        }
        data = data.subarray(this.trackedStart - pos);
        pos = 0;
      }
      const neededSize = pos + data.byteLength - this.trackedStart;
      let newLength = this.trackedWrites.byteLength;
      while (newLength < neededSize) {
        newLength *= 2;
      }
      if (newLength !== this.trackedWrites.byteLength) {
        const copy = new Uint8Array(newLength);
        copy.set(this.trackedWrites, 0);
        this.trackedWrites = copy;
      }
      this.trackedWrites.set(data, pos - this.trackedStart);
      this.trackedEnd = Math.max(this.trackedEnd, pos + data.byteLength);
    }
    startTrackingWrites() {
      this.trackedWrites = new Uint8Array(2 ** 10);
      this.trackedStart = this.getPos();
      this.trackedEnd = this.trackedStart;
    }
    stopTrackingWrites() {
      if (!this.trackedWrites) {
        throw new Error("Internal error: Can't get tracked writes since nothing was tracked.");
      }
      const slice = this.trackedWrites.subarray(0, this.trackedEnd - this.trackedStart);
      const result = {
        data: slice,
        start: this.trackedStart,
        end: this.trackedEnd
      };
      this.trackedWrites = null;
      return result;
    }
  };
  var ARRAY_BUFFER_INITIAL_SIZE = 2 ** 16;
  var ARRAY_BUFFER_MAX_SIZE = 2 ** 32;
  var BufferTargetWriter = class extends Writer {
    constructor(target) {
      super();
      this.pos = 0;
      this.maxPos = 0;
      this.target = target;
      this.supportsResize = "resize" in new ArrayBuffer(0);
      if (this.supportsResize) {
        try {
          this.buffer = new ArrayBuffer(ARRAY_BUFFER_INITIAL_SIZE, { maxByteLength: ARRAY_BUFFER_MAX_SIZE });
        } catch {
          this.buffer = new ArrayBuffer(ARRAY_BUFFER_INITIAL_SIZE);
          this.supportsResize = false;
        }
      } else {
        this.buffer = new ArrayBuffer(ARRAY_BUFFER_INITIAL_SIZE);
      }
      this.bytes = new Uint8Array(this.buffer);
    }
    ensureSize(size) {
      let newLength = this.buffer.byteLength;
      while (newLength < size) newLength *= 2;
      if (newLength === this.buffer.byteLength) return;
      if (newLength > ARRAY_BUFFER_MAX_SIZE) {
        throw new Error(
          `ArrayBuffer exceeded maximum size of ${ARRAY_BUFFER_MAX_SIZE} bytes. Please consider using another target.`
        );
      }
      if (this.supportsResize) {
        this.buffer.resize(newLength);
      } else {
        const newBuffer = new ArrayBuffer(newLength);
        const newBytes = new Uint8Array(newBuffer);
        newBytes.set(this.bytes, 0);
        this.buffer = newBuffer;
        this.bytes = newBytes;
      }
    }
    write(data) {
      this.maybeTrackWrites(data);
      this.ensureSize(this.pos + data.byteLength);
      this.bytes.set(data, this.pos);
      this.pos += data.byteLength;
      this.maxPos = Math.max(this.maxPos, this.pos);
    }
    seek(newPos) {
      this.pos = newPos;
    }
    getPos() {
      return this.pos;
    }
    async flush() {
    }
    async finalize() {
      this.ensureSize(this.pos);
      this.target.buffer = this.buffer.slice(0, Math.max(this.maxPos, this.pos));
    }
    async close() {
    }
    getSlice(start, end) {
      return this.bytes.slice(start, end);
    }
  };
  var DEFAULT_CHUNK_SIZE = 2 ** 24;
  var MAX_CHUNKS_AT_ONCE = 2;
  var StreamTargetWriter = class extends Writer {
    constructor(target) {
      super();
      this.pos = 0;
      this.sections = [];
      this.lastWriteEnd = 0;
      this.lastFlushEnd = 0;
      this.writer = null;
      /**
       * The data is divided up into fixed-size chunks, whose contents are first filled in RAM and then flushed out.
       * A chunk is flushed if all of its contents have been written.
       */
      this.chunks = [];
      this.target = target;
      this.chunked = target._options.chunked ?? false;
      this.chunkSize = target._options.chunkSize ?? DEFAULT_CHUNK_SIZE;
    }
    start() {
      this.writer = this.target._writable.getWriter();
    }
    write(data) {
      if (this.pos > this.lastWriteEnd) {
        const paddingBytesNeeded = this.pos - this.lastWriteEnd;
        this.pos = this.lastWriteEnd;
        this.write(new Uint8Array(paddingBytesNeeded));
      }
      this.maybeTrackWrites(data);
      this.sections.push({
        data: data.slice(),
        start: this.pos
      });
      this.pos += data.byteLength;
      this.lastWriteEnd = Math.max(this.lastWriteEnd, this.pos);
    }
    seek(newPos) {
      this.pos = newPos;
    }
    getPos() {
      return this.pos;
    }
    async flush() {
      if (this.pos > this.lastWriteEnd) {
        const paddingBytesNeeded = this.pos - this.lastWriteEnd;
        this.pos = this.lastWriteEnd;
        this.write(new Uint8Array(paddingBytesNeeded));
      }
      assert(this.writer);
      if (this.sections.length === 0) return;
      const chunks = [];
      const sorted = [...this.sections].sort((a, b) => a.start - b.start);
      chunks.push({
        start: sorted[0].start,
        size: sorted[0].data.byteLength
      });
      for (let i = 1; i < sorted.length; i++) {
        const lastChunk = chunks[chunks.length - 1];
        const section = sorted[i];
        if (section.start <= lastChunk.start + lastChunk.size) {
          lastChunk.size = Math.max(lastChunk.size, section.start + section.data.byteLength - lastChunk.start);
        } else {
          chunks.push({
            start: section.start,
            size: section.data.byteLength
          });
        }
      }
      for (const chunk of chunks) {
        chunk.data = new Uint8Array(chunk.size);
        for (const section of this.sections) {
          if (chunk.start <= section.start && section.start < chunk.start + chunk.size) {
            chunk.data.set(section.data, section.start - chunk.start);
          }
        }
        if (this.writer.desiredSize !== null && this.writer.desiredSize <= 0) {
          await this.writer.ready;
        }
        if (this.chunked) {
          this.writeDataIntoChunks(chunk.data, chunk.start);
          this.tryToFlushChunks();
        } else {
          if (this.ensureMonotonicity && chunk.start !== this.lastFlushEnd) {
            throw new Error("Internal error: Monotonicity violation.");
          }
          void this.writer.write({
            type: "write",
            data: chunk.data,
            position: chunk.start
          });
          this.lastFlushEnd = chunk.start + chunk.data.byteLength;
        }
      }
      this.sections.length = 0;
    }
    writeDataIntoChunks(data, position) {
      let chunkIndex = this.chunks.findIndex((x) => x.start <= position && position < x.start + this.chunkSize);
      if (chunkIndex === -1) chunkIndex = this.createChunk(position);
      const chunk = this.chunks[chunkIndex];
      const relativePosition = position - chunk.start;
      const toWrite = data.subarray(0, Math.min(this.chunkSize - relativePosition, data.byteLength));
      chunk.data.set(toWrite, relativePosition);
      const section = {
        start: relativePosition,
        end: relativePosition + toWrite.byteLength
      };
      this.insertSectionIntoChunk(chunk, section);
      if (chunk.written[0].start === 0 && chunk.written[0].end === this.chunkSize) {
        chunk.shouldFlush = true;
      }
      if (this.chunks.length > MAX_CHUNKS_AT_ONCE) {
        for (let i = 0; i < this.chunks.length - 1; i++) {
          this.chunks[i].shouldFlush = true;
        }
        this.tryToFlushChunks();
      }
      if (toWrite.byteLength < data.byteLength) {
        this.writeDataIntoChunks(data.subarray(toWrite.byteLength), position + toWrite.byteLength);
      }
    }
    insertSectionIntoChunk(chunk, section) {
      let low = 0;
      let high = chunk.written.length - 1;
      let index = -1;
      while (low <= high) {
        const mid = Math.floor(low + (high - low + 1) / 2);
        if (chunk.written[mid].start <= section.start) {
          low = mid + 1;
          index = mid;
        } else {
          high = mid - 1;
        }
      }
      chunk.written.splice(index + 1, 0, section);
      if (index === -1 || chunk.written[index].end < section.start) index++;
      while (index < chunk.written.length - 1 && chunk.written[index].end >= chunk.written[index + 1].start) {
        chunk.written[index].end = Math.max(chunk.written[index].end, chunk.written[index + 1].end);
        chunk.written.splice(index + 1, 1);
      }
    }
    createChunk(includesPosition) {
      const start = Math.floor(includesPosition / this.chunkSize) * this.chunkSize;
      const chunk = {
        start,
        data: new Uint8Array(this.chunkSize),
        written: [],
        shouldFlush: false
      };
      this.chunks.push(chunk);
      this.chunks.sort((a, b) => a.start - b.start);
      return this.chunks.indexOf(chunk);
    }
    tryToFlushChunks(force = false) {
      assert(this.writer);
      for (let i = 0; i < this.chunks.length; i++) {
        const chunk = this.chunks[i];
        if (!chunk.shouldFlush && !force) continue;
        for (const section of chunk.written) {
          const position = chunk.start + section.start;
          if (this.ensureMonotonicity && position !== this.lastFlushEnd) {
            throw new Error("Internal error: Monotonicity violation.");
          }
          void this.writer.write({
            type: "write",
            data: chunk.data.subarray(section.start, section.end),
            position
          });
          this.lastFlushEnd = chunk.start + section.end;
        }
        this.chunks.splice(i--, 1);
      }
    }
    finalize() {
      if (this.chunked) {
        this.tryToFlushChunks(true);
      }
      assert(this.writer);
      return this.writer.close();
    }
    async close() {
      return this.writer?.close();
    }
  };

  // src/target.ts
  var Target = class {
    constructor() {
      /** @internal */
      this._output = null;
    }
  };
  var BufferTarget = class extends Target {
    constructor() {
      super(...arguments);
      /** Stores the final output buffer. Until the output is finalized, this will be null. */
      this.buffer = null;
    }
    /** @internal */
    _createWriter() {
      return new BufferTargetWriter(this);
    }
  };
  var StreamTarget = class extends Target {
    constructor(writable, options = {}) {
      super();
      if (!(writable instanceof WritableStream)) {
        throw new TypeError("StreamTarget requires a WritableStream instance.");
      }
      if (options != null && typeof options !== "object") {
        throw new TypeError("StreamTarget options, when provided, must be an object.");
      }
      if (options.chunked !== void 0 && typeof options.chunked !== "boolean") {
        throw new TypeError("options.chunked, when provided, must be a boolean.");
      }
      if (options.chunkSize !== void 0 && (!Number.isInteger(options.chunkSize) || options.chunkSize < 1024)) {
        throw new TypeError("options.chunkSize, when provided, must be an integer and not smaller than 1024.");
      }
      this._writable = writable;
      this._options = options;
    }
    /** @internal */
    _createWriter() {
      return new StreamTargetWriter(this);
    }
  };

  // src/isobmff/isobmff-misc.ts
  var buildIsobmffMimeType = (info) => {
    const base = info.hasVideo ? "video/" : info.hasAudio ? "audio/" : "application/";
    let string = base + (info.isQuickTime ? "quicktime" : "mp4");
    if (info.codecStrings.length > 0) {
      const uniqueCodecMimeTypes = [...new Set(info.codecStrings)];
      string += `; codecs="${uniqueCodecMimeTypes.join(", ")}"`;
    }
    return string;
  };

  // src/isobmff/isobmff-reader.ts
  var MIN_BOX_HEADER_SIZE = 8;
  var MAX_BOX_HEADER_SIZE = 16;
  var IsobmffReader = class {
    constructor(reader) {
      this.reader = reader;
      this.pos = 0;
    }
    readBytes(length) {
      const { view: view2, offset } = this.reader.getViewAndOffset(this.pos, this.pos + length);
      this.pos += length;
      return new Uint8Array(view2.buffer, offset, length);
    }
    readU8() {
      const { view: view2, offset } = this.reader.getViewAndOffset(this.pos, this.pos + 1);
      this.pos++;
      return view2.getUint8(offset);
    }
    readU16() {
      const { view: view2, offset } = this.reader.getViewAndOffset(this.pos, this.pos + 2);
      this.pos += 2;
      return view2.getUint16(offset, false);
    }
    readI16() {
      const { view: view2, offset } = this.reader.getViewAndOffset(this.pos, this.pos + 2);
      this.pos += 2;
      return view2.getInt16(offset, false);
    }
    readU24() {
      const { view: view2, offset } = this.reader.getViewAndOffset(this.pos, this.pos + 3);
      this.pos += 3;
      const high = view2.getUint16(offset, false);
      const low = view2.getUint8(offset + 2);
      return high * 256 + low;
    }
    readU32() {
      const { view: view2, offset } = this.reader.getViewAndOffset(this.pos, this.pos + 4);
      this.pos += 4;
      return view2.getUint32(offset, false);
    }
    readI32() {
      const { view: view2, offset } = this.reader.getViewAndOffset(this.pos, this.pos + 4);
      this.pos += 4;
      return view2.getInt32(offset, false);
    }
    readU64() {
      const high = this.readU32();
      const low = this.readU32();
      return high * 4294967296 + low;
    }
    readI64() {
      const high = this.readI32();
      const low = this.readU32();
      return high * 4294967296 + low;
    }
    readF64() {
      const { view: view2, offset } = this.reader.getViewAndOffset(this.pos, this.pos + 8);
      this.pos += 8;
      return view2.getFloat64(offset, false);
    }
    readFixed_16_16() {
      return this.readI32() / 65536;
    }
    readFixed_2_30() {
      return this.readI32() / 1073741824;
    }
    readAscii(length) {
      const { view: view2, offset } = this.reader.getViewAndOffset(this.pos, this.pos + length);
      this.pos += length;
      let str = "";
      for (let i = 0; i < length; i++) {
        str += String.fromCharCode(view2.getUint8(offset + i));
      }
      return str;
    }
    readIsomVariableInteger() {
      let result = 0;
      for (let i = 0; i < 4; i++) {
        result <<= 7;
        const nextByte = this.readU8();
        result |= nextByte & 127;
        if ((nextByte & 128) === 0) {
          break;
        }
      }
      return result;
    }
    readBoxHeader() {
      let totalSize = this.readU32();
      const name = this.readAscii(4);
      let headerSize = 8;
      const hasLargeSize = totalSize === 1;
      if (hasLargeSize) {
        totalSize = this.readU64();
        headerSize = 16;
      }
      return { name, totalSize, headerSize, contentSize: totalSize - headerSize };
    }
  };

  // src/isobmff/isobmff-muxer.ts
  var GLOBAL_TIMESCALE = 1e3;
  var TIMESTAMP_OFFSET = 2082844800;
  var intoTimescale = (timeInSeconds, timescale, round = true) => {
    const value = timeInSeconds * timescale;
    return round ? Math.round(value) : value;
  };
  var IsobmffMuxer = class extends Muxer {
    constructor(output, format) {
      super(output);
      this.auxTarget = new BufferTarget();
      this.auxWriter = this.auxTarget._createWriter();
      this.auxBoxWriter = new IsobmffBoxWriter(this.auxWriter);
      this.mdat = null;
      this.trackDatas = [];
      this.allTracksKnown = promiseWithResolvers();
      this.creationTime = Math.floor(Date.now() / 1e3) + TIMESTAMP_OFFSET;
      this.finalizedChunks = [];
      this.nextFragmentNumber = 1;
      // Only relevant for fragmented files, to make sure new fragments start with the highest timestamp seen so far
      this.maxWrittenTimestamp = -Infinity;
      this.format = format;
      this.writer = output._writer;
      this.boxWriter = new IsobmffBoxWriter(this.writer);
      this.isQuickTime = format instanceof MovOutputFormat;
      const fastStartDefault = this.writer instanceof BufferTargetWriter ? "in-memory" : false;
      this.fastStart = format._options.fastStart ?? fastStartDefault;
      this.isFragmented = this.fastStart === "fragmented";
      if (this.fastStart === "in-memory" || this.isFragmented) {
        this.writer.ensureMonotonicity = true;
      }
      this.minimumFragmentDuration = format._options.minimumFragmentDuration ?? 1;
    }
    async start() {
      const release = await this.mutex.acquire();
      const holdsAvc = this.output._tracks.some((x) => x.type === "video" && x.source._codec === "avc");
      {
        if (this.format._options.onFtyp) {
          this.writer.startTrackingWrites();
        }
        this.boxWriter.writeBox(ftyp({
          isQuickTime: this.isQuickTime,
          holdsAvc,
          fragmented: this.isFragmented
        }));
        if (this.format._options.onFtyp) {
          const { data, start } = this.writer.stopTrackingWrites();
          this.format._options.onFtyp(data, start);
        }
      }
      if (this.fastStart === "in-memory") {
        this.mdat = mdat(false);
      } else if (this.isFragmented) {
      } else {
        if (this.format._options.onMdat) {
          this.writer.startTrackingWrites();
        }
        this.mdat = mdat(true);
        this.boxWriter.writeBox(this.mdat);
      }
      await this.writer.flush();
      release();
    }
    allTracksAreKnown() {
      for (const track of this.output._tracks) {
        if (!track.source._closed && !this.trackDatas.some((x) => x.track === track)) {
          return false;
        }
      }
      return true;
    }
    async getMimeType() {
      await this.allTracksKnown.promise;
      const codecStrings = this.trackDatas.map((trackData) => {
        if (trackData.type === "video") {
          return trackData.info.decoderConfig.codec;
        } else if (trackData.type === "audio") {
          return trackData.info.decoderConfig.codec;
        } else {
          const map = {
            webvtt: "wvtt"
          };
          return map[trackData.track.source._codec];
        }
      });
      return buildIsobmffMimeType({
        isQuickTime: this.isQuickTime,
        hasVideo: this.trackDatas.some((x) => x.type === "video"),
        hasAudio: this.trackDatas.some((x) => x.type === "audio"),
        codecStrings
      });
    }
    getVideoTrackData(track, packet, meta) {
      const existingTrackData = this.trackDatas.find((x) => x.track === track);
      if (existingTrackData) {
        return existingTrackData;
      }
      validateVideoChunkMetadata(meta);
      assert(meta);
      assert(meta.decoderConfig);
      const decoderConfig = { ...meta.decoderConfig };
      assert(decoderConfig.codedWidth !== void 0);
      assert(decoderConfig.codedHeight !== void 0);
      let requiresAnnexBTransformation = false;
      if (track.source._codec === "avc" && !decoderConfig.description) {
        const decoderConfigurationRecord = extractAvcDecoderConfigurationRecord(packet.data);
        if (!decoderConfigurationRecord) {
          throw new Error(
            "Couldn't extract an AVCDecoderConfigurationRecord from the AVC packet. Make sure the packets are in Annex B format (as specified in ITU-T-REC-H.264) when not providing a description, or provide a description (must be an AVCDecoderConfigurationRecord as specified in ISO 14496-15) and ensure the packets are in AVCC format."
          );
        }
        decoderConfig.description = serializeAvcDecoderConfigurationRecord(decoderConfigurationRecord);
        requiresAnnexBTransformation = true;
      } else if (track.source._codec === "hevc" && !decoderConfig.description) {
        const decoderConfigurationRecord = extractHevcDecoderConfigurationRecord(packet.data);
        if (!decoderConfigurationRecord) {
          throw new Error(
            "Couldn't extract an HEVCDecoderConfigurationRecord from the HEVC packet. Make sure the packets are in Annex B format (as specified in ITU-T-REC-H.265) when not providing a description, or provide a description (must be an HEVCDecoderConfigurationRecord as specified in ISO 14496-15) and ensure the packets are in HEVC format."
          );
        }
        decoderConfig.description = serializeHevcDecoderConfigurationRecord(decoderConfigurationRecord);
        requiresAnnexBTransformation = true;
      }
      const timescale = computeRationalApproximation(1 / (track.metadata.frameRate ?? 57600), 1e6).denominator;
      const newTrackData = {
        muxer: this,
        track,
        type: "video",
        info: {
          width: decoderConfig.codedWidth,
          height: decoderConfig.codedHeight,
          decoderConfig,
          requiresAnnexBTransformation
        },
        timescale,
        samples: [],
        sampleQueue: [],
        timestampProcessingQueue: [],
        timeToSampleTable: [],
        compositionTimeOffsetTable: [],
        lastTimescaleUnits: null,
        lastSample: null,
        finalizedChunks: [],
        currentChunk: null,
        compactlyCodedChunkTable: []
      };
      this.trackDatas.push(newTrackData);
      this.trackDatas.sort((a, b) => a.track.id - b.track.id);
      if (this.allTracksAreKnown()) {
        this.allTracksKnown.resolve();
      }
      return newTrackData;
    }
    getAudioTrackData(track, meta) {
      const existingTrackData = this.trackDatas.find((x) => x.track === track);
      if (existingTrackData) {
        return existingTrackData;
      }
      validateAudioChunkMetadata(meta);
      assert(meta);
      assert(meta.decoderConfig);
      const newTrackData = {
        muxer: this,
        track,
        type: "audio",
        info: {
          numberOfChannels: meta.decoderConfig.numberOfChannels,
          sampleRate: meta.decoderConfig.sampleRate,
          decoderConfig: meta.decoderConfig,
          requiresPcmTransformation: !this.isFragmented && PCM_AUDIO_CODECS.includes(track.source._codec)
        },
        timescale: meta.decoderConfig.sampleRate,
        samples: [],
        sampleQueue: [],
        timestampProcessingQueue: [],
        timeToSampleTable: [],
        compositionTimeOffsetTable: [],
        lastTimescaleUnits: null,
        lastSample: null,
        finalizedChunks: [],
        currentChunk: null,
        compactlyCodedChunkTable: []
      };
      this.trackDatas.push(newTrackData);
      this.trackDatas.sort((a, b) => a.track.id - b.track.id);
      if (this.allTracksAreKnown()) {
        this.allTracksKnown.resolve();
      }
      return newTrackData;
    }
    getSubtitleTrackData(track, meta) {
      const existingTrackData = this.trackDatas.find((x) => x.track === track);
      if (existingTrackData) {
        return existingTrackData;
      }
      validateSubtitleMetadata(meta);
      assert(meta);
      assert(meta.config);
      const newTrackData = {
        muxer: this,
        track,
        type: "subtitle",
        info: {
          config: meta.config
        },
        timescale: 1e3,
        // Reasonable
        samples: [],
        sampleQueue: [],
        timestampProcessingQueue: [],
        timeToSampleTable: [],
        compositionTimeOffsetTable: [],
        lastTimescaleUnits: null,
        lastSample: null,
        finalizedChunks: [],
        currentChunk: null,
        compactlyCodedChunkTable: [],
        lastCueEndTimestamp: 0,
        cueQueue: [],
        nextSourceId: 0,
        cueToSourceId: /* @__PURE__ */ new WeakMap()
      };
      this.trackDatas.push(newTrackData);
      this.trackDatas.sort((a, b) => a.track.id - b.track.id);
      if (this.allTracksAreKnown()) {
        this.allTracksKnown.resolve();
      }
      return newTrackData;
    }
    async addEncodedVideoPacket(track, packet, meta) {
      const release = await this.mutex.acquire();
      try {
        const trackData = this.getVideoTrackData(track, packet, meta);
        let packetData = packet.data;
        if (trackData.info.requiresAnnexBTransformation) {
          const transformedData = transformAnnexBToLengthPrefixed(packetData);
          if (!transformedData) {
            throw new Error(
              "Failed to transform packet data. Make sure all packets are provided in Annex B format, as specified in ITU-T-REC-H.264 and ITU-T-REC-H.265."
            );
          }
          packetData = transformedData;
        }
        const timestamp = this.validateAndNormalizeTimestamp(
          trackData.track,
          packet.timestamp,
          packet.type === "key"
        );
        const internalSample = this.createSampleForTrack(
          trackData,
          packetData,
          timestamp,
          packet.duration,
          packet.type
        );
        await this.registerSample(trackData, internalSample);
      } finally {
        release();
      }
    }
    async addEncodedAudioPacket(track, packet, meta) {
      const release = await this.mutex.acquire();
      try {
        const trackData = this.getAudioTrackData(track, meta);
        const timestamp = this.validateAndNormalizeTimestamp(
          trackData.track,
          packet.timestamp,
          packet.type === "key"
        );
        const internalSample = this.createSampleForTrack(
          trackData,
          packet.data,
          timestamp,
          packet.duration,
          packet.type
        );
        if (trackData.info.requiresPcmTransformation) {
          await this.maybePadWithSilence(trackData, timestamp);
        }
        await this.registerSample(trackData, internalSample);
      } finally {
        release();
      }
    }
    async maybePadWithSilence(trackData, untilTimestamp) {
      const lastSample = last(trackData.samples);
      const lastEndTimestamp = lastSample ? lastSample.timestamp + lastSample.duration : 0;
      const delta = untilTimestamp - lastEndTimestamp;
      const deltaInTimescale = intoTimescale(delta, trackData.timescale);
      if (deltaInTimescale > 0) {
        const { sampleSize, silentValue } = parsePcmCodec(
          trackData.info.decoderConfig.codec
        );
        const samplesNeeded = deltaInTimescale * trackData.info.numberOfChannels;
        const data = new Uint8Array(sampleSize * samplesNeeded).fill(silentValue);
        const paddingSample = this.createSampleForTrack(
          trackData,
          new Uint8Array(data.buffer),
          lastEndTimestamp,
          delta,
          "key"
        );
        await this.registerSample(trackData, paddingSample);
      }
    }
    async addSubtitleCue(track, cue, meta) {
      const release = await this.mutex.acquire();
      try {
        const trackData = this.getSubtitleTrackData(track, meta);
        this.validateAndNormalizeTimestamp(trackData.track, cue.timestamp, true);
        if (track.source._codec === "webvtt") {
          trackData.cueQueue.push(cue);
          await this.processWebVTTCues(trackData, cue.timestamp);
        } else {
        }
      } finally {
        release();
      }
    }
    async processWebVTTCues(trackData, until) {
      while (trackData.cueQueue.length > 0) {
        const timestamps = /* @__PURE__ */ new Set([]);
        for (const cue of trackData.cueQueue) {
          assert(cue.timestamp <= until);
          assert(trackData.lastCueEndTimestamp <= cue.timestamp + cue.duration);
          timestamps.add(Math.max(cue.timestamp, trackData.lastCueEndTimestamp));
          timestamps.add(cue.timestamp + cue.duration);
        }
        const sortedTimestamps = [...timestamps].sort((a, b) => a - b);
        const sampleStart = sortedTimestamps[0];
        const sampleEnd = sortedTimestamps[1] ?? sampleStart;
        if (until < sampleEnd) {
          break;
        }
        if (trackData.lastCueEndTimestamp < sampleStart) {
          this.auxWriter.seek(0);
          const box2 = vtte();
          this.auxBoxWriter.writeBox(box2);
          const body2 = this.auxWriter.getSlice(0, this.auxWriter.getPos());
          const sample2 = this.createSampleForTrack(
            trackData,
            body2,
            trackData.lastCueEndTimestamp,
            sampleStart - trackData.lastCueEndTimestamp,
            "key"
          );
          await this.registerSample(trackData, sample2);
          trackData.lastCueEndTimestamp = sampleStart;
        }
        this.auxWriter.seek(0);
        for (let i = 0; i < trackData.cueQueue.length; i++) {
          const cue = trackData.cueQueue[i];
          if (cue.timestamp >= sampleEnd) {
            break;
          }
          inlineTimestampRegex.lastIndex = 0;
          const containsTimestamp = inlineTimestampRegex.test(cue.text);
          const endTimestamp = cue.timestamp + cue.duration;
          let sourceId = trackData.cueToSourceId.get(cue);
          if (sourceId === void 0 && sampleEnd < endTimestamp) {
            sourceId = trackData.nextSourceId++;
            trackData.cueToSourceId.set(cue, sourceId);
          }
          if (cue.notes) {
            const box3 = vtta(cue.notes);
            this.auxBoxWriter.writeBox(box3);
          }
          const box2 = vttc(
            cue.text,
            containsTimestamp ? sampleStart : null,
            cue.identifier ?? null,
            cue.settings ?? null,
            sourceId ?? null
          );
          this.auxBoxWriter.writeBox(box2);
          if (endTimestamp === sampleEnd) {
            trackData.cueQueue.splice(i--, 1);
          }
        }
        const body = this.auxWriter.getSlice(0, this.auxWriter.getPos());
        const sample = this.createSampleForTrack(trackData, body, sampleStart, sampleEnd - sampleStart, "key");
        await this.registerSample(trackData, sample);
        trackData.lastCueEndTimestamp = sampleEnd;
      }
    }
    createSampleForTrack(trackData, data, timestamp, duration, type) {
      const sample = {
        timestamp,
        decodeTimestamp: timestamp,
        // This may be refined later
        duration,
        data,
        size: data.byteLength,
        type,
        timescaleUnitsToNextSample: intoTimescale(duration, trackData.timescale)
        // Will be refined
      };
      return sample;
    }
    processTimestamps(trackData, nextSample) {
      if (trackData.timestampProcessingQueue.length === 0) {
        return;
      }
      if (trackData.type === "audio" && trackData.info.requiresPcmTransformation) {
        let totalDuration = 0;
        for (let i = 0; i < trackData.timestampProcessingQueue.length; i++) {
          const sample = trackData.timestampProcessingQueue[i];
          const duration = intoTimescale(sample.duration, trackData.timescale);
          totalDuration += duration;
        }
        if (trackData.timeToSampleTable.length === 0) {
          trackData.timeToSampleTable.push({
            sampleCount: totalDuration,
            sampleDelta: 1
          });
        } else {
          const lastEntry = last(trackData.timeToSampleTable);
          lastEntry.sampleCount += totalDuration;
        }
        trackData.timestampProcessingQueue.length = 0;
        return;
      }
      const sortedTimestamps = trackData.timestampProcessingQueue.map((x) => x.timestamp).sort((a, b) => a - b);
      for (let i = 0; i < trackData.timestampProcessingQueue.length; i++) {
        const sample = trackData.timestampProcessingQueue[i];
        sample.decodeTimestamp = sortedTimestamps[i];
        if (!this.isFragmented && trackData.lastTimescaleUnits === null) {
          sample.decodeTimestamp = 0;
        }
        const sampleCompositionTimeOffset = intoTimescale(sample.timestamp - sample.decodeTimestamp, trackData.timescale);
        const durationInTimescale = intoTimescale(sample.duration, trackData.timescale);
        if (trackData.lastTimescaleUnits !== null) {
          assert(trackData.lastSample);
          const timescaleUnits = intoTimescale(sample.decodeTimestamp, trackData.timescale, false);
          const delta = Math.round(timescaleUnits - trackData.lastTimescaleUnits);
          assert(delta >= 0);
          trackData.lastTimescaleUnits += delta;
          trackData.lastSample.timescaleUnitsToNextSample = delta;
          if (!this.isFragmented) {
            let lastTableEntry = last(trackData.timeToSampleTable);
            assert(lastTableEntry);
            if (lastTableEntry.sampleCount === 1) {
              lastTableEntry.sampleDelta = delta;
              const entryBefore = trackData.timeToSampleTable[trackData.timeToSampleTable.length - 2];
              if (entryBefore && entryBefore.sampleDelta === delta) {
                entryBefore.sampleCount++;
                trackData.timeToSampleTable.pop();
                lastTableEntry = entryBefore;
              }
            } else if (lastTableEntry.sampleDelta !== delta) {
              lastTableEntry.sampleCount--;
              trackData.timeToSampleTable.push(lastTableEntry = {
                sampleCount: 1,
                sampleDelta: delta
              });
            }
            if (lastTableEntry.sampleDelta === durationInTimescale) {
              lastTableEntry.sampleCount++;
            } else {
              trackData.timeToSampleTable.push({
                sampleCount: 1,
                sampleDelta: durationInTimescale
              });
            }
            const lastCompositionTimeOffsetTableEntry = last(trackData.compositionTimeOffsetTable);
            assert(lastCompositionTimeOffsetTableEntry);
            if (lastCompositionTimeOffsetTableEntry.sampleCompositionTimeOffset === sampleCompositionTimeOffset) {
              lastCompositionTimeOffsetTableEntry.sampleCount++;
            } else {
              trackData.compositionTimeOffsetTable.push({
                sampleCount: 1,
                sampleCompositionTimeOffset
              });
            }
          }
        } else {
          trackData.lastTimescaleUnits = intoTimescale(sample.decodeTimestamp, trackData.timescale, false);
          if (!this.isFragmented) {
            trackData.timeToSampleTable.push({
              sampleCount: 1,
              sampleDelta: durationInTimescale
            });
            trackData.compositionTimeOffsetTable.push({
              sampleCount: 1,
              sampleCompositionTimeOffset
            });
          }
        }
        trackData.lastSample = sample;
      }
      trackData.timestampProcessingQueue.length = 0;
      assert(trackData.lastSample);
      assert(trackData.lastTimescaleUnits !== null);
      if (nextSample !== void 0 && trackData.lastSample.timescaleUnitsToNextSample === 0) {
        assert(nextSample.type === "key");
        const timescaleUnits = intoTimescale(nextSample.timestamp, trackData.timescale, false);
        const delta = Math.round(timescaleUnits - trackData.lastTimescaleUnits);
        trackData.lastSample.timescaleUnitsToNextSample = delta;
      }
    }
    async registerSample(trackData, sample) {
      if (sample.type === "key") {
        this.processTimestamps(trackData, sample);
      }
      trackData.timestampProcessingQueue.push(sample);
      if (this.isFragmented) {
        trackData.sampleQueue.push(sample);
        await this.interleaveSamples();
      } else {
        await this.addSampleToTrack(trackData, sample);
      }
    }
    async addSampleToTrack(trackData, sample) {
      if (!this.isFragmented) {
        trackData.samples.push(sample);
      }
      let beginNewChunk = false;
      if (!trackData.currentChunk) {
        beginNewChunk = true;
      } else {
        trackData.currentChunk.startTimestamp = Math.min(
          trackData.currentChunk.startTimestamp,
          sample.timestamp
        );
        const currentChunkDuration = sample.timestamp - trackData.currentChunk.startTimestamp;
        if (this.isFragmented) {
          const keyFrameQueuedEverywhere = this.trackDatas.every((otherTrackData) => {
            if (trackData === otherTrackData) {
              return sample.type === "key";
            }
            const firstQueuedSample = otherTrackData.sampleQueue[0];
            if (firstQueuedSample) {
              return firstQueuedSample.type === "key";
            }
            return otherTrackData.track.source._closed;
          });
          if (currentChunkDuration >= this.minimumFragmentDuration && keyFrameQueuedEverywhere && sample.timestamp > this.maxWrittenTimestamp) {
            beginNewChunk = true;
            await this.finalizeFragment();
          }
        } else {
          beginNewChunk = currentChunkDuration >= 0.5;
        }
      }
      if (beginNewChunk) {
        if (trackData.currentChunk) {
          await this.finalizeCurrentChunk(trackData);
        }
        trackData.currentChunk = {
          startTimestamp: sample.timestamp,
          samples: [],
          offset: null,
          moofOffset: null
        };
      }
      assert(trackData.currentChunk);
      trackData.currentChunk.samples.push(sample);
      if (this.isFragmented) {
        this.maxWrittenTimestamp = Math.max(this.maxWrittenTimestamp, sample.timestamp);
      }
    }
    async finalizeCurrentChunk(trackData) {
      assert(!this.isFragmented);
      if (!trackData.currentChunk) return;
      trackData.finalizedChunks.push(trackData.currentChunk);
      this.finalizedChunks.push(trackData.currentChunk);
      let sampleCount = trackData.currentChunk.samples.length;
      if (trackData.type === "audio" && trackData.info.requiresPcmTransformation) {
        sampleCount = trackData.currentChunk.samples.reduce((acc, sample) => acc + intoTimescale(sample.duration, trackData.timescale), 0);
      }
      if (trackData.compactlyCodedChunkTable.length === 0 || last(trackData.compactlyCodedChunkTable).samplesPerChunk !== sampleCount) {
        trackData.compactlyCodedChunkTable.push({
          firstChunk: trackData.finalizedChunks.length,
          // 1-indexed
          samplesPerChunk: sampleCount
        });
      }
      if (this.fastStart === "in-memory") {
        trackData.currentChunk.offset = 0;
        return;
      }
      trackData.currentChunk.offset = this.writer.getPos();
      for (const sample of trackData.currentChunk.samples) {
        assert(sample.data);
        this.writer.write(sample.data);
        sample.data = null;
      }
      await this.writer.flush();
    }
    async interleaveSamples(isFinalCall = false) {
      assert(this.isFragmented);
      if (!isFinalCall) {
        if (!this.allTracksAreKnown()) {
          return;
        }
      }
      outer:
        while (true) {
          let trackWithMinTimestamp = null;
          let minTimestamp = Infinity;
          for (const trackData of this.trackDatas) {
            if (!isFinalCall && trackData.sampleQueue.length === 0 && !trackData.track.source._closed) {
              break outer;
            }
            if (trackData.sampleQueue.length > 0 && trackData.sampleQueue[0].timestamp < minTimestamp) {
              trackWithMinTimestamp = trackData;
              minTimestamp = trackData.sampleQueue[0].timestamp;
            }
          }
          if (!trackWithMinTimestamp) {
            break;
          }
          const sample = trackWithMinTimestamp.sampleQueue.shift();
          await this.addSampleToTrack(trackWithMinTimestamp, sample);
        }
    }
    async finalizeFragment(flushWriter = true) {
      assert(this.isFragmented);
      const fragmentNumber = this.nextFragmentNumber++;
      if (fragmentNumber === 1) {
        if (this.format._options.onMoov) {
          this.writer.startTrackingWrites();
        }
        const movieBox = moov(this.trackDatas, this.creationTime, true);
        this.boxWriter.writeBox(movieBox);
        if (this.format._options.onMoov) {
          const { data, start } = this.writer.stopTrackingWrites();
          this.format._options.onMoov(data, start);
        }
      }
      const tracksInFragment = this.trackDatas.filter((x) => x.currentChunk);
      const moofBox = moof(fragmentNumber, tracksInFragment);
      const moofOffset = this.writer.getPos();
      const mdatStartPos = moofOffset + this.boxWriter.measureBox(moofBox);
      let currentPos = mdatStartPos + MIN_BOX_HEADER_SIZE;
      let fragmentStartTimestamp = Infinity;
      for (const trackData of tracksInFragment) {
        trackData.currentChunk.offset = currentPos;
        trackData.currentChunk.moofOffset = moofOffset;
        for (const sample of trackData.currentChunk.samples) {
          currentPos += sample.size;
        }
        fragmentStartTimestamp = Math.min(fragmentStartTimestamp, trackData.currentChunk.startTimestamp);
      }
      const mdatSize = currentPos - mdatStartPos;
      const needsLargeMdatSize = mdatSize >= 2 ** 32;
      if (needsLargeMdatSize) {
        for (const trackData of tracksInFragment) {
          trackData.currentChunk.offset += MAX_BOX_HEADER_SIZE - MIN_BOX_HEADER_SIZE;
        }
      }
      if (this.format._options.onMoof) {
        this.writer.startTrackingWrites();
      }
      const newMoofBox = moof(fragmentNumber, tracksInFragment);
      this.boxWriter.writeBox(newMoofBox);
      if (this.format._options.onMoof) {
        const { data, start } = this.writer.stopTrackingWrites();
        this.format._options.onMoof(data, start, fragmentStartTimestamp);
      }
      assert(this.writer.getPos() === mdatStartPos);
      if (this.format._options.onMdat) {
        this.writer.startTrackingWrites();
      }
      const mdatBox = mdat(needsLargeMdatSize);
      mdatBox.size = mdatSize;
      this.boxWriter.writeBox(mdatBox);
      this.writer.seek(mdatStartPos + (needsLargeMdatSize ? MAX_BOX_HEADER_SIZE : MIN_BOX_HEADER_SIZE));
      for (const trackData of tracksInFragment) {
        for (const sample of trackData.currentChunk.samples) {
          this.writer.write(sample.data);
          sample.data = null;
        }
      }
      if (this.format._options.onMdat) {
        const { data, start } = this.writer.stopTrackingWrites();
        this.format._options.onMdat(data, start);
      }
      for (const trackData of tracksInFragment) {
        trackData.finalizedChunks.push(trackData.currentChunk);
        this.finalizedChunks.push(trackData.currentChunk);
        trackData.currentChunk = null;
      }
      if (flushWriter) {
        await this.writer.flush();
      }
    }
    // eslint-disable-next-line @typescript-eslint/no-misused-promises
    async onTrackClose(track) {
      const release = await this.mutex.acquire();
      if (track.type === "subtitle" && track.source._codec === "webvtt") {
        const trackData = this.trackDatas.find((x) => x.track === track);
        if (trackData) {
          await this.processWebVTTCues(trackData, Infinity);
        }
      }
      if (this.allTracksAreKnown()) {
        this.allTracksKnown.resolve();
      }
      if (this.isFragmented) {
        await this.interleaveSamples();
      }
      release();
    }
    /** Finalizes the file, making it ready for use. Must be called after all video and audio chunks have been added. */
    async finalize() {
      const release = await this.mutex.acquire();
      this.allTracksKnown.resolve();
      for (const trackData of this.trackDatas) {
        if (trackData.type === "subtitle" && trackData.track.source._codec === "webvtt") {
          await this.processWebVTTCues(trackData, Infinity);
        }
      }
      if (this.isFragmented) {
        await this.interleaveSamples(true);
        for (const trackData of this.trackDatas) {
          this.processTimestamps(trackData);
        }
        await this.finalizeFragment(false);
      } else {
        for (const trackData of this.trackDatas) {
          this.processTimestamps(trackData);
          await this.finalizeCurrentChunk(trackData);
        }
      }
      if (this.fastStart === "in-memory") {
        assert(this.mdat);
        let mdatSize;
        for (let i = 0; i < 2; i++) {
          const movieBox2 = moov(this.trackDatas, this.creationTime);
          const movieBoxSize = this.boxWriter.measureBox(movieBox2);
          mdatSize = this.boxWriter.measureBox(this.mdat);
          let currentChunkPos = this.writer.getPos() + movieBoxSize + mdatSize;
          for (const chunk of this.finalizedChunks) {
            chunk.offset = currentChunkPos;
            for (const { data } of chunk.samples) {
              assert(data);
              currentChunkPos += data.byteLength;
              mdatSize += data.byteLength;
            }
          }
          if (currentChunkPos < 2 ** 32) break;
          if (mdatSize >= 2 ** 32) this.mdat.largeSize = true;
        }
        if (this.format._options.onMoov) {
          this.writer.startTrackingWrites();
        }
        const movieBox = moov(this.trackDatas, this.creationTime);
        this.boxWriter.writeBox(movieBox);
        if (this.format._options.onMoov) {
          const { data, start } = this.writer.stopTrackingWrites();
          this.format._options.onMoov(data, start);
        }
        if (this.format._options.onMdat) {
          this.writer.startTrackingWrites();
        }
        this.mdat.size = mdatSize;
        this.boxWriter.writeBox(this.mdat);
        for (const chunk of this.finalizedChunks) {
          for (const sample of chunk.samples) {
            assert(sample.data);
            this.writer.write(sample.data);
            sample.data = null;
          }
        }
        if (this.format._options.onMdat) {
          const { data, start } = this.writer.stopTrackingWrites();
          this.format._options.onMdat(data, start);
        }
      } else if (this.isFragmented) {
        const startPos = this.writer.getPos();
        const mfraBox = mfra(this.trackDatas);
        this.boxWriter.writeBox(mfraBox);
        const mfraBoxSize = this.writer.getPos() - startPos;
        this.writer.seek(this.writer.getPos() - 4);
        this.boxWriter.writeU32(mfraBoxSize);
      } else {
        assert(this.mdat);
        const mdatPos = this.boxWriter.offsets.get(this.mdat);
        assert(mdatPos !== void 0);
        const mdatSize = this.writer.getPos() - mdatPos;
        this.mdat.size = mdatSize;
        this.mdat.largeSize = mdatSize >= 2 ** 32;
        this.boxWriter.patchBox(this.mdat);
        if (this.format._options.onMdat) {
          const { data, start } = this.writer.stopTrackingWrites();
          this.format._options.onMdat(data, start);
        }
        if (this.format._options.onMoov) {
          this.writer.startTrackingWrites();
        }
        const movieBox = moov(this.trackDatas, this.creationTime);
        this.boxWriter.writeBox(movieBox);
        if (this.format._options.onMoov) {
          const { data, start } = this.writer.stopTrackingWrites();
          this.format._options.onMoov(data, start);
        }
      }
      release();
    }
  };

  // src/matroska/ebml.ts
  var EBMLFloat32 = class {
    constructor(value) {
      this.value = value;
    }
  };
  var EBMLFloat64 = class {
    constructor(value) {
      this.value = value;
    }
  };
  var EBMLSignedInt = class {
    constructor(value) {
      this.value = value;
    }
  };
  var LEVEL_0_EBML_IDS = [
    440786851 /* EBML */,
    408125543 /* Segment */
  ];
  var LEVEL_1_EBML_IDS = [
    17138 /* EBMLMaxIDLength */,
    17139 /* EBMLMaxSizeLength */,
    290298740 /* SeekHead */,
    357149030 /* Info */,
    524531317 /* Cluster */,
    374648427 /* Tracks */,
    475249515 /* Cues */,
    423732329 /* Attachments */,
    272869232 /* Chapters */,
    307544935 /* Tags */
  ];
  var LEVEL_0_AND_1_EBML_IDS = [
    ...LEVEL_0_EBML_IDS,
    ...LEVEL_1_EBML_IDS
  ];
  var measureUnsignedInt = (value) => {
    if (value < 1 << 8) {
      return 1;
    } else if (value < 1 << 16) {
      return 2;
    } else if (value < 1 << 24) {
      return 3;
    } else if (value < 2 ** 32) {
      return 4;
    } else if (value < 2 ** 40) {
      return 5;
    } else {
      return 6;
    }
  };
  var measureSignedInt = (value) => {
    if (value >= -(1 << 6) && value < 1 << 6) {
      return 1;
    } else if (value >= -(1 << 13) && value < 1 << 13) {
      return 2;
    } else if (value >= -(1 << 20) && value < 1 << 20) {
      return 3;
    } else if (value >= -(1 << 27) && value < 1 << 27) {
      return 4;
    } else if (value >= -(2 ** 34) && value < 2 ** 34) {
      return 5;
    } else {
      return 6;
    }
  };
  var measureVarInt = (value) => {
    if (value < (1 << 7) - 1) {
      return 1;
    } else if (value < (1 << 14) - 1) {
      return 2;
    } else if (value < (1 << 21) - 1) {
      return 3;
    } else if (value < (1 << 28) - 1) {
      return 4;
    } else if (value < 2 ** 35 - 1) {
      return 5;
    } else if (value < 2 ** 42 - 1) {
      return 6;
    } else {
      throw new Error("EBML varint size not supported " + value);
    }
  };
  var EBMLWriter = class {
    constructor(writer) {
      this.writer = writer;
      this.helper = new Uint8Array(8);
      this.helperView = new DataView(this.helper.buffer);
      /**
       * Stores the position from the start of the file to where EBML elements have been written. This is used to
       * rewrite/edit elements that were already added before, and to measure sizes of things.
       */
      this.offsets = /* @__PURE__ */ new WeakMap();
      /** Same as offsets, but stores position where the element's data starts (after ID and size fields). */
      this.dataOffsets = /* @__PURE__ */ new WeakMap();
    }
    writeByte(value) {
      this.helperView.setUint8(0, value);
      this.writer.write(this.helper.subarray(0, 1));
    }
    writeFloat32(value) {
      this.helperView.setFloat32(0, value, false);
      this.writer.write(this.helper.subarray(0, 4));
    }
    writeFloat64(value) {
      this.helperView.setFloat64(0, value, false);
      this.writer.write(this.helper);
    }
    writeUnsignedInt(value, width = measureUnsignedInt(value)) {
      let pos = 0;
      switch (width) {
        case 6:
          this.helperView.setUint8(pos++, value / 2 ** 40 | 0);
        // eslint-disable-next-line no-fallthrough
        case 5:
          this.helperView.setUint8(pos++, value / 2 ** 32 | 0);
        // eslint-disable-next-line no-fallthrough
        case 4:
          this.helperView.setUint8(pos++, value >> 24);
        // eslint-disable-next-line no-fallthrough
        case 3:
          this.helperView.setUint8(pos++, value >> 16);
        // eslint-disable-next-line no-fallthrough
        case 2:
          this.helperView.setUint8(pos++, value >> 8);
        // eslint-disable-next-line no-fallthrough
        case 1:
          this.helperView.setUint8(pos++, value);
          break;
        default:
          throw new Error("Bad unsigned int size " + width);
      }
      this.writer.write(this.helper.subarray(0, pos));
    }
    writeSignedInt(value, width = measureSignedInt(value)) {
      if (value < 0) {
        value += 2 ** (width * 8);
      }
      this.writeUnsignedInt(value, width);
    }
    writeVarInt(value, width = measureVarInt(value)) {
      let pos = 0;
      switch (width) {
        case 1:
          this.helperView.setUint8(pos++, 1 << 7 | value);
          break;
        case 2:
          this.helperView.setUint8(pos++, 1 << 6 | value >> 8);
          this.helperView.setUint8(pos++, value);
          break;
        case 3:
          this.helperView.setUint8(pos++, 1 << 5 | value >> 16);
          this.helperView.setUint8(pos++, value >> 8);
          this.helperView.setUint8(pos++, value);
          break;
        case 4:
          this.helperView.setUint8(pos++, 1 << 4 | value >> 24);
          this.helperView.setUint8(pos++, value >> 16);
          this.helperView.setUint8(pos++, value >> 8);
          this.helperView.setUint8(pos++, value);
          break;
        case 5:
          this.helperView.setUint8(pos++, 1 << 3 | value / 2 ** 32 & 7);
          this.helperView.setUint8(pos++, value >> 24);
          this.helperView.setUint8(pos++, value >> 16);
          this.helperView.setUint8(pos++, value >> 8);
          this.helperView.setUint8(pos++, value);
          break;
        case 6:
          this.helperView.setUint8(pos++, 1 << 2 | value / 2 ** 40 & 3);
          this.helperView.setUint8(pos++, value / 2 ** 32 | 0);
          this.helperView.setUint8(pos++, value >> 24);
          this.helperView.setUint8(pos++, value >> 16);
          this.helperView.setUint8(pos++, value >> 8);
          this.helperView.setUint8(pos++, value);
          break;
        default:
          throw new Error("Bad EBML varint size " + width);
      }
      this.writer.write(this.helper.subarray(0, pos));
    }
    // Assumes the string is ASCII
    writeString(str) {
      this.writer.write(new Uint8Array(str.split("").map((x) => x.charCodeAt(0))));
    }
    writeEBML(data) {
      if (data === null) return;
      if (data instanceof Uint8Array) {
        this.writer.write(data);
      } else if (Array.isArray(data)) {
        for (const elem of data) {
          this.writeEBML(elem);
        }
      } else {
        this.offsets.set(data, this.writer.getPos());
        this.writeUnsignedInt(data.id);
        if (Array.isArray(data.data)) {
          const sizePos = this.writer.getPos();
          const sizeSize = data.size === -1 ? 1 : data.size ?? 4;
          if (data.size === -1) {
            this.writeByte(255);
          } else {
            this.writer.seek(this.writer.getPos() + sizeSize);
          }
          const startPos = this.writer.getPos();
          this.dataOffsets.set(data, startPos);
          this.writeEBML(data.data);
          if (data.size !== -1) {
            const size = this.writer.getPos() - startPos;
            const endPos = this.writer.getPos();
            this.writer.seek(sizePos);
            this.writeVarInt(size, sizeSize);
            this.writer.seek(endPos);
          }
        } else if (typeof data.data === "number") {
          const size = data.size ?? measureUnsignedInt(data.data);
          this.writeVarInt(size);
          this.writeUnsignedInt(data.data, size);
        } else if (typeof data.data === "string") {
          this.writeVarInt(data.data.length);
          this.writeString(data.data);
        } else if (data.data instanceof Uint8Array) {
          this.writeVarInt(data.data.byteLength, data.size);
          this.writer.write(data.data);
        } else if (data.data instanceof EBMLFloat32) {
          this.writeVarInt(4);
          this.writeFloat32(data.data.value);
        } else if (data.data instanceof EBMLFloat64) {
          this.writeVarInt(8);
          this.writeFloat64(data.data.value);
        } else if (data.data instanceof EBMLSignedInt) {
          const size = data.size ?? measureSignedInt(data.data.value);
          this.writeVarInt(size);
          this.writeSignedInt(data.data.value, size);
        }
      }
    }
  };
  var MAX_VAR_INT_SIZE = 8;
  var MIN_HEADER_SIZE = 2;
  var MAX_HEADER_SIZE = 4 + MAX_VAR_INT_SIZE;
  var EBMLReader = class {
    constructor(reader) {
      this.reader = reader;
      this.pos = 0;
    }
    readBytes(length) {
      const { view: view2, offset } = this.reader.getViewAndOffset(this.pos, this.pos + length);
      this.pos += length;
      return new Uint8Array(view2.buffer, offset, length);
    }
    readU8() {
      const { view: view2, offset } = this.reader.getViewAndOffset(this.pos, this.pos + 1);
      this.pos++;
      return view2.getUint8(offset);
    }
    readS16() {
      const { view: view2, offset } = this.reader.getViewAndOffset(this.pos, this.pos + 2);
      this.pos += 2;
      return view2.getInt16(offset, false);
    }
    readVarIntSize() {
      const { view: view2, offset } = this.reader.getViewAndOffset(this.pos, this.pos + 1);
      const firstByte = view2.getUint8(offset);
      let width = 1;
      let mask = 128;
      while ((firstByte & mask) === 0 && width < 8) {
        width++;
        mask >>= 1;
      }
      return width;
    }
    readVarInt() {
      const { view: view2, offset } = this.reader.getViewAndOffset(this.pos, this.pos + 1);
      const firstByte = view2.getUint8(offset);
      let width = 1;
      let mask = 1 << 7;
      while ((firstByte & mask) === 0 && width < MAX_VAR_INT_SIZE) {
        width++;
        mask >>= 1;
      }
      const { view: fullView, offset: fullOffset } = this.reader.getViewAndOffset(this.pos, this.pos + width);
      let value = firstByte & mask - 1;
      for (let i = 1; i < width; i++) {
        value *= 1 << 8;
        value += fullView.getUint8(fullOffset + i);
      }
      this.pos += width;
      return value;
    }
    readUnsignedInt(width) {
      if (width < 1 || width > 8) {
        throw new Error("Bad unsigned int size " + width);
      }
      const { view: view2, offset } = this.reader.getViewAndOffset(this.pos, this.pos + width);
      let value = 0;
      for (let i = 0; i < width; i++) {
        value *= 1 << 8;
        value += view2.getUint8(offset + i);
      }
      this.pos += width;
      return value;
    }
    readSignedInt(width) {
      let value = this.readUnsignedInt(width);
      if (value & 1 << width * 8 - 1) {
        value -= 2 ** (width * 8);
      }
      return value;
    }
    readFloat(width) {
      if (width === 0) {
        return 0;
      }
      if (width !== 4 && width !== 8) {
        throw new Error("Bad float size " + width);
      }
      const { view: view2, offset } = this.reader.getViewAndOffset(this.pos, this.pos + width);
      const value = width === 4 ? view2.getFloat32(offset, false) : view2.getFloat64(offset, false);
      this.pos += width;
      return value;
    }
    readString(length) {
      const { view: view2, offset } = this.reader.getViewAndOffset(this.pos, this.pos + length);
      this.pos += length;
      let strLength = 0;
      while (strLength < length && view2.getUint8(offset + strLength) !== 0) {
        strLength += 1;
      }
      return String.fromCharCode(...new Uint8Array(view2.buffer, offset, strLength));
    }
    readElementId() {
      const size = this.readVarIntSize();
      const id = this.readUnsignedInt(size);
      return id;
    }
    readElementSize() {
      let size = this.readU8();
      if (size === 255) {
        size = null;
      } else {
        this.pos--;
        size = this.readVarInt();
        if (size === 72057594037927940) {
          size = null;
        }
      }
      return size;
    }
    readElementHeader() {
      const id = this.readElementId();
      const size = this.readElementSize();
      return { id, size };
    }
    /** Returns the byte offset in the file of the next element with a matching ID. */
    async searchForNextElementId(ids, until) {
      const loadChunkSize = 2 ** 20;
      const idsSet = new Set(ids);
      while (this.pos < until - MAX_HEADER_SIZE) {
        if (!this.reader.rangeIsLoaded(this.pos, this.pos + MAX_HEADER_SIZE)) {
          await this.reader.loadRange(this.pos, Math.min(this.pos + loadChunkSize, until));
        }
        const elementStartPos = this.pos;
        const elementHeader = this.readElementHeader();
        if (idsSet.has(elementHeader.id)) {
          return elementStartPos;
        }
        assertDefinedSize(elementHeader.size);
        this.pos += elementHeader.size;
      }
      return null;
    }
  };
  var CODEC_STRING_MAP = {
    "avc": "V_MPEG4/ISO/AVC",
    "hevc": "V_MPEGH/ISO/HEVC",
    "vp8": "V_VP8",
    "vp9": "V_VP9",
    "av1": "V_AV1",
    "aac": "A_AAC",
    "mp3": "A_MPEG/L3",
    "opus": "A_OPUS",
    "vorbis": "A_VORBIS",
    "flac": "A_FLAC",
    "pcm-u8": "A_PCM/INT/LIT",
    "pcm-s16": "A_PCM/INT/LIT",
    "pcm-s16be": "A_PCM/INT/BIG",
    "pcm-s24": "A_PCM/INT/LIT",
    "pcm-s24be": "A_PCM/INT/BIG",
    "pcm-s32": "A_PCM/INT/LIT",
    "pcm-s32be": "A_PCM/INT/BIG",
    "pcm-f32": "A_PCM/FLOAT/IEEE",
    "pcm-f64": "A_PCM/FLOAT/IEEE",
    "webvtt": "S_TEXT/WEBVTT"
  };
  var readVarInt = (data, offset) => {
    if (offset >= data.length) {
      throw new Error("Offset out of bounds.");
    }
    const firstByte = data[offset];
    let width = 1;
    let mask = 1 << 7;
    while ((firstByte & mask) === 0 && width < 8) {
      width++;
      mask >>= 1;
    }
    if (offset + width > data.length) {
      throw new Error("VarInt extends beyond data bounds.");
    }
    let value = firstByte & mask - 1;
    for (let i = 1; i < width; i++) {
      value *= 1 << 8;
      value += data[offset + i];
    }
    return { value, width };
  };
  function assertDefinedSize(size) {
    if (size === null) {
      throw new Error("Undefined element size is used in a place where it is not supported.");
    }
  }

  // src/matroska/matroska-misc.ts
  var buildMatroskaMimeType = (info) => {
    const base = info.hasVideo ? "video/" : info.hasAudio ? "audio/" : "application/";
    let string = base + (info.isWebM ? "webm" : "x-matroska");
    if (info.codecStrings.length > 0) {
      const uniqueCodecMimeTypes = [...new Set(info.codecStrings.filter(Boolean))];
      string += `; codecs="${uniqueCodecMimeTypes.join(", ")}"`;
    }
    return string;
  };

  // src/matroska/matroska-muxer.ts
  var MIN_CLUSTER_TIMESTAMP_MS = -(2 ** 15);
  var MAX_CLUSTER_TIMESTAMP_MS = 2 ** 15 - 1;
  var APP_NAME = "https://github.com/Vanilagy/mediabunny";
  var SEGMENT_SIZE_BYTES = 6;
  var CLUSTER_SIZE_BYTES = 5;
  var TRACK_TYPE_MAP = {
    video: 1,
    audio: 2,
    subtitle: 17
  };
  var MatroskaMuxer = class extends Muxer {
    constructor(output, format) {
      super(output);
      this.trackDatas = [];
      this.allTracksKnown = promiseWithResolvers();
      this.segment = null;
      this.segmentInfo = null;
      this.seekHead = null;
      this.tracksElement = null;
      this.segmentDuration = null;
      this.cues = null;
      this.currentCluster = null;
      this.currentClusterStartMsTimestamp = null;
      this.currentClusterMaxMsTimestamp = null;
      this.trackDatasInCurrentCluster = /* @__PURE__ */ new Map();
      this.duration = 0;
      this.writer = output._writer;
      this.format = format;
      this.ebmlWriter = new EBMLWriter(this.writer);
      if (this.format._options.appendOnly) {
        this.writer.ensureMonotonicity = true;
      }
    }
    async start() {
      const release = await this.mutex.acquire();
      this.writeEBMLHeader();
      if (!this.format._options.appendOnly) {
        this.createSeekHead();
      }
      this.createSegmentInfo();
      this.createCues();
      await this.writer.flush();
      release();
    }
    writeEBMLHeader() {
      if (this.format._options.onEbmlHeader) {
        this.writer.startTrackingWrites();
      }
      const ebmlHeader = { id: 440786851 /* EBML */, data: [
        { id: 17030 /* EBMLVersion */, data: 1 },
        { id: 17143 /* EBMLReadVersion */, data: 1 },
        { id: 17138 /* EBMLMaxIDLength */, data: 4 },
        { id: 17139 /* EBMLMaxSizeLength */, data: 8 },
        { id: 17026 /* DocType */, data: this.format instanceof WebMOutputFormat ? "webm" : "matroska" },
        { id: 17031 /* DocTypeVersion */, data: 2 },
        { id: 17029 /* DocTypeReadVersion */, data: 2 }
      ] };
      this.ebmlWriter.writeEBML(ebmlHeader);
      if (this.format._options.onEbmlHeader) {
        const { data, start } = this.writer.stopTrackingWrites();
        this.format._options.onEbmlHeader(data, start);
      }
    }
    /**
     * Creates a SeekHead element which is positioned near the start of the file and allows the media player to seek to
     * relevant sections more easily. Since we don't know the positions of those sections yet, we'll set them later.
     */
    createSeekHead() {
      const kaxCues = new Uint8Array([28, 83, 187, 107]);
      const kaxInfo = new Uint8Array([21, 73, 169, 102]);
      const kaxTracks = new Uint8Array([22, 84, 174, 107]);
      const seekHead = { id: 290298740 /* SeekHead */, data: [
        { id: 19899 /* Seek */, data: [
          { id: 21419 /* SeekID */, data: kaxCues },
          { id: 21420 /* SeekPosition */, size: 5, data: 0 }
        ] },
        { id: 19899 /* Seek */, data: [
          { id: 21419 /* SeekID */, data: kaxInfo },
          { id: 21420 /* SeekPosition */, size: 5, data: 0 }
        ] },
        { id: 19899 /* Seek */, data: [
          { id: 21419 /* SeekID */, data: kaxTracks },
          { id: 21420 /* SeekPosition */, size: 5, data: 0 }
        ] }
      ] };
      this.seekHead = seekHead;
    }
    createSegmentInfo() {
      const segmentDuration = { id: 17545 /* Duration */, data: new EBMLFloat64(0) };
      this.segmentDuration = segmentDuration;
      const segmentInfo = { id: 357149030 /* Info */, data: [
        { id: 2807729 /* TimestampScale */, data: 1e6 },
        { id: 19840 /* MuxingApp */, data: APP_NAME },
        { id: 22337 /* WritingApp */, data: APP_NAME },
        !this.format._options.appendOnly ? segmentDuration : null
      ] };
      this.segmentInfo = segmentInfo;
    }
    createTracks() {
      const tracksElement = { id: 374648427 /* Tracks */, data: [] };
      this.tracksElement = tracksElement;
      for (const trackData of this.trackDatas) {
        const codecId = CODEC_STRING_MAP[trackData.track.source._codec];
        assert(codecId);
        let seekPreRollNs = 0;
        if (trackData.type === "audio" && trackData.track.source._codec === "opus") {
          seekPreRollNs = 1e6 * 80;
          const description = trackData.info.decoderConfig.description;
          if (description) {
            const bytes2 = toUint8Array(description);
            const header = parseOpusIdentificationHeader(bytes2);
            seekPreRollNs = Math.round(1e9 * (header.preSkip / OPUS_INTERNAL_SAMPLE_RATE));
          }
        }
        tracksElement.data.push({ id: 174 /* TrackEntry */, data: [
          { id: 215 /* TrackNumber */, data: trackData.track.id },
          { id: 29637 /* TrackUID */, data: trackData.track.id },
          { id: 131 /* TrackType */, data: TRACK_TYPE_MAP[trackData.type] },
          { id: 156 /* FlagLacing */, data: 0 },
          { id: 2274716 /* Language */, data: trackData.track.metadata.languageCode ?? UNDETERMINED_LANGUAGE },
          { id: 134 /* CodecID */, data: codecId },
          { id: 22186 /* CodecDelay */, data: 0 },
          { id: 22203 /* SeekPreRoll */, data: seekPreRollNs },
          trackData.type === "video" ? this.videoSpecificTrackInfo(trackData) : null,
          trackData.type === "audio" ? this.audioSpecificTrackInfo(trackData) : null,
          trackData.type === "subtitle" ? this.subtitleSpecificTrackInfo(trackData) : null
        ] });
      }
    }
    videoSpecificTrackInfo(trackData) {
      const { frameRate, rotation } = trackData.track.metadata;
      const elements = [
        trackData.info.decoderConfig.description ? {
          id: 25506 /* CodecPrivate */,
          data: toUint8Array(trackData.info.decoderConfig.description)
        } : null,
        frameRate ? {
          id: 2352003 /* DefaultDuration */,
          data: 1e9 / frameRate
        } : null
      ];
      const flippedRotation = rotation ? normalizeRotation(-rotation) : 0;
      const colorSpace = trackData.info.decoderConfig.colorSpace;
      const videoElement = { id: 224 /* Video */, data: [
        { id: 176 /* PixelWidth */, data: trackData.info.width },
        { id: 186 /* PixelHeight */, data: trackData.info.height },
        colorSpaceIsComplete(colorSpace) ? {
          id: 21936 /* Colour */,
          data: [
            {
              id: 21937 /* MatrixCoefficients */,
              data: MATRIX_COEFFICIENTS_MAP[colorSpace.matrix]
            },
            {
              id: 21946 /* TransferCharacteristics */,
              data: TRANSFER_CHARACTERISTICS_MAP[colorSpace.transfer]
            },
            {
              id: 21947 /* Primaries */,
              data: COLOR_PRIMARIES_MAP[colorSpace.primaries]
            },
            {
              id: 21945 /* Range */,
              data: colorSpace.fullRange ? 2 : 1
            }
          ]
        } : null,
        flippedRotation ? {
          id: 30320 /* Projection */,
          data: [
            {
              id: 30321 /* ProjectionType */,
              data: 0
              // rectangular
            },
            {
              id: 30325 /* ProjectionPoseRoll */,
              data: new EBMLFloat32((flippedRotation + 180) % 360 - 180)
              // [0, 270] -> [-180, 90]
            }
          ]
        } : null
      ] };
      elements.push(videoElement);
      return elements;
    }
    audioSpecificTrackInfo(trackData) {
      const pcmInfo = PCM_AUDIO_CODECS.includes(trackData.track.source._codec) ? parsePcmCodec(trackData.track.source._codec) : null;
      return [
        trackData.info.decoderConfig.description ? {
          id: 25506 /* CodecPrivate */,
          data: toUint8Array(trackData.info.decoderConfig.description)
        } : null,
        { id: 225 /* Audio */, data: [
          { id: 181 /* SamplingFrequency */, data: new EBMLFloat32(trackData.info.sampleRate) },
          { id: 159 /* Channels */, data: trackData.info.numberOfChannels },
          pcmInfo ? { id: 25188 /* BitDepth */, data: 8 * pcmInfo.sampleSize } : null
        ] }
      ];
    }
    subtitleSpecificTrackInfo(trackData) {
      return [
        { id: 25506 /* CodecPrivate */, data: textEncoder.encode(trackData.info.config.description) }
      ];
    }
    createSegment() {
      const segment = {
        id: 408125543 /* Segment */,
        size: this.format._options.appendOnly ? -1 : SEGMENT_SIZE_BYTES,
        data: [
          !this.format._options.appendOnly ? this.seekHead : null,
          this.segmentInfo,
          this.tracksElement
        ]
      };
      this.segment = segment;
      if (this.format._options.onSegmentHeader) {
        this.writer.startTrackingWrites();
      }
      this.ebmlWriter.writeEBML(segment);
      if (this.format._options.onSegmentHeader) {
        const { data, start } = this.writer.stopTrackingWrites();
        this.format._options.onSegmentHeader(data, start);
      }
    }
    createCues() {
      this.cues = { id: 475249515 /* Cues */, data: [] };
    }
    get segmentDataOffset() {
      assert(this.segment);
      return this.ebmlWriter.dataOffsets.get(this.segment);
    }
    allTracksAreKnown() {
      for (const track of this.output._tracks) {
        if (!track.source._closed && !this.trackDatas.some((x) => x.track === track)) {
          return false;
        }
      }
      return true;
    }
    async getMimeType() {
      await this.allTracksKnown.promise;
      const codecStrings = this.trackDatas.map((trackData) => {
        if (trackData.type === "video") {
          return trackData.info.decoderConfig.codec;
        } else if (trackData.type === "audio") {
          return trackData.info.decoderConfig.codec;
        } else {
          const map = {
            webvtt: "wvtt"
          };
          return map[trackData.track.source._codec];
        }
      });
      return buildMatroskaMimeType({
        isWebM: this.format instanceof WebMOutputFormat,
        hasVideo: this.trackDatas.some((x) => x.type === "video"),
        hasAudio: this.trackDatas.some((x) => x.type === "audio"),
        codecStrings
      });
    }
    getVideoTrackData(track, meta) {
      const existingTrackData = this.trackDatas.find((x) => x.track === track);
      if (existingTrackData) {
        return existingTrackData;
      }
      validateVideoChunkMetadata(meta);
      assert(meta);
      assert(meta.decoderConfig);
      assert(meta.decoderConfig.codedWidth !== void 0);
      assert(meta.decoderConfig.codedHeight !== void 0);
      const newTrackData = {
        track,
        type: "video",
        info: {
          width: meta.decoderConfig.codedWidth,
          height: meta.decoderConfig.codedHeight,
          decoderConfig: meta.decoderConfig
        },
        chunkQueue: [],
        lastWrittenMsTimestamp: null
      };
      if (track.source._codec === "vp9") {
        newTrackData.info.decoderConfig = {
          ...newTrackData.info.decoderConfig,
          description: new Uint8Array(
            generateVp9CodecConfigurationFromCodecString(newTrackData.info.decoderConfig.codec)
          )
        };
      } else if (track.source._codec === "av1") {
        newTrackData.info.decoderConfig = {
          ...newTrackData.info.decoderConfig,
          description: new Uint8Array(
            generateAv1CodecConfigurationFromCodecString(newTrackData.info.decoderConfig.codec)
          )
        };
      }
      this.trackDatas.push(newTrackData);
      this.trackDatas.sort((a, b) => a.track.id - b.track.id);
      if (this.allTracksAreKnown()) {
        this.allTracksKnown.resolve();
      }
      return newTrackData;
    }
    getAudioTrackData(track, meta) {
      const existingTrackData = this.trackDatas.find((x) => x.track === track);
      if (existingTrackData) {
        return existingTrackData;
      }
      validateAudioChunkMetadata(meta);
      assert(meta);
      assert(meta.decoderConfig);
      const newTrackData = {
        track,
        type: "audio",
        info: {
          numberOfChannels: meta.decoderConfig.numberOfChannels,
          sampleRate: meta.decoderConfig.sampleRate,
          decoderConfig: meta.decoderConfig
        },
        chunkQueue: [],
        lastWrittenMsTimestamp: null
      };
      this.trackDatas.push(newTrackData);
      this.trackDatas.sort((a, b) => a.track.id - b.track.id);
      if (this.allTracksAreKnown()) {
        this.allTracksKnown.resolve();
      }
      return newTrackData;
    }
    getSubtitleTrackData(track, meta) {
      const existingTrackData = this.trackDatas.find((x) => x.track === track);
      if (existingTrackData) {
        return existingTrackData;
      }
      validateSubtitleMetadata(meta);
      assert(meta);
      assert(meta.config);
      const newTrackData = {
        track,
        type: "subtitle",
        info: {
          config: meta.config
        },
        chunkQueue: [],
        lastWrittenMsTimestamp: null
      };
      this.trackDatas.push(newTrackData);
      this.trackDatas.sort((a, b) => a.track.id - b.track.id);
      if (this.allTracksAreKnown()) {
        this.allTracksKnown.resolve();
      }
      return newTrackData;
    }
    async addEncodedVideoPacket(track, packet, meta) {
      const release = await this.mutex.acquire();
      try {
        const trackData = this.getVideoTrackData(track, meta);
        const isKeyFrame = packet.type === "key";
        let timestamp = this.validateAndNormalizeTimestamp(trackData.track, packet.timestamp, isKeyFrame);
        let duration = packet.duration;
        if (track.metadata.frameRate !== void 0) {
          timestamp = roundToMultiple(timestamp, 1 / track.metadata.frameRate);
          duration = roundToMultiple(duration, 1 / track.metadata.frameRate);
        }
        const videoChunk = this.createInternalChunk(packet.data, timestamp, duration, packet.type);
        if (track.source._codec === "vp9") this.fixVP9ColorSpace(trackData, videoChunk);
        trackData.chunkQueue.push(videoChunk);
        await this.interleaveChunks();
      } finally {
        release();
      }
    }
    async addEncodedAudioPacket(track, packet, meta) {
      const release = await this.mutex.acquire();
      try {
        const trackData = this.getAudioTrackData(track, meta);
        const isKeyFrame = packet.type === "key";
        const timestamp = this.validateAndNormalizeTimestamp(trackData.track, packet.timestamp, isKeyFrame);
        const audioChunk = this.createInternalChunk(packet.data, timestamp, packet.duration, packet.type);
        trackData.chunkQueue.push(audioChunk);
        await this.interleaveChunks();
      } finally {
        release();
      }
    }
    async addSubtitleCue(track, cue, meta) {
      const release = await this.mutex.acquire();
      try {
        const trackData = this.getSubtitleTrackData(track, meta);
        const timestamp = this.validateAndNormalizeTimestamp(trackData.track, cue.timestamp, true);
        let bodyText = cue.text;
        const timestampMs = Math.round(timestamp * 1e3);
        inlineTimestampRegex.lastIndex = 0;
        bodyText = bodyText.replace(inlineTimestampRegex, (match) => {
          const time = parseSubtitleTimestamp(match.slice(1, -1));
          const offsetTime = time - timestampMs;
          return `<${formatSubtitleTimestamp(offsetTime)}>`;
        });
        const body = textEncoder.encode(bodyText);
        const additions = `${cue.settings ?? ""}
${cue.identifier ?? ""}
${cue.notes ?? ""}`;
        const subtitleChunk = this.createInternalChunk(
          body,
          timestamp,
          cue.duration,
          "key",
          additions.trim() ? textEncoder.encode(additions) : null
        );
        trackData.chunkQueue.push(subtitleChunk);
        await this.interleaveChunks();
      } finally {
        release();
      }
    }
    async interleaveChunks(isFinalCall = false) {
      if (!isFinalCall) {
        if (!this.allTracksAreKnown()) {
          return;
        }
      }
      outer:
        while (true) {
          let trackWithMinTimestamp = null;
          let minTimestamp = Infinity;
          for (const trackData of this.trackDatas) {
            if (!isFinalCall && trackData.chunkQueue.length === 0 && !trackData.track.source._closed) {
              break outer;
            }
            if (trackData.chunkQueue.length > 0 && trackData.chunkQueue[0].timestamp < minTimestamp) {
              trackWithMinTimestamp = trackData;
              minTimestamp = trackData.chunkQueue[0].timestamp;
            }
          }
          if (!trackWithMinTimestamp) {
            break;
          }
          const chunk = trackWithMinTimestamp.chunkQueue.shift();
          this.writeBlock(trackWithMinTimestamp, chunk);
        }
      if (!isFinalCall) {
        await this.writer.flush();
      }
    }
    /**
     * Due to [a bug in Chromium](https://bugs.chromium.org/p/chromium/issues/detail?id=1377842), VP9 streams often
    	 * lack color space information. This method patches in that information.
     */
    fixVP9ColorSpace(trackData, chunk) {
      if (chunk.type !== "key") return;
      if (!trackData.info.decoderConfig.colorSpace || !trackData.info.decoderConfig.colorSpace.matrix) return;
      const bitstream = new Bitstream(chunk.data);
      bitstream.skipBits(2);
      const profileLowBit = bitstream.readBits(1);
      const profileHighBit = bitstream.readBits(1);
      const profile = (profileHighBit << 1) + profileLowBit;
      if (profile === 3) bitstream.skipBits(1);
      const showExistingFrame = bitstream.readBits(1);
      if (showExistingFrame) return;
      const frameType = bitstream.readBits(1);
      if (frameType !== 0) return;
      bitstream.skipBits(2);
      const syncCode = bitstream.readBits(24);
      if (syncCode !== 4817730) return;
      if (profile >= 2) bitstream.skipBits(1);
      const colorSpaceID = {
        rgb: 7,
        bt709: 2,
        bt470bg: 1,
        smpte170m: 3
      }[trackData.info.decoderConfig.colorSpace.matrix];
      writeBits(chunk.data, bitstream.pos, bitstream.pos + 3, colorSpaceID);
    }
    /** Converts a read-only external chunk into an internal one for easier use. */
    createInternalChunk(data, timestamp, duration, type, additions = null) {
      const internalChunk = {
        data,
        type,
        timestamp,
        duration,
        additions
      };
      return internalChunk;
    }
    /** Writes a block containing media data to the file. */
    writeBlock(trackData, chunk) {
      if (!this.segment) {
        this.createTracks();
        this.createSegment();
      }
      const msTimestamp = Math.round(1e3 * chunk.timestamp);
      const keyFrameQueuedEverywhere = this.trackDatas.every((otherTrackData) => {
        if (trackData === otherTrackData) {
          return chunk.type === "key";
        }
        const firstQueuedSample = otherTrackData.chunkQueue[0];
        if (firstQueuedSample) {
          return firstQueuedSample.type === "key";
        }
        return otherTrackData.track.source._closed;
      });
      let shouldCreateNewCluster = false;
      if (!this.currentCluster) {
        shouldCreateNewCluster = true;
      } else {
        assert(this.currentClusterStartMsTimestamp !== null);
        assert(this.currentClusterMaxMsTimestamp !== null);
        const relativeTimestamp2 = msTimestamp - this.currentClusterStartMsTimestamp;
        shouldCreateNewCluster = keyFrameQueuedEverywhere && msTimestamp > this.currentClusterMaxMsTimestamp && relativeTimestamp2 >= 1e3 * (this.format._options.minimumClusterDuration ?? 1) || relativeTimestamp2 > MAX_CLUSTER_TIMESTAMP_MS;
      }
      if (shouldCreateNewCluster) {
        this.createNewCluster(msTimestamp);
      }
      const relativeTimestamp = msTimestamp - this.currentClusterStartMsTimestamp;
      if (relativeTimestamp < MIN_CLUSTER_TIMESTAMP_MS) {
        return;
      }
      const prelude = new Uint8Array(4);
      const view2 = new DataView(prelude.buffer);
      view2.setUint8(0, 128 | trackData.track.id);
      view2.setInt16(1, relativeTimestamp, false);
      const msDuration = Math.round(1e3 * chunk.duration);
      if (msDuration === 0 && !chunk.additions) {
        view2.setUint8(3, Number(chunk.type === "key") << 7);
        const simpleBlock = { id: 163 /* SimpleBlock */, data: [
          prelude,
          chunk.data
        ] };
        this.ebmlWriter.writeEBML(simpleBlock);
      } else {
        const blockGroup = { id: 160 /* BlockGroup */, data: [
          { id: 161 /* Block */, data: [
            prelude,
            chunk.data
          ] },
          chunk.type === "delta" ? {
            id: 251 /* ReferenceBlock */,
            data: new EBMLSignedInt(trackData.lastWrittenMsTimestamp - msTimestamp)
          } : null,
          chunk.additions ? { id: 30113 /* BlockAdditions */, data: [
            { id: 166 /* BlockMore */, data: [
              { id: 165 /* BlockAdditional */, data: chunk.additions },
              { id: 238 /* BlockAddID */, data: 1 }
            ] }
          ] } : null,
          msDuration > 0 ? { id: 155 /* BlockDuration */, data: msDuration } : null
        ] };
        this.ebmlWriter.writeEBML(blockGroup);
      }
      this.duration = Math.max(this.duration, msTimestamp + msDuration);
      trackData.lastWrittenMsTimestamp = msTimestamp;
      if (!this.trackDatasInCurrentCluster.has(trackData)) {
        this.trackDatasInCurrentCluster.set(trackData, {
          firstMsTimestamp: msTimestamp
        });
      }
      this.currentClusterMaxMsTimestamp = Math.max(this.currentClusterMaxMsTimestamp, msTimestamp);
    }
    /** Creates a new Cluster element to contain media chunks. */
    createNewCluster(msTimestamp) {
      if (this.currentCluster) {
        this.finalizeCurrentCluster();
      }
      if (this.format._options.onCluster) {
        this.writer.startTrackingWrites();
      }
      this.currentCluster = {
        id: 524531317 /* Cluster */,
        size: this.format._options.appendOnly ? -1 : CLUSTER_SIZE_BYTES,
        data: [
          { id: 231 /* Timestamp */, data: msTimestamp }
        ]
      };
      this.ebmlWriter.writeEBML(this.currentCluster);
      this.currentClusterStartMsTimestamp = msTimestamp;
      this.currentClusterMaxMsTimestamp = msTimestamp;
      this.trackDatasInCurrentCluster.clear();
    }
    finalizeCurrentCluster() {
      assert(this.currentCluster);
      if (!this.format._options.appendOnly) {
        const clusterSize = this.writer.getPos() - this.ebmlWriter.dataOffsets.get(this.currentCluster);
        const endPos = this.writer.getPos();
        this.writer.seek(this.ebmlWriter.offsets.get(this.currentCluster) + 4);
        this.ebmlWriter.writeVarInt(clusterSize, CLUSTER_SIZE_BYTES);
        this.writer.seek(endPos);
      }
      if (this.format._options.onCluster) {
        assert(this.currentClusterStartMsTimestamp !== null);
        const { data, start } = this.writer.stopTrackingWrites();
        this.format._options.onCluster(data, start, this.currentClusterStartMsTimestamp / 1e3);
      }
      const clusterOffsetFromSegment = this.ebmlWriter.offsets.get(this.currentCluster) - this.segmentDataOffset;
      const groupedByTimestamp = /* @__PURE__ */ new Map();
      for (const [trackData, { firstMsTimestamp }] of this.trackDatasInCurrentCluster) {
        if (!groupedByTimestamp.has(firstMsTimestamp)) {
          groupedByTimestamp.set(firstMsTimestamp, []);
        }
        groupedByTimestamp.get(firstMsTimestamp).push(trackData);
      }
      const groupedAndSortedByTimestamp = [...groupedByTimestamp.entries()].sort((a, b) => a[0] - b[0]);
      for (const [msTimestamp, trackDatas] of groupedAndSortedByTimestamp) {
        assert(this.cues);
        this.cues.data.push({ id: 187 /* CuePoint */, data: [
          { id: 179 /* CueTime */, data: msTimestamp },
          // Create CueTrackPositions for each track that starts at this timestamp
          ...trackDatas.map((trackData) => {
            return { id: 183 /* CueTrackPositions */, data: [
              { id: 247 /* CueTrack */, data: trackData.track.id },
              { id: 241 /* CueClusterPosition */, data: clusterOffsetFromSegment }
            ] };
          })
        ] });
      }
    }
    // eslint-disable-next-line @typescript-eslint/no-misused-promises
    async onTrackClose() {
      const release = await this.mutex.acquire();
      if (this.allTracksAreKnown()) {
        this.allTracksKnown.resolve();
      }
      await this.interleaveChunks();
      release();
    }
    /** Finalizes the file, making it ready for use. Must be called after all media chunks have been added. */
    async finalize() {
      const release = await this.mutex.acquire();
      this.allTracksKnown.resolve();
      if (!this.segment) {
        this.createTracks();
        this.createSegment();
      }
      await this.interleaveChunks(true);
      if (this.currentCluster) {
        this.finalizeCurrentCluster();
      }
      assert(this.cues);
      this.ebmlWriter.writeEBML(this.cues);
      if (!this.format._options.appendOnly) {
        const endPos = this.writer.getPos();
        const segmentSize = this.writer.getPos() - this.segmentDataOffset;
        this.writer.seek(this.ebmlWriter.offsets.get(this.segment) + 4);
        this.ebmlWriter.writeVarInt(segmentSize, SEGMENT_SIZE_BYTES);
        this.segmentDuration.data = new EBMLFloat64(this.duration);
        this.writer.seek(this.ebmlWriter.offsets.get(this.segmentDuration));
        this.ebmlWriter.writeEBML(this.segmentDuration);
        this.seekHead.data[0].data[1].data = this.ebmlWriter.offsets.get(this.cues) - this.segmentDataOffset;
        this.seekHead.data[1].data[1].data = this.ebmlWriter.offsets.get(this.segmentInfo) - this.segmentDataOffset;
        this.seekHead.data[2].data[1].data = this.ebmlWriter.offsets.get(this.tracksElement) - this.segmentDataOffset;
        this.writer.seek(this.ebmlWriter.offsets.get(this.seekHead));
        this.ebmlWriter.writeEBML(this.seekHead);
        this.writer.seek(endPos);
      }
      release();
    }
  };

  // shared/mp3-misc.ts
  var FRAME_HEADER_SIZE = 4;
  var MPEG_V1_BITRATES = {
    // Layer 3
    1: [-1, 32, 40, 48, 56, 64, 80, 96, 112, 128, 160, 192, 224, 256, 320, -1],
    // Layer 2
    2: [-1, 32, 48, 56, 64, 80, 96, 112, 128, 160, 192, 224, 256, 320, 384, -1],
    // Layer 1
    3: [-1, 32, 64, 96, 128, 160, 192, 224, 256, 288, 320, 352, 384, 416, 448, -1]
  };
  var MPEG_V2_BITRATES = {
    // Layer 3
    1: [-1, 32, 48, 56, 64, 80, 96, 112, 128, 144, 160, 176, 192, 224, 256, -1],
    // Layer 2
    2: [-1, 8, 16, 24, 32, 40, 48, 56, 64, 80, 96, 112, 128, 144, 160, -1],
    // Layer 1
    3: [-1, 8, 16, 24, 32, 40, 48, 56, 64, 80, 96, 112, 128, 144, 160, -1]
  };
  var SAMPLING_RATES = {
    // MPEG Version 2.5
    0: [11025, 12e3, 8e3, -1],
    // MPEG Version 2 (ISO/IEC 13818-3)
    2: [22050, 24e3, 16e3, -1],
    // MPEG Version 1 (ISO/IEC 11172-3)
    3: [44100, 48e3, 32e3, -1]
  };
  var XING = 1483304551;
  var INFO = 1231971951;
  var computeMp3FrameSize = (layer, bitrate, sampleRate, padding) => {
    if (layer === 3) {
      return Math.floor((12 * bitrate / sampleRate + padding) * 4);
    } else {
      return Math.floor(144 * bitrate / sampleRate + padding);
    }
  };
  var getXingOffset = (mpegVersionId, channel) => {
    return mpegVersionId === 3 ? channel === 3 ? 21 : 36 : channel === 3 ? 13 : 21;
  };
  var readFrameHeader = (word, reader) => {
    const startPos = reader.pos;
    const firstByte = word >>> 24;
    const secondByte = word >>> 16 & 255;
    const thirdByte = word >>> 8 & 255;
    const fourthByte = word & 255;
    if (firstByte !== 255 && secondByte !== 255 && thirdByte !== 255 && fourthByte !== 255) {
      reader.pos += 4;
      return null;
    }
    reader.pos += 1;
    if (firstByte !== 255) {
      return null;
    }
    if ((secondByte & 224) !== 224) {
      return null;
    }
    const mpegVersionId = secondByte >> 3 & 3;
    const layer = secondByte >> 1 & 3;
    const bitrateIndex = thirdByte >> 4 & 15;
    const frequencyIndex = thirdByte >> 2 & 3;
    const padding = thirdByte >> 1 & 1;
    const channel = fourthByte >> 6 & 3;
    const modeExtension = fourthByte >> 4 & 3;
    const copyright = fourthByte >> 3 & 1;
    const original = fourthByte >> 2 & 1;
    const emphasis = fourthByte & 3;
    const kilobitRate = mpegVersionId === 3 ? MPEG_V1_BITRATES[layer]?.[bitrateIndex] : MPEG_V2_BITRATES[layer]?.[bitrateIndex];
    if (!kilobitRate || kilobitRate === -1) {
      return null;
    }
    const bitrate = kilobitRate * 1e3;
    const sampleRate = SAMPLING_RATES[mpegVersionId]?.[frequencyIndex];
    if (!sampleRate || sampleRate === -1) {
      return null;
    }
    const frameLength = computeMp3FrameSize(layer, bitrate, sampleRate, padding);
    if (reader.fileSize !== null && reader.fileSize - startPos < frameLength) {
      return null;
    }
    let audioSamplesInFrame;
    if (mpegVersionId === 3) {
      audioSamplesInFrame = layer === 3 ? 384 : 1152;
    } else {
      if (layer === 3) {
        audioSamplesInFrame = 384;
      } else if (layer === 2) {
        audioSamplesInFrame = 1152;
      } else {
        audioSamplesInFrame = 576;
      }
    }
    return {
      startPos,
      totalSize: frameLength,
      mpegVersionId,
      layer,
      bitrate,
      frequencyIndex,
      sampleRate,
      channel,
      modeExtension,
      copyright,
      original,
      emphasis,
      audioSamplesInFrame
    };
  };

  // src/mp3/mp3-writer.ts
  var Mp3Writer = class {
    constructor(writer) {
      this.writer = writer;
      this.helper = new Uint8Array(8);
      this.helperView = new DataView(this.helper.buffer);
    }
    writeU32(value) {
      this.helperView.setUint32(0, value, false);
      this.writer.write(this.helper.subarray(0, 4));
    }
    writeXingFrame(data) {
      const startPos = this.writer.getPos();
      const firstByte = 255;
      const secondByte = 224 | data.mpegVersionId << 3 | data.layer << 1;
      const bitrateGroup = data.mpegVersionId === 3 ? MPEG_V1_BITRATES : MPEG_V2_BITRATES;
      const bitrates = bitrateGroup?.[data.layer];
      if (!bitrates) {
        throw new Error("Invalid MPEG version and layer combination.");
      }
      const sampleRate = SAMPLING_RATES[data.mpegVersionId]?.[data.frequencyIndex];
      if (!sampleRate || sampleRate === -1) {
        throw new Error("Invalid MPEG version and frequency index combination.");
      }
      const padding = 0;
      const neededBytes = 155;
      const bitrateIndex = bitrates.findIndex((kbr) => {
        return computeMp3FrameSize(data.layer, 1e3 * kbr, sampleRate, padding) >= neededBytes;
      });
      if (bitrateIndex === -1) {
        throw new Error("No suitable bitrate found.");
      }
      const thirdByte = bitrateIndex << 4 | data.frequencyIndex << 2 | padding << 1;
      const fourthByte = data.channel << 6 | data.modeExtension << 4 | data.copyright << 3 | data.original << 2 | data.emphasis;
      this.helper[0] = firstByte;
      this.helper[1] = secondByte;
      this.helper[2] = thirdByte;
      this.helper[3] = fourthByte;
      this.writer.write(this.helper.subarray(0, 4));
      const xingOffset = getXingOffset(data.mpegVersionId, data.channel);
      this.writer.seek(startPos + xingOffset);
      this.writeU32(XING);
      let flags = 0;
      if (data.frameCount !== null) {
        flags |= 1;
      }
      if (data.fileSize !== null) {
        flags |= 2;
      }
      if (data.toc !== null) {
        flags |= 4;
      }
      this.writeU32(flags);
      this.writeU32(data.frameCount ?? 0);
      this.writeU32(data.fileSize ?? 0);
      this.writer.write(data.toc ?? new Uint8Array(100));
      const frameSize = computeMp3FrameSize(data.layer, 1e3 * bitrates[bitrateIndex], sampleRate, padding);
      this.writer.seek(startPos + frameSize);
    }
  };

  // src/mp3/mp3-muxer.ts
  var Mp3Muxer = class extends Muxer {
    constructor(output, format) {
      super(output);
      this.xingFrameData = null;
      this.frameCount = 0;
      this.framePositions = [];
      this.format = format;
      this.writer = output._writer;
      this.mp3Writer = new Mp3Writer(output._writer);
    }
    async start() {
    }
    async getMimeType() {
      return "audio/mpeg";
    }
    async addEncodedVideoPacket() {
      throw new Error("MP3 does not support video.");
    }
    async addEncodedAudioPacket(track, packet) {
      const release = await this.mutex.acquire();
      try {
        const writeXingHeader = this.format._options.xingHeader !== false;
        if (!this.xingFrameData && writeXingHeader) {
          const view2 = toDataView(packet.data);
          if (view2.byteLength < 4) {
            throw new Error("Invalid MP3 header in sample.");
          }
          const word = view2.getUint32(0, false);
          const header = readFrameHeader(word, { pos: 0, fileSize: null });
          if (!header) {
            throw new Error("Invalid MP3 header in sample.");
          }
          const xingOffset = getXingOffset(header.mpegVersionId, header.channel);
          if (view2.byteLength >= xingOffset + 4) {
            const word2 = view2.getUint32(xingOffset, false);
            const isXing = word2 === XING || word2 === INFO;
            if (isXing) {
              return;
            }
          }
          this.xingFrameData = {
            mpegVersionId: header.mpegVersionId,
            layer: header.layer,
            frequencyIndex: header.frequencyIndex,
            channel: header.channel,
            modeExtension: header.modeExtension,
            copyright: header.copyright,
            original: header.original,
            emphasis: header.emphasis,
            frameCount: null,
            fileSize: null,
            toc: null
          };
          this.mp3Writer.writeXingFrame(this.xingFrameData);
          this.frameCount++;
        }
        this.validateAndNormalizeTimestamp(track, packet.timestamp, packet.type === "key");
        this.writer.write(packet.data);
        this.frameCount++;
        await this.writer.flush();
        if (writeXingHeader) {
          this.framePositions.push(this.writer.getPos());
        }
      } finally {
        release();
      }
    }
    async addSubtitleCue() {
      throw new Error("MP3 does not support subtitles.");
    }
    async finalize() {
      if (!this.xingFrameData) {
        return;
      }
      const release = await this.mutex.acquire();
      const endPos = this.writer.getPos();
      this.writer.seek(0);
      const toc = new Uint8Array(100);
      for (let i = 0; i < 100; i++) {
        const index = Math.floor(this.framePositions.length * (i / 100));
        assert(index !== -1 && index < this.framePositions.length);
        const byteOffset = this.framePositions[index];
        toc[i] = 256 * (byteOffset / endPos);
      }
      this.xingFrameData.frameCount = this.frameCount;
      this.xingFrameData.fileSize = endPos;
      this.xingFrameData.toc = toc;
      if (this.format._options.onXingFrame) {
        this.writer.startTrackingWrites();
      }
      this.mp3Writer.writeXingFrame(this.xingFrameData);
      if (this.format._options.onXingFrame) {
        const { data, start } = this.writer.stopTrackingWrites();
        this.format._options.onXingFrame(data, start);
      }
      this.writer.seek(endPos);
      release();
    }
  };

  // src/ogg/ogg-misc.ts
  var OGGS = 1399285583;
  var OGG_CRC_POLYNOMIAL = 79764919;
  var OGG_CRC_TABLE = new Uint32Array(256);
  for (let n = 0; n < 256; n++) {
    let crc = n << 24;
    for (let k = 0; k < 8; k++) {
      crc = crc & 2147483648 ? crc << 1 ^ OGG_CRC_POLYNOMIAL : crc << 1;
    }
    OGG_CRC_TABLE[n] = crc >>> 0 & 4294967295;
  }
  var computeOggPageCrc = (bytes2) => {
    const view2 = toDataView(bytes2);
    const originalChecksum = view2.getUint32(22, true);
    view2.setUint32(22, 0, true);
    let crc = 0;
    for (let i = 0; i < bytes2.length; i++) {
      const byte = bytes2[i];
      crc = (crc << 8 ^ OGG_CRC_TABLE[crc >>> 24 ^ byte]) >>> 0;
    }
    view2.setUint32(22, originalChecksum, true);
    return crc;
  };
  var extractSampleMetadata = (data, codecInfo, vorbisLastBlocksize) => {
    let durationInSamples = 0;
    let currentBlocksize = null;
    if (data.length > 0) {
      if (codecInfo.codec === "vorbis") {
        assert(codecInfo.vorbisInfo);
        const vorbisModeCount = codecInfo.vorbisInfo.modeBlockflags.length;
        const bitCount = ilog(vorbisModeCount - 1);
        const modeMask = (1 << bitCount) - 1 << 1;
        const modeNumber = (data[0] & modeMask) >> 1;
        if (modeNumber >= codecInfo.vorbisInfo.modeBlockflags.length) {
          throw new Error("Invalid mode number.");
        }
        let prevBlocksize = vorbisLastBlocksize;
        const blockflag = codecInfo.vorbisInfo.modeBlockflags[modeNumber];
        currentBlocksize = codecInfo.vorbisInfo.blocksizes[blockflag];
        if (blockflag === 1) {
          const prevMask = (modeMask | 1) + 1;
          const flag = data[0] & prevMask ? 1 : 0;
          prevBlocksize = codecInfo.vorbisInfo.blocksizes[flag];
        }
        durationInSamples = prevBlocksize !== null ? prevBlocksize + currentBlocksize >> 2 : 0;
      } else if (codecInfo.codec === "opus") {
        const toc = parseOpusTocByte(data);
        durationInSamples = toc.durationInSamples;
      }
    }
    return {
      durationInSamples,
      vorbisBlockSize: currentBlocksize
    };
  };
  var buildOggMimeType = (info) => {
    let string = "audio/ogg";
    if (info.codecStrings) {
      const uniqueCodecMimeTypes = [...new Set(info.codecStrings)];
      string += `; codecs="${uniqueCodecMimeTypes.join(", ")}"`;
    }
    return string;
  };

  // src/ogg/ogg-reader.ts
  var MIN_PAGE_HEADER_SIZE = 27;
  var MAX_PAGE_HEADER_SIZE = 27 + 255;
  var MAX_PAGE_SIZE = MAX_PAGE_HEADER_SIZE + 255 * 255;
  var OggReader = class {
    constructor(reader) {
      this.reader = reader;
      this.pos = 0;
    }
    readBytes(length) {
      const { view: view2, offset } = this.reader.getViewAndOffset(this.pos, this.pos + length);
      this.pos += length;
      return new Uint8Array(view2.buffer, offset, length);
    }
    readU8() {
      const { view: view2, offset } = this.reader.getViewAndOffset(this.pos, this.pos + 1);
      this.pos += 1;
      return view2.getUint8(offset);
    }
    readU32() {
      const { view: view2, offset } = this.reader.getViewAndOffset(this.pos, this.pos + 4);
      this.pos += 4;
      return view2.getUint32(offset, true);
    }
    readI32() {
      const { view: view2, offset } = this.reader.getViewAndOffset(this.pos, this.pos + 4);
      this.pos += 4;
      return view2.getInt32(offset, true);
    }
    readI64() {
      const low = this.readU32();
      const high = this.readI32();
      return high * 4294967296 + low;
    }
    readAscii(length) {
      const { view: view2, offset } = this.reader.getViewAndOffset(this.pos, this.pos + length);
      this.pos += length;
      let str = "";
      for (let i = 0; i < length; i++) {
        str += String.fromCharCode(view2.getUint8(offset + i));
      }
      return str;
    }
    readPageHeader() {
      const startPos = this.pos;
      const capturePattern = this.readU32();
      if (capturePattern !== OGGS) {
        return null;
      }
      this.pos += 1;
      const headerType = this.readU8();
      const granulePosition = this.readI64();
      const serialNumber = this.readU32();
      const sequenceNumber = this.readU32();
      const checksum = this.readU32();
      const numberPageSegments = this.readU8();
      const lacingValues = new Uint8Array(numberPageSegments);
      for (let i = 0; i < numberPageSegments; i++) {
        lacingValues[i] = this.readU8();
      }
      const headerSize = 27 + numberPageSegments;
      const dataSize = lacingValues.reduce((a, b) => a + b, 0);
      const totalSize = headerSize + dataSize;
      return {
        headerStartPos: startPos,
        totalSize,
        dataStartPos: startPos + headerSize,
        dataSize,
        headerType,
        granulePosition,
        serialNumber,
        sequenceNumber,
        checksum,
        lacingValues
      };
    }
    findNextPageHeader(until) {
      while (this.pos < until - (4 - 1)) {
        const word = this.readU32();
        const firstByte = word & 255;
        const secondByte = word >>> 8 & 255;
        const thirdByte = word >>> 16 & 255;
        const fourthByte = word >>> 24 & 255;
        const O = 79;
        if (firstByte !== O && secondByte !== O && thirdByte !== O && fourthByte !== O) {
          continue;
        }
        this.pos -= 4;
        if (word === OGGS) {
          return true;
        }
        this.pos += 1;
      }
      return false;
    }
  };

  // src/ogg/ogg-muxer.ts
  var PAGE_SIZE_TARGET = 8192;
  var OggMuxer = class extends Muxer {
    constructor(output, format) {
      super(output);
      this.trackDatas = [];
      this.bosPagesWritten = false;
      this.allTracksKnown = promiseWithResolvers();
      this.pageBytes = new Uint8Array(MAX_PAGE_SIZE);
      this.pageView = new DataView(this.pageBytes.buffer);
      this.format = format;
      this.writer = output._writer;
      this.writer.ensureMonotonicity = true;
    }
    async start() {
    }
    async getMimeType() {
      await this.allTracksKnown.promise;
      return buildOggMimeType({
        codecStrings: this.trackDatas.map((x) => x.codecInfo.codec)
      });
    }
    addEncodedVideoPacket() {
      throw new Error("Video tracks are not supported.");
    }
    getTrackData(track, meta) {
      const existingTrackData = this.trackDatas.find((td) => td.track === track);
      if (existingTrackData) {
        return existingTrackData;
      }
      let serialNumber;
      do {
        serialNumber = Math.floor(2 ** 32 * Math.random());
      } while (this.trackDatas.some((td) => td.serialNumber === serialNumber));
      assert(track.source._codec === "vorbis" || track.source._codec === "opus");
      validateAudioChunkMetadata(meta);
      assert(meta);
      assert(meta.decoderConfig);
      const newTrackData = {
        track,
        serialNumber,
        internalSampleRate: track.source._codec === "opus" ? OPUS_INTERNAL_SAMPLE_RATE : meta.decoderConfig.sampleRate,
        codecInfo: {
          codec: track.source._codec,
          vorbisInfo: null,
          opusInfo: null
        },
        vorbisLastBlocksize: null,
        packetQueue: [],
        currentTimestampInSamples: 0,
        pagesWritten: 0,
        currentGranulePosition: 0,
        currentLacingValues: [],
        currentPageData: [],
        currentPageSize: 27,
        currentPageStartsWithFreshPacket: true
      };
      this.queueHeaderPackets(newTrackData, meta);
      this.trackDatas.push(newTrackData);
      if (this.allTracksAreKnown()) {
        this.allTracksKnown.resolve();
      }
      return newTrackData;
    }
    queueHeaderPackets(trackData, meta) {
      assert(meta.decoderConfig);
      if (trackData.track.source._codec === "vorbis") {
        assert(meta.decoderConfig.description);
        const bytes2 = toUint8Array(meta.decoderConfig.description);
        if (bytes2[0] !== 2) {
          throw new TypeError("First byte of Vorbis decoder description must be 2.");
        }
        let pos = 1;
        const readPacketLength = () => {
          let length = 0;
          while (true) {
            const value = bytes2[pos++];
            if (value === void 0) {
              throw new TypeError("Vorbis decoder description is too short.");
            }
            length += value;
            if (value < 255) {
              return length;
            }
          }
        };
        const identificationHeaderLength = readPacketLength();
        const commentHeaderLength = readPacketLength();
        const setupHeaderLength = bytes2.length - pos;
        if (setupHeaderLength <= 0) {
          throw new TypeError("Vorbis decoder description is too short.");
        }
        const identificationHeader = bytes2.subarray(pos, pos += identificationHeaderLength);
        const commentHeader = bytes2.subarray(pos, pos += commentHeaderLength);
        const setupHeader = bytes2.subarray(pos);
        trackData.packetQueue.push({
          data: identificationHeader,
          endGranulePosition: 0,
          timestamp: 0,
          forcePageFlush: true
        }, {
          data: commentHeader,
          endGranulePosition: 0,
          timestamp: 0,
          forcePageFlush: false
        }, {
          data: setupHeader,
          endGranulePosition: 0,
          timestamp: 0,
          forcePageFlush: true
          // The last header packet must flush the page
        });
        const view2 = toDataView(identificationHeader);
        const blockSizeByte = view2.getUint8(28);
        trackData.codecInfo.vorbisInfo = {
          blocksizes: [
            1 << (blockSizeByte & 15),
            1 << (blockSizeByte >> 4)
          ],
          modeBlockflags: parseModesFromVorbisSetupPacket(setupHeader).modeBlockflags
        };
      } else if (trackData.track.source._codec === "opus") {
        if (!meta.decoderConfig.description) {
          throw new TypeError("For Ogg, Opus decoder description is required.");
        }
        const identificationHeader = toUint8Array(meta.decoderConfig.description);
        const commentHeader = new Uint8Array(8 + 4 + 4);
        const view2 = new DataView(commentHeader.buffer);
        view2.setUint32(0, 1332770163, false);
        view2.setUint32(4, 1415669619, false);
        view2.setUint32(8, 0, true);
        view2.setUint32(12, 0, true);
        trackData.packetQueue.push({
          data: identificationHeader,
          endGranulePosition: 0,
          timestamp: 0,
          forcePageFlush: true
        }, {
          data: commentHeader,
          endGranulePosition: 0,
          timestamp: 0,
          forcePageFlush: true
          // The last header packet must flush the page
        });
        trackData.codecInfo.opusInfo = {
          preSkip: parseOpusIdentificationHeader(identificationHeader).preSkip
        };
      }
    }
    async addEncodedAudioPacket(track, packet, meta) {
      const release = await this.mutex.acquire();
      try {
        const trackData = this.getTrackData(track, meta);
        this.validateAndNormalizeTimestamp(trackData.track, packet.timestamp, packet.type === "key");
        const currentTimestampInSamples = trackData.currentTimestampInSamples;
        const { durationInSamples, vorbisBlockSize } = extractSampleMetadata(
          packet.data,
          trackData.codecInfo,
          trackData.vorbisLastBlocksize
        );
        trackData.currentTimestampInSamples += durationInSamples;
        trackData.vorbisLastBlocksize = vorbisBlockSize;
        trackData.packetQueue.push({
          data: packet.data,
          endGranulePosition: trackData.currentTimestampInSamples,
          timestamp: currentTimestampInSamples / trackData.internalSampleRate,
          forcePageFlush: false
        });
        await this.interleavePages();
      } finally {
        release();
      }
    }
    addSubtitleCue() {
      throw new Error("Subtitle tracks are not supported.");
    }
    allTracksAreKnown() {
      for (const track of this.output._tracks) {
        if (!track.source._closed && !this.trackDatas.some((x) => x.track === track)) {
          return false;
        }
      }
      return true;
    }
    async interleavePages(isFinalCall = false) {
      if (!this.bosPagesWritten) {
        if (!this.allTracksAreKnown()) {
          return;
        }
        for (const trackData of this.trackDatas) {
          while (trackData.packetQueue.length > 0) {
            const packet = trackData.packetQueue.shift();
            this.writePacket(trackData, packet, false);
            if (packet.forcePageFlush) {
              break;
            }
          }
        }
        this.bosPagesWritten = true;
      }
      outer:
        while (true) {
          let trackWithMinTimestamp = null;
          let minTimestamp = Infinity;
          for (const trackData of this.trackDatas) {
            if (!isFinalCall && trackData.packetQueue.length <= 1 && !trackData.track.source._closed) {
              break outer;
            }
            if (trackData.packetQueue.length > 0 && trackData.packetQueue[0].timestamp < minTimestamp) {
              trackWithMinTimestamp = trackData;
              minTimestamp = trackData.packetQueue[0].timestamp;
            }
          }
          if (!trackWithMinTimestamp) {
            break;
          }
          const packet = trackWithMinTimestamp.packetQueue.shift();
          const isFinalPacket = trackWithMinTimestamp.packetQueue.length === 0;
          this.writePacket(trackWithMinTimestamp, packet, isFinalPacket);
        }
      if (!isFinalCall) {
        await this.writer.flush();
      }
    }
    writePacket(trackData, packet, isFinalPacket) {
      let remainingLength = packet.data.length;
      let dataStartOffset = 0;
      let dataOffset = 0;
      while (true) {
        if (trackData.currentLacingValues.length === 0 && dataStartOffset > 0) {
          trackData.currentPageStartsWithFreshPacket = false;
        }
        const segmentSize = Math.min(255, remainingLength);
        trackData.currentLacingValues.push(segmentSize);
        trackData.currentPageSize++;
        dataOffset += segmentSize;
        const segmentIsLastOfPacket = remainingLength < 255;
        if (trackData.currentLacingValues.length === 255) {
          const slice2 = packet.data.subarray(dataStartOffset, dataOffset);
          dataStartOffset = dataOffset;
          trackData.currentPageData.push(slice2);
          trackData.currentPageSize += slice2.length;
          this.writePage(trackData, isFinalPacket && segmentIsLastOfPacket);
          if (segmentIsLastOfPacket) {
            return;
          }
        }
        if (segmentIsLastOfPacket) {
          break;
        }
        remainingLength -= 255;
      }
      const slice = packet.data.subarray(dataStartOffset);
      trackData.currentPageData.push(slice);
      trackData.currentPageSize += slice.length;
      trackData.currentGranulePosition = packet.endGranulePosition;
      if (trackData.currentPageSize >= PAGE_SIZE_TARGET || packet.forcePageFlush) {
        this.writePage(trackData, isFinalPacket);
      }
    }
    writePage(trackData, isEos) {
      this.pageView.setUint32(0, OGGS, true);
      this.pageView.setUint8(4, 0);
      let headerType = 0;
      if (!trackData.currentPageStartsWithFreshPacket) {
        headerType |= 1;
      }
      if (trackData.pagesWritten === 0) {
        headerType |= 2;
      }
      if (isEos) {
        headerType |= 4;
      }
      this.pageView.setUint8(5, headerType);
      const granulePosition = trackData.currentLacingValues.every((x) => x === 255) ? -1 : trackData.currentGranulePosition;
      setInt64(this.pageView, 6, granulePosition, true);
      this.pageView.setUint32(14, trackData.serialNumber, true);
      this.pageView.setUint32(18, trackData.pagesWritten, true);
      this.pageView.setUint32(22, 0, true);
      this.pageView.setUint8(26, trackData.currentLacingValues.length);
      this.pageBytes.set(trackData.currentLacingValues, 27);
      let pos = 27 + trackData.currentLacingValues.length;
      for (const data of trackData.currentPageData) {
        this.pageBytes.set(data, pos);
        pos += data.length;
      }
      const slice = this.pageBytes.subarray(0, pos);
      const crc = computeOggPageCrc(slice);
      this.pageView.setUint32(22, crc, true);
      trackData.pagesWritten++;
      trackData.currentLacingValues.length = 0;
      trackData.currentPageData.length = 0;
      trackData.currentPageSize = 27;
      trackData.currentPageStartsWithFreshPacket = true;
      if (this.format._options.onPage) {
        this.writer.startTrackingWrites();
      }
      this.writer.write(slice);
      if (this.format._options.onPage) {
        const { data, start } = this.writer.stopTrackingWrites();
        this.format._options.onPage(data, start, trackData.track.source);
      }
    }
    // eslint-disable-next-line @typescript-eslint/no-misused-promises
    async onTrackClose() {
      const release = await this.mutex.acquire();
      if (this.allTracksAreKnown()) {
        this.allTracksKnown.resolve();
      }
      await this.interleavePages();
      release();
    }
    async finalize() {
      const release = await this.mutex.acquire();
      this.allTracksKnown.resolve();
      await this.interleavePages(true);
      for (const trackData of this.trackDatas) {
        if (trackData.currentLacingValues.length > 0) {
          this.writePage(trackData, true);
        }
      }
      release();
    }
  };

  // src/demuxer.ts
  var Demuxer = class {
    constructor(input) {
      this.input = input;
    }
  };

  // src/packet.ts
  var PLACEHOLDER_DATA = new Uint8Array(0);
  var EncodedPacket = class _EncodedPacket {
    constructor(data, type, timestamp, duration, sequenceNumber = -1, byteLength) {
      this.data = data;
      this.type = type;
      this.timestamp = timestamp;
      this.duration = duration;
      this.sequenceNumber = sequenceNumber;
      if (data === PLACEHOLDER_DATA && byteLength === void 0) {
        throw new Error(
          "Internal error: byteLength must be explicitly provided when constructing metadata-only packets."
        );
      }
      if (byteLength === void 0) {
        byteLength = data.byteLength;
      }
      if (!(data instanceof Uint8Array)) {
        throw new TypeError("data must be a Uint8Array.");
      }
      if (type !== "key" && type !== "delta") {
        throw new TypeError('type must be either "key" or "delta".');
      }
      if (!Number.isFinite(timestamp)) {
        throw new TypeError("timestamp must be a number.");
      }
      if (!Number.isFinite(duration) || duration < 0) {
        throw new TypeError("duration must be a non-negative number.");
      }
      if (!Number.isFinite(sequenceNumber)) {
        throw new TypeError("sequenceNumber must be a number.");
      }
      if (!Number.isInteger(byteLength) || byteLength < 0) {
        throw new TypeError("byteLength must be a non-negative integer.");
      }
      this.byteLength = byteLength;
    }
    /** If this packet is a metadata-only packet. Metadata-only packets don't contain their packet data. */
    get isMetadataOnly() {
      return this.data === PLACEHOLDER_DATA;
    }
    /** The timestamp of this packet in microseconds. */
    get microsecondTimestamp() {
      return Math.trunc(SECOND_TO_MICROSECOND_FACTOR * this.timestamp);
    }
    /** The duration of this packet in microseconds. */
    get microsecondDuration() {
      return Math.trunc(SECOND_TO_MICROSECOND_FACTOR * this.duration);
    }
    /** Converts this packet to an EncodedVideoChunk for use with the WebCodecs API. */
    toEncodedVideoChunk() {
      if (this.isMetadataOnly) {
        throw new TypeError("Metadata-only packets cannot be converted to a video chunk.");
      }
      if (typeof EncodedVideoChunk === "undefined") {
        throw new Error("Your browser does not support EncodedVideoChunk.");
      }
      return new EncodedVideoChunk({
        data: this.data,
        type: this.type,
        timestamp: this.microsecondTimestamp,
        duration: this.microsecondDuration
      });
    }
    /** Converts this packet to an EncodedAudioChunk for use with the WebCodecs API. */
    toEncodedAudioChunk() {
      if (this.isMetadataOnly) {
        throw new TypeError("Metadata-only packets cannot be converted to an audio chunk.");
      }
      if (typeof EncodedAudioChunk === "undefined") {
        throw new Error("Your browser does not support EncodedAudioChunk.");
      }
      return new EncodedAudioChunk({
        data: this.data,
        type: this.type,
        timestamp: this.microsecondTimestamp,
        duration: this.microsecondDuration
      });
    }
    /**
     * Creates an EncodedPacket from an EncodedVideoChunk or EncodedAudioChunk. This method is useful for converting
     * chunks from the WebCodecs API to EncodedPackets.
     */
    static fromEncodedChunk(chunk) {
      if (!(chunk instanceof EncodedVideoChunk || chunk instanceof EncodedAudioChunk)) {
        throw new TypeError("chunk must be an EncodedVideoChunk or EncodedAudioChunk.");
      }
      const data = new Uint8Array(chunk.byteLength);
      chunk.copyTo(data);
      return new _EncodedPacket(
        data,
        chunk.type,
        chunk.timestamp / 1e6,
        (chunk.duration ?? 0) / 1e6
      );
    }
    /** Clones this packet while optionally updating timing information. */
    clone(options) {
      if (options !== void 0 && (typeof options !== "object" || options === null)) {
        throw new TypeError("options, when provided, must be an object.");
      }
      if (options?.timestamp !== void 0 && !Number.isFinite(options.timestamp)) {
        throw new TypeError("options.timestamp, when provided, must be a number.");
      }
      if (options?.duration !== void 0 && !Number.isFinite(options.duration)) {
        throw new TypeError("options.duration, when provided, must be a number.");
      }
      return new _EncodedPacket(
        this.data,
        this.type,
        options?.timestamp ?? this.timestamp,
        options?.duration ?? this.duration,
        this.sequenceNumber,
        this.byteLength
      );
    }
  };

  // src/pcm.ts
  var toUlaw = (s16) => {
    const MULAW_MAX = 8191;
    const MULAW_BIAS = 33;
    let number = s16;
    let mask = 4096;
    let sign = 0;
    let position = 12;
    let lsb = 0;
    if (number < 0) {
      number = -number;
      sign = 128;
    }
    number += MULAW_BIAS;
    if (number > MULAW_MAX) {
      number = MULAW_MAX;
    }
    while ((number & mask) !== mask && position >= 5) {
      mask >>= 1;
      position--;
    }
    lsb = number >> position - 4 & 15;
    return ~(sign | position - 5 << 4 | lsb) & 255;
  };
  var fromUlaw = (u82) => {
    const MULAW_BIAS = 33;
    let sign = 0;
    let position = 0;
    let number = ~u82;
    if (number & 128) {
      number &= ~(1 << 7);
      sign = -1;
    }
    position = ((number & 240) >> 4) + 5;
    const decoded = (1 << position | (number & 15) << position - 4 | 1 << position - 5) - MULAW_BIAS;
    return sign === 0 ? decoded : -decoded;
  };
  var toAlaw = (s16) => {
    const ALAW_MAX = 4095;
    let mask = 2048;
    let sign = 0;
    let position = 11;
    let lsb = 0;
    let number = s16;
    if (number < 0) {
      number = -number;
      sign = 128;
    }
    if (number > ALAW_MAX) {
      number = ALAW_MAX;
    }
    while ((number & mask) !== mask && position >= 5) {
      mask >>= 1;
      position--;
    }
    lsb = number >> (position === 4 ? 1 : position - 4) & 15;
    return (sign | position - 4 << 4 | lsb) ^ 85;
  };
  var fromAlaw = (u82) => {
    let sign = 0;
    let position = 0;
    let number = u82 ^ 85;
    if (number & 128) {
      number &= ~(1 << 7);
      sign = -1;
    }
    position = ((number & 240) >> 4) + 4;
    let decoded = 0;
    if (position !== 4) {
      decoded = 1 << position | (number & 15) << position - 4 | 1 << position - 5;
    } else {
      decoded = number << 1 | 1;
    }
    return sign === 0 ? decoded : -decoded;
  };

  // src/sample.ts
  var VideoSample = class _VideoSample {
    constructor(data, init) {
      /** @internal */
      this._closed = false;
      if (data instanceof ArrayBuffer || ArrayBuffer.isView(data)) {
        if (!init || typeof init !== "object") {
          throw new TypeError("init must be an object.");
        }
        if (!("format" in init) || typeof init.format !== "string") {
          throw new TypeError("init.format must be a string.");
        }
        if (!Number.isInteger(init.codedWidth) || init.codedWidth <= 0) {
          throw new TypeError("init.codedWidth must be a positive integer.");
        }
        if (!Number.isInteger(init.codedHeight) || init.codedHeight <= 0) {
          throw new TypeError("init.codedHeight must be a positive integer.");
        }
        if (init.rotation !== void 0 && ![0, 90, 180, 270].includes(init.rotation)) {
          throw new TypeError("init.rotation, when provided, must be 0, 90, 180, or 270.");
        }
        if (!Number.isFinite(init.timestamp)) {
          throw new TypeError("init.timestamp must be a number.");
        }
        if (init.duration !== void 0 && (!Number.isFinite(init.duration) || init.duration < 0)) {
          throw new TypeError("init.duration, when provided, must be a non-negative number.");
        }
        this._data = toUint8Array(data).slice();
        this.format = init.format;
        this.codedWidth = init.codedWidth;
        this.codedHeight = init.codedHeight;
        this.rotation = init.rotation ?? 0;
        this.timestamp = init.timestamp;
        this.duration = init.duration ?? 0;
        this.colorSpace = new VideoColorSpace(init.colorSpace);
      } else if (typeof VideoFrame !== "undefined" && data instanceof VideoFrame) {
        if (init?.rotation !== void 0 && ![0, 90, 180, 270].includes(init.rotation)) {
          throw new TypeError("init.rotation, when provided, must be 0, 90, 180, or 270.");
        }
        if (init?.timestamp !== void 0 && !Number.isFinite(init?.timestamp)) {
          throw new TypeError("init.timestamp, when provided, must be a number.");
        }
        if (init?.duration !== void 0 && (!Number.isFinite(init.duration) || init.duration < 0)) {
          throw new TypeError("init.duration, when provided, must be a non-negative number.");
        }
        this._data = data;
        this.format = data.format;
        this.codedWidth = data.codedWidth;
        this.codedHeight = data.codedHeight;
        this.rotation = init?.rotation ?? 0;
        this.timestamp = init?.timestamp ?? data.timestamp / 1e6;
        this.duration = init?.duration ?? (data.duration ?? 0) / 1e6;
        this.colorSpace = data.colorSpace;
      } else if (typeof HTMLImageElement !== "undefined" && data instanceof HTMLImageElement || typeof SVGImageElement !== "undefined" && data instanceof SVGImageElement || typeof ImageBitmap !== "undefined" && data instanceof ImageBitmap || typeof HTMLVideoElement !== "undefined" && data instanceof HTMLVideoElement || typeof HTMLCanvasElement !== "undefined" && data instanceof HTMLCanvasElement || typeof OffscreenCanvas !== "undefined" && data instanceof OffscreenCanvas) {
        if (!init || typeof init !== "object") {
          throw new TypeError("init must be an object.");
        }
        if (init.rotation !== void 0 && ![0, 90, 180, 270].includes(init.rotation)) {
          throw new TypeError("init.rotation, when provided, must be 0, 90, 180, or 270.");
        }
        if (!Number.isFinite(init.timestamp)) {
          throw new TypeError("init.timestamp must be a number.");
        }
        if (init.duration !== void 0 && (!Number.isFinite(init.duration) || init.duration < 0)) {
          throw new TypeError("init.duration, when provided, must be a non-negative number.");
        }
        if (typeof VideoFrame !== "undefined") {
          return new _VideoSample(
            new VideoFrame(data, {
              timestamp: Math.trunc(init.timestamp * SECOND_TO_MICROSECOND_FACTOR),
              duration: Math.trunc((init.duration ?? 0) * SECOND_TO_MICROSECOND_FACTOR)
            }),
            init
          );
        }
        let width = 0;
        let height = 0;
        if ("naturalWidth" in data) {
          width = data.naturalWidth;
          height = data.naturalHeight;
        } else if ("videoWidth" in data) {
          width = data.videoWidth;
          height = data.videoHeight;
        } else if ("width" in data) {
          width = Number(data.width);
          height = Number(data.height);
        }
        if (!width || !height) {
          throw new TypeError("Could not determine dimensions.");
        }
        const canvas = new OffscreenCanvas(width, height);
        const context = canvas.getContext("2d", { alpha: false, willReadFrequently: true });
        assert(context);
        context.drawImage(data, 0, 0);
        this._data = canvas;
        this.format = "RGBX";
        this.codedWidth = width;
        this.codedHeight = height;
        this.rotation = init.rotation ?? 0;
        this.timestamp = init.timestamp;
        this.duration = init.duration ?? 0;
        this.colorSpace = new VideoColorSpace({
          matrix: "rgb",
          primaries: "bt709",
          transfer: "iec61966-2-1",
          fullRange: true
        });
      } else {
        throw new TypeError("Invalid data type: Must be a BufferSource or CanvasImageSource.");
      }
    }
    /** The width of the frame in pixels after rotation. */
    get displayWidth() {
      return this.rotation % 180 === 0 ? this.codedWidth : this.codedHeight;
    }
    /** The height of the frame in pixels after rotation. */
    get displayHeight() {
      return this.rotation % 180 === 0 ? this.codedHeight : this.codedWidth;
    }
    /** The presentation timestamp of the frame in microseconds. */
    get microsecondTimestamp() {
      return Math.trunc(SECOND_TO_MICROSECOND_FACTOR * this.timestamp);
    }
    /** The duration of the frame in microseconds. */
    get microsecondDuration() {
      return Math.trunc(SECOND_TO_MICROSECOND_FACTOR * this.duration);
    }
    /** Clones this video sample. */
    clone() {
      if (this._closed) {
        throw new Error("VideoSample is closed.");
      }
      assert(this._data !== null);
      if (isVideoFrame(this._data)) {
        return new _VideoSample(this._data.clone(), {
          timestamp: this.timestamp,
          duration: this.duration,
          rotation: this.rotation
        });
      } else if (this._data instanceof Uint8Array) {
        return new _VideoSample(this._data.slice(), {
          format: this.format,
          codedWidth: this.codedWidth,
          codedHeight: this.codedHeight,
          timestamp: this.timestamp,
          duration: this.duration,
          colorSpace: this.colorSpace,
          rotation: this.rotation
        });
      } else {
        return new _VideoSample(this._data, {
          format: this.format,
          codedWidth: this.codedWidth,
          codedHeight: this.codedHeight,
          timestamp: this.timestamp,
          duration: this.duration,
          colorSpace: this.colorSpace,
          rotation: this.rotation
        });
      }
    }
    /**
     * Closes this video sample, releasing held resources. Video samples should be closed as soon as they are not
     * needed anymore.
     */
    close() {
      if (this._closed) {
        return;
      }
      if (isVideoFrame(this._data)) {
        this._data.close();
      } else {
        this._data = null;
      }
      this._closed = true;
    }
    /** Returns the number of bytes required to hold this video sample's pixel data. */
    allocationSize() {
      if (this._closed) {
        throw new Error("VideoSample is closed.");
      }
      assert(this._data !== null);
      if (isVideoFrame(this._data)) {
        return this._data.allocationSize();
      } else if (this._data instanceof Uint8Array) {
        return this._data.byteLength;
      } else {
        return this.codedWidth * this.codedHeight * 4;
      }
    }
    /** Copies this video sample's pixel data to an ArrayBuffer or ArrayBufferView. */
    async copyTo(destination) {
      if (!isAllowSharedBufferSource(destination)) {
        throw new TypeError("destination must be an ArrayBuffer or an ArrayBuffer view.");
      }
      if (this._closed) {
        throw new Error("VideoSample is closed.");
      }
      assert(this._data !== null);
      if (isVideoFrame(this._data)) {
        await this._data.copyTo(destination);
      } else if (this._data instanceof Uint8Array) {
        const dest = toUint8Array(destination);
        dest.set(this._data);
      } else {
        const canvas = this._data;
        const context = canvas.getContext("2d", { alpha: false });
        assert(context);
        const imageData = context.getImageData(0, 0, this.codedWidth, this.codedHeight);
        const dest = toUint8Array(destination);
        dest.set(imageData.data);
      }
    }
    /**
     * Converts this video sample to a VideoFrame for use with the WebCodecs API. The VideoFrame returned by this
     * method *must* be closed separately from this video sample.
     */
    toVideoFrame() {
      if (this._closed) {
        throw new Error("VideoSample is closed.");
      }
      assert(this._data !== null);
      if (isVideoFrame(this._data)) {
        return new VideoFrame(this._data, {
          timestamp: this.microsecondTimestamp,
          duration: this.microsecondDuration || void 0
          // Drag 0 duration to undefined, glitches some codecs
        });
      } else if (this._data instanceof Uint8Array) {
        return new VideoFrame(this._data, {
          format: this.format,
          codedWidth: this.codedWidth,
          codedHeight: this.codedHeight,
          timestamp: this.microsecondTimestamp,
          duration: this.microsecondDuration,
          colorSpace: this.colorSpace
        });
      } else {
        return new VideoFrame(this._data, {
          timestamp: this.microsecondTimestamp,
          duration: this.microsecondDuration
        });
      }
    }
    draw(context, arg1, arg2, arg3, arg4, arg5, arg6, arg7, arg8) {
      let sx = 0;
      let sy = 0;
      let sWidth = this.displayWidth;
      let sHeight = this.displayHeight;
      let dx = 0;
      let dy = 0;
      let dWidth = this.displayWidth;
      let dHeight = this.displayHeight;
      if (arg5 !== void 0) {
        sx = arg1;
        sy = arg2;
        sWidth = arg3;
        sHeight = arg4;
        dx = arg5;
        dy = arg6;
        if (arg7 !== void 0) {
          dWidth = arg7;
          dHeight = arg8;
        } else {
          dWidth = sWidth;
          dHeight = sHeight;
        }
      } else {
        dx = arg1;
        dy = arg2;
        if (arg3 !== void 0) {
          dWidth = arg3;
          dHeight = arg4;
        }
      }
      if (!(typeof CanvasRenderingContext2D !== "undefined" && context instanceof CanvasRenderingContext2D || typeof OffscreenCanvasRenderingContext2D !== "undefined" && context instanceof OffscreenCanvasRenderingContext2D)) {
        throw new TypeError("context must be a CanvasRenderingContext2D or OffscreenCanvasRenderingContext2D.");
      }
      if (!Number.isFinite(sx)) {
        throw new TypeError("sx must be a number.");
      }
      if (!Number.isFinite(sy)) {
        throw new TypeError("sy must be a number.");
      }
      if (!Number.isFinite(sWidth) || sWidth < 0) {
        throw new TypeError("sWidth must be a non-negative number.");
      }
      if (!Number.isFinite(sHeight) || sHeight < 0) {
        throw new TypeError("sHeight must be a non-negative number.");
      }
      if (!Number.isFinite(dx)) {
        throw new TypeError("dx must be a number.");
      }
      if (!Number.isFinite(dy)) {
        throw new TypeError("dy must be a number.");
      }
      if (!Number.isFinite(dWidth) || dWidth < 0) {
        throw new TypeError("dWidth must be a non-negative number.");
      }
      if (!Number.isFinite(dHeight) || dHeight < 0) {
        throw new TypeError("dHeight must be a non-negative number.");
      }
      if (this._closed) {
        throw new Error("VideoSample is closed.");
      }
      if (this.rotation === 90) {
        [sx, sy, sWidth, sHeight] = [
          sy,
          this.codedHeight - sx - sWidth,
          sHeight,
          sWidth
        ];
      } else if (this.rotation === 180) {
        [sx, sy] = [
          this.codedWidth - sx - sWidth,
          this.codedHeight - sy - sHeight
        ];
      } else if (this.rotation === 270) {
        [sx, sy, sWidth, sHeight] = [
          this.codedWidth - sy - sHeight,
          sx,
          sHeight,
          sWidth
        ];
      }
      const source = this.toCanvasImageSource();
      context.save();
      const centerX = dx + dWidth / 2;
      const centerY = dy + dHeight / 2;
      context.translate(centerX, centerY);
      context.rotate(this.rotation * Math.PI / 180);
      const aspectRatioChange = this.rotation % 180 === 0 ? 1 : dWidth / dHeight;
      context.scale(1 / aspectRatioChange, aspectRatioChange);
      context.drawImage(
        source,
        sx,
        sy,
        sWidth,
        sHeight,
        -dWidth / 2,
        -dHeight / 2,
        dWidth,
        dHeight
      );
      context.restore();
    }
    /**
     * Converts this video sample to a CanvasImageSource for drawing to a canvas.
     *
     * You must use the value returned by this method immediately, as any VideoFrame created internally will
     * automatically be closed in the next microtask.
     */
    toCanvasImageSource() {
      if (this._closed) {
        throw new Error("VideoSample is closed.");
      }
      assert(this._data !== null);
      if (this._data instanceof Uint8Array) {
        const videoFrame = this.toVideoFrame();
        queueMicrotask(() => videoFrame.close());
        return videoFrame;
      } else {
        return this._data;
      }
    }
    /** Sets the rotation metadata of this video sample. */
    setRotation(newRotation) {
      if (![0, 90, 180, 270].includes(newRotation)) {
        throw new TypeError("newRotation must be 0, 90, 180, or 270.");
      }
      this.rotation = newRotation;
    }
    /** Sets the presentation timestamp of this video sample, in seconds. */
    setTimestamp(newTimestamp) {
      if (!Number.isFinite(newTimestamp)) {
        throw new TypeError("newTimestamp must be a number.");
      }
      this.timestamp = newTimestamp;
    }
    /** Sets the duration of this video sample, in seconds. */
    setDuration(newDuration) {
      if (!Number.isFinite(newDuration) || newDuration < 0) {
        throw new TypeError("newDuration must be a non-negative number.");
      }
      this.duration = newDuration;
    }
  };
  var isVideoFrame = (x) => {
    return typeof VideoFrame !== "undefined" && x instanceof VideoFrame;
  };
  var AUDIO_SAMPLE_FORMATS = /* @__PURE__ */ new Set(
    ["f32", "f32-planar", "s16", "s16-planar", "s32", "s32-planar", "u8", "u8-planar"]
  );
  var AudioSample = class _AudioSample {
    constructor(init) {
      /** @internal */
      this._closed = false;
      if (isAudioData(init)) {
        if (init.format === null) {
          throw new TypeError("AudioData with null format is not supported.");
        }
        this._data = init;
        this.format = init.format;
        this.sampleRate = init.sampleRate;
        this.numberOfFrames = init.numberOfFrames;
        this.numberOfChannels = init.numberOfChannels;
        this.timestamp = init.timestamp / 1e6;
        this.duration = init.numberOfFrames / init.sampleRate;
      } else {
        if (!init || typeof init !== "object") {
          throw new TypeError("Invalid AudioDataInit: must be an object.");
        }
        if (!AUDIO_SAMPLE_FORMATS.has(init.format)) {
          throw new TypeError("Invalid AudioDataInit: invalid format.");
        }
        if (!Number.isFinite(init.sampleRate) || init.sampleRate <= 0) {
          throw new TypeError("Invalid AudioDataInit: sampleRate must be > 0.");
        }
        if (!Number.isInteger(init.numberOfChannels) || init.numberOfChannels === 0) {
          throw new TypeError("Invalid AudioDataInit: numberOfChannels must be an integer > 0.");
        }
        if (!Number.isFinite(init?.timestamp)) {
          throw new TypeError("init.timestamp must be a number.");
        }
        const numberOfFrames = init.data.byteLength / (getBytesPerSample(init.format) * init.numberOfChannels);
        if (!Number.isInteger(numberOfFrames)) {
          throw new TypeError("Invalid AudioDataInit: data size is not a multiple of frame size.");
        }
        this.format = init.format;
        this.sampleRate = init.sampleRate;
        this.numberOfFrames = numberOfFrames;
        this.numberOfChannels = init.numberOfChannels;
        this.timestamp = init.timestamp;
        this.duration = numberOfFrames / init.sampleRate;
        let dataBuffer;
        if (init.data instanceof ArrayBuffer) {
          dataBuffer = new Uint8Array(init.data);
        } else if (ArrayBuffer.isView(init.data)) {
          dataBuffer = new Uint8Array(init.data.buffer, init.data.byteOffset, init.data.byteLength);
        } else {
          throw new TypeError("Invalid AudioDataInit: data is not a BufferSource.");
        }
        const expectedSize = this.numberOfFrames * this.numberOfChannels * getBytesPerSample(this.format);
        if (dataBuffer.byteLength < expectedSize) {
          throw new TypeError("Invalid AudioDataInit: insufficient data size.");
        }
        this._data = dataBuffer;
      }
    }
    /** The presentation timestamp of the sample in microseconds. */
    get microsecondTimestamp() {
      return Math.trunc(SECOND_TO_MICROSECOND_FACTOR * this.timestamp);
    }
    /** The duration of the sample in microseconds. */
    get microsecondDuration() {
      return Math.trunc(SECOND_TO_MICROSECOND_FACTOR * this.duration);
    }
    /** Returns the number of bytes required to hold the audio sample's data as specified by the given options. */
    allocationSize(options) {
      if (!options || typeof options !== "object") {
        throw new TypeError("options must be an object.");
      }
      if (!Number.isInteger(options.planeIndex) || options.planeIndex < 0) {
        throw new TypeError("planeIndex must be a non-negative integer.");
      }
      if (options.format !== void 0 && !AUDIO_SAMPLE_FORMATS.has(options.format)) {
        throw new TypeError("Invalid format.");
      }
      if (options.frameOffset !== void 0 && (!Number.isInteger(options.frameOffset) || options.frameOffset < 0)) {
        throw new TypeError("frameOffset must be a non-negative integer.");
      }
      if (options.frameCount !== void 0 && (!Number.isInteger(options.frameCount) || options.frameCount < 0)) {
        throw new TypeError("frameCount must be a non-negative integer.");
      }
      if (this._closed) {
        throw new Error("AudioSample is closed.");
      }
      const destFormat = options.format ?? this.format;
      const frameOffset = options.frameOffset ?? 0;
      if (frameOffset >= this.numberOfFrames) {
        throw new RangeError("frameOffset out of range");
      }
      const copyFrameCount = options.frameCount !== void 0 ? options.frameCount : this.numberOfFrames - frameOffset;
      if (copyFrameCount > this.numberOfFrames - frameOffset) {
        throw new RangeError("frameCount out of range");
      }
      const bytesPerSample = getBytesPerSample(destFormat);
      const isPlanar = formatIsPlanar(destFormat);
      if (isPlanar && options.planeIndex >= this.numberOfChannels) {
        throw new RangeError("planeIndex out of range");
      }
      if (!isPlanar && options.planeIndex !== 0) {
        throw new RangeError("planeIndex out of range");
      }
      const elementCount = isPlanar ? copyFrameCount : copyFrameCount * this.numberOfChannels;
      return elementCount * bytesPerSample;
    }
    /** Copies the audio sample's data to an ArrayBuffer or ArrayBufferView as specified by the given options. */
    copyTo(destination, options) {
      if (!isAllowSharedBufferSource(destination)) {
        throw new TypeError("destination must be an ArrayBuffer or an ArrayBuffer view.");
      }
      if (!options || typeof options !== "object") {
        throw new TypeError("options must be an object.");
      }
      if (!Number.isInteger(options.planeIndex) || options.planeIndex < 0) {
        throw new TypeError("planeIndex must be a non-negative integer.");
      }
      if (options.format !== void 0 && !AUDIO_SAMPLE_FORMATS.has(options.format)) {
        throw new TypeError("Invalid format.");
      }
      if (options.frameOffset !== void 0 && (!Number.isInteger(options.frameOffset) || options.frameOffset < 0)) {
        throw new TypeError("frameOffset must be a non-negative integer.");
      }
      if (options.frameCount !== void 0 && (!Number.isInteger(options.frameCount) || options.frameCount < 0)) {
        throw new TypeError("frameCount must be a non-negative integer.");
      }
      if (this._closed) {
        throw new Error("AudioSample is closed.");
      }
      const { planeIndex, format, frameCount: optFrameCount, frameOffset: optFrameOffset } = options;
      const destFormat = format ?? this.format;
      if (!destFormat) throw new Error("Destination format not determined");
      const numFrames = this.numberOfFrames;
      const numChannels = this.numberOfChannels;
      const frameOffset = optFrameOffset ?? 0;
      if (frameOffset >= numFrames) {
        throw new RangeError("frameOffset out of range");
      }
      const copyFrameCount = optFrameCount !== void 0 ? optFrameCount : numFrames - frameOffset;
      if (copyFrameCount > numFrames - frameOffset) {
        throw new RangeError("frameCount out of range");
      }
      const destBytesPerSample = getBytesPerSample(destFormat);
      const destIsPlanar = formatIsPlanar(destFormat);
      if (destIsPlanar && planeIndex >= numChannels) {
        throw new RangeError("planeIndex out of range");
      }
      if (!destIsPlanar && planeIndex !== 0) {
        throw new RangeError("planeIndex out of range");
      }
      const destElementCount = destIsPlanar ? copyFrameCount : copyFrameCount * numChannels;
      const requiredSize = destElementCount * destBytesPerSample;
      if (destination.byteLength < requiredSize) {
        throw new RangeError("Destination buffer is too small");
      }
      const destView = toDataView(destination);
      const writeFn = getWriteFunction(destFormat);
      if (isAudioData(this._data)) {
        if (destIsPlanar) {
          if (destFormat === "f32-planar") {
            this._data.copyTo(destination, {
              planeIndex,
              frameOffset,
              frameCount: copyFrameCount,
              format: "f32-planar"
            });
          } else {
            const tempBuffer = new ArrayBuffer(copyFrameCount * 4);
            const tempArray = new Float32Array(tempBuffer);
            this._data.copyTo(tempArray, {
              planeIndex,
              frameOffset,
              frameCount: copyFrameCount,
              format: "f32-planar"
            });
            const tempView = new DataView(tempBuffer);
            for (let i = 0; i < copyFrameCount; i++) {
              const destOffset = i * destBytesPerSample;
              const sample = tempView.getFloat32(i * 4, true);
              writeFn(destView, destOffset, sample);
            }
          }
        } else {
          const numCh = numChannels;
          const temp = new Float32Array(copyFrameCount);
          for (let ch = 0; ch < numCh; ch++) {
            this._data.copyTo(temp, {
              planeIndex: ch,
              frameOffset,
              frameCount: copyFrameCount,
              format: "f32-planar"
            });
            for (let i = 0; i < copyFrameCount; i++) {
              const destIndex = i * numCh + ch;
              const destOffset = destIndex * destBytesPerSample;
              writeFn(destView, destOffset, temp[i]);
            }
          }
        }
      } else {
        const uint8Data = this._data;
        const srcView = new DataView(uint8Data.buffer, uint8Data.byteOffset, uint8Data.byteLength);
        const srcFormat = this.format;
        const readFn = getReadFunction(srcFormat);
        const srcBytesPerSample = getBytesPerSample(srcFormat);
        const srcIsPlanar = formatIsPlanar(srcFormat);
        for (let i = 0; i < copyFrameCount; i++) {
          if (destIsPlanar) {
            const destOffset = i * destBytesPerSample;
            let srcOffset;
            if (srcIsPlanar) {
              srcOffset = (planeIndex * numFrames + (i + frameOffset)) * srcBytesPerSample;
            } else {
              srcOffset = ((i + frameOffset) * numChannels + planeIndex) * srcBytesPerSample;
            }
            const normalized = readFn(srcView, srcOffset);
            writeFn(destView, destOffset, normalized);
          } else {
            for (let ch = 0; ch < numChannels; ch++) {
              const destIndex = i * numChannels + ch;
              const destOffset = destIndex * destBytesPerSample;
              let srcOffset;
              if (srcIsPlanar) {
                srcOffset = (ch * numFrames + (i + frameOffset)) * srcBytesPerSample;
              } else {
                srcOffset = ((i + frameOffset) * numChannels + ch) * srcBytesPerSample;
              }
              const normalized = readFn(srcView, srcOffset);
              writeFn(destView, destOffset, normalized);
            }
          }
        }
      }
    }
    /** Clones this audio sample. */
    clone() {
      if (this._closed) {
        throw new Error("AudioSample is closed.");
      }
      if (isAudioData(this._data)) {
        const sample = new _AudioSample(this._data.clone());
        sample.setTimestamp(this.timestamp);
        return sample;
      } else {
        return new _AudioSample({
          format: this.format,
          sampleRate: this.sampleRate,
          numberOfFrames: this.numberOfFrames,
          numberOfChannels: this.numberOfChannels,
          timestamp: this.timestamp,
          data: this._data
        });
      }
    }
    /**
     * Closes this audio sample, releasing held resources. Audio samples should be closed as soon as they are not
     * needed anymore.
     */
    close() {
      if (this._closed) {
        return;
      }
      if (isAudioData(this._data)) {
        this._data.close();
      } else {
        this._data = new Uint8Array(0);
      }
      this._closed = true;
    }
    /**
     * Converts this audio sample to an AudioData for use with the WebCodecs API. The AudioData returned by this
     * method *must* be closed separately from this audio sample.
     */
    toAudioData() {
      if (this._closed) {
        throw new Error("AudioSample is closed.");
      }
      if (isAudioData(this._data)) {
        if (this._data.timestamp === this.microsecondTimestamp) {
          return this._data.clone();
        } else {
          if (formatIsPlanar(this.format)) {
            const size = this.allocationSize({ planeIndex: 0, format: this.format });
            const data = new ArrayBuffer(size * this.numberOfChannels);
            for (let i = 0; i < this.numberOfChannels; i++) {
              this.copyTo(new Uint8Array(data, i * size, size), { planeIndex: i, format: this.format });
            }
            return new AudioData({
              format: this.format,
              sampleRate: this.sampleRate,
              numberOfFrames: this.numberOfFrames,
              numberOfChannels: this.numberOfChannels,
              timestamp: this.microsecondTimestamp,
              data
            });
          } else {
            const data = new ArrayBuffer(this.allocationSize({ planeIndex: 0, format: this.format }));
            this.copyTo(data, { planeIndex: 0, format: this.format });
            return new AudioData({
              format: this.format,
              sampleRate: this.sampleRate,
              numberOfFrames: this.numberOfFrames,
              numberOfChannels: this.numberOfChannels,
              timestamp: this.microsecondTimestamp,
              data
            });
          }
        }
      } else {
        return new AudioData({
          format: this.format,
          sampleRate: this.sampleRate,
          numberOfFrames: this.numberOfFrames,
          numberOfChannels: this.numberOfChannels,
          timestamp: this.microsecondTimestamp,
          data: this._data
        });
      }
    }
    /** Convert this audio sample to an AudioBuffer for use with the Web Audio API. */
    toAudioBuffer() {
      if (this._closed) {
        throw new Error("AudioSample is closed.");
      }
      const audioBuffer = new AudioBuffer({
        numberOfChannels: this.numberOfChannels,
        length: this.numberOfFrames,
        sampleRate: this.sampleRate
      });
      const dataBytes = new Float32Array(this.allocationSize({ planeIndex: 0, format: "f32-planar" }) / 4);
      for (let i = 0; i < this.numberOfChannels; i++) {
        this.copyTo(dataBytes, { planeIndex: i, format: "f32-planar" });
        audioBuffer.copyToChannel(dataBytes, i);
      }
      return audioBuffer;
    }
    /** Sets the presentation timestamp of this audio sample, in seconds. */
    setTimestamp(newTimestamp) {
      if (!Number.isFinite(newTimestamp)) {
        throw new TypeError("newTimestamp must be a number.");
      }
      this.timestamp = newTimestamp;
    }
    /**
     * Creates AudioSamples from an AudioBuffer, starting at the given timestamp in seconds. Typically creates exactly
     * one sample, but may create multiple if the AudioBuffer is exceedingly large.
     */
    static fromAudioBuffer(audioBuffer, timestamp) {
      if (!(audioBuffer instanceof AudioBuffer)) {
        throw new TypeError("audioBuffer must be an AudioBuffer.");
      }
      const MAX_FLOAT_COUNT = 64 * 1024 * 1024;
      const numberOfChannels = audioBuffer.numberOfChannels;
      const sampleRate = audioBuffer.sampleRate;
      const totalFrames = audioBuffer.length;
      const maxFramesPerChunk = Math.floor(MAX_FLOAT_COUNT / numberOfChannels);
      let currentRelativeFrame = 0;
      let remainingFrames = totalFrames;
      const result = [];
      while (remainingFrames > 0) {
        const framesToCopy = Math.min(maxFramesPerChunk, remainingFrames);
        const chunkData = new Float32Array(numberOfChannels * framesToCopy);
        for (let channel = 0; channel < numberOfChannels; channel++) {
          audioBuffer.copyFromChannel(
            chunkData.subarray(channel * framesToCopy, channel * framesToCopy + framesToCopy),
            channel,
            currentRelativeFrame
          );
        }
        const audioSample = new _AudioSample({
          format: "f32-planar",
          sampleRate,
          numberOfFrames: framesToCopy,
          numberOfChannels,
          timestamp: timestamp + currentRelativeFrame / sampleRate,
          data: chunkData
        });
        result.push(audioSample);
        currentRelativeFrame += framesToCopy;
        remainingFrames -= framesToCopy;
      }
      return result;
    }
  };
  var getBytesPerSample = (format) => {
    switch (format) {
      case "u8":
      case "u8-planar":
        return 1;
      case "s16":
      case "s16-planar":
        return 2;
      case "s32":
      case "s32-planar":
        return 4;
      case "f32":
      case "f32-planar":
        return 4;
      default:
        throw new Error("Unknown AudioSampleFormat");
    }
  };
  var formatIsPlanar = (format) => {
    switch (format) {
      case "u8-planar":
      case "s16-planar":
      case "s32-planar":
      case "f32-planar":
        return true;
      default:
        return false;
    }
  };
  var getReadFunction = (format) => {
    switch (format) {
      case "u8":
      case "u8-planar":
        return (view2, offset) => (view2.getUint8(offset) - 128) / 128;
      case "s16":
      case "s16-planar":
        return (view2, offset) => view2.getInt16(offset, true) / 32768;
      case "s32":
      case "s32-planar":
        return (view2, offset) => view2.getInt32(offset, true) / 2147483648;
      case "f32":
      case "f32-planar":
        return (view2, offset) => view2.getFloat32(offset, true);
    }
  };
  var getWriteFunction = (format) => {
    switch (format) {
      case "u8":
      case "u8-planar":
        return (view2, offset, value) => view2.setUint8(offset, clamp((value + 1) * 127.5, 0, 255));
      case "s16":
      case "s16-planar":
        return (view2, offset, value) => view2.setInt16(offset, clamp(Math.round(value * 32767), -32768, 32767), true);
      case "s32":
      case "s32-planar":
        return (view2, offset, value) => view2.setInt32(offset, clamp(Math.round(value * 2147483647), -2147483648, 2147483647), true);
      case "f32":
      case "f32-planar":
        return (view2, offset, value) => view2.setFloat32(offset, value, true);
    }
  };
  var isAudioData = (x) => {
    return typeof AudioData !== "undefined" && x instanceof AudioData;
  };

  // src/media-sink.ts
  var validatePacketRetrievalOptions = (options) => {
    if (!options || typeof options !== "object") {
      throw new TypeError("options must be an object.");
    }
    if (options.metadataOnly !== void 0 && typeof options.metadataOnly !== "boolean") {
      throw new TypeError("options.metadataOnly, when defined, must be a boolean.");
    }
    if (options.verifyKeyPackets !== void 0 && typeof options.verifyKeyPackets !== "boolean") {
      throw new TypeError("options.verifyKeyPackets, when defined, must be a boolean.");
    }
    if (options.verifyKeyPackets && options.metadataOnly) {
      throw new TypeError("options.verifyKeyPackets and options.metadataOnly cannot be enabled together.");
    }
  };
  var validateTimestamp = (timestamp) => {
    if (typeof timestamp !== "number" || Number.isNaN(timestamp)) {
      throw new TypeError("timestamp must be a number.");
    }
  };
  var maybeFixPacketType = (track, promise, options) => {
    if (options.verifyKeyPackets) {
      return promise.then(async (packet) => {
        if (!packet || packet.type === "delta") {
          return packet;
        }
        const determinedType = await track.determinePacketType(packet);
        if (determinedType) {
          packet.type = determinedType;
        }
        return packet;
      });
    } else {
      return promise;
    }
  };
  var EncodedPacketSink = class {
    constructor(track) {
      if (!(track instanceof InputTrack)) {
        throw new TypeError("track must be an InputTrack.");
      }
      this._track = track;
    }
    /**
     * Retrieves the track's first packet (in decode order), or null if it has no packets. The first packet is very
     * likely to be a key packet.
     */
    getFirstPacket(options = {}) {
      validatePacketRetrievalOptions(options);
      return maybeFixPacketType(this._track, this._track._backing.getFirstPacket(options), options);
    }
    /**
     * Retrieves the packet corresponding to the given timestamp, in seconds. More specifically, returns the last packet
     * (in presentation order) with a start timestamp less than or equal to the given timestamp. This method can be
     * used to retrieve a track's last packet using `getPacket(Infinity)`. The method returns null if the timestamp
     * is before the first packet in the track.
     *
     * @param timestamp - The timestamp used for retrieval, in seconds.
     */
    getPacket(timestamp, options = {}) {
      validateTimestamp(timestamp);
      validatePacketRetrievalOptions(options);
      return maybeFixPacketType(this._track, this._track._backing.getPacket(timestamp, options), options);
    }
    /**
     * Retrieves the packet following the given packet (in decode order), or null if the given packet is the
     * last packet.
     */
    getNextPacket(packet, options = {}) {
      if (!(packet instanceof EncodedPacket)) {
        throw new TypeError("packet must be an EncodedPacket.");
      }
      validatePacketRetrievalOptions(options);
      return maybeFixPacketType(this._track, this._track._backing.getNextPacket(packet, options), options);
    }
    /**
     * Retrieves the key packet corresponding to the given timestamp, in seconds. More specifically, returns the last
     * key packet (in presentation order) with a start timestamp less than or equal to the given timestamp. A key packet
     * is a packet that doesn't require previous packets to be decoded. This method can be used to retrieve a track's
     * last key packet using `getKeyPacket(Infinity)`. The method returns null if the timestamp is before the first
     * key packet in the track.
     *
     * To ensure that the returned packet is guaranteed to be a real key frame, enable `options.verifyKeyPackets`.
     *
     * @param timestamp - The timestamp used for retrieval, in seconds.
     */
    async getKeyPacket(timestamp, options = {}) {
      validateTimestamp(timestamp);
      validatePacketRetrievalOptions(options);
      if (!options.verifyKeyPackets) {
        return this._track._backing.getKeyPacket(timestamp, options);
      }
      const packet = await this._track._backing.getKeyPacket(timestamp, options);
      if (!packet || packet.type === "delta") {
        return packet;
      }
      const determinedType = await this._track.determinePacketType(packet);
      if (determinedType === "delta") {
        return this.getKeyPacket(packet.timestamp - 1 / this._track.timeResolution, options);
      }
      return packet;
    }
    /**
     * Retrieves the key packet following the given packet (in decode order), or null if the given packet is the last
     * key packet.
     *
     * To ensure that the returned packet is guaranteed to be a real key frame, enable `options.verifyKeyPackets`.
     */
    async getNextKeyPacket(packet, options = {}) {
      if (!(packet instanceof EncodedPacket)) {
        throw new TypeError("packet must be an EncodedPacket.");
      }
      validatePacketRetrievalOptions(options);
      if (!options.verifyKeyPackets) {
        return this._track._backing.getNextKeyPacket(packet, options);
      }
      const nextPacket = await this._track._backing.getNextKeyPacket(packet, options);
      if (!nextPacket || nextPacket.type === "delta") {
        return nextPacket;
      }
      const determinedType = await this._track.determinePacketType(nextPacket);
      if (determinedType === "delta") {
        return this.getNextKeyPacket(nextPacket, options);
      }
      return nextPacket;
    }
    /**
     * Creates an async iterator that yields the packets in this track in decode order. To enable fast iteration, this
     * method will intelligently preload packets based on the speed of the consumer.
     *
     * @param startPacket - (optional) The packet from which iteration should begin. This packet will also be yielded.
     * @param endTimestamp - (optional) The timestamp at which iteration should end. This packet will _not_ be yielded.
     */
    packets(startPacket, endPacket, options = {}) {
      if (startPacket !== void 0 && !(startPacket instanceof EncodedPacket)) {
        throw new TypeError("startPacket must be an EncodedPacket.");
      }
      if (startPacket !== void 0 && startPacket.isMetadataOnly && !options?.metadataOnly) {
        throw new TypeError("startPacket can only be metadata-only if options.metadataOnly is enabled.");
      }
      if (endPacket !== void 0 && !(endPacket instanceof EncodedPacket)) {
        throw new TypeError("endPacket must be an EncodedPacket.");
      }
      validatePacketRetrievalOptions(options);
      const packetQueue = [];
      let { promise: queueNotEmpty, resolve: onQueueNotEmpty } = promiseWithResolvers();
      let { promise: queueDequeue, resolve: onQueueDequeue } = promiseWithResolvers();
      let ended = false;
      let terminated = false;
      let outOfBandError = null;
      const timestamps = [];
      const maxQueueSize = () => Math.max(2, timestamps.length);
      (async () => {
        let packet = startPacket ?? await this.getFirstPacket(options);
        while (packet && !terminated) {
          if (endPacket && packet.sequenceNumber >= endPacket?.sequenceNumber) {
            break;
          }
          if (packetQueue.length > maxQueueSize()) {
            ({ promise: queueDequeue, resolve: onQueueDequeue } = promiseWithResolvers());
            await queueDequeue;
            continue;
          }
          packetQueue.push(packet);
          onQueueNotEmpty();
          ({ promise: queueNotEmpty, resolve: onQueueNotEmpty } = promiseWithResolvers());
          packet = await this.getNextPacket(packet, options);
        }
        ended = true;
        onQueueNotEmpty();
      })().catch((error) => {
        if (!outOfBandError) {
          outOfBandError = error;
          onQueueNotEmpty();
        }
      });
      return {
        async next() {
          while (true) {
            if (terminated) {
              return { value: void 0, done: true };
            } else if (outOfBandError) {
              throw outOfBandError;
            } else if (packetQueue.length > 0) {
              const value = packetQueue.shift();
              const now = performance.now();
              timestamps.push(now);
              while (timestamps.length > 0 && now - timestamps[0] >= 1e3) {
                timestamps.shift();
              }
              onQueueDequeue();
              return { value, done: false };
            } else if (ended) {
              return { value: void 0, done: true };
            } else {
              await queueNotEmpty;
            }
          }
        },
        async return() {
          terminated = true;
          onQueueDequeue();
          onQueueNotEmpty();
          return { value: void 0, done: true };
        },
        async throw(error) {
          throw error;
        },
        [Symbol.asyncIterator]() {
          return this;
        }
      };
    }
  };
  var DecoderWrapper = class {
    constructor(onSample, onError) {
      this.onSample = onSample;
      this.onError = onError;
    }
  };
  var BaseMediaSampleSink = class {
    /** @internal */
    mediaSamplesInRange(startTimestamp = 0, endTimestamp = Infinity) {
      validateTimestamp(startTimestamp);
      validateTimestamp(endTimestamp);
      const sampleQueue = [];
      let firstSampleQueued = false;
      let lastSample = null;
      let { promise: queueNotEmpty, resolve: onQueueNotEmpty } = promiseWithResolvers();
      let { promise: queueDequeue, resolve: onQueueDequeue } = promiseWithResolvers();
      let decoderIsFlushed = false;
      let ended = false;
      let terminated = false;
      let outOfBandError = null;
      (async () => {
        const decoderError = new Error();
        const decoder = await this._createDecoder((sample) => {
          onQueueDequeue();
          if (sample.timestamp >= endTimestamp) {
            ended = true;
          }
          if (ended) {
            sample.close();
            return;
          }
          if (lastSample) {
            if (sample.timestamp > startTimestamp) {
              sampleQueue.push(lastSample);
              firstSampleQueued = true;
            } else {
              lastSample.close();
            }
          }
          if (sample.timestamp >= startTimestamp) {
            sampleQueue.push(sample);
            firstSampleQueued = true;
          }
          lastSample = firstSampleQueued ? null : sample;
          if (sampleQueue.length > 0) {
            onQueueNotEmpty();
            ({ promise: queueNotEmpty, resolve: onQueueNotEmpty } = promiseWithResolvers());
          }
        }, (error) => {
          if (!outOfBandError) {
            error.stack = decoderError.stack;
            outOfBandError = error;
            onQueueNotEmpty();
          }
        });
        const packetSink = this._createPacketSink();
        const keyPacket = await packetSink.getKeyPacket(startTimestamp, { verifyKeyPackets: true }) ?? await packetSink.getFirstPacket();
        if (!keyPacket) {
          return;
        }
        let currentPacket = keyPacket;
        let endPacket = void 0;
        if (endTimestamp < Infinity) {
          const packet = await packetSink.getPacket(endTimestamp);
          const keyPacket2 = !packet ? null : packet.type === "key" && packet.timestamp === endTimestamp ? packet : await packetSink.getNextKeyPacket(packet, { verifyKeyPackets: true });
          if (keyPacket2) {
            endPacket = keyPacket2;
          }
        }
        const packets = packetSink.packets(keyPacket, endPacket);
        await packets.next();
        while (currentPacket && !ended) {
          const maxQueueSize = computeMaxQueueSize(sampleQueue.length);
          if (sampleQueue.length + decoder.getDecodeQueueSize() > maxQueueSize) {
            ({ promise: queueDequeue, resolve: onQueueDequeue } = promiseWithResolvers());
            await queueDequeue;
            continue;
          }
          decoder.decode(currentPacket);
          const packetResult = await packets.next();
          if (packetResult.done) {
            break;
          }
          currentPacket = packetResult.value;
        }
        await packets.return();
        if (!terminated) await decoder.flush();
        decoder.close();
        if (!firstSampleQueued && lastSample) {
          sampleQueue.push(lastSample);
        }
        decoderIsFlushed = true;
        onQueueNotEmpty();
      })().catch((error) => {
        if (!outOfBandError) {
          outOfBandError = error;
          onQueueNotEmpty();
        }
      });
      return {
        async next() {
          while (true) {
            if (terminated) {
              return { value: void 0, done: true };
            } else if (outOfBandError) {
              throw outOfBandError;
            } else if (sampleQueue.length > 0) {
              const value = sampleQueue.shift();
              onQueueDequeue();
              return { value, done: false };
            } else if (!decoderIsFlushed) {
              await queueNotEmpty;
            } else {
              return { value: void 0, done: true };
            }
          }
        },
        async return() {
          terminated = true;
          ended = true;
          onQueueDequeue();
          onQueueNotEmpty();
          lastSample?.close();
          for (const sample of sampleQueue) {
            sample.close();
          }
          return { value: void 0, done: true };
        },
        async throw(error) {
          throw error;
        },
        [Symbol.asyncIterator]() {
          return this;
        }
      };
    }
    /** @internal */
    mediaSamplesAtTimestamps(timestamps) {
      validateAnyIterable(timestamps);
      const timestampIterator = toAsyncIterator(timestamps);
      const timestampsOfInterest = [];
      const sampleQueue = [];
      let { promise: queueNotEmpty, resolve: onQueueNotEmpty } = promiseWithResolvers();
      let { promise: queueDequeue, resolve: onQueueDequeue } = promiseWithResolvers();
      let decoderIsFlushed = false;
      let terminated = false;
      let outOfBandError = null;
      const pushToQueue = (sample) => {
        sampleQueue.push(sample);
        onQueueNotEmpty();
        ({ promise: queueNotEmpty, resolve: onQueueNotEmpty } = promiseWithResolvers());
      };
      (async () => {
        const decoderError = new Error();
        const decoder = await this._createDecoder((sample) => {
          onQueueDequeue();
          if (terminated) {
            sample.close();
            return;
          }
          let sampleUses = 0;
          while (timestampsOfInterest.length > 0 && sample.timestamp - timestampsOfInterest[0] > -1e-10) {
            sampleUses++;
            timestampsOfInterest.shift();
          }
          if (sampleUses > 0) {
            for (let i = 0; i < sampleUses; i++) {
              pushToQueue(i < sampleUses - 1 ? sample.clone() : sample);
            }
          } else {
            sample.close();
          }
        }, (error) => {
          if (!outOfBandError) {
            error.stack = decoderError.stack;
            outOfBandError = error;
            onQueueNotEmpty();
          }
        });
        const packetSink = this._createPacketSink();
        let lastPacket = null;
        let lastKeyPacket = null;
        let maxSequenceNumber = -1;
        const decodePackets = async () => {
          assert(lastKeyPacket);
          let currentPacket = lastKeyPacket;
          decoder.decode(currentPacket);
          while (currentPacket.sequenceNumber < maxSequenceNumber) {
            const maxQueueSize = computeMaxQueueSize(sampleQueue.length);
            while (sampleQueue.length + decoder.getDecodeQueueSize() > maxQueueSize && !terminated) {
              ({ promise: queueDequeue, resolve: onQueueDequeue } = promiseWithResolvers());
              await queueDequeue;
            }
            if (terminated) {
              break;
            }
            const nextPacket = await packetSink.getNextPacket(currentPacket);
            assert(nextPacket);
            currentPacket = nextPacket;
            decoder.decode(nextPacket);
          }
          maxSequenceNumber = -1;
        };
        const flushDecoder = async () => {
          await decoder.flush();
          for (let i = 0; i < timestampsOfInterest.length; i++) {
            pushToQueue(null);
          }
          timestampsOfInterest.length = 0;
        };
        for await (const timestamp of timestampIterator) {
          validateTimestamp(timestamp);
          if (terminated) {
            break;
          }
          const targetPacket = await packetSink.getPacket(timestamp);
          const keyPacket = targetPacket && await packetSink.getKeyPacket(timestamp, { verifyKeyPackets: true });
          if (!keyPacket) {
            if (maxSequenceNumber !== -1) {
              await decodePackets();
              await flushDecoder();
            }
            pushToQueue(null);
            lastPacket = null;
            continue;
          }
          if (lastPacket && (keyPacket.sequenceNumber !== lastKeyPacket.sequenceNumber || targetPacket.timestamp < lastPacket.timestamp)) {
            await decodePackets();
            await flushDecoder();
          }
          timestampsOfInterest.push(targetPacket.timestamp);
          maxSequenceNumber = Math.max(targetPacket.sequenceNumber, maxSequenceNumber);
          lastPacket = targetPacket;
          lastKeyPacket = keyPacket;
        }
        if (!terminated) {
          if (maxSequenceNumber !== -1) {
            await decodePackets();
          }
          await flushDecoder();
        }
        decoder.close();
        decoderIsFlushed = true;
        onQueueNotEmpty();
      })().catch((error) => {
        if (!outOfBandError) {
          outOfBandError = error;
          onQueueNotEmpty();
        }
      });
      return {
        async next() {
          while (true) {
            if (terminated) {
              return { value: void 0, done: true };
            } else if (outOfBandError) {
              throw outOfBandError;
            } else if (sampleQueue.length > 0) {
              const value = sampleQueue.shift();
              assert(value !== void 0);
              onQueueDequeue();
              return { value, done: false };
            } else if (!decoderIsFlushed) {
              await queueNotEmpty;
            } else {
              return { value: void 0, done: true };
            }
          }
        },
        async return() {
          terminated = true;
          onQueueDequeue();
          onQueueNotEmpty();
          for (const sample of sampleQueue) {
            sample?.close();
          }
          return { value: void 0, done: true };
        },
        async throw(error) {
          throw error;
        },
        [Symbol.asyncIterator]() {
          return this;
        }
      };
    }
  };
  var computeMaxQueueSize = (decodedSampleQueueSize) => {
    return decodedSampleQueueSize === 0 ? 40 : 8;
  };
  var VideoDecoderWrapper = class extends DecoderWrapper {
    // Safari-specific thing, check usage.
    constructor(onSample, onError, codec, decoderConfig, rotation, timeResolution) {
      super(onSample, onError);
      this.rotation = rotation;
      this.timeResolution = timeResolution;
      this.decoder = null;
      this.customDecoder = null;
      this.customDecoderCallSerializer = new CallSerializer();
      this.customDecoderQueueSize = 0;
      this.inputTimestamps = [];
      // Timestamps input into the decoder, sorted.
      this.sampleQueue = [];
      const MatchingCustomDecoder = customVideoDecoders.find((x) => x.supports(codec, decoderConfig));
      if (MatchingCustomDecoder) {
        this.customDecoder = new MatchingCustomDecoder();
        this.customDecoder.codec = codec;
        this.customDecoder.config = decoderConfig;
        this.customDecoder.onSample = (sample) => {
          if (!(sample instanceof VideoSample)) {
            throw new TypeError("The argument passed to onSample must be a VideoSample.");
          }
          this.finalizeAndEmitSample(sample);
        };
        void this.customDecoderCallSerializer.call(() => this.customDecoder.init());
      } else {
        const sampleHandler = (sample) => {
          if (isSafari()) {
            if (this.sampleQueue.length > 0 && sample.timestamp >= last(this.sampleQueue).timestamp) {
              for (const sample2 of this.sampleQueue) {
                this.finalizeAndEmitSample(sample2);
              }
              this.sampleQueue.length = 0;
            }
            insertSorted(this.sampleQueue, sample, (x) => x.timestamp);
          } else {
            const timestamp = this.inputTimestamps.shift();
            assert(timestamp !== void 0);
            sample.setTimestamp(timestamp);
            this.finalizeAndEmitSample(sample);
          }
        };
        this.decoder = new VideoDecoder({
          output: (frame) => sampleHandler(new VideoSample(frame)),
          error: onError
        });
        this.decoder.configure(decoderConfig);
      }
    }
    finalizeAndEmitSample(sample) {
      sample.setTimestamp(Math.round(sample.timestamp * this.timeResolution) / this.timeResolution);
      sample.setDuration(Math.round(sample.duration * this.timeResolution) / this.timeResolution);
      sample.setRotation(this.rotation);
      this.onSample(sample);
    }
    getDecodeQueueSize() {
      if (this.customDecoder) {
        return this.customDecoderQueueSize;
      } else {
        assert(this.decoder);
        return this.decoder.decodeQueueSize;
      }
    }
    decode(packet) {
      if (this.customDecoder) {
        this.customDecoderQueueSize++;
        void this.customDecoderCallSerializer.call(() => this.customDecoder.decode(packet)).then(() => this.customDecoderQueueSize--);
      } else {
        assert(this.decoder);
        if (!isSafari()) {
          insertSorted(this.inputTimestamps, packet.timestamp, (x) => x);
        }
        this.decoder.decode(packet.toEncodedVideoChunk());
      }
    }
    async flush() {
      if (this.customDecoder) {
        await this.customDecoderCallSerializer.call(() => this.customDecoder.flush());
      } else {
        assert(this.decoder);
        await this.decoder.flush();
      }
      if (isSafari()) {
        for (const sample of this.sampleQueue) {
          this.finalizeAndEmitSample(sample);
        }
        this.sampleQueue.length = 0;
      }
    }
    close() {
      if (this.customDecoder) {
        void this.customDecoderCallSerializer.call(() => this.customDecoder.close());
      } else {
        assert(this.decoder);
        this.decoder.close();
      }
      for (const sample of this.sampleQueue) {
        sample.close();
      }
      this.sampleQueue.length = 0;
    }
  };
  var VideoSampleSink = class extends BaseMediaSampleSink {
    constructor(videoTrack) {
      if (!(videoTrack instanceof InputVideoTrack)) {
        throw new TypeError("videoTrack must be an InputVideoTrack.");
      }
      super();
      this._videoTrack = videoTrack;
    }
    /** @internal */
    async _createDecoder(onSample, onError) {
      if (!await this._videoTrack.canDecode()) {
        throw new Error(
          "This video track cannot be decoded by this browser. Make sure to check decodability before using a track."
        );
      }
      const codec = this._videoTrack.codec;
      const rotation = this._videoTrack.rotation;
      const decoderConfig = await this._videoTrack.getDecoderConfig();
      const timeResolution = this._videoTrack.timeResolution;
      assert(codec && decoderConfig);
      return new VideoDecoderWrapper(onSample, onError, codec, decoderConfig, rotation, timeResolution);
    }
    /** @internal */
    _createPacketSink() {
      return new EncodedPacketSink(this._videoTrack);
    }
    /**
     * Retrieves the video sample (frame) corresponding to the given timestamp, in seconds. More specifically, returns
     * the last video sample (in presentation order) with a start timestamp less than or equal to the given timestamp.
     * Returns null if the timestamp is before the track's first timestamp.
     *
     * @param timestamp - The timestamp used for retrieval, in seconds.
     */
    async getSample(timestamp) {
      validateTimestamp(timestamp);
      for await (const sample of this.mediaSamplesAtTimestamps([timestamp])) {
        return sample;
      }
      throw new Error("Internal error: Iterator returned nothing.");
    }
    /**
     * Creates an async iterator that yields the video samples (frames) of this track in presentation order. This method
     * will intelligently pre-decode a few frames ahead to enable fast iteration.
     *
     * @param startTimestamp - The timestamp in seconds at which to start yielding samples (inclusive).
     * @param endTimestamp - The timestamp in seconds at which to stop yielding samples (exclusive).
     */
    samples(startTimestamp = 0, endTimestamp = Infinity) {
      return this.mediaSamplesInRange(startTimestamp, endTimestamp);
    }
    /**
     * Creates an async iterator that yields a video sample (frame) for each timestamp in the argument. This method
     * uses an optimized decoding pipeline if these timestamps are monotonically sorted, decoding each packet at most
     * once, and is therefore more efficient than manually getting the sample for every timestamp. The iterator may
     * yield null if no frame is available for a given timestamp.
     *
     * @param timestamps - An iterable or async iterable of timestamps in seconds.
     */
    samplesAtTimestamps(timestamps) {
      return this.mediaSamplesAtTimestamps(timestamps);
    }
  };
  var CanvasSink = class {
    constructor(videoTrack, options = {}) {
      /** @internal */
      this._nextCanvasIndex = 0;
      if (!(videoTrack instanceof InputVideoTrack)) {
        throw new TypeError("videoTrack must be an InputVideoTrack.");
      }
      if (options && typeof options !== "object") {
        throw new TypeError("options must be an object.");
      }
      if (options.width !== void 0 && (!Number.isInteger(options.width) || options.width <= 0)) {
        throw new TypeError("options.width, when defined, must be a positive integer.");
      }
      if (options.height !== void 0 && (!Number.isInteger(options.height) || options.height <= 0)) {
        throw new TypeError("options.height, when defined, must be a positive integer.");
      }
      if (options.fit !== void 0 && !["fill", "contain", "cover"].includes(options.fit)) {
        throw new TypeError('options.fit, when provided, must be one of "fill", "contain", or "cover".');
      }
      if (options.width !== void 0 && options.height !== void 0 && options.fit === void 0) {
        throw new TypeError(
          "When both options.width and options.height are provided, options.fit must also be provided."
        );
      }
      if (options.rotation !== void 0 && ![0, 90, 180, 270].includes(options.rotation)) {
        throw new TypeError("options.rotation, when provided, must be 0, 90, 180 or 270.");
      }
      if (options.poolSize !== void 0 && (typeof options.poolSize !== "number" || !Number.isInteger(options.poolSize) || options.poolSize < 0)) {
        throw new TypeError("poolSize must be a non-negative integer.");
      }
      const rotation = options.rotation ?? videoTrack.rotation;
      let [width, height] = rotation % 180 === 0 ? [videoTrack.codedWidth, videoTrack.codedHeight] : [videoTrack.codedHeight, videoTrack.codedWidth];
      const originalAspectRatio = width / height;
      if (options.width !== void 0 && options.height === void 0) {
        width = options.width;
        height = Math.round(width / originalAspectRatio);
      } else if (options.width === void 0 && options.height !== void 0) {
        height = options.height;
        width = Math.round(height * originalAspectRatio);
      } else if (options.width !== void 0 && options.height !== void 0) {
        width = options.width;
        height = options.height;
      }
      this._videoTrack = videoTrack;
      this._width = width;
      this._height = height;
      this._rotation = rotation;
      this._fit = options.fit ?? "fill";
      this._videoSampleSink = new VideoSampleSink(videoTrack);
      this._canvasPool = Array.from({ length: options.poolSize ?? 0 }, () => null);
    }
    /** @internal */
    _videoSampleToWrappedCanvas(sample) {
      let canvas = this._canvasPool[this._nextCanvasIndex];
      if (!canvas) {
        if (typeof document !== "undefined") {
          canvas = document.createElement("canvas");
          canvas.width = this._width;
          canvas.height = this._height;
        } else {
          canvas = new OffscreenCanvas(this._width, this._height);
        }
        if (this._canvasPool.length > 0) {
          this._canvasPool[this._nextCanvasIndex] = canvas;
        }
      }
      if (this._canvasPool.length > 0) {
        this._nextCanvasIndex = (this._nextCanvasIndex + 1) % this._canvasPool.length;
      }
      const context = canvas.getContext("2d", { alpha: false });
      assert(context);
      context.resetTransform();
      let dx;
      let dy;
      let newWidth;
      let newHeight;
      if (this._fit === "fill") {
        dx = 0;
        dy = 0;
        newWidth = this._width;
        newHeight = this._height;
      } else {
        const [sampleWidth, sampleHeight] = this._rotation % 180 === 0 ? [sample.codedWidth, sample.codedHeight] : [sample.codedHeight, sample.codedWidth];
        const scale = this._fit === "contain" ? Math.min(this._width / sampleWidth, this._height / sampleHeight) : Math.max(this._width / sampleWidth, this._height / sampleHeight);
        newWidth = sampleWidth * scale;
        newHeight = sampleHeight * scale;
        dx = (this._width - newWidth) / 2;
        dy = (this._height - newHeight) / 2;
      }
      const aspectRatioChange = this._rotation % 180 === 0 ? 1 : newWidth / newHeight;
      context.translate(this._width / 2, this._height / 2);
      context.rotate(this._rotation * Math.PI / 180);
      context.scale(1 / aspectRatioChange, aspectRatioChange);
      context.translate(-this._width / 2, -this._height / 2);
      context.drawImage(sample.toCanvasImageSource(), dx, dy, newWidth, newHeight);
      const result = {
        canvas,
        timestamp: sample.timestamp,
        duration: sample.duration
      };
      sample.close();
      return result;
    }
    /**
     * Retrieves a canvas with the video frame corresponding to the given timestamp, in seconds. More specifically,
     * returns the last video frame (in presentation order) with a start timestamp less than or equal to the given
     * timestamp. Returns null if the timestamp is before the track's first timestamp.
     *
     * @param timestamp - The timestamp used for retrieval, in seconds.
     */
    async getCanvas(timestamp) {
      validateTimestamp(timestamp);
      const sample = await this._videoSampleSink.getSample(timestamp);
      return sample && this._videoSampleToWrappedCanvas(sample);
    }
    /**
     * Creates an async iterator that yields canvases with the video frames of this track in presentation order. This
     * method will intelligently pre-decode a few frames ahead to enable fast iteration.
     *
     * @param startTimestamp - The timestamp in seconds at which to start yielding canvases (inclusive).
     * @param endTimestamp - The timestamp in seconds at which to stop yielding canvases (exclusive).
     */
    canvases(startTimestamp = 0, endTimestamp = Infinity) {
      return mapAsyncGenerator(
        this._videoSampleSink.samples(startTimestamp, endTimestamp),
        (sample) => this._videoSampleToWrappedCanvas(sample)
      );
    }
    /**
     * Creates an async iterator that yields a canvas for each timestamp in the argument. This method uses an optimized
     * decoding pipeline if these timestamps are monotonically sorted, decoding each packet at most once, and is
     * therefore more efficient than manually getting the canvas for every timestamp. The iterator may yield null if
     * no frame is available for a given timestamp.
     *
     * @param timestamps - An iterable or async iterable of timestamps in seconds.
     */
    canvasesAtTimestamps(timestamps) {
      return mapAsyncGenerator(
        this._videoSampleSink.samplesAtTimestamps(timestamps),
        (sample) => sample && this._videoSampleToWrappedCanvas(sample)
      );
    }
  };
  var AudioDecoderWrapper = class extends DecoderWrapper {
    constructor(onSample, onError, codec, decoderConfig) {
      super(onSample, onError);
      this.decoder = null;
      this.customDecoder = null;
      this.customDecoderCallSerializer = new CallSerializer();
      this.customDecoderQueueSize = 0;
      const sampleHandler = (sample) => {
        const sampleRate = decoderConfig.sampleRate;
        sample.setTimestamp(Math.round(sample.timestamp * sampleRate) / sampleRate);
        onSample(sample);
      };
      const MatchingCustomDecoder = customAudioDecoders.find((x) => x.supports(codec, decoderConfig));
      if (MatchingCustomDecoder) {
        this.customDecoder = new MatchingCustomDecoder();
        this.customDecoder.codec = codec;
        this.customDecoder.config = decoderConfig;
        this.customDecoder.onSample = (sample) => {
          if (!(sample instanceof AudioSample)) {
            throw new TypeError("The argument passed to onSample must be an AudioSample.");
          }
          sampleHandler(sample);
        };
        void this.customDecoderCallSerializer.call(() => this.customDecoder.init());
      } else {
        this.decoder = new AudioDecoder({
          output: (data) => sampleHandler(new AudioSample(data)),
          error: onError
        });
        this.decoder.configure(decoderConfig);
      }
    }
    getDecodeQueueSize() {
      if (this.customDecoder) {
        return this.customDecoderQueueSize;
      } else {
        assert(this.decoder);
        return this.decoder.decodeQueueSize;
      }
    }
    decode(packet) {
      if (this.customDecoder) {
        this.customDecoderQueueSize++;
        void this.customDecoderCallSerializer.call(() => this.customDecoder.decode(packet)).then(() => this.customDecoderQueueSize--);
      } else {
        assert(this.decoder);
        this.decoder.decode(packet.toEncodedAudioChunk());
      }
    }
    flush() {
      if (this.customDecoder) {
        return this.customDecoderCallSerializer.call(() => this.customDecoder.flush());
      } else {
        assert(this.decoder);
        return this.decoder.flush();
      }
    }
    close() {
      if (this.customDecoder) {
        void this.customDecoderCallSerializer.call(() => this.customDecoder.close());
      } else {
        assert(this.decoder);
        this.decoder.close();
      }
    }
  };
  var PcmAudioDecoderWrapper = class extends DecoderWrapper {
    constructor(onSample, onError, decoderConfig) {
      super(onSample, onError);
      this.decoderConfig = decoderConfig;
      // Internal state to accumulate a precise current timestamp based on audio durations, not the (potentially
      // inaccurate) sample timestamps.
      this.currentTimestamp = null;
      assert(PCM_AUDIO_CODECS.includes(decoderConfig.codec));
      this.codec = decoderConfig.codec;
      const { dataType, sampleSize, littleEndian } = parsePcmCodec(this.codec);
      this.inputSampleSize = sampleSize;
      switch (sampleSize) {
        case 1:
          {
            if (dataType === "unsigned") {
              this.readInputValue = (view2, byteOffset) => view2.getUint8(byteOffset) - 2 ** 7;
            } else if (dataType === "signed") {
              this.readInputValue = (view2, byteOffset) => view2.getInt8(byteOffset);
            } else if (dataType === "ulaw") {
              this.readInputValue = (view2, byteOffset) => fromUlaw(view2.getUint8(byteOffset));
            } else if (dataType === "alaw") {
              this.readInputValue = (view2, byteOffset) => fromAlaw(view2.getUint8(byteOffset));
            } else {
              assert(false);
            }
          }
          ;
          break;
        case 2:
          {
            if (dataType === "unsigned") {
              this.readInputValue = (view2, byteOffset) => view2.getUint16(byteOffset, littleEndian) - 2 ** 15;
            } else if (dataType === "signed") {
              this.readInputValue = (view2, byteOffset) => view2.getInt16(byteOffset, littleEndian);
            } else {
              assert(false);
            }
          }
          ;
          break;
        case 3:
          {
            if (dataType === "unsigned") {
              this.readInputValue = (view2, byteOffset) => getUint24(view2, byteOffset, littleEndian) - 2 ** 23;
            } else if (dataType === "signed") {
              this.readInputValue = (view2, byteOffset) => getInt24(view2, byteOffset, littleEndian);
            } else {
              assert(false);
            }
          }
          ;
          break;
        case 4:
          {
            if (dataType === "unsigned") {
              this.readInputValue = (view2, byteOffset) => view2.getUint32(byteOffset, littleEndian) - 2 ** 31;
            } else if (dataType === "signed") {
              this.readInputValue = (view2, byteOffset) => view2.getInt32(byteOffset, littleEndian);
            } else if (dataType === "float") {
              this.readInputValue = (view2, byteOffset) => view2.getFloat32(byteOffset, littleEndian);
            } else {
              assert(false);
            }
          }
          ;
          break;
        case 8:
          {
            if (dataType === "float") {
              this.readInputValue = (view2, byteOffset) => view2.getFloat64(byteOffset, littleEndian);
            } else {
              assert(false);
            }
          }
          ;
          break;
        default:
          {
            assertNever(sampleSize);
            assert(false);
          }
          ;
      }
      switch (sampleSize) {
        case 1:
          {
            if (dataType === "ulaw" || dataType === "alaw") {
              this.outputSampleSize = 2;
              this.outputFormat = "s16";
              this.writeOutputValue = (view2, byteOffset, value) => view2.setInt16(byteOffset, value, true);
            } else {
              this.outputSampleSize = 1;
              this.outputFormat = "u8";
              this.writeOutputValue = (view2, byteOffset, value) => view2.setUint8(byteOffset, value + 2 ** 7);
            }
          }
          ;
          break;
        case 2:
          {
            this.outputSampleSize = 2;
            this.outputFormat = "s16";
            this.writeOutputValue = (view2, byteOffset, value) => view2.setInt16(byteOffset, value, true);
          }
          ;
          break;
        case 3:
          {
            this.outputSampleSize = 4;
            this.outputFormat = "s32";
            this.writeOutputValue = (view2, byteOffset, value) => view2.setInt32(byteOffset, value << 8, true);
          }
          ;
          break;
        case 4:
          {
            this.outputSampleSize = 4;
            if (dataType === "float") {
              this.outputFormat = "f32";
              this.writeOutputValue = (view2, byteOffset, value) => view2.setFloat32(byteOffset, value, true);
            } else {
              this.outputFormat = "s32";
              this.writeOutputValue = (view2, byteOffset, value) => view2.setInt32(byteOffset, value, true);
            }
          }
          ;
          break;
        case 8:
          {
            this.outputSampleSize = 4;
            this.outputFormat = "f32";
            this.writeOutputValue = (view2, byteOffset, value) => view2.setFloat32(byteOffset, value, true);
          }
          ;
          break;
        default:
          {
            assertNever(sampleSize);
            assert(false);
          }
          ;
      }
      ;
    }
    getDecodeQueueSize() {
      return 0;
    }
    decode(packet) {
      const inputView = toDataView(packet.data);
      const numberOfFrames = packet.byteLength / this.decoderConfig.numberOfChannels / this.inputSampleSize;
      const outputBufferSize = numberOfFrames * this.decoderConfig.numberOfChannels * this.outputSampleSize;
      const outputBuffer = new ArrayBuffer(outputBufferSize);
      const outputView = new DataView(outputBuffer);
      for (let i = 0; i < numberOfFrames * this.decoderConfig.numberOfChannels; i++) {
        const inputIndex = i * this.inputSampleSize;
        const outputIndex = i * this.outputSampleSize;
        const value = this.readInputValue(inputView, inputIndex);
        this.writeOutputValue(outputView, outputIndex, value);
      }
      const preciseDuration = numberOfFrames / this.decoderConfig.sampleRate;
      if (this.currentTimestamp === null || Math.abs(packet.timestamp - this.currentTimestamp) >= preciseDuration) {
        this.currentTimestamp = packet.timestamp;
      }
      const preciseTimestamp = this.currentTimestamp;
      this.currentTimestamp += preciseDuration;
      const audioSample = new AudioSample({
        format: this.outputFormat,
        data: outputBuffer,
        numberOfChannels: this.decoderConfig.numberOfChannels,
        sampleRate: this.decoderConfig.sampleRate,
        numberOfFrames,
        timestamp: preciseTimestamp
      });
      this.onSample(audioSample);
    }
    async flush() {
    }
    close() {
    }
  };
  var AudioSampleSink = class extends BaseMediaSampleSink {
    constructor(audioTrack) {
      if (!(audioTrack instanceof InputAudioTrack)) {
        throw new TypeError("audioTrack must be an InputAudioTrack.");
      }
      super();
      this._audioTrack = audioTrack;
    }
    /** @internal */
    async _createDecoder(onSample, onError) {
      if (!await this._audioTrack.canDecode()) {
        throw new Error(
          "This audio track cannot be decoded by this browser. Make sure to check decodability before using a track."
        );
      }
      const codec = this._audioTrack.codec;
      const decoderConfig = await this._audioTrack.getDecoderConfig();
      assert(codec && decoderConfig);
      if (PCM_AUDIO_CODECS.includes(decoderConfig.codec)) {
        return new PcmAudioDecoderWrapper(onSample, onError, decoderConfig);
      } else {
        return new AudioDecoderWrapper(onSample, onError, codec, decoderConfig);
      }
    }
    /** @internal */
    _createPacketSink() {
      return new EncodedPacketSink(this._audioTrack);
    }
    /**
     * Retrieves the audio sample corresponding to the given timestamp, in seconds. More specifically, returns
     * the last audio sample (in presentation order) with a start timestamp less than or equal to the given timestamp.
     * Returns null if the timestamp is before the track's first timestamp.
     *
     * @param timestamp - The timestamp used for retrieval, in seconds.
     */
    async getSample(timestamp) {
      validateTimestamp(timestamp);
      for await (const sample of this.mediaSamplesAtTimestamps([timestamp])) {
        return sample;
      }
      throw new Error("Internal error: Iterator returned nothing.");
    }
    /**
     * Creates an async iterator that yields the audio samples of this track in presentation order. This method
     * will intelligently pre-decode a few samples ahead to enable fast iteration.
     *
     * @param startTimestamp - The timestamp in seconds at which to start yielding samples (inclusive).
     * @param endTimestamp - The timestamp in seconds at which to stop yielding samples (exclusive).
     */
    samples(startTimestamp = 0, endTimestamp = Infinity) {
      return this.mediaSamplesInRange(startTimestamp, endTimestamp);
    }
    /**
     * Creates an async iterator that yields an audio sample for each timestamp in the argument. This method
     * uses an optimized decoding pipeline if these timestamps are monotonically sorted, decoding each packet at most
     * once, and is therefore more efficient than manually getting the sample for every timestamp. The iterator may
     * yield null if no sample is available for a given timestamp.
     *
     * @param timestamps - An iterable or async iterable of timestamps in seconds.
     */
    samplesAtTimestamps(timestamps) {
      return this.mediaSamplesAtTimestamps(timestamps);
    }
  };
  var AudioBufferSink = class {
    constructor(audioTrack) {
      if (!(audioTrack instanceof InputAudioTrack)) {
        throw new TypeError("audioTrack must be an InputAudioTrack.");
      }
      this._audioSampleSink = new AudioSampleSink(audioTrack);
    }
    /** @internal */
    _audioSampleToWrappedArrayBuffer(sample) {
      return {
        buffer: sample.toAudioBuffer(),
        timestamp: sample.timestamp,
        duration: sample.duration
      };
    }
    /**
     * Retrieves the audio buffer corresponding to the given timestamp, in seconds. More specifically, returns
     * the last audio buffer (in presentation order) with a start timestamp less than or equal to the given timestamp.
     * Returns null if the timestamp is before the track's first timestamp.
     *
     * @param timestamp - The timestamp used for retrieval, in seconds.
     */
    async getBuffer(timestamp) {
      validateTimestamp(timestamp);
      const data = await this._audioSampleSink.getSample(timestamp);
      return data && this._audioSampleToWrappedArrayBuffer(data);
    }
    /**
     * Creates an async iterator that yields audio buffers of this track in presentation order. This method
     * will intelligently pre-decode a few buffers ahead to enable fast iteration.
     *
     * @param startTimestamp - The timestamp in seconds at which to start yielding buffers (inclusive).
     * @param endTimestamp - The timestamp in seconds at which to stop yielding buffers (exclusive).
     */
    buffers(startTimestamp = 0, endTimestamp = Infinity) {
      return mapAsyncGenerator(
        this._audioSampleSink.samples(startTimestamp, endTimestamp),
        (data) => this._audioSampleToWrappedArrayBuffer(data)
      );
    }
    /**
     * Creates an async iterator that yields an audio buffer for each timestamp in the argument. This method
     * uses an optimized decoding pipeline if these timestamps are monotonically sorted, decoding each packet at most
     * once, and is therefore more efficient than manually getting the buffer for every timestamp. The iterator may
     * yield null if no buffer is available for a given timestamp.
     *
     * @param timestamps - An iterable or async iterable of timestamps in seconds.
     */
    buffersAtTimestamps(timestamps) {
      return mapAsyncGenerator(
        this._audioSampleSink.samplesAtTimestamps(timestamps),
        (data) => data && this._audioSampleToWrappedArrayBuffer(data)
      );
    }
  };

  // src/input-track.ts
  var InputTrack = class {
    /** @internal */
    constructor(backing) {
      this._backing = backing;
    }
    /** Returns true iff this track is a video track. */
    isVideoTrack() {
      return this instanceof InputVideoTrack;
    }
    /** Returns true iff this track is an audio track. */
    isAudioTrack() {
      return this instanceof InputAudioTrack;
    }
    /** The unique ID of this track in the input file. */
    get id() {
      return this._backing.getId();
    }
    /** The ISO 639-2/T language code for this track. If the language is unknown, this field is 'und' (undetermined). */
    get languageCode() {
      return this._backing.getLanguageCode();
    }
    /**
     * A positive number x such that all timestamps and durations of all packets of this track are
     * integer multiples of 1/x.
     */
    get timeResolution() {
      return this._backing.getTimeResolution();
    }
    /**
     * Returns the start timestamp of the first packet of this track, in seconds. While often near zero, this value
     * may be positive or even negative. A negative starting timestamp means the track's timing has been offset. Samples
     * with a negative timestamp should not be presented.
     */
    getFirstTimestamp() {
      return this._backing.getFirstTimestamp();
    }
    /** Returns the end timestamp of the last packet of this track, in seconds. */
    computeDuration() {
      return this._backing.computeDuration();
    }
    /**
     * Computes aggregate packet statistics for this track, such as average packet rate or bitrate.
     *
     * @param targetPacketCount - This optional parameter sets a target for how many packets this method must have
     * looked at before it can return early; this means, you can use it to aggregate only a subset (prefix) of all
     * packets. This is very useful for getting a great estimate of video frame rate without having to scan through the
     * entire file.
     */
    async computePacketStats(targetPacketCount = Infinity) {
      const sink = new EncodedPacketSink(this);
      let startTimestamp = Infinity;
      let endTimestamp = -Infinity;
      let packetCount = 0;
      let totalPacketBytes = 0;
      for await (const packet of sink.packets(void 0, void 0, { metadataOnly: true })) {
        if (packetCount >= targetPacketCount && packet.timestamp >= endTimestamp) {
          break;
        }
        startTimestamp = Math.min(startTimestamp, packet.timestamp);
        endTimestamp = Math.max(endTimestamp, packet.timestamp + packet.duration);
        packetCount++;
        totalPacketBytes += packet.byteLength;
      }
      return {
        packetCount,
        averagePacketRate: packetCount ? Number((packetCount / (endTimestamp - startTimestamp)).toPrecision(16)) : 0,
        averageBitrate: packetCount ? Number((8 * totalPacketBytes / (endTimestamp - startTimestamp)).toPrecision(16)) : 0
      };
    }
  };
  var InputVideoTrack = class extends InputTrack {
    /** @internal */
    constructor(backing) {
      super(backing);
      this._backing = backing;
    }
    get type() {
      return "video";
    }
    get codec() {
      return this._backing.getCodec();
    }
    /** The width in pixels of the track's coded samples, before any transformations or rotations. */
    get codedWidth() {
      return this._backing.getCodedWidth();
    }
    /** The height in pixels of the track's coded samples, before any transformations or rotations. */
    get codedHeight() {
      return this._backing.getCodedHeight();
    }
    /** The angle in degrees by which the track's frames should be rotated (clockwise). */
    get rotation() {
      return this._backing.getRotation();
    }
    /** The width in pixels of the track's frames after rotation. */
    get displayWidth() {
      const rotation = this._backing.getRotation();
      return rotation % 180 === 0 ? this._backing.getCodedWidth() : this._backing.getCodedHeight();
    }
    /** The height in pixels of the track's frames after rotation. */
    get displayHeight() {
      const rotation = this._backing.getRotation();
      return rotation % 180 === 0 ? this._backing.getCodedHeight() : this._backing.getCodedWidth();
    }
    /** Returns the color space of the track's samples. */
    getColorSpace() {
      return this._backing.getColorSpace();
    }
    /** If this method returns true, the track's samples use a high dynamic range (HDR). */
    async hasHighDynamicRange() {
      const colorSpace = await this._backing.getColorSpace();
      return colorSpace.primaries === "bt2020" || colorSpace.primaries === "smpte432" || colorSpace.transfer === "pg" || colorSpace.transfer === "hlg" || colorSpace.matrix === "bt2020-ncl";
    }
    /**
     * Returns the decoder configuration for decoding the track's packets using a VideoDecoder. Returns null if the
     * track's codec is unknown.
     */
    getDecoderConfig() {
      return this._backing.getDecoderConfig();
    }
    async getCodecParameterString() {
      const decoderConfig = await this._backing.getDecoderConfig();
      return decoderConfig?.codec ?? null;
    }
    async canDecode() {
      try {
        const decoderConfig = await this._backing.getDecoderConfig();
        if (!decoderConfig) {
          return false;
        }
        const codec = this._backing.getCodec();
        assert(codec !== null);
        if (customVideoDecoders.some((x) => x.supports(codec, decoderConfig))) {
          return true;
        }
        if (typeof VideoDecoder === "undefined") {
          return false;
        }
        const support = await VideoDecoder.isConfigSupported(decoderConfig);
        return support.supported === true;
      } catch (error) {
        console.error("Error during decodability check:", error);
        return false;
      }
    }
    async determinePacketType(packet) {
      if (!(packet instanceof EncodedPacket)) {
        throw new TypeError("packet must be an EncodedPacket.");
      }
      if (packet.isMetadataOnly) {
        throw new TypeError("packet must not be metadata-only to determine its type.");
      }
      if (this.codec === null) {
        return null;
      }
      return determineVideoPacketType(this, packet);
    }
  };
  var InputAudioTrack = class extends InputTrack {
    /** @internal */
    constructor(backing) {
      super(backing);
      this._backing = backing;
    }
    get type() {
      return "audio";
    }
    get codec() {
      return this._backing.getCodec();
    }
    /** The number of audio channels in the track. */
    get numberOfChannels() {
      return this._backing.getNumberOfChannels();
    }
    /** The track's audio sample rate in hertz. */
    get sampleRate() {
      return this._backing.getSampleRate();
    }
    /**
     * Returns the decoder configuration for decoding the track's packets using an AudioDecoder. Returns null if the
     * track's codec is unknown.
     */
    getDecoderConfig() {
      return this._backing.getDecoderConfig();
    }
    async getCodecParameterString() {
      const decoderConfig = await this._backing.getDecoderConfig();
      return decoderConfig?.codec ?? null;
    }
    async canDecode() {
      try {
        const decoderConfig = await this._backing.getDecoderConfig();
        if (!decoderConfig) {
          return false;
        }
        const codec = this._backing.getCodec();
        assert(codec !== null);
        if (customAudioDecoders.some((x) => x.supports(codec, decoderConfig))) {
          return true;
        }
        if (decoderConfig.codec.startsWith("pcm-")) {
          return true;
        } else {
          if (typeof AudioDecoder === "undefined") {
            return false;
          }
          const support = await AudioDecoder.isConfigSupported(decoderConfig);
          return support.supported === true;
        }
      } catch (error) {
        console.error("Error during decodability check:", error);
        return false;
      }
    }
    async determinePacketType(packet) {
      if (!(packet instanceof EncodedPacket)) {
        throw new TypeError("packet must be an EncodedPacket.");
      }
      if (this.codec === null) {
        return null;
      }
      return "key";
    }
  };

  // src/reader.ts
  var Reader = class {
    constructor(source, maxStorableBytes = Infinity) {
      this.source = source;
      this.maxStorableBytes = maxStorableBytes;
      this.loadedSegments = [];
      this.loadingSegments = [];
      this.sourceSizePromise = null;
      this.nextAge = 0;
      this.totalStoredBytes = 0;
    }
    async loadRange(start, end) {
      end = Math.min(end, await this.source.getSize());
      if (start >= end) {
        return;
      }
      const matchingLoadingSegment = this.loadingSegments.find((x) => x.start <= start && x.end >= end);
      if (matchingLoadingSegment) {
        await matchingLoadingSegment.promise;
        return;
      }
      const index = binarySearchLessOrEqual(
        this.loadedSegments,
        start,
        (x) => x.start
      );
      if (index !== -1) {
        for (let i = index; i < this.loadedSegments.length; i++) {
          const segment = this.loadedSegments[i];
          if (segment.start > start) {
            break;
          }
          const segmentEncasesRequestedRange = segment.end >= end;
          if (segmentEncasesRequestedRange) {
            return;
          }
        }
      }
      this.source.onread?.(start, end);
      const bytesPromise = this.source._read(start, end);
      const loadingSegment = { start, end, promise: bytesPromise };
      this.loadingSegments.push(loadingSegment);
      const bytes2 = await bytesPromise;
      removeItem(this.loadingSegments, loadingSegment);
      this.insertIntoLoadedSegments(start, bytes2);
    }
    rangeIsLoaded(start, end) {
      if (end <= start) {
        return true;
      }
      const index = binarySearchLessOrEqual(this.loadedSegments, start, (x) => x.start);
      if (index === -1) {
        return false;
      }
      for (let i = index; i < this.loadedSegments.length; i++) {
        const segment = this.loadedSegments[i];
        if (segment.start > start) {
          break;
        }
        const segmentEncasesRequestedRange = segment.end >= end;
        if (segmentEncasesRequestedRange) {
          return true;
        }
      }
      return false;
    }
    insertIntoLoadedSegments(start, bytes2) {
      const segment = {
        start,
        end: start + bytes2.byteLength,
        bytes: bytes2,
        view: new DataView(bytes2.buffer),
        age: this.nextAge++
      };
      let index = binarySearchLessOrEqual(this.loadedSegments, start, (x) => x.start);
      if (index === -1 || this.loadedSegments[index].start < segment.start) {
        index++;
      }
      this.loadedSegments.splice(index, 0, segment);
      this.totalStoredBytes += bytes2.byteLength;
      for (let i = index + 1; i < this.loadedSegments.length; i++) {
        const otherSegment = this.loadedSegments[i];
        if (otherSegment.start >= segment.end) {
          break;
        }
        if (segment.start <= otherSegment.start && otherSegment.end <= segment.end) {
          this.loadedSegments.splice(i, 1);
          i--;
        }
      }
      while (this.totalStoredBytes > this.maxStorableBytes && this.loadedSegments.length > 1) {
        let oldestSegment = null;
        let oldestSegmentIndex = -1;
        for (let i = 0; i < this.loadedSegments.length; i++) {
          const candidate = this.loadedSegments[i];
          if (!oldestSegment || candidate.age < oldestSegment.age) {
            oldestSegment = candidate;
            oldestSegmentIndex = i;
          }
        }
        assert(oldestSegment);
        this.totalStoredBytes -= oldestSegment.bytes.byteLength;
        this.loadedSegments.splice(oldestSegmentIndex, 1);
      }
    }
    getViewAndOffset(start, end) {
      const startIndex = binarySearchLessOrEqual(this.loadedSegments, start, (x) => x.start);
      let segment = null;
      if (startIndex !== -1) {
        for (let i = startIndex; i < this.loadedSegments.length; i++) {
          const candidate = this.loadedSegments[i];
          if (candidate.start > start) {
            break;
          }
          if (end <= candidate.end) {
            segment = candidate;
            break;
          }
        }
      }
      if (!segment) {
        throw new Error(`No segment loaded for range [${start}, ${end}).`);
      }
      segment.age = this.nextAge++;
      return {
        view: segment.view,
        offset: segment.bytes.byteOffset + start - segment.start
      };
    }
    forgetRange(start, end) {
      if (end <= start) {
        return;
      }
      const startIndex = binarySearchLessOrEqual(this.loadedSegments, start, (x) => x.start);
      if (startIndex === -1) {
        return;
      }
      const segment = this.loadedSegments[startIndex];
      if (segment.start !== start || segment.end !== end) {
        return;
      }
      this.loadedSegments.splice(startIndex, 1);
      this.totalStoredBytes -= segment.bytes.byteLength;
    }
  };

  // src/wave/riff-reader.ts
  var RiffReader = class {
    constructor(reader) {
      this.reader = reader;
      this.pos = 0;
      this.littleEndian = true;
    }
    readBytes(length) {
      const { view: view2, offset } = this.reader.getViewAndOffset(this.pos, this.pos + length);
      this.pos += length;
      return new Uint8Array(view2.buffer, offset, length);
    }
    readU16() {
      const { view: view2, offset } = this.reader.getViewAndOffset(this.pos, this.pos + 2);
      this.pos += 2;
      return view2.getUint16(offset, this.littleEndian);
    }
    readU32() {
      const { view: view2, offset } = this.reader.getViewAndOffset(this.pos, this.pos + 4);
      this.pos += 4;
      return view2.getUint32(offset, this.littleEndian);
    }
    readU64() {
      let low;
      let high;
      if (this.littleEndian) {
        low = this.readU32();
        high = this.readU32();
      } else {
        high = this.readU32();
        low = this.readU32();
      }
      return high * 4294967296 + low;
    }
    readAscii(length) {
      const { view: view2, offset } = this.reader.getViewAndOffset(this.pos, this.pos + length);
      this.pos += length;
      let str = "";
      for (let i = 0; i < length; i++) {
        str += String.fromCharCode(view2.getUint8(offset + i));
      }
      return str;
    }
  };

  // src/wave/wave-demuxer.ts
  var WaveDemuxer = class extends Demuxer {
    constructor(input) {
      super(input);
      this.metadataPromise = null;
      this.dataStart = -1;
      this.dataSize = -1;
      this.audioInfo = null;
      this.tracks = [];
      this.metadataReader = new RiffReader(input._mainReader);
      this.chunkReader = new RiffReader(new Reader(input.source, 64 * 2 ** 20));
    }
    async readMetadata() {
      return this.metadataPromise ??= (async () => {
        const actualFileSize = await this.metadataReader.reader.source.getSize();
        const riffType = this.metadataReader.readAscii(4);
        this.metadataReader.littleEndian = riffType !== "RIFX";
        const isRf64 = riffType === "RF64";
        const outerChunkSize = this.metadataReader.readU32();
        let totalFileSize = isRf64 ? actualFileSize : Math.min(outerChunkSize + 8, actualFileSize);
        const format = this.metadataReader.readAscii(4);
        if (format !== "WAVE") {
          throw new Error("Invalid WAVE file - wrong format");
        }
        this.metadataReader.pos = 12;
        let chunksRead = 0;
        let dataChunkSize = null;
        while (this.metadataReader.pos < totalFileSize) {
          await this.metadataReader.reader.loadRange(this.metadataReader.pos, this.metadataReader.pos + 8);
          const chunkId = this.metadataReader.readAscii(4);
          const chunkSize = this.metadataReader.readU32();
          const startPos = this.metadataReader.pos;
          if (isRf64 && chunksRead === 0 && chunkId !== "ds64") {
            throw new Error('Invalid RF64 file: First chunk must be "ds64".');
          }
          if (chunkId === "fmt ") {
            await this.parseFmtChunk(chunkSize);
          } else if (chunkId === "data") {
            dataChunkSize ??= chunkSize;
            this.dataStart = this.metadataReader.pos;
            this.dataSize = Math.min(dataChunkSize, totalFileSize - this.dataStart);
          } else if (chunkId === "ds64") {
            const riffChunkSize = this.metadataReader.readU64();
            dataChunkSize = this.metadataReader.readU64();
            totalFileSize = Math.min(riffChunkSize + 8, actualFileSize);
          }
          this.metadataReader.pos = startPos + chunkSize + (chunkSize & 1);
          chunksRead++;
        }
        if (!this.audioInfo) {
          throw new Error('Invalid WAVE file - missing "fmt " chunk');
        }
        if (this.dataStart === -1) {
          throw new Error('Invalid WAVE file - missing "data" chunk');
        }
        const blockSize = this.audioInfo.blockSizeInBytes;
        this.dataSize = Math.floor(this.dataSize / blockSize) * blockSize;
        this.tracks.push(new InputAudioTrack(new WaveAudioTrackBacking(this)));
      })();
    }
    async parseFmtChunk(size) {
      await this.metadataReader.reader.loadRange(this.metadataReader.pos, this.metadataReader.pos + size);
      let formatTag = this.metadataReader.readU16();
      const numChannels = this.metadataReader.readU16();
      const sampleRate = this.metadataReader.readU32();
      this.metadataReader.pos += 4;
      const blockAlign = this.metadataReader.readU16();
      let bitsPerSample;
      if (size === 14) {
        bitsPerSample = 8;
      } else {
        bitsPerSample = this.metadataReader.readU16();
      }
      if (size >= 18 && formatTag !== 357) {
        const cbSize = this.metadataReader.readU16();
        const remainingSize = size - 18;
        const extensionSize = Math.min(remainingSize, cbSize);
        if (extensionSize >= 22 && formatTag === 65534 /* EXTENSIBLE */) {
          this.metadataReader.pos += 2 + 4;
          const subFormat = this.metadataReader.readBytes(16);
          formatTag = subFormat[0] | subFormat[1] << 8;
        }
      }
      if (formatTag === 7 /* MULAW */ || formatTag === 6 /* ALAW */) {
        bitsPerSample = 8;
      }
      this.audioInfo = {
        format: formatTag,
        numberOfChannels: numChannels,
        sampleRate,
        sampleSizeInBytes: Math.ceil(bitsPerSample / 8),
        blockSizeInBytes: blockAlign
      };
    }
    getCodec() {
      assert(this.audioInfo);
      if (this.audioInfo.format === 7 /* MULAW */) {
        return "ulaw";
      }
      if (this.audioInfo.format === 6 /* ALAW */) {
        return "alaw";
      }
      if (this.audioInfo.format === 1 /* PCM */) {
        if (this.audioInfo.sampleSizeInBytes === 1) {
          return "pcm-u8";
        } else if (this.audioInfo.sampleSizeInBytes === 2) {
          return "pcm-s16";
        } else if (this.audioInfo.sampleSizeInBytes === 3) {
          return "pcm-s24";
        } else if (this.audioInfo.sampleSizeInBytes === 4) {
          return "pcm-s32";
        }
      }
      if (this.audioInfo.format === 3 /* IEEE_FLOAT */) {
        if (this.audioInfo.sampleSizeInBytes === 4) {
          return "pcm-f32";
        }
      }
      return null;
    }
    async getMimeType() {
      return "audio/wav";
    }
    async computeDuration() {
      await this.readMetadata();
      assert(this.audioInfo);
      const numberOfBlocks = this.dataSize / this.audioInfo.blockSizeInBytes;
      return numberOfBlocks / this.audioInfo.sampleRate;
    }
    async getTracks() {
      await this.readMetadata();
      return this.tracks;
    }
  };
  var PACKET_SIZE_IN_FRAMES = 2048;
  var WaveAudioTrackBacking = class {
    constructor(demuxer) {
      this.demuxer = demuxer;
    }
    getId() {
      return 1;
    }
    getCodec() {
      return this.demuxer.getCodec();
    }
    async getDecoderConfig() {
      const codec = this.demuxer.getCodec();
      if (!codec) {
        return null;
      }
      assert(this.demuxer.audioInfo);
      return {
        codec,
        numberOfChannels: this.demuxer.audioInfo.numberOfChannels,
        sampleRate: this.demuxer.audioInfo.sampleRate
      };
    }
    computeDuration() {
      return this.demuxer.computeDuration();
    }
    getNumberOfChannels() {
      assert(this.demuxer.audioInfo);
      return this.demuxer.audioInfo.numberOfChannels;
    }
    getSampleRate() {
      assert(this.demuxer.audioInfo);
      return this.demuxer.audioInfo.sampleRate;
    }
    getTimeResolution() {
      assert(this.demuxer.audioInfo);
      return this.demuxer.audioInfo.sampleRate;
    }
    getLanguageCode() {
      return UNDETERMINED_LANGUAGE;
    }
    async getFirstTimestamp() {
      return 0;
    }
    async getPacketAtIndex(packetIndex, options) {
      assert(this.demuxer.audioInfo);
      const startOffset = packetIndex * PACKET_SIZE_IN_FRAMES * this.demuxer.audioInfo.blockSizeInBytes;
      if (startOffset >= this.demuxer.dataSize) {
        return null;
      }
      const sizeInBytes = Math.min(
        PACKET_SIZE_IN_FRAMES * this.demuxer.audioInfo.blockSizeInBytes,
        this.demuxer.dataSize - startOffset
      );
      let data;
      if (options.metadataOnly) {
        data = PLACEHOLDER_DATA;
      } else {
        const sizeOfOnePacket = PACKET_SIZE_IN_FRAMES * this.demuxer.audioInfo.blockSizeInBytes;
        const chunkSize = Math.ceil(2 ** 19 / sizeOfOnePacket) * sizeOfOnePacket;
        const chunkStart = Math.floor(startOffset / chunkSize) * chunkSize;
        const chunkEnd = chunkStart + chunkSize;
        await this.demuxer.chunkReader.reader.loadRange(
          this.demuxer.dataStart + chunkStart,
          this.demuxer.dataStart + chunkEnd
        );
        this.demuxer.chunkReader.pos = this.demuxer.dataStart + startOffset;
        data = this.demuxer.chunkReader.readBytes(sizeInBytes);
      }
      const timestamp = packetIndex * PACKET_SIZE_IN_FRAMES / this.demuxer.audioInfo.sampleRate;
      const duration = sizeInBytes / this.demuxer.audioInfo.blockSizeInBytes / this.demuxer.audioInfo.sampleRate;
      return new EncodedPacket(
        data,
        "key",
        timestamp,
        duration,
        packetIndex,
        sizeInBytes
      );
    }
    getFirstPacket(options) {
      return this.getPacketAtIndex(0, options);
    }
    getPacket(timestamp, options) {
      assert(this.demuxer.audioInfo);
      const packetIndex = Math.floor(timestamp * this.demuxer.audioInfo.sampleRate / PACKET_SIZE_IN_FRAMES);
      return this.getPacketAtIndex(packetIndex, options);
    }
    getNextPacket(packet, options) {
      assert(this.demuxer.audioInfo);
      const packetIndex = Math.round(packet.timestamp * this.demuxer.audioInfo.sampleRate / PACKET_SIZE_IN_FRAMES);
      return this.getPacketAtIndex(packetIndex + 1, options);
    }
    getKeyPacket(timestamp, options) {
      return this.getPacket(timestamp, options);
    }
    getNextKeyPacket(packet, options) {
      return this.getNextPacket(packet, options);
    }
  };

  // src/wave/riff-writer.ts
  var RiffWriter = class {
    constructor(writer) {
      this.writer = writer;
      this.helper = new Uint8Array(8);
      this.helperView = new DataView(this.helper.buffer);
    }
    writeU16(value) {
      this.helperView.setUint16(0, value, true);
      this.writer.write(this.helper.subarray(0, 2));
    }
    writeU32(value) {
      this.helperView.setUint32(0, value, true);
      this.writer.write(this.helper.subarray(0, 4));
    }
    writeU64(value) {
      this.helperView.setUint32(0, value, true);
      this.helperView.setUint32(4, Math.floor(value / 2 ** 32), true);
      this.writer.write(this.helper);
    }
    writeAscii(text) {
      this.writer.write(new TextEncoder().encode(text));
    }
  };

  // src/wave/wave-muxer.ts
  var WaveMuxer = class extends Muxer {
    constructor(output, format) {
      super(output);
      this.headerWritten = false;
      this.dataSize = 0;
      this.sampleRate = null;
      this.sampleCount = 0;
      this.format = format;
      this.writer = output._writer;
      this.riffWriter = new RiffWriter(output._writer);
      this.isRf64 = !!format._options.large;
    }
    async start() {
    }
    async getMimeType() {
      return "audio/wav";
    }
    async addEncodedVideoPacket() {
      throw new Error("WAVE does not support video.");
    }
    async addEncodedAudioPacket(track, packet, meta) {
      const release = await this.mutex.acquire();
      try {
        if (!this.headerWritten) {
          validateAudioChunkMetadata(meta);
          assert(meta);
          assert(meta.decoderConfig);
          this.writeHeader(track, meta.decoderConfig);
          this.sampleRate = meta.decoderConfig.sampleRate;
          this.headerWritten = true;
        }
        this.validateAndNormalizeTimestamp(track, packet.timestamp, packet.type === "key");
        if (!this.isRf64 && this.writer.getPos() + packet.data.byteLength >= 2 ** 32) {
          throw new Error(
            "Adding more audio data would exceed the maximum RIFF size of 4 GiB. To write larger files, use RF64 by setting `large: true` in the WavOutputFormatOptions."
          );
        }
        this.writer.write(packet.data);
        this.dataSize += packet.data.byteLength;
        this.sampleCount += Math.round(packet.duration * this.sampleRate);
        await this.writer.flush();
      } finally {
        release();
      }
    }
    async addSubtitleCue() {
      throw new Error("WAVE does not support subtitles.");
    }
    writeHeader(track, config) {
      if (this.format._options.onHeader) {
        this.writer.startTrackingWrites();
      }
      let format;
      const codec = track.source._codec;
      const pcmInfo = parsePcmCodec(codec);
      if (pcmInfo.dataType === "ulaw") {
        format = 7 /* MULAW */;
      } else if (pcmInfo.dataType === "alaw") {
        format = 6 /* ALAW */;
      } else if (pcmInfo.dataType === "float") {
        format = 3 /* IEEE_FLOAT */;
      } else {
        format = 1 /* PCM */;
      }
      const channels = config.numberOfChannels;
      const sampleRate = config.sampleRate;
      const blockSize = pcmInfo.sampleSize * channels;
      this.riffWriter.writeAscii(this.isRf64 ? "RF64" : "RIFF");
      if (this.isRf64) {
        this.riffWriter.writeU32(4294967295);
      } else {
        this.riffWriter.writeU32(0);
      }
      this.riffWriter.writeAscii("WAVE");
      if (this.isRf64) {
        this.riffWriter.writeAscii("ds64");
        this.riffWriter.writeU32(28);
        this.riffWriter.writeU64(0);
        this.riffWriter.writeU64(0);
        this.riffWriter.writeU64(0);
        this.riffWriter.writeU32(0);
      }
      this.riffWriter.writeAscii("fmt ");
      this.riffWriter.writeU32(16);
      this.riffWriter.writeU16(format);
      this.riffWriter.writeU16(channels);
      this.riffWriter.writeU32(sampleRate);
      this.riffWriter.writeU32(sampleRate * blockSize);
      this.riffWriter.writeU16(blockSize);
      this.riffWriter.writeU16(8 * pcmInfo.sampleSize);
      this.riffWriter.writeAscii("data");
      if (this.isRf64) {
        this.riffWriter.writeU32(4294967295);
      } else {
        this.riffWriter.writeU32(0);
      }
      if (this.format._options.onHeader) {
        const { data, start } = this.writer.stopTrackingWrites();
        this.format._options.onHeader(data, start);
      }
    }
    async finalize() {
      const release = await this.mutex.acquire();
      const endPos = this.writer.getPos();
      if (this.isRf64) {
        this.writer.seek(20);
        this.riffWriter.writeU64(endPos - 8);
        this.writer.seek(28);
        this.riffWriter.writeU64(this.dataSize);
        this.writer.seek(36);
        this.riffWriter.writeU64(this.sampleCount);
      } else {
        this.writer.seek(4);
        this.riffWriter.writeU32(endPos - 8);
        this.writer.seek(40);
        this.riffWriter.writeU32(this.dataSize);
      }
      this.writer.seek(endPos);
      release();
    }
  };

  // src/output-format.ts
  var OutputFormat = class {
    /** Returns a list of video codecs that this output format can contain. */
    getSupportedVideoCodecs() {
      return this.getSupportedCodecs().filter((codec) => VIDEO_CODECS.includes(codec));
    }
    /** Returns a list of audio codecs that this output format can contain. */
    getSupportedAudioCodecs() {
      return this.getSupportedCodecs().filter((codec) => AUDIO_CODECS.includes(codec));
    }
    /** Returns a list of subtitle codecs that this output format can contain. */
    getSupportedSubtitleCodecs() {
      return this.getSupportedCodecs().filter((codec) => SUBTITLE_CODECS.includes(codec));
    }
    /** @internal */
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    _codecUnsupportedHint(codec) {
      return "";
    }
  };
  var IsobmffOutputFormat2 = class extends OutputFormat {
    constructor(options = {}) {
      if (!options || typeof options !== "object") {
        throw new TypeError("options must be an object.");
      }
      if (options.fastStart !== void 0 && ![false, "in-memory", "fragmented"].includes(options.fastStart)) {
        throw new TypeError('options.fastStart, when provided, must be false, "in-memory", or "fragmented".');
      }
      if (options.minimumFragmentDuration !== void 0 && (!Number.isFinite(options.minimumFragmentDuration) || options.minimumFragmentDuration < 0)) {
        throw new TypeError("options.minimumFragmentDuration, when provided, must be a non-negative number.");
      }
      if (options.onFtyp !== void 0 && typeof options.onFtyp !== "function") {
        throw new TypeError("options.onFtyp, when provided, must be a function.");
      }
      if (options.onMoov !== void 0 && typeof options.onMoov !== "function") {
        throw new TypeError("options.onMoov, when provided, must be a function.");
      }
      if (options.onMdat !== void 0 && typeof options.onMdat !== "function") {
        throw new TypeError("options.onMdat, when provided, must be a function.");
      }
      if (options.onMoof !== void 0 && typeof options.onMoof !== "function") {
        throw new TypeError("options.onMoof, when provided, must be a function.");
      }
      super();
      this._options = options;
    }
    getSupportedTrackCounts() {
      return {
        video: { min: 0, max: Infinity },
        audio: { min: 0, max: Infinity },
        subtitle: { min: 0, max: Infinity },
        total: { min: 1, max: 2 ** 32 - 1 }
        // Have fun reaching this one
      };
    }
    get supportsVideoRotationMetadata() {
      return true;
    }
    /** @internal */
    _createMuxer(output) {
      return new IsobmffMuxer(output, this);
    }
  };
  var Mp4OutputFormat = class extends IsobmffOutputFormat2 {
    /** @internal */
    get _name() {
      return "MP4";
    }
    get fileExtension() {
      return ".mp4";
    }
    get mimeType() {
      return "video/mp4";
    }
    getSupportedCodecs() {
      return [
        ...VIDEO_CODECS,
        ...NON_PCM_AUDIO_CODECS,
        // These are supported via ISO/IEC 23003-5
        "pcm-s16",
        "pcm-s16be",
        "pcm-s24",
        "pcm-s24be",
        "pcm-s32",
        "pcm-s32be",
        "pcm-f32",
        "pcm-f32be",
        "pcm-f64",
        "pcm-f64be",
        ...SUBTITLE_CODECS
      ];
    }
    /** @internal */
    _codecUnsupportedHint(codec) {
      if (new MovOutputFormat().getSupportedCodecs().includes(codec)) {
        return " Switching to MOV will grant support for this codec.";
      }
      return "";
    }
  };
  var MovOutputFormat = class extends IsobmffOutputFormat2 {
    /** @internal */
    get _name() {
      return "MOV";
    }
    get fileExtension() {
      return ".mov";
    }
    get mimeType() {
      return "video/quicktime";
    }
    getSupportedCodecs() {
      return [
        ...VIDEO_CODECS,
        ...AUDIO_CODECS
      ];
    }
    /** @internal */
    _codecUnsupportedHint(codec) {
      if (new Mp4OutputFormat().getSupportedCodecs().includes(codec)) {
        return " Switching to MP4 will grant support for this codec.";
      }
      return "";
    }
  };
  var MkvOutputFormat2 = class extends OutputFormat {
    constructor(options = {}) {
      if (!options || typeof options !== "object") {
        throw new TypeError("options must be an object.");
      }
      if (options.appendOnly !== void 0 && typeof options.appendOnly !== "boolean") {
        throw new TypeError("options.appendOnly, when provided, must be a boolean.");
      }
      if (options.minimumClusterDuration !== void 0 && (!Number.isFinite(options.minimumClusterDuration) || options.minimumClusterDuration < 0)) {
        throw new TypeError("options.minimumClusterDuration, when provided, must be a non-negative number.");
      }
      if (options.onEbmlHeader !== void 0 && typeof options.onEbmlHeader !== "function") {
        throw new TypeError("options.onEbmlHeader, when provided, must be a function.");
      }
      if (options.onSegmentHeader !== void 0 && typeof options.onSegmentHeader !== "function") {
        throw new TypeError("options.onHeader, when provided, must be a function.");
      }
      if (options.onCluster !== void 0 && typeof options.onCluster !== "function") {
        throw new TypeError("options.onCluster, when provided, must be a function.");
      }
      super();
      this._options = options;
    }
    /** @internal */
    _createMuxer(output) {
      return new MatroskaMuxer(output, this);
    }
    /** @internal */
    get _name() {
      return "Matroska";
    }
    getSupportedTrackCounts() {
      return {
        video: { min: 0, max: Infinity },
        audio: { min: 0, max: Infinity },
        subtitle: { min: 0, max: Infinity },
        total: { min: 1, max: 127 }
      };
    }
    get fileExtension() {
      return ".mkv";
    }
    get mimeType() {
      return "video/x-matroska";
    }
    getSupportedCodecs() {
      return [
        ...VIDEO_CODECS,
        ...NON_PCM_AUDIO_CODECS,
        ...PCM_AUDIO_CODECS.filter((codec) => !["pcm-s8", "pcm-f32be", "pcm-f64be", "ulaw", "alaw"].includes(codec)),
        ...SUBTITLE_CODECS
      ];
    }
    get supportsVideoRotationMetadata() {
      return false;
    }
  };
  var WebMOutputFormat = class extends MkvOutputFormat2 {
    getSupportedCodecs() {
      return [
        ...VIDEO_CODECS.filter((codec) => ["vp8", "vp9", "av1"].includes(codec)),
        ...AUDIO_CODECS.filter((codec) => ["opus", "vorbis"].includes(codec)),
        ...SUBTITLE_CODECS
      ];
    }
    /** @internal */
    get _name() {
      return "WebM";
    }
    get fileExtension() {
      return ".webm";
    }
    get mimeType() {
      return "video/webm";
    }
    /** @internal */
    _codecUnsupportedHint(codec) {
      if (new MkvOutputFormat2().getSupportedCodecs().includes(codec)) {
        return " Switching to MKV will grant support for this codec.";
      }
      return "";
    }
  };
  var Mp3OutputFormat = class extends OutputFormat {
    constructor(options = {}) {
      if (!options || typeof options !== "object") {
        throw new TypeError("options must be an object.");
      }
      if (options.xingHeader !== void 0 && typeof options.xingHeader !== "boolean") {
        throw new TypeError("options.xingHeader, when provided, must be a boolean.");
      }
      if (options.onXingFrame !== void 0 && typeof options.onXingFrame !== "function") {
        throw new TypeError("options.onXingFrame, when provided, must be a function.");
      }
      super();
      this._options = options;
    }
    /** @internal */
    _createMuxer(output) {
      return new Mp3Muxer(output, this);
    }
    /** @internal */
    get _name() {
      return "MP3";
    }
    getSupportedTrackCounts() {
      return {
        video: { min: 0, max: 0 },
        audio: { min: 1, max: 1 },
        subtitle: { min: 0, max: 0 },
        total: { min: 1, max: 1 }
      };
    }
    get fileExtension() {
      return ".mp3";
    }
    get mimeType() {
      return "audio/mpeg";
    }
    getSupportedCodecs() {
      return ["mp3"];
    }
    get supportsVideoRotationMetadata() {
      return false;
    }
  };
  var WavOutputFormat = class extends OutputFormat {
    constructor(options = {}) {
      if (!options || typeof options !== "object") {
        throw new TypeError("options must be an object.");
      }
      if (options.large !== void 0 && typeof options.large !== "boolean") {
        throw new TypeError("options.large, when provided, must be a boolean.");
      }
      if (options.onHeader !== void 0 && typeof options.onHeader !== "function") {
        throw new TypeError("options.onHeader, when provided, must be a function.");
      }
      super();
      this._options = options;
    }
    /** @internal */
    _createMuxer(output) {
      return new WaveMuxer(output, this);
    }
    /** @internal */
    get _name() {
      return "WAVE";
    }
    getSupportedTrackCounts() {
      return {
        video: { min: 0, max: 0 },
        audio: { min: 1, max: 1 },
        subtitle: { min: 0, max: 0 },
        total: { min: 1, max: 1 }
      };
    }
    get fileExtension() {
      return ".wav";
    }
    get mimeType() {
      return "audio/wav";
    }
    getSupportedCodecs() {
      return [
        ...PCM_AUDIO_CODECS.filter(
          (codec) => ["pcm-s16", "pcm-s24", "pcm-s32", "pcm-f32", "pcm-u8", "ulaw", "alaw"].includes(codec)
        )
      ];
    }
    get supportsVideoRotationMetadata() {
      return false;
    }
  };
  var OggOutputFormat = class extends OutputFormat {
    constructor(options = {}) {
      if (!options || typeof options !== "object") {
        throw new TypeError("options must be an object.");
      }
      if (options.onPage !== void 0 && typeof options.onPage !== "function") {
        throw new TypeError("options.onPage, when provided, must be a function.");
      }
      super();
      this._options = options;
    }
    /** @internal */
    _createMuxer(output) {
      return new OggMuxer(output, this);
    }
    /** @internal */
    get _name() {
      return "Ogg";
    }
    getSupportedTrackCounts() {
      return {
        video: { min: 0, max: 0 },
        audio: { min: 0, max: Infinity },
        subtitle: { min: 0, max: 0 },
        total: { min: 1, max: 2 ** 32 }
      };
    }
    get fileExtension() {
      return ".ogg";
    }
    get mimeType() {
      return "application/ogg";
    }
    getSupportedCodecs() {
      return [
        ...AUDIO_CODECS.filter((codec) => ["vorbis", "opus"].includes(codec))
      ];
    }
    get supportsVideoRotationMetadata() {
      return false;
    }
  };

  // src/media-source.ts
  var MediaSource = class {
    constructor() {
      /** @internal */
      this._connectedTrack = null;
      /** @internal */
      this._closingPromise = null;
      /** @internal */
      this._closed = false;
      /**
       * @internal
       * A time offset in seconds that is added to all timestamps generated by this source.
       */
      this._timestampOffset = 0;
    }
    /** @internal */
    _ensureValidAdd() {
      if (!this._connectedTrack) {
        throw new Error("Source is not connected to an output track.");
      }
      if (this._connectedTrack.output.state === "canceled") {
        throw new Error("Output has been canceled.");
      }
      if (this._connectedTrack.output.state === "finalizing" || this._connectedTrack.output.state === "finalized") {
        throw new Error("Output has been finalized.");
      }
      if (this._connectedTrack.output.state === "pending") {
        throw new Error("Output has not started.");
      }
      if (this._closed) {
        throw new Error("Source is closed.");
      }
    }
    /** @internal */
    async _start() {
    }
    /** @internal */
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    async _flushAndClose(forceClose) {
    }
    /**
     * Closes this source. This prevents future samples from being added and signals to the output file that no further
     * samples will come in for this track. Calling `.close()` is optional but recommended after adding the
     * last sample - for improved performance and reduced memory usage.
     */
    close() {
      if (this._closingPromise) {
        return;
      }
      const connectedTrack = this._connectedTrack;
      if (!connectedTrack) {
        throw new Error("Cannot call close without connecting the source to an output track.");
      }
      if (connectedTrack.output.state === "pending") {
        throw new Error("Cannot call close before output has been started.");
      }
      this._closingPromise = (async () => {
        await this._flushAndClose(false);
        this._closed = true;
        if (connectedTrack.output.state === "finalizing" || connectedTrack.output.state === "finalized") {
          return;
        }
        connectedTrack.output._muxer.onTrackClose(connectedTrack);
      })();
    }
    /** @internal */
    async _flushOrWaitForOngoingClose(forceClose) {
      if (this._closingPromise) {
        return this._closingPromise;
      } else {
        return this._flushAndClose(forceClose);
      }
    }
  };
  var VideoSource = class extends MediaSource {
    constructor(codec) {
      super();
      /** @internal */
      this._connectedTrack = null;
      if (!VIDEO_CODECS.includes(codec)) {
        throw new TypeError(`Invalid video codec '${codec}'. Must be one of: ${VIDEO_CODECS.join(", ")}.`);
      }
      this._codec = codec;
    }
  };
  var EncodedVideoPacketSource = class extends VideoSource {
    constructor(codec) {
      super(codec);
    }
    /**
     * Adds an encoded packet to the output video track.
     *
     * @param meta - Additional metadata from the encoder. You should pass this for the first call, including a valid
     * decoder config.
     *
     * @returns A Promise that resolves once the output is ready to receive more samples. You should await this Promise
     * to respect writer and encoder backpressure.
     */
    add(packet, meta) {
      if (!(packet instanceof EncodedPacket)) {
        throw new TypeError("packet must be an EncodedPacket.");
      }
      if (packet.isMetadataOnly) {
        throw new TypeError("Metadata-only packets cannot be added.");
      }
      if (meta !== void 0 && (!meta || typeof meta !== "object")) {
        throw new TypeError("meta, when provided, must be an object.");
      }
      this._ensureValidAdd();
      return this._connectedTrack.output._muxer.addEncodedVideoPacket(this._connectedTrack, packet, meta);
    }
  };
  var validateVideoEncodingConfig = (config) => {
    if (!config || typeof config !== "object") {
      throw new TypeError("Encoding config must be an object.");
    }
    if (!VIDEO_CODECS.includes(config.codec)) {
      throw new TypeError(`Invalid video codec '${config.codec}'. Must be one of: ${VIDEO_CODECS.join(", ")}.`);
    }
    if (!(config.bitrate instanceof Quality) && (!Number.isInteger(config.bitrate) || config.bitrate <= 0)) {
      throw new TypeError("config.bitrate must be a positive integer or a quality.");
    }
    if (config.latencyMode !== void 0 && !["quality", "realtime"].includes(config.latencyMode)) {
      throw new TypeError("config.latencyMode, when provided, must be 'quality' or 'realtime'.");
    }
    if (config.keyFrameInterval !== void 0 && (!Number.isFinite(config.keyFrameInterval) || config.keyFrameInterval < 0)) {
      throw new TypeError("config.keyFrameInterval, when provided, must be a non-negative number.");
    }
    if (config.fullCodecString !== void 0 && typeof config.fullCodecString !== "string") {
      throw new TypeError("config.fullCodecString, when provided, must be a string.");
    }
    if (config.fullCodecString !== void 0 && inferCodecFromCodecString(config.fullCodecString) !== config.codec) {
      throw new TypeError(
        `config.fullCodecString, when provided, must be a string that matches the specified codec (${config.codec}).`
      );
    }
    if (config.onEncodedPacket !== void 0 && typeof config.onEncodedPacket !== "function") {
      throw new TypeError("config.onEncodedChunk, when provided, must be a function.");
    }
    if (config.onEncoderConfig !== void 0 && typeof config.onEncoderConfig !== "function") {
      throw new TypeError("config.onEncoderConfig, when provided, must be a function.");
    }
  };
  var VideoEncoderWrapper = class {
    constructor(source, encodingConfig) {
      this.source = source;
      this.encodingConfig = encodingConfig;
      this.ensureEncoderPromise = null;
      this.encoderInitialized = false;
      this.encoder = null;
      this.muxer = null;
      this.lastMultipleOfKeyFrameInterval = -1;
      this.lastWidth = null;
      this.lastHeight = null;
      this.customEncoder = null;
      this.customEncoderCallSerializer = new CallSerializer();
      this.customEncoderQueueSize = 0;
      /**
       * Encoders typically throw their errors "out of band", meaning asynchronously in some other execution context.
       * However, we want to surface these errors to the user within the normal control flow, so they don't go uncaught.
       * So, we keep track of the encoder error and throw it as soon as we get the chance.
       */
      this.encoderError = null;
    }
    async add(videoSample, shouldClose, encodeOptions) {
      try {
        this.checkForEncoderError();
        this.source._ensureValidAdd();
        if (this.lastWidth !== null && this.lastHeight !== null) {
          if (videoSample.codedWidth !== this.lastWidth || videoSample.codedHeight !== this.lastHeight) {
            throw new Error(
              `Video sample size must remain constant. Expected ${this.lastWidth}x${this.lastHeight}, got ${videoSample.codedWidth}x${videoSample.codedHeight}.`
            );
          }
        } else {
          this.lastWidth = videoSample.codedWidth;
          this.lastHeight = videoSample.codedHeight;
        }
        if (!this.encoderInitialized) {
          if (!this.ensureEncoderPromise) {
            void this.ensureEncoder(videoSample);
          }
          if (!this.encoderInitialized) {
            await this.ensureEncoderPromise;
          }
        }
        assert(this.encoderInitialized);
        const keyFrameInterval = this.encodingConfig.keyFrameInterval ?? 5;
        const multipleOfKeyFrameInterval = Math.floor(videoSample.timestamp / keyFrameInterval);
        const finalEncodeOptions = {
          ...encodeOptions,
          keyFrame: encodeOptions?.keyFrame || keyFrameInterval === 0 || multipleOfKeyFrameInterval !== this.lastMultipleOfKeyFrameInterval
        };
        this.lastMultipleOfKeyFrameInterval = multipleOfKeyFrameInterval;
        if (this.customEncoder) {
          this.customEncoderQueueSize++;
          const promise = this.customEncoderCallSerializer.call(() => this.customEncoder.encode(videoSample, finalEncodeOptions)).then(() => {
            this.customEncoderQueueSize--;
            if (shouldClose) {
              videoSample.close();
            }
          }).catch((error) => {
            this.encoderError ??= error;
          });
          if (this.customEncoderQueueSize >= 4) {
            await promise;
          }
        } else {
          assert(this.encoder);
          const videoFrame = videoSample.toVideoFrame();
          this.encoder.encode(videoFrame, finalEncodeOptions);
          videoFrame.close();
          if (shouldClose) {
            videoSample.close();
          }
          if (this.encoder.encodeQueueSize >= 4) {
            await new Promise((resolve) => this.encoder.addEventListener("dequeue", resolve, { once: true }));
          }
        }
        await this.muxer.mutex.currentPromise;
      } finally {
        if (shouldClose) {
          videoSample.close();
        }
      }
    }
    async ensureEncoder(videoSample) {
      if (this.encoder) {
        return;
      }
      return this.ensureEncoderPromise = (async () => {
        const width = videoSample.codedWidth;
        const height = videoSample.codedHeight;
        const bitrate = this.encodingConfig.bitrate instanceof Quality ? this.encodingConfig.bitrate._toVideoBitrate(this.encodingConfig.codec, width, height) : this.encodingConfig.bitrate;
        const encoderConfig = {
          codec: this.encodingConfig.fullCodecString ?? buildVideoCodecString(
            this.encodingConfig.codec,
            width,
            height,
            bitrate
          ),
          width,
          height,
          bitrate,
          framerate: this.source._connectedTrack?.metadata.frameRate,
          latencyMode: this.encodingConfig.latencyMode,
          ...getVideoEncoderConfigExtension(this.encodingConfig.codec)
        };
        this.encodingConfig.onEncoderConfig?.(encoderConfig);
        const MatchingCustomEncoder = customVideoEncoders.find((x) => x.supports(
          this.encodingConfig.codec,
          encoderConfig
        ));
        if (MatchingCustomEncoder) {
          this.customEncoder = new MatchingCustomEncoder();
          this.customEncoder.codec = this.encodingConfig.codec;
          this.customEncoder.config = encoderConfig;
          this.customEncoder.onPacket = (packet, meta) => {
            if (!(packet instanceof EncodedPacket)) {
              throw new TypeError("The first argument passed to onPacket must be an EncodedPacket.");
            }
            if (meta !== void 0 && (!meta || typeof meta !== "object")) {
              throw new TypeError("The second argument passed to onPacket must be an object or undefined.");
            }
            this.encodingConfig.onEncodedPacket?.(packet, meta);
            void this.muxer.addEncodedVideoPacket(this.source._connectedTrack, packet, meta);
          };
          await this.customEncoder.init();
        } else {
          if (typeof VideoEncoder === "undefined") {
            throw new Error("VideoEncoder is not supported by this browser.");
          }
          const support = await VideoEncoder.isConfigSupported(encoderConfig);
          if (!support.supported) {
            throw new Error(
              `This specific encoder configuration (${encoderConfig.codec}, ${encoderConfig.bitrate} bps, ${encoderConfig.width}x${encoderConfig.height}) is not supported by this browser. Consider using another codec or changing your video parameters.`
            );
          }
          this.encoder = new VideoEncoder({
            output: (chunk, meta) => {
              const packet = EncodedPacket.fromEncodedChunk(chunk);
              this.encodingConfig.onEncodedPacket?.(packet, meta);
              void this.muxer.addEncodedVideoPacket(this.source._connectedTrack, packet, meta);
            },
            error: (error) => {
              this.encoderError ??= error;
            }
          });
          this.encoder.configure(encoderConfig);
        }
        assert(this.source._connectedTrack);
        this.muxer = this.source._connectedTrack.output._muxer;
        this.encoderInitialized = true;
      })();
    }
    async flushAndClose(forceClose) {
      this.checkForEncoderError();
      if (this.customEncoder) {
        if (!forceClose) {
          void this.customEncoderCallSerializer.call(() => this.customEncoder.flush());
        }
        await this.customEncoderCallSerializer.call(() => this.customEncoder.close());
      } else if (this.encoder) {
        if (!forceClose) {
          await this.encoder.flush();
        }
        this.encoder.close();
      }
      this.checkForEncoderError();
    }
    getQueueSize() {
      if (this.customEncoder) {
        return this.customEncoderQueueSize;
      } else {
        return this.encoder?.encodeQueueSize ?? 0;
      }
    }
    checkForEncoderError() {
      if (this.encoderError) {
        this.encoderError.stack = new Error().stack;
        throw this.encoderError;
      }
    }
  };
  var VideoSampleSource = class extends VideoSource {
    constructor(encodingConfig) {
      validateVideoEncodingConfig(encodingConfig);
      super(encodingConfig.codec);
      this._encoder = new VideoEncoderWrapper(this, encodingConfig);
    }
    /**
     * Encodes a video sample (frame) and then adds it to the output.
     *
     * @returns A Promise that resolves once the output is ready to receive more samples. You should await this Promise
     * to respect writer and encoder backpressure.
     */
    add(videoSample, encodeOptions) {
      if (!(videoSample instanceof VideoSample)) {
        throw new TypeError("videoSample must be a VideoSample.");
      }
      return this._encoder.add(videoSample, false, encodeOptions);
    }
    /** @internal */
    _flushAndClose(forceClose) {
      return this._encoder.flushAndClose(forceClose);
    }
  };
  var CanvasSource = class extends VideoSource {
    constructor(canvas, encodingConfig) {
      if (!(typeof HTMLCanvasElement !== "undefined" && canvas instanceof HTMLCanvasElement) && !(typeof OffscreenCanvas !== "undefined" && canvas instanceof OffscreenCanvas)) {
        throw new TypeError("canvas must be an HTMLCanvasElement or OffscreenCanvas.");
      }
      validateVideoEncodingConfig(encodingConfig);
      super(encodingConfig.codec);
      this._encoder = new VideoEncoderWrapper(this, encodingConfig);
      this._canvas = canvas;
    }
    /**
     * Captures the current canvas state as a video sample (frame), encodes it and adds it to the output.
     *
     * @param timestamp - The timestamp of the sample, in seconds.
     * @param duration - The duration of the sample, in seconds.
     *
     * @returns A Promise that resolves once the output is ready to receive more samples. You should await this Promise
     * to respect writer and encoder backpressure.
     */
    add(timestamp, duration = 0, encodeOptions) {
      if (!Number.isFinite(timestamp) || timestamp < 0) {
        throw new TypeError("timestamp must be a non-negative number.");
      }
      if (!Number.isFinite(duration) || duration < 0) {
        throw new TypeError("duration must be a non-negative number.");
      }
      const sample = new VideoSample(this._canvas, { timestamp, duration });
      return this._encoder.add(sample, true, encodeOptions);
    }
    /** @internal */
    _flushAndClose(forceClose) {
      return this._encoder.flushAndClose(forceClose);
    }
  };
  var MediaStreamVideoTrackSource = class extends VideoSource {
    constructor(track, encodingConfig) {
      if (!(track instanceof MediaStreamTrack) || track.kind !== "video") {
        throw new TypeError("track must be a video MediaStreamTrack.");
      }
      validateVideoEncodingConfig(encodingConfig);
      encodingConfig = {
        ...encodingConfig,
        latencyMode: "realtime"
      };
      super(encodingConfig.codec);
      /** @internal */
      this._abortController = null;
      /** @internal */
      this._workerTrackId = null;
      /** @internal */
      this._workerListener = null;
      /** @internal */
      this._promiseWithResolvers = promiseWithResolvers();
      /** @internal */
      this._errorPromiseAccessed = false;
      this._encoder = new VideoEncoderWrapper(this, encodingConfig);
      this._track = track;
    }
    /** A promise that rejects upon any error within this source. This promise never resolves. */
    get errorPromise() {
      this._errorPromiseAccessed = true;
      return this._promiseWithResolvers.promise;
    }
    /** @internal */
    async _start() {
      if (!this._errorPromiseAccessed) {
        console.warn(
          "Make sure not to ignore the `errorPromise` field on MediaStreamVideoTrackSource, so that any internal errors get bubbled up properly."
        );
      }
      this._abortController = new AbortController();
      let firstVideoFrameTimestamp = null;
      let errored = false;
      const onVideoFrame = (videoFrame) => {
        if (errored) {
          videoFrame.close();
          return;
        }
        if (firstVideoFrameTimestamp === null) {
          firstVideoFrameTimestamp = videoFrame.timestamp / 1e6;
          const muxer = this._connectedTrack.output._muxer;
          if (muxer.firstMediaStreamTimestamp === null) {
            muxer.firstMediaStreamTimestamp = performance.now() / 1e3;
            this._timestampOffset = -firstVideoFrameTimestamp;
          } else {
            this._timestampOffset = performance.now() / 1e3 - muxer.firstMediaStreamTimestamp - firstVideoFrameTimestamp;
          }
        }
        if (this._encoder.getQueueSize() >= 4) {
          videoFrame.close();
          return;
        }
        void this._encoder.add(new VideoSample(videoFrame), true).catch((error) => {
          errored = true;
          this._abortController?.abort();
          this._promiseWithResolvers.reject(error);
          if (this._workerTrackId !== null) {
            sendMessageToMediaStreamTrackProcessorWorker({
              type: "stopTrack",
              trackId: this._workerTrackId
            });
          }
        });
      };
      if (typeof MediaStreamTrackProcessor !== "undefined") {
        const processor = new MediaStreamTrackProcessor({ track: this._track });
        const consumer = new WritableStream({ write: onVideoFrame });
        processor.readable.pipeTo(consumer, {
          signal: this._abortController.signal
        }).catch((error) => {
          if (error instanceof DOMException && error.name === "AbortError") return;
          this._promiseWithResolvers.reject(error);
        });
      } else {
        const supportedInWorker = await mediaStreamTrackProcessorIsSupportedInWorker();
        if (supportedInWorker) {
          this._workerTrackId = nextMediaStreamTrackProcessorWorkerId++;
          sendMessageToMediaStreamTrackProcessorWorker({
            type: "videoTrack",
            trackId: this._workerTrackId,
            track: this._track
          }, [this._track]);
          this._workerListener = (event) => {
            const message = event.data;
            if (message.type === "videoFrame" && message.trackId === this._workerTrackId) {
              onVideoFrame(message.videoFrame);
            } else if (message.type === "error" && message.trackId === this._workerTrackId) {
              this._promiseWithResolvers.reject(message.error);
            }
          };
          mediaStreamTrackProcessorWorker.addEventListener("message", this._workerListener);
        } else {
          throw new Error("MediaStreamTrackProcessor is required but not supported by this browser.");
        }
      }
    }
    /** @internal */
    async _flushAndClose(forceClose) {
      if (this._abortController) {
        this._abortController.abort();
        this._abortController = null;
      }
      if (this._workerTrackId !== null) {
        assert(this._workerListener);
        sendMessageToMediaStreamTrackProcessorWorker({
          type: "stopTrack",
          trackId: this._workerTrackId
        });
        await new Promise((resolve) => {
          const listener = (event) => {
            const message = event.data;
            if (message.type === "trackStopped" && message.trackId === this._workerTrackId) {
              assert(this._workerListener);
              mediaStreamTrackProcessorWorker.removeEventListener("message", this._workerListener);
              mediaStreamTrackProcessorWorker.removeEventListener("message", listener);
              resolve();
            }
          };
          mediaStreamTrackProcessorWorker.addEventListener("message", listener);
        });
      }
      await this._encoder.flushAndClose(forceClose);
    }
  };
  var AudioSource = class extends MediaSource {
    constructor(codec) {
      super();
      /** @internal */
      this._connectedTrack = null;
      if (!AUDIO_CODECS.includes(codec)) {
        throw new TypeError(`Invalid audio codec '${codec}'. Must be one of: ${AUDIO_CODECS.join(", ")}.`);
      }
      this._codec = codec;
    }
  };
  var EncodedAudioPacketSource = class extends AudioSource {
    constructor(codec) {
      super(codec);
    }
    /**
     * Adds an encoded packet to the output audio track.
     *
     * @param meta - Additional metadata from the encoder. You should pass this for the first call, including a valid
     * decoder config.
     *
     * @returns A Promise that resolves once the output is ready to receive more samples. You should await this Promise
     * to respect writer and encoder backpressure.
     */
    add(packet, meta) {
      if (!(packet instanceof EncodedPacket)) {
        throw new TypeError("packet must be an EncodedPacket.");
      }
      if (packet.isMetadataOnly) {
        throw new TypeError("Metadata-only packets cannot be added.");
      }
      if (meta !== void 0 && (!meta || typeof meta !== "object")) {
        throw new TypeError("meta, when provided, must be an object.");
      }
      this._ensureValidAdd();
      return this._connectedTrack.output._muxer.addEncodedAudioPacket(this._connectedTrack, packet, meta);
    }
  };
  var validateAudioEncodingConfig = (config) => {
    if (!config || typeof config !== "object") {
      throw new TypeError("Encoding config must be an object.");
    }
    if (!AUDIO_CODECS.includes(config.codec)) {
      throw new TypeError(`Invalid audio codec '${config.codec}'. Must be one of: ${AUDIO_CODECS.join(", ")}.`);
    }
    if (config.bitrate === void 0 && (!PCM_AUDIO_CODECS.includes(config.codec) || config.codec === "flac")) {
      throw new TypeError("config.bitrate must be provided for compressed audio codecs.");
    }
    if (config.bitrate !== void 0 && !(config.bitrate instanceof Quality) && (!Number.isInteger(config.bitrate) || config.bitrate <= 0)) {
      throw new TypeError("config.bitrate, when provided, must be a positive integer or a quality.");
    }
    if (config.fullCodecString !== void 0 && typeof config.fullCodecString !== "string") {
      throw new TypeError("config.fullCodecString, when provided, must be a string.");
    }
    if (config.fullCodecString !== void 0 && inferCodecFromCodecString(config.fullCodecString) !== config.codec) {
      throw new TypeError(
        `config.fullCodecString, when provided, must be a string that matches the specified codec (${config.codec}).`
      );
    }
    if (config.onEncodedPacket !== void 0 && typeof config.onEncodedPacket !== "function") {
      throw new TypeError("config.onEncodedChunk, when provided, must be a function.");
    }
    if (config.onEncoderConfig !== void 0 && typeof config.onEncoderConfig !== "function") {
      throw new TypeError("config.onEncoderConfig, when provided, must be a function.");
    }
  };
  var AudioEncoderWrapper = class {
    constructor(source, encodingConfig) {
      this.source = source;
      this.encodingConfig = encodingConfig;
      this.ensureEncoderPromise = null;
      this.encoderInitialized = false;
      this.encoder = null;
      this.muxer = null;
      this.lastNumberOfChannels = null;
      this.lastSampleRate = null;
      this.isPcmEncoder = false;
      this.outputSampleSize = null;
      this.writeOutputValue = null;
      this.customEncoder = null;
      this.customEncoderCallSerializer = new CallSerializer();
      this.customEncoderQueueSize = 0;
      /**
       * Encoders typically throw their errors "out of band", meaning asynchronously in some other execution context.
       * However, we want to surface these errors to the user within the normal control flow, so they don't go uncaught.
       * So, we keep track of the encoder error and throw it as soon as we get the chance.
       */
      this.encoderError = null;
    }
    async add(audioSample, shouldClose) {
      try {
        this.checkForEncoderError();
        this.source._ensureValidAdd();
        if (this.lastNumberOfChannels !== null && this.lastSampleRate !== null) {
          if (audioSample.numberOfChannels !== this.lastNumberOfChannels || audioSample.sampleRate !== this.lastSampleRate) {
            throw new Error(
              `Audio parameters must remain constant. Expected ${this.lastNumberOfChannels} channels at ${this.lastSampleRate} Hz, got ${audioSample.numberOfChannels} channels at ${audioSample.sampleRate} Hz.`
            );
          }
        } else {
          this.lastNumberOfChannels = audioSample.numberOfChannels;
          this.lastSampleRate = audioSample.sampleRate;
        }
        if (!this.encoderInitialized) {
          if (!this.ensureEncoderPromise) {
            void this.ensureEncoder(audioSample);
          }
          if (!this.encoderInitialized) {
            await this.ensureEncoderPromise;
          }
        }
        assert(this.encoderInitialized);
        if (this.customEncoder) {
          this.customEncoderQueueSize++;
          const promise = this.customEncoderCallSerializer.call(() => this.customEncoder.encode(audioSample)).then(() => {
            this.customEncoderQueueSize--;
            if (shouldClose) {
              audioSample.close();
            }
          }).catch((error) => {
            this.encoderError ??= error;
          });
          if (this.customEncoderQueueSize >= 4) {
            await promise;
          }
          await this.muxer.mutex.currentPromise;
        } else if (this.isPcmEncoder) {
          await this.doPcmEncoding(audioSample, shouldClose);
        } else {
          assert(this.encoder);
          const audioData = audioSample.toAudioData();
          this.encoder.encode(audioData);
          audioData.close();
          if (shouldClose) {
            audioSample.close();
          }
          if (this.encoder.encodeQueueSize >= 4) {
            await new Promise((resolve) => this.encoder.addEventListener("dequeue", resolve, { once: true }));
          }
          await this.muxer.mutex.currentPromise;
        }
      } finally {
        if (shouldClose) {
          audioSample.close();
        }
      }
    }
    async doPcmEncoding(audioSample, shouldClose) {
      assert(this.outputSampleSize);
      assert(this.writeOutputValue);
      const { numberOfChannels, numberOfFrames, sampleRate, timestamp } = audioSample;
      const CHUNK_SIZE = 2048;
      const outputs = [];
      for (let frame = 0; frame < numberOfFrames; frame += CHUNK_SIZE) {
        const frameCount = Math.min(CHUNK_SIZE, audioSample.numberOfFrames - frame);
        const outputSize = frameCount * numberOfChannels * this.outputSampleSize;
        const outputBuffer = new ArrayBuffer(outputSize);
        const outputView = new DataView(outputBuffer);
        outputs.push({ frameCount, view: outputView });
      }
      const allocationSize = audioSample.allocationSize({ planeIndex: 0, format: "f32-planar" });
      const floats = new Float32Array(allocationSize / Float32Array.BYTES_PER_ELEMENT);
      for (let i = 0; i < numberOfChannels; i++) {
        audioSample.copyTo(floats, { planeIndex: i, format: "f32-planar" });
        for (let j = 0; j < outputs.length; j++) {
          const { frameCount, view: view2 } = outputs[j];
          for (let k = 0; k < frameCount; k++) {
            this.writeOutputValue(
              view2,
              (k * numberOfChannels + i) * this.outputSampleSize,
              floats[j * CHUNK_SIZE + k]
            );
          }
        }
      }
      if (shouldClose) {
        audioSample.close();
      }
      const meta = {
        decoderConfig: {
          codec: this.encodingConfig.codec,
          numberOfChannels,
          sampleRate
        }
      };
      for (let i = 0; i < outputs.length; i++) {
        const { frameCount, view: view2 } = outputs[i];
        const outputBuffer = view2.buffer;
        const startFrame = i * CHUNK_SIZE;
        const packet = new EncodedPacket(
          new Uint8Array(outputBuffer),
          "key",
          timestamp + startFrame / sampleRate,
          frameCount / sampleRate
        );
        this.encodingConfig.onEncodedPacket?.(packet, meta);
        await this.muxer.addEncodedAudioPacket(this.source._connectedTrack, packet, meta);
      }
    }
    ensureEncoder(audioSample) {
      if (this.encoderInitialized) {
        return;
      }
      return this.ensureEncoderPromise = (async () => {
        const { numberOfChannels, sampleRate } = audioSample;
        const bitrate = this.encodingConfig.bitrate instanceof Quality ? this.encodingConfig.bitrate._toAudioBitrate(this.encodingConfig.codec) : this.encodingConfig.bitrate;
        const encoderConfig = {
          codec: this.encodingConfig.fullCodecString ?? buildAudioCodecString(
            this.encodingConfig.codec,
            numberOfChannels,
            sampleRate
          ),
          numberOfChannels,
          sampleRate,
          bitrate,
          ...getAudioEncoderConfigExtension(this.encodingConfig.codec)
        };
        this.encodingConfig.onEncoderConfig?.(encoderConfig);
        const MatchingCustomEncoder = customAudioEncoders.find((x) => x.supports(
          this.encodingConfig.codec,
          encoderConfig
        ));
        if (MatchingCustomEncoder) {
          this.customEncoder = new MatchingCustomEncoder();
          this.customEncoder.codec = this.encodingConfig.codec;
          this.customEncoder.config = encoderConfig;
          this.customEncoder.onPacket = (packet, meta) => {
            if (!(packet instanceof EncodedPacket)) {
              throw new TypeError("The first argument passed to onPacket must be an EncodedPacket.");
            }
            if (meta !== void 0 && (!meta || typeof meta !== "object")) {
              throw new TypeError("The second argument passed to onPacket must be an object or undefined.");
            }
            this.encodingConfig.onEncodedPacket?.(packet, meta);
            void this.muxer.addEncodedAudioPacket(this.source._connectedTrack, packet, meta);
          };
          await this.customEncoder.init();
        } else if (PCM_AUDIO_CODECS.includes(this.encodingConfig.codec)) {
          this.initPcmEncoder();
        } else {
          if (typeof AudioEncoder === "undefined") {
            throw new Error("AudioEncoder is not supported by this browser.");
          }
          const support = await AudioEncoder.isConfigSupported(encoderConfig);
          if (!support.supported) {
            throw new Error(
              `This specific encoder configuration (${encoderConfig.codec}, ${encoderConfig.bitrate} bps, ${encoderConfig.numberOfChannels} channels, ${encoderConfig.sampleRate} Hz) is not supported by this browser. Consider using another codec or changing your audio parameters.`
            );
          }
          this.encoder = new AudioEncoder({
            output: (chunk, meta) => {
              const packet = EncodedPacket.fromEncodedChunk(chunk);
              this.encodingConfig.onEncodedPacket?.(packet, meta);
              void this.muxer.addEncodedAudioPacket(this.source._connectedTrack, packet, meta);
            },
            error: (error) => {
              this.encoderError ??= error;
            }
          });
          this.encoder.configure(encoderConfig);
        }
        assert(this.source._connectedTrack);
        this.muxer = this.source._connectedTrack.output._muxer;
        this.encoderInitialized = true;
      })();
    }
    initPcmEncoder() {
      this.isPcmEncoder = true;
      const codec = this.encodingConfig.codec;
      const { dataType, sampleSize, littleEndian } = parsePcmCodec(codec);
      this.outputSampleSize = sampleSize;
      switch (sampleSize) {
        case 1:
          {
            if (dataType === "unsigned") {
              this.writeOutputValue = (view2, byteOffset, value) => view2.setUint8(byteOffset, clamp((value + 1) * 127.5, 0, 255));
            } else if (dataType === "signed") {
              this.writeOutputValue = (view2, byteOffset, value) => {
                view2.setInt8(byteOffset, clamp(Math.round(value * 128), -128, 127));
              };
            } else if (dataType === "ulaw") {
              this.writeOutputValue = (view2, byteOffset, value) => {
                const int16 = clamp(Math.floor(value * 32767), -32768, 32767);
                view2.setUint8(byteOffset, toUlaw(int16));
              };
            } else if (dataType === "alaw") {
              this.writeOutputValue = (view2, byteOffset, value) => {
                const int16 = clamp(Math.floor(value * 32767), -32768, 32767);
                view2.setUint8(byteOffset, toAlaw(int16));
              };
            } else {
              assert(false);
            }
          }
          ;
          break;
        case 2:
          {
            if (dataType === "unsigned") {
              this.writeOutputValue = (view2, byteOffset, value) => view2.setUint16(byteOffset, clamp((value + 1) * 32767.5, 0, 65535), littleEndian);
            } else if (dataType === "signed") {
              this.writeOutputValue = (view2, byteOffset, value) => view2.setInt16(byteOffset, clamp(Math.round(value * 32767), -32768, 32767), littleEndian);
            } else {
              assert(false);
            }
          }
          ;
          break;
        case 3:
          {
            if (dataType === "unsigned") {
              this.writeOutputValue = (view2, byteOffset, value) => setUint24(view2, byteOffset, clamp((value + 1) * 83886075e-1, 0, 16777215), littleEndian);
            } else if (dataType === "signed") {
              this.writeOutputValue = (view2, byteOffset, value) => setInt24(
                view2,
                byteOffset,
                clamp(Math.round(value * 8388607), -8388608, 8388607),
                littleEndian
              );
            } else {
              assert(false);
            }
          }
          ;
          break;
        case 4:
          {
            if (dataType === "unsigned") {
              this.writeOutputValue = (view2, byteOffset, value) => view2.setUint32(byteOffset, clamp((value + 1) * 21474836475e-1, 0, 4294967295), littleEndian);
            } else if (dataType === "signed") {
              this.writeOutputValue = (view2, byteOffset, value) => view2.setInt32(
                byteOffset,
                clamp(Math.round(value * 2147483647), -2147483648, 2147483647),
                littleEndian
              );
            } else if (dataType === "float") {
              this.writeOutputValue = (view2, byteOffset, value) => view2.setFloat32(byteOffset, value, littleEndian);
            } else {
              assert(false);
            }
          }
          ;
          break;
        case 8:
          {
            if (dataType === "float") {
              this.writeOutputValue = (view2, byteOffset, value) => view2.setFloat64(byteOffset, value, littleEndian);
            } else {
              assert(false);
            }
          }
          ;
          break;
        default:
          {
            assertNever(sampleSize);
            assert(false);
          }
          ;
      }
    }
    async flushAndClose(forceClose) {
      this.checkForEncoderError();
      if (this.customEncoder) {
        if (!forceClose) {
          void this.customEncoderCallSerializer.call(() => this.customEncoder.flush());
        }
        await this.customEncoderCallSerializer.call(() => this.customEncoder.close());
      } else if (this.encoder) {
        if (!forceClose) {
          await this.encoder.flush();
        }
        this.encoder.close();
      }
      this.checkForEncoderError();
    }
    getQueueSize() {
      if (this.customEncoder) {
        return this.customEncoderQueueSize;
      } else if (this.isPcmEncoder) {
        return 0;
      } else {
        return this.encoder?.encodeQueueSize ?? 0;
      }
    }
    checkForEncoderError() {
      if (this.encoderError) {
        this.encoderError.stack = new Error().stack;
        throw this.encoderError;
      }
    }
  };
  var AudioSampleSource = class extends AudioSource {
    constructor(encodingConfig) {
      validateAudioEncodingConfig(encodingConfig);
      super(encodingConfig.codec);
      this._encoder = new AudioEncoderWrapper(this, encodingConfig);
    }
    /**
     * Encodes an audio sample and then adds it to the output.
     *
     * @returns A Promise that resolves once the output is ready to receive more samples. You should await this Promise
     * to respect writer and encoder backpressure.
     */
    add(audioSample) {
      if (!(audioSample instanceof AudioSample)) {
        throw new TypeError("audioSample must be an AudioSample.");
      }
      return this._encoder.add(audioSample, false);
    }
    /** @internal */
    _flushAndClose(forceClose) {
      return this._encoder.flushAndClose(forceClose);
    }
  };
  var AudioBufferSource = class extends AudioSource {
    constructor(encodingConfig) {
      validateAudioEncodingConfig(encodingConfig);
      super(encodingConfig.codec);
      /** @internal */
      this._accumulatedTime = 0;
      this._encoder = new AudioEncoderWrapper(this, encodingConfig);
    }
    /**
     * Converts an AudioBuffer to audio samples, encodes them and adds them to the output. The first AudioBuffer will
     * be played at timestamp 0, and any subsequent AudioBuffer will have a timestamp equal to the total duration of
     * all previous AudioBuffers.
     *
     * @returns A Promise that resolves once the output is ready to receive more samples. You should await this Promise
     * to respect writer and encoder backpressure.
     */
    add(audioBuffer) {
      if (!(audioBuffer instanceof AudioBuffer)) {
        throw new TypeError("audioBuffer must be an AudioBuffer.");
      }
      const audioSamples = AudioSample.fromAudioBuffer(audioBuffer, this._accumulatedTime);
      const promises = audioSamples.map((sample) => this._encoder.add(sample, true));
      this._accumulatedTime += audioBuffer.duration;
      return Promise.all(promises);
    }
    /** @internal */
    _flushAndClose(forceClose) {
      return this._encoder.flushAndClose(forceClose);
    }
  };
  var MediaStreamAudioTrackSource = class extends AudioSource {
    constructor(track, encodingConfig) {
      if (!(track instanceof MediaStreamTrack) || track.kind !== "audio") {
        throw new TypeError("track must be an audio MediaStreamTrack.");
      }
      validateAudioEncodingConfig(encodingConfig);
      super(encodingConfig.codec);
      /** @internal */
      this._abortController = null;
      /** @internal */
      this._audioContext = null;
      /** @internal */
      this._scriptProcessorNode = null;
      // Deprecated but goated
      /** @internal */
      this._promiseWithResolvers = promiseWithResolvers();
      /** @internal */
      this._errorPromiseAccessed = false;
      this._encoder = new AudioEncoderWrapper(this, encodingConfig);
      this._track = track;
    }
    /** A promise that rejects upon any error within this source. This promise never resolves. */
    get errorPromise() {
      this._errorPromiseAccessed = true;
      return this._promiseWithResolvers.promise;
    }
    /** @internal */
    async _start() {
      if (!this._errorPromiseAccessed) {
        console.warn(
          "Make sure not to ignore the `errorPromise` field on MediaStreamVideoTrackSource, so that any internal errors get bubbled up properly."
        );
      }
      this._abortController = new AbortController();
      if (typeof MediaStreamTrackProcessor !== "undefined") {
        let firstAudioDataTimestamp = null;
        const processor = new MediaStreamTrackProcessor({ track: this._track });
        const consumer = new WritableStream({
          write: (audioData) => {
            if (firstAudioDataTimestamp === null) {
              firstAudioDataTimestamp = audioData.timestamp / 1e6;
              const muxer = this._connectedTrack.output._muxer;
              if (muxer.firstMediaStreamTimestamp === null) {
                muxer.firstMediaStreamTimestamp = performance.now() / 1e3;
                this._timestampOffset = -firstAudioDataTimestamp;
              } else {
                this._timestampOffset = performance.now() / 1e3 - muxer.firstMediaStreamTimestamp - firstAudioDataTimestamp;
              }
            }
            if (this._encoder.getQueueSize() >= 4) {
              audioData.close();
              return;
            }
            void this._encoder.add(new AudioSample(audioData), true).catch((error) => {
              this._abortController?.abort();
              this._promiseWithResolvers.reject(error);
            });
          }
        });
        processor.readable.pipeTo(consumer, {
          signal: this._abortController.signal
        }).catch((error) => {
          if (error instanceof DOMException && error.name === "AbortError") return;
          this._promiseWithResolvers.reject(error);
        });
      } else {
        const AudioContext = window.AudioContext || window.webkitAudioContext;
        this._audioContext = new AudioContext({ sampleRate: this._track.getSettings().sampleRate });
        const sourceNode = this._audioContext.createMediaStreamSource(new MediaStream([this._track]));
        this._scriptProcessorNode = this._audioContext.createScriptProcessor(4096);
        if (this._audioContext.state === "suspended") {
          await this._audioContext.resume();
        }
        sourceNode.connect(this._scriptProcessorNode);
        this._scriptProcessorNode.connect(this._audioContext.destination);
        let audioReceived = false;
        let totalDuration = 0;
        this._scriptProcessorNode.onaudioprocess = (event) => {
          const audioSamples = AudioSample.fromAudioBuffer(event.inputBuffer, totalDuration);
          totalDuration += event.inputBuffer.duration;
          for (const audioSample of audioSamples) {
            if (!audioReceived) {
              audioReceived = true;
              const muxer = this._connectedTrack.output._muxer;
              if (muxer.firstMediaStreamTimestamp === null) {
                muxer.firstMediaStreamTimestamp = performance.now() / 1e3;
              } else {
                this._timestampOffset = performance.now() / 1e3 - muxer.firstMediaStreamTimestamp;
              }
            }
            if (this._encoder.getQueueSize() >= 4) {
              audioSample.close();
              continue;
            }
            void this._encoder.add(audioSample, true).catch((error) => {
              void this._audioContext.suspend();
              this._promiseWithResolvers.reject(error);
            });
          }
        };
      }
    }
    /** @internal */
    async _flushAndClose(forceClose) {
      if (this._abortController) {
        this._abortController.abort();
        this._abortController = null;
      }
      if (this._audioContext) {
        assert(this._scriptProcessorNode);
        this._scriptProcessorNode.disconnect();
        await this._audioContext.suspend();
      }
      await this._encoder.flushAndClose(forceClose);
    }
  };
  var mediaStreamTrackProcessorWorkerCode = () => {
    const sendMessage = (message, transfer) => {
      if (transfer) {
        self.postMessage(message, { transfer });
      } else {
        self.postMessage(message);
      }
    };
    sendMessage({
      type: "support",
      supported: typeof MediaStreamTrackProcessor !== "undefined"
    });
    const abortControllers = /* @__PURE__ */ new Map();
    const stoppedTracks = /* @__PURE__ */ new Set();
    self.addEventListener("message", (event) => {
      const message = event.data;
      switch (message.type) {
        case "videoTrack":
          {
            const processor = new MediaStreamTrackProcessor({ track: message.track });
            const consumer = new WritableStream({
              write: (videoFrame) => {
                if (stoppedTracks.has(message.trackId)) {
                  videoFrame.close();
                  return;
                }
                sendMessage({
                  type: "videoFrame",
                  trackId: message.trackId,
                  videoFrame
                }, [videoFrame]);
              }
            });
            const abortController = new AbortController();
            abortControllers.set(message.trackId, abortController);
            processor.readable.pipeTo(consumer, {
              signal: abortController.signal
            }).catch((error) => {
              if (error instanceof DOMException && error.name === "AbortError") return;
              sendMessage({
                type: "error",
                trackId: message.trackId,
                error
              });
            });
          }
          ;
          break;
        case "stopTrack":
          {
            const abortController = abortControllers.get(message.trackId);
            if (abortController) {
              abortController.abort();
              abortControllers.delete(message.trackId);
            }
            stoppedTracks.add(message.trackId);
            sendMessage({
              type: "trackStopped",
              trackId: message.trackId
            });
          }
          ;
          break;
        default:
          assertNever(message);
      }
    });
  };
  var nextMediaStreamTrackProcessorWorkerId = 0;
  var mediaStreamTrackProcessorWorker = null;
  var initMediaStreamTrackProcessorWorker = () => {
    const blob = new Blob(
      [`(${mediaStreamTrackProcessorWorkerCode.toString()})()`],
      { type: "application/javascript" }
    );
    const url2 = URL.createObjectURL(blob);
    mediaStreamTrackProcessorWorker = new Worker(url2);
  };
  var mediaStreamTrackProcessorIsSupportedInWorkerCache = null;
  var mediaStreamTrackProcessorIsSupportedInWorker = async () => {
    if (mediaStreamTrackProcessorIsSupportedInWorkerCache !== null) {
      return mediaStreamTrackProcessorIsSupportedInWorkerCache;
    }
    if (!mediaStreamTrackProcessorWorker) {
      initMediaStreamTrackProcessorWorker();
    }
    return new Promise((resolve) => {
      assert(mediaStreamTrackProcessorWorker);
      const listener = (event) => {
        const message = event.data;
        if (message.type === "support") {
          mediaStreamTrackProcessorIsSupportedInWorkerCache = message.supported;
          mediaStreamTrackProcessorWorker.removeEventListener("message", listener);
          resolve(message.supported);
        }
      };
      mediaStreamTrackProcessorWorker.addEventListener("message", listener);
    });
  };
  var sendMessageToMediaStreamTrackProcessorWorker = (message, transfer) => {
    assert(mediaStreamTrackProcessorWorker);
    if (transfer) {
      mediaStreamTrackProcessorWorker.postMessage(message, transfer);
    } else {
      mediaStreamTrackProcessorWorker.postMessage(message);
    }
  };
  var SubtitleSource = class extends MediaSource {
    constructor(codec) {
      super();
      /** @internal */
      this._connectedTrack = null;
      if (!SUBTITLE_CODECS.includes(codec)) {
        throw new TypeError(`Invalid subtitle codec '${codec}'. Must be one of: ${SUBTITLE_CODECS.join(", ")}.`);
      }
      this._codec = codec;
    }
  };
  var TextSubtitleSource = class extends SubtitleSource {
    constructor(codec) {
      super(codec);
      this._parser = new SubtitleParser({
        codec,
        output: (cue, metadata) => this._connectedTrack?.output._muxer.addSubtitleCue(this._connectedTrack, cue, metadata)
      });
    }
    /**
     * Parses the subtitle text according to the specified codec and adds it to the output track. You don't have to
     * add the entire subtitle file at once here; you can provide it in chunks.
     *
     * @returns A Promise that resolves once the output is ready to receive more samples. You should await this Promise
     * to respect writer and encoder backpressure.
     */
    add(text) {
      if (typeof text !== "string") {
        throw new TypeError("text must be a string.");
      }
      this._ensureValidAdd();
      this._parser.parse(text);
      return this._connectedTrack.output._muxer.mutex.currentPromise;
    }
  };

  // src/output.ts
  var ALL_TRACK_TYPES = ["video", "audio", "subtitle"];
  var validateBaseTrackMetadata = (metadata) => {
    if (!metadata || typeof metadata !== "object") {
      throw new TypeError("metadata must be an object.");
    }
    if (metadata.languageCode !== void 0 && !isIso639Dash2LanguageCode(metadata.languageCode)) {
      throw new TypeError("metadata.languageCode must be a three-letter, ISO 639-2/T language code.");
    }
  };
  var Output = class {
    constructor(options) {
      /** The current state of the output. */
      this.state = "pending";
      /** @internal */
      this._tracks = [];
      /** @internal */
      this._startPromise = null;
      /** @internal */
      this._cancelPromise = null;
      /** @internal */
      this._finalizePromise = null;
      /** @internal */
      this._mutex = new AsyncMutex();
      if (!options || typeof options !== "object") {
        throw new TypeError("options must be an object.");
      }
      if (!(options.format instanceof OutputFormat)) {
        throw new TypeError("options.format must be an OutputFormat.");
      }
      if (!(options.target instanceof Target)) {
        throw new TypeError("options.target must be a Target.");
      }
      if (options.target._output) {
        throw new Error("Target is already used for another output.");
      }
      options.target._output = this;
      this.format = options.format;
      this.target = options.target;
      this._writer = options.target._createWriter();
      this._muxer = options.format._createMuxer(this);
    }
    /** Adds a video track to the output with the given source. Must be called before output is started. */
    addVideoTrack(source, metadata = {}) {
      if (!(source instanceof VideoSource)) {
        throw new TypeError("source must be a VideoSource.");
      }
      validateBaseTrackMetadata(metadata);
      if (metadata.rotation !== void 0 && ![0, 90, 180, 270].includes(metadata.rotation)) {
        throw new TypeError(`Invalid video rotation: ${metadata.rotation}. Has to be 0, 90, 180 or 270.`);
      }
      if (!this.format.supportsVideoRotationMetadata && metadata.rotation) {
        throw new Error(`${this.format._name} does not support video rotation metadata.`);
      }
      if (metadata.frameRate !== void 0 && (!Number.isFinite(metadata.frameRate) || metadata.frameRate <= 0)) {
        throw new TypeError(
          `Invalid video frame rate: ${metadata.frameRate}. Must be a positive number.`
        );
      }
      this._addTrack("video", source, metadata);
    }
    /** Adds an audio track to the output with the given source. Must be called before output is started. */
    addAudioTrack(source, metadata = {}) {
      if (!(source instanceof AudioSource)) {
        throw new TypeError("source must be an AudioSource.");
      }
      validateBaseTrackMetadata(metadata);
      this._addTrack("audio", source, metadata);
    }
    /** Adds a subtitle track to the output with the given source. Must be called before output is started. */
    addSubtitleTrack(source, metadata = {}) {
      if (!(source instanceof SubtitleSource)) {
        throw new TypeError("source must be a SubtitleSource.");
      }
      validateBaseTrackMetadata(metadata);
      this._addTrack("subtitle", source, metadata);
    }
    /** @internal */
    _addTrack(type, source, metadata) {
      if (this.state !== "pending") {
        throw new Error("Cannot add track after output has been started or canceled.");
      }
      if (source._connectedTrack) {
        throw new Error("Source is already used for a track.");
      }
      const supportedTrackCounts = this.format.getSupportedTrackCounts();
      const presentTracksOfThisType = this._tracks.reduce(
        (count, track2) => count + (track2.type === type ? 1 : 0),
        0
      );
      const maxCount = supportedTrackCounts[type].max;
      if (presentTracksOfThisType === maxCount) {
        throw new Error(
          maxCount === 0 ? `${this.format._name} does not support ${type} tracks.` : `${this.format._name} does not support more than ${maxCount} ${type} track${maxCount === 1 ? "" : "s"}.`
        );
      }
      const maxTotalCount = supportedTrackCounts.total.max;
      if (this._tracks.length === maxTotalCount) {
        throw new Error(
          `${this.format._name} does not support more than ${maxTotalCount} tracks${maxTotalCount === 1 ? "" : "s"} in total.`
        );
      }
      const track = {
        id: this._tracks.length + 1,
        output: this,
        type,
        source,
        metadata
      };
      if (track.type === "video") {
        const supportedVideoCodecs = this.format.getSupportedVideoCodecs();
        if (supportedVideoCodecs.length === 0) {
          throw new Error(
            `${this.format._name} does not support video tracks.` + this.format._codecUnsupportedHint(track.source._codec)
          );
        } else if (!supportedVideoCodecs.includes(track.source._codec)) {
          throw new Error(
            `Codec '${track.source._codec}' cannot be contained within ${this.format._name}. Supported video codecs are: ${supportedVideoCodecs.map((codec) => `'${codec}'`).join(", ")}.` + this.format._codecUnsupportedHint(track.source._codec)
          );
        }
      } else if (track.type === "audio") {
        const supportedAudioCodecs = this.format.getSupportedAudioCodecs();
        if (supportedAudioCodecs.length === 0) {
          throw new Error(
            `${this.format._name} does not support audio tracks.` + this.format._codecUnsupportedHint(track.source._codec)
          );
        } else if (!supportedAudioCodecs.includes(track.source._codec)) {
          throw new Error(
            `Codec '${track.source._codec}' cannot be contained within ${this.format._name}. Supported audio codecs are: ${supportedAudioCodecs.map((codec) => `'${codec}'`).join(", ")}.` + this.format._codecUnsupportedHint(track.source._codec)
          );
        }
      } else if (track.type === "subtitle") {
        const supportedSubtitleCodecs = this.format.getSupportedSubtitleCodecs();
        if (supportedSubtitleCodecs.length === 0) {
          throw new Error(
            `${this.format._name} does not support subtitle tracks.` + this.format._codecUnsupportedHint(track.source._codec)
          );
        } else if (!supportedSubtitleCodecs.includes(track.source._codec)) {
          throw new Error(
            `Codec '${track.source._codec}' cannot be contained within ${this.format._name}. Supported subtitle codecs are: ${supportedSubtitleCodecs.map((codec) => `'${codec}'`).join(", ")}.` + this.format._codecUnsupportedHint(track.source._codec)
          );
        }
      }
      this._tracks.push(track);
      source._connectedTrack = track;
    }
    /**
     * Starts the creation of the output file. This method should be called after all tracks have been added. Only after
     * the output has started can media samples be added to the tracks.
     *
     * @returns A promise that resolves when the output has successfully started and is ready to receive media samples.
     */
    async start() {
      const supportedTrackCounts = this.format.getSupportedTrackCounts();
      for (const trackType of ALL_TRACK_TYPES) {
        const presentTracksOfThisType = this._tracks.reduce(
          (count, track) => count + (track.type === trackType ? 1 : 0),
          0
        );
        const minCount = supportedTrackCounts[trackType].min;
        if (presentTracksOfThisType < minCount) {
          throw new Error(
            minCount === supportedTrackCounts[trackType].max ? `${this.format._name} requires exactly ${minCount} ${trackType} track${minCount === 1 ? "" : "s"}.` : `${this.format._name} requires at least ${minCount} ${trackType} track${minCount === 1 ? "" : "s"}.`
          );
        }
      }
      const totalMinCount = supportedTrackCounts.total.min;
      if (this._tracks.length < totalMinCount) {
        throw new Error(
          totalMinCount === supportedTrackCounts.total.max ? `${this.format._name} requires exactly ${totalMinCount} track${totalMinCount === 1 ? "" : "s"}.` : `${this.format._name} requires at least ${totalMinCount} track${totalMinCount === 1 ? "" : "s"}.`
        );
      }
      if (this.state === "canceled") {
        throw new Error("Output has been canceled.");
      }
      if (this._startPromise) {
        console.warn("Output has already been started.");
        return this._startPromise;
      }
      return this._startPromise = (async () => {
        this.state = "started";
        this._writer.start();
        const release = await this._mutex.acquire();
        await this._muxer.start();
        const promises = this._tracks.map((track) => track.source._start());
        await Promise.all(promises);
        release();
      })();
    }
    /**
     * Resolves with the full MIME type of the output file, including track codecs.
     *
     * The returned promise will resolve only once the precise codec strings of all tracks are known.
     */
    getMimeType() {
      return this._muxer.getMimeType();
    }
    /**
     * Cancels the creation of the output file, releasing internal resources like encoders and preventing further
     * samples from being added.
     *
     * @returns A promise that resolves once all internal resources have been released.
     */
    async cancel() {
      if (this._cancelPromise) {
        console.warn("Output has already been canceled.");
        return this._cancelPromise;
      } else if (this.state === "finalizing" || this.state === "finalized") {
        console.warn("Output has already been finalized.");
        return;
      }
      return this._cancelPromise = (async () => {
        this.state = "canceled";
        const release = await this._mutex.acquire();
        const promises = this._tracks.map((x) => x.source._flushOrWaitForOngoingClose(true));
        await Promise.all(promises);
        await this._writer.close();
        release();
      })();
    }
    /**
     * Finalizes the output file. This method must be called after all media samples across all tracks have been added.
     * Once the Promise returned by this method completes, the output file is ready.
     */
    async finalize() {
      if (this.state === "pending") {
        throw new Error("Cannot finalize before starting.");
      }
      if (this.state === "canceled") {
        throw new Error("Cannot finalize after canceling.");
      }
      if (this._finalizePromise) {
        console.warn("Output has already been finalized.");
        return this._finalizePromise;
      }
      return this._finalizePromise = (async () => {
        this.state = "finalizing";
        const release = await this._mutex.acquire();
        const promises = this._tracks.map((x) => x.source._flushOrWaitForOngoingClose(false));
        await Promise.all(promises);
        await this._muxer.finalize();
        await this._writer.flush();
        await this._writer.finalize();
        this.state = "finalized";
        release();
      })();
    }
  };

  // src/source.ts
  var Source = class {
    constructor() {
      /** @internal */
      this._sizePromise = null;
      /** Called each time data is requested from the source. */
      this.onread = null;
    }
    /**
     * Resolves with the total size of the file in bytes. This function is memoized, meaning only the first call
     * will retrieve the size.
     */
    getSize() {
      return this._sizePromise ??= this._retrieveSize();
    }
  };
  var BufferSource = class extends Source {
    constructor(buffer) {
      if (!(buffer instanceof ArrayBuffer) && !(buffer instanceof Uint8Array)) {
        throw new TypeError("buffer must be an ArrayBuffer or Uint8Array.");
      }
      super();
      this._bytes = buffer instanceof Uint8Array ? buffer : new Uint8Array(buffer);
    }
    /** @internal */
    async _read(start, end) {
      return this._bytes.subarray(start, end);
    }
    /** @internal */
    async _retrieveSize() {
      return this._bytes.byteLength;
    }
  };
  var StreamSource = class extends Source {
    constructor(options) {
      if (!options || typeof options !== "object") {
        throw new TypeError("options must be an object.");
      }
      if (typeof options.read !== "function") {
        throw new TypeError("options.read must be a function.");
      }
      if (typeof options.getSize !== "function") {
        throw new TypeError("options.getSize must be a function.");
      }
      super();
      this._options = options;
    }
    /** @internal */
    async _read(start, end) {
      return this._options.read(start, end);
    }
    /** @internal */
    async _retrieveSize() {
      return this._options.getSize();
    }
  };
  var BlobSource = class extends Source {
    constructor(blob) {
      if (!(blob instanceof Blob)) {
        throw new TypeError("blob must be a Blob.");
      }
      super();
      this._blob = blob;
    }
    /** @internal */
    async _read(start, end) {
      const slice = this._blob.slice(start, end);
      const buffer = await slice.arrayBuffer();
      return new Uint8Array(buffer);
    }
    /** @internal */
    async _retrieveSize() {
      return this._blob.size;
    }
  };
  var UrlSource = class extends Source {
    constructor(url2, options = {}) {
      if (typeof url2 !== "string" && !(url2 instanceof URL)) {
        throw new TypeError("url must be a string or URL.");
      }
      if (!options || typeof options !== "object") {
        throw new TypeError("options must be an object.");
      }
      if (options.requestInit !== void 0 && (!options.requestInit || typeof options.requestInit !== "object")) {
        throw new TypeError("options.requestInit, when provided, must be an object.");
      }
      if (options.getRetryDelay !== void 0 && typeof options.getRetryDelay !== "function") {
        throw new TypeError("options.getRetryDelay, when provided, must be a function.");
      }
      super();
      /** @internal */
      this._fullData = null;
      this._url = url2;
      this._options = options;
    }
    /** @internal */
    async _makeRequest(range) {
      const headers = {};
      if (range) {
        headers["Range"] = `bytes=${range.start}-${range.end - 1}`;
      }
      const response = await retriedFetch(
        this._url,
        mergeObjectsDeeply(this._options.requestInit ?? {}, {
          method: "GET",
          headers
        }),
        this._options.getRetryDelay ?? (() => null)
      );
      if (!response.ok) {
        throw new Error(`Error fetching ${this._url}: ${response.status} ${response.statusText}`);
      }
      const buffer = await response.arrayBuffer();
      if (response.status === 200) {
        this._fullData = buffer;
      }
      return {
        response: buffer,
        statusCode: response.status
      };
    }
    /** @internal */
    async _read(start, end) {
      if (this._fullData) {
        return new Uint8Array(this._fullData, start, end - start);
      }
      const { response, statusCode } = await this._makeRequest({ start, end });
      if (statusCode === 200) {
        const fullData = new Uint8Array(response);
        return fullData.subarray(start, end);
      }
      return new Uint8Array(response);
    }
    /** @internal */
    async _retrieveSize() {
      if (this._fullData) {
        return this._fullData.byteLength;
      }
      try {
        const headResponse = await retriedFetch(
          this._url,
          mergeObjectsDeeply(this._options.requestInit ?? {}, {
            method: "HEAD"
          }),
          this._options.getRetryDelay ?? (() => null)
        );
        if (headResponse.ok) {
          const contentLength = headResponse.headers.get("Content-Length");
          if (contentLength) {
            return parseInt(contentLength);
          }
        }
      } catch {
      }
      const rangeResponse = await retriedFetch(
        this._url,
        mergeObjectsDeeply(this._options.requestInit ?? {}, {
          method: "GET",
          headers: { Range: "bytes=0-0" }
        }),
        this._options.getRetryDelay ?? (() => null)
      );
      if (rangeResponse.status === 206) {
        const contentRange = rangeResponse.headers.get("Content-Range");
        if (contentRange) {
          const match = contentRange.match(/bytes \d+-\d+\/(\d+)/);
          if (match && match[1]) {
            return parseInt(match[1]);
          }
        }
      } else if (rangeResponse.status === 200) {
        this._fullData = await rangeResponse.arrayBuffer();
        return this._fullData.byteLength;
      }
      const { response } = await this._makeRequest();
      return response.byteLength;
    }
  };

  // src/isobmff/isobmff-demuxer.ts
  var IsobmffDemuxer = class extends Demuxer {
    constructor(input) {
      super(input);
      this.currentTrack = null;
      this.tracks = [];
      this.metadataPromise = null;
      this.movieTimescale = -1;
      this.movieDurationInTimescale = -1;
      this.isQuickTime = false;
      this.isFragmented = false;
      this.fragmentTrackDefaults = [];
      this.fragments = [];
      this.currentFragment = null;
      this.fragmentLookupMutex = new AsyncMutex();
      this.metadataReader = new IsobmffReader(input._mainReader);
      this.chunkReader = new IsobmffReader(new Reader(input.source, 64 * 2 ** 20));
    }
    async computeDuration() {
      const tracks = await this.getTracks();
      const trackDurations = await Promise.all(tracks.map((x) => x.computeDuration()));
      return Math.max(0, ...trackDurations);
    }
    async getTracks() {
      await this.readMetadata();
      return this.tracks.map((track) => track.inputTrack);
    }
    async getMimeType() {
      await this.readMetadata();
      const codecStrings = await Promise.all(this.tracks.map((x) => x.inputTrack.getCodecParameterString()));
      return buildIsobmffMimeType({
        isQuickTime: this.isQuickTime,
        hasVideo: this.tracks.some((x) => x.info?.type === "video"),
        hasAudio: this.tracks.some((x) => x.info?.type === "audio"),
        codecStrings: codecStrings.filter(Boolean)
      });
    }
    readMetadata() {
      return this.metadataPromise ??= (async () => {
        const sourceSize = await this.metadataReader.reader.source.getSize();
        while (this.metadataReader.pos < sourceSize) {
          await this.metadataReader.reader.loadRange(
            this.metadataReader.pos,
            this.metadataReader.pos + MAX_BOX_HEADER_SIZE
          );
          const startPos = this.metadataReader.pos;
          const boxInfo = this.metadataReader.readBoxHeader();
          if (boxInfo.name === "ftyp") {
            const majorBrand = this.metadataReader.readAscii(4);
            this.isQuickTime = majorBrand === "qt  ";
          } else if (boxInfo.name === "moov") {
            await this.metadataReader.reader.loadRange(
              this.metadataReader.pos,
              this.metadataReader.pos + boxInfo.contentSize
            );
            this.readContiguousBoxes(boxInfo.contentSize);
            for (const track of this.tracks) {
              const previousSegmentDurationsInSeconds = track.editListPreviousSegmentDurations / this.movieTimescale;
              track.editListOffset -= Math.round(previousSegmentDurationsInSeconds * track.timescale);
            }
            break;
          }
          this.metadataReader.pos = startPos + boxInfo.totalSize;
        }
        if (this.isFragmented) {
          await this.metadataReader.reader.loadRange(sourceSize - 4, sourceSize);
          this.metadataReader.pos = sourceSize - 4;
          const lastWord = this.metadataReader.readU32();
          const potentialMfraPos = sourceSize - lastWord;
          if (potentialMfraPos >= 0 && potentialMfraPos < sourceSize) {
            await this.metadataReader.reader.loadRange(potentialMfraPos, sourceSize);
            this.metadataReader.pos = potentialMfraPos;
            const boxInfo = this.metadataReader.readBoxHeader();
            if (boxInfo.name === "mfra") {
              this.readContiguousBoxes(boxInfo.contentSize);
            }
          }
        }
      })();
    }
    getSampleTableForTrack(internalTrack) {
      if (internalTrack.sampleTable) {
        return internalTrack.sampleTable;
      }
      const sampleTable = {
        sampleTimingEntries: [],
        sampleCompositionTimeOffsets: [],
        sampleSizes: [],
        keySampleIndices: null,
        chunkOffsets: [],
        sampleToChunk: [],
        presentationTimestamps: null,
        presentationTimestampIndexMap: null
      };
      internalTrack.sampleTable = sampleTable;
      this.metadataReader.pos = internalTrack.sampleTableByteOffset;
      this.currentTrack = internalTrack;
      this.traverseBox();
      this.currentTrack = null;
      const isPcmCodec = internalTrack.info?.type === "audio" && internalTrack.info.codec && PCM_AUDIO_CODECS.includes(internalTrack.info.codec);
      if (isPcmCodec && sampleTable.sampleCompositionTimeOffsets.length === 0) {
        assert(internalTrack.info?.type === "audio");
        const pcmInfo = parsePcmCodec(internalTrack.info.codec);
        const newSampleTimingEntries = [];
        const newSampleSizes = [];
        for (let i = 0; i < sampleTable.sampleToChunk.length; i++) {
          const chunkEntry = sampleTable.sampleToChunk[i];
          const nextEntry = sampleTable.sampleToChunk[i + 1];
          const chunkCount = (nextEntry ? nextEntry.startChunkIndex : sampleTable.chunkOffsets.length) - chunkEntry.startChunkIndex;
          for (let j = 0; j < chunkCount; j++) {
            const startSampleIndex = chunkEntry.startSampleIndex + j * chunkEntry.samplesPerChunk;
            const endSampleIndex = startSampleIndex + chunkEntry.samplesPerChunk;
            const startTimingEntryIndex = binarySearchLessOrEqual(
              sampleTable.sampleTimingEntries,
              startSampleIndex,
              (x) => x.startIndex
            );
            const startTimingEntry = sampleTable.sampleTimingEntries[startTimingEntryIndex];
            const endTimingEntryIndex = binarySearchLessOrEqual(
              sampleTable.sampleTimingEntries,
              endSampleIndex,
              (x) => x.startIndex
            );
            const endTimingEntry = sampleTable.sampleTimingEntries[endTimingEntryIndex];
            const firstSampleTimestamp = startTimingEntry.startDecodeTimestamp + (startSampleIndex - startTimingEntry.startIndex) * startTimingEntry.delta;
            const lastSampleTimestamp = endTimingEntry.startDecodeTimestamp + (endSampleIndex - endTimingEntry.startIndex) * endTimingEntry.delta;
            const delta = lastSampleTimestamp - firstSampleTimestamp;
            const lastSampleTimingEntry = last(newSampleTimingEntries);
            if (lastSampleTimingEntry && lastSampleTimingEntry.delta === delta) {
              lastSampleTimingEntry.count++;
            } else {
              newSampleTimingEntries.push({
                startIndex: chunkEntry.startChunkIndex + j,
                startDecodeTimestamp: firstSampleTimestamp,
                count: 1,
                delta
              });
            }
            const chunkSize = chunkEntry.samplesPerChunk * pcmInfo.sampleSize * internalTrack.info.numberOfChannels;
            newSampleSizes.push(chunkSize);
          }
          chunkEntry.startSampleIndex = chunkEntry.startChunkIndex;
          chunkEntry.samplesPerChunk = 1;
        }
        sampleTable.sampleTimingEntries = newSampleTimingEntries;
        sampleTable.sampleSizes = newSampleSizes;
      }
      if (sampleTable.sampleCompositionTimeOffsets.length > 0) {
        sampleTable.presentationTimestamps = [];
        for (const entry of sampleTable.sampleTimingEntries) {
          for (let i = 0; i < entry.count; i++) {
            sampleTable.presentationTimestamps.push({
              presentationTimestamp: entry.startDecodeTimestamp + i * entry.delta,
              sampleIndex: entry.startIndex + i
            });
          }
        }
        for (const entry of sampleTable.sampleCompositionTimeOffsets) {
          for (let i = 0; i < entry.count; i++) {
            const sampleIndex = entry.startIndex + i;
            const sample = sampleTable.presentationTimestamps[sampleIndex];
            if (!sample) {
              continue;
            }
            sample.presentationTimestamp += entry.offset;
          }
        }
        sampleTable.presentationTimestamps.sort((a, b) => a.presentationTimestamp - b.presentationTimestamp);
        sampleTable.presentationTimestampIndexMap = Array(sampleTable.presentationTimestamps.length).fill(-1);
        for (let i = 0; i < sampleTable.presentationTimestamps.length; i++) {
          sampleTable.presentationTimestampIndexMap[sampleTable.presentationTimestamps[i].sampleIndex] = i;
        }
      } else {
      }
      return sampleTable;
    }
    async readFragment() {
      const startPos = this.metadataReader.pos;
      await this.metadataReader.reader.loadRange(
        this.metadataReader.pos,
        this.metadataReader.pos + MAX_BOX_HEADER_SIZE
      );
      const moofBoxInfo = this.metadataReader.readBoxHeader();
      assert(moofBoxInfo.name === "moof");
      const contentStart = this.metadataReader.pos;
      await this.metadataReader.reader.loadRange(contentStart, contentStart + moofBoxInfo.contentSize);
      this.metadataReader.pos = startPos;
      this.traverseBox();
      const index = binarySearchExact(this.fragments, startPos, (x) => x.moofOffset);
      assert(index !== -1);
      const fragment = this.fragments[index];
      assert(fragment.moofOffset === startPos);
      this.metadataReader.reader.forgetRange(contentStart, contentStart + moofBoxInfo.contentSize);
      for (const [trackId, trackData] of fragment.trackData) {
        if (trackData.startTimestampIsFinal) {
          continue;
        }
        const internalTrack = this.tracks.find((x) => x.id === trackId);
        this.metadataReader.pos = 0;
        let currentFragment = null;
        let lastFragment = null;
        const index2 = binarySearchLessOrEqual(
          internalTrack.fragments,
          startPos - 1,
          (x) => x.moofOffset
        );
        if (index2 !== -1) {
          currentFragment = internalTrack.fragments[index2];
          lastFragment = currentFragment;
          this.metadataReader.pos = currentFragment.moofOffset + currentFragment.moofSize;
        }
        let nextFragmentIsFirstFragment = this.metadataReader.pos === 0;
        while (this.metadataReader.pos < startPos) {
          if (currentFragment?.nextFragment) {
            currentFragment = currentFragment.nextFragment;
            this.metadataReader.pos = currentFragment.moofOffset + currentFragment.moofSize;
          } else {
            await this.metadataReader.reader.loadRange(
              this.metadataReader.pos,
              this.metadataReader.pos + MAX_BOX_HEADER_SIZE
            );
            const startPos2 = this.metadataReader.pos;
            const boxInfo = this.metadataReader.readBoxHeader();
            if (boxInfo.name === "moof") {
              const index3 = binarySearchExact(this.fragments, startPos2, (x) => x.moofOffset);
              let fragment2;
              if (index3 === -1) {
                this.metadataReader.pos = startPos2;
                fragment2 = await this.readFragment();
              } else {
                fragment2 = this.fragments[index3];
              }
              if (currentFragment) currentFragment.nextFragment = fragment2;
              currentFragment = fragment2;
              if (nextFragmentIsFirstFragment) {
                fragment2.isKnownToBeFirstFragment = true;
                nextFragmentIsFirstFragment = false;
              }
            }
            this.metadataReader.pos = startPos2 + boxInfo.totalSize;
          }
          if (currentFragment && currentFragment.trackData.has(trackId)) {
            lastFragment = currentFragment;
          }
        }
        if (lastFragment) {
          const otherTrackData = lastFragment.trackData.get(trackId);
          assert(otherTrackData.startTimestampIsFinal);
          offsetFragmentTrackDataByTimestamp(trackData, otherTrackData.endTimestamp);
        }
        trackData.startTimestampIsFinal = true;
      }
      return fragment;
    }
    readContiguousBoxes(totalSize) {
      const startIndex = this.metadataReader.pos;
      while (this.metadataReader.pos - startIndex <= totalSize - MIN_BOX_HEADER_SIZE) {
        this.traverseBox();
      }
    }
    traverseBox() {
      const startPos = this.metadataReader.pos;
      const boxInfo = this.metadataReader.readBoxHeader();
      const boxEndPos = startPos + boxInfo.totalSize;
      switch (boxInfo.name) {
        case "mdia":
        case "minf":
        case "dinf":
        case "mfra":
        case "edts":
          {
            this.readContiguousBoxes(boxInfo.contentSize);
          }
          ;
          break;
        case "mvhd":
          {
            const version = this.metadataReader.readU8();
            this.metadataReader.pos += 3;
            if (version === 1) {
              this.metadataReader.pos += 8 + 8;
              this.movieTimescale = this.metadataReader.readU32();
              this.movieDurationInTimescale = this.metadataReader.readU64();
            } else {
              this.metadataReader.pos += 4 + 4;
              this.movieTimescale = this.metadataReader.readU32();
              this.movieDurationInTimescale = this.metadataReader.readU32();
            }
          }
          ;
          break;
        case "trak":
          {
            const track = {
              id: -1,
              demuxer: this,
              inputTrack: null,
              info: null,
              timescale: -1,
              durationInMovieTimescale: -1,
              durationInMediaTimescale: -1,
              rotation: 0,
              languageCode: UNDETERMINED_LANGUAGE,
              sampleTableByteOffset: -1,
              sampleTable: null,
              fragmentLookupTable: null,
              currentFragmentState: null,
              fragments: [],
              fragmentsWithKeyFrame: [],
              editListPreviousSegmentDurations: 0,
              editListOffset: 0
            };
            this.currentTrack = track;
            this.readContiguousBoxes(boxInfo.contentSize);
            if (track.id !== -1 && track.timescale !== -1 && track.info !== null) {
              if (track.info.type === "video" && track.info.width !== -1) {
                const videoTrack = track;
                track.inputTrack = new InputVideoTrack(new IsobmffVideoTrackBacking(videoTrack));
                this.tracks.push(track);
              } else if (track.info.type === "audio" && track.info.numberOfChannels !== -1) {
                const audioTrack = track;
                track.inputTrack = new InputAudioTrack(new IsobmffAudioTrackBacking(audioTrack));
                this.tracks.push(track);
              }
            }
            this.currentTrack = null;
          }
          ;
          break;
        case "tkhd":
          {
            const track = this.currentTrack;
            assert(track);
            const version = this.metadataReader.readU8();
            const flags = this.metadataReader.readU24();
            const trackEnabled = (flags & 1) !== 0;
            if (!trackEnabled) {
              break;
            }
            if (version === 0) {
              this.metadataReader.pos += 8;
              track.id = this.metadataReader.readU32();
              this.metadataReader.pos += 4;
              track.durationInMovieTimescale = this.metadataReader.readU32();
            } else if (version === 1) {
              this.metadataReader.pos += 16;
              track.id = this.metadataReader.readU32();
              this.metadataReader.pos += 4;
              track.durationInMovieTimescale = this.metadataReader.readU64();
            } else {
              throw new Error(`Incorrect track header version ${version}.`);
            }
            this.metadataReader.pos += 2 * 4 + 2 + 2 + 2 + 2;
            const matrix = [
              this.metadataReader.readFixed_16_16(),
              this.metadataReader.readFixed_16_16(),
              this.metadataReader.readFixed_2_30(),
              this.metadataReader.readFixed_16_16(),
              this.metadataReader.readFixed_16_16(),
              this.metadataReader.readFixed_2_30(),
              this.metadataReader.readFixed_16_16(),
              this.metadataReader.readFixed_16_16(),
              this.metadataReader.readFixed_2_30()
            ];
            const rotation = normalizeRotation(roundToMultiple(extractRotationFromMatrix(matrix), 90));
            assert(rotation === 0 || rotation === 90 || rotation === 180 || rotation === 270);
            track.rotation = rotation;
          }
          ;
          break;
        case "elst":
          {
            const track = this.currentTrack;
            assert(track);
            const version = this.metadataReader.readU8();
            this.metadataReader.pos += 3;
            let relevantEntryFound = false;
            let previousSegmentDurations = 0;
            const entryCount = this.metadataReader.readU32();
            for (let i = 0; i < entryCount; i++) {
              const segmentDuration = version === 1 ? this.metadataReader.readU64() : this.metadataReader.readU32();
              const mediaTime = version === 1 ? this.metadataReader.readI64() : this.metadataReader.readI32();
              const mediaRate = this.metadataReader.readFixed_16_16();
              if (segmentDuration === 0) {
                continue;
              }
              if (relevantEntryFound) {
                console.warn(
                  "Unsupported edit list: multiple edits are not currently supported. Only using first edit."
                );
                break;
              }
              if (mediaTime === -1) {
                previousSegmentDurations += segmentDuration;
                continue;
              }
              if (mediaRate !== 1) {
                console.warn("Unsupported edit list entry: media rate must be 1.");
                break;
              }
              track.editListPreviousSegmentDurations = previousSegmentDurations;
              track.editListOffset = mediaTime;
              relevantEntryFound = true;
            }
          }
          ;
          break;
        case "mdhd":
          {
            const track = this.currentTrack;
            assert(track);
            const version = this.metadataReader.readU8();
            this.metadataReader.pos += 3;
            if (version === 0) {
              this.metadataReader.pos += 8;
              track.timescale = this.metadataReader.readU32();
              track.durationInMediaTimescale = this.metadataReader.readU32();
            } else if (version === 1) {
              this.metadataReader.pos += 16;
              track.timescale = this.metadataReader.readU32();
              track.durationInMediaTimescale = this.metadataReader.readU64();
            }
            let language = this.metadataReader.readU16();
            if (language > 0) {
              track.languageCode = "";
              for (let i = 0; i < 3; i++) {
                track.languageCode = String.fromCharCode(96 + (language & 31)) + track.languageCode;
                language >>= 5;
              }
              if (!isIso639Dash2LanguageCode(track.languageCode)) {
                track.languageCode = UNDETERMINED_LANGUAGE;
              }
            }
          }
          ;
          break;
        case "hdlr":
          {
            const track = this.currentTrack;
            assert(track);
            this.metadataReader.pos += 8;
            const handlerType = this.metadataReader.readAscii(4);
            if (handlerType === "vide") {
              track.info = {
                type: "video",
                width: -1,
                height: -1,
                codec: null,
                codecDescription: null,
                colorSpace: null,
                avcCodecInfo: null,
                hevcCodecInfo: null,
                vp9CodecInfo: null,
                av1CodecInfo: null
              };
            } else if (handlerType === "soun") {
              track.info = {
                type: "audio",
                numberOfChannels: -1,
                sampleRate: -1,
                codec: null,
                codecDescription: null,
                aacCodecInfo: null
              };
            }
          }
          ;
          break;
        case "stbl":
          {
            const track = this.currentTrack;
            assert(track);
            track.sampleTableByteOffset = startPos;
            this.readContiguousBoxes(boxInfo.contentSize);
          }
          ;
          break;
        case "stsd":
          {
            const track = this.currentTrack;
            assert(track);
            if (track.info === null || track.sampleTable) {
              break;
            }
            const stsdVersion = this.metadataReader.readU8();
            this.metadataReader.pos += 3;
            const entries = this.metadataReader.readU32();
            for (let i = 0; i < entries; i++) {
              const startPos2 = this.metadataReader.pos;
              const sampleBoxInfo = this.metadataReader.readBoxHeader();
              const lowercaseBoxName = sampleBoxInfo.name.toLowerCase();
              if (track.info.type === "video") {
                if (lowercaseBoxName === "avc1") {
                  track.info.codec = "avc";
                } else if (lowercaseBoxName === "hvc1" || lowercaseBoxName === "hev1") {
                  track.info.codec = "hevc";
                } else if (lowercaseBoxName === "vp08") {
                  track.info.codec = "vp8";
                } else if (lowercaseBoxName === "vp09") {
                  track.info.codec = "vp9";
                } else if (lowercaseBoxName === "av01") {
                  track.info.codec = "av1";
                } else {
                  console.warn(`Unsupported video codec (sample entry type '${sampleBoxInfo.name}').`);
                }
                this.metadataReader.pos += 6 * 1 + 2 + 2 + 2 + 3 * 4;
                track.info.width = this.metadataReader.readU16();
                track.info.height = this.metadataReader.readU16();
                this.metadataReader.pos += 4 + 4 + 4 + 2 + 32 + 2 + 2;
                this.readContiguousBoxes(startPos2 + sampleBoxInfo.totalSize - this.metadataReader.pos);
              } else {
                if (lowercaseBoxName === "mp4a") {
                } else if (lowercaseBoxName === "opus") {
                  track.info.codec = "opus";
                } else if (lowercaseBoxName === "flac") {
                  track.info.codec = "flac";
                } else if (lowercaseBoxName === "twos" || lowercaseBoxName === "sowt" || lowercaseBoxName === "raw " || lowercaseBoxName === "in24" || lowercaseBoxName === "in32" || lowercaseBoxName === "fl32" || lowercaseBoxName === "fl64" || lowercaseBoxName === "lpcm" || lowercaseBoxName === "ipcm" || lowercaseBoxName === "fpcm") {
                } else if (lowercaseBoxName === "ulaw") {
                  track.info.codec = "ulaw";
                } else if (lowercaseBoxName === "alaw") {
                  track.info.codec = "alaw";
                } else {
                  console.warn(`Unsupported audio codec (sample entry type '${sampleBoxInfo.name}').`);
                }
                this.metadataReader.pos += 6 * 1 + 2;
                const version = this.metadataReader.readU16();
                this.metadataReader.pos += 3 * 2;
                let channelCount = this.metadataReader.readU16();
                let sampleSize = this.metadataReader.readU16();
                this.metadataReader.pos += 2 * 2;
                let sampleRate = this.metadataReader.readU32() / 65536;
                if (stsdVersion === 0 && version > 0) {
                  if (version === 1) {
                    this.metadataReader.pos += 4;
                    sampleSize = 8 * this.metadataReader.readU32();
                    this.metadataReader.pos += 2 * 4;
                  } else if (version === 2) {
                    this.metadataReader.pos += 4;
                    sampleRate = this.metadataReader.readF64();
                    channelCount = this.metadataReader.readU32();
                    this.metadataReader.pos += 4;
                    sampleSize = this.metadataReader.readU32();
                    const flags = this.metadataReader.readU32();
                    this.metadataReader.pos += 2 * 4;
                    if (lowercaseBoxName === "lpcm") {
                      const bytesPerSample = sampleSize + 7 >> 3;
                      const isFloat = Boolean(flags & 1);
                      const isBigEndian = Boolean(flags & 2);
                      const sFlags = flags & 4 ? -1 : 0;
                      if (sampleSize > 0 && sampleSize <= 64) {
                        if (isFloat) {
                          if (sampleSize === 32) {
                            track.info.codec = isBigEndian ? "pcm-f32be" : "pcm-f32";
                          }
                        } else {
                          if (sFlags & 1 << bytesPerSample - 1) {
                            if (bytesPerSample === 1) {
                              track.info.codec = "pcm-s8";
                            } else if (bytesPerSample === 2) {
                              track.info.codec = isBigEndian ? "pcm-s16be" : "pcm-s16";
                            } else if (bytesPerSample === 3) {
                              track.info.codec = isBigEndian ? "pcm-s24be" : "pcm-s24";
                            } else if (bytesPerSample === 4) {
                              track.info.codec = isBigEndian ? "pcm-s32be" : "pcm-s32";
                            }
                          } else {
                            if (bytesPerSample === 1) {
                              track.info.codec = "pcm-u8";
                            }
                          }
                        }
                      }
                      if (track.info.codec === null) {
                        console.warn("Unsupported PCM format.");
                      }
                    }
                  }
                }
                track.info.numberOfChannels = channelCount;
                track.info.sampleRate = sampleRate;
                if (lowercaseBoxName === "twos") {
                  if (sampleSize === 8) {
                    track.info.codec = "pcm-s8";
                  } else if (sampleSize === 16) {
                    track.info.codec = "pcm-s16be";
                  } else {
                    console.warn(`Unsupported sample size ${sampleSize} for codec 'twos'.`);
                    track.info.codec = null;
                  }
                } else if (lowercaseBoxName === "sowt") {
                  if (sampleSize === 8) {
                    track.info.codec = "pcm-s8";
                  } else if (sampleSize === 16) {
                    track.info.codec = "pcm-s16";
                  } else {
                    console.warn(`Unsupported sample size ${sampleSize} for codec 'sowt'.`);
                    track.info.codec = null;
                  }
                } else if (lowercaseBoxName === "raw ") {
                  track.info.codec = "pcm-u8";
                } else if (lowercaseBoxName === "in24") {
                  track.info.codec = "pcm-s24be";
                } else if (lowercaseBoxName === "in32") {
                  track.info.codec = "pcm-s32be";
                } else if (lowercaseBoxName === "fl32") {
                  track.info.codec = "pcm-f32be";
                } else if (lowercaseBoxName === "fl64") {
                  track.info.codec = "pcm-f64be";
                } else if (lowercaseBoxName === "ipcm") {
                  track.info.codec = "pcm-s16be";
                } else if (lowercaseBoxName === "fpcm") {
                  track.info.codec = "pcm-f32be";
                }
                this.readContiguousBoxes(startPos2 + sampleBoxInfo.totalSize - this.metadataReader.pos);
              }
            }
          }
          ;
          break;
        case "avcC":
          {
            const track = this.currentTrack;
            assert(track && track.info);
            track.info.codecDescription = this.metadataReader.readBytes(boxInfo.contentSize);
          }
          ;
          break;
        case "hvcC":
          {
            const track = this.currentTrack;
            assert(track && track.info);
            track.info.codecDescription = this.metadataReader.readBytes(boxInfo.contentSize);
          }
          ;
          break;
        case "vpcC":
          {
            const track = this.currentTrack;
            assert(track && track.info?.type === "video");
            this.metadataReader.pos += 4;
            const profile = this.metadataReader.readU8();
            const level = this.metadataReader.readU8();
            const thirdByte = this.metadataReader.readU8();
            const bitDepth = thirdByte >> 4;
            const chromaSubsampling = thirdByte >> 1 & 7;
            const videoFullRangeFlag = thirdByte & 1;
            const colourPrimaries = this.metadataReader.readU8();
            const transferCharacteristics = this.metadataReader.readU8();
            const matrixCoefficients = this.metadataReader.readU8();
            track.info.vp9CodecInfo = {
              profile,
              level,
              bitDepth,
              chromaSubsampling,
              videoFullRangeFlag,
              colourPrimaries,
              transferCharacteristics,
              matrixCoefficients
            };
          }
          ;
          break;
        case "av1C":
          {
            const track = this.currentTrack;
            assert(track && track.info?.type === "video");
            this.metadataReader.pos += 1;
            const secondByte = this.metadataReader.readU8();
            const profile = secondByte >> 5;
            const level = secondByte & 31;
            const thirdByte = this.metadataReader.readU8();
            const tier = thirdByte >> 7;
            const highBitDepth = thirdByte >> 6 & 1;
            const twelveBit = thirdByte >> 5 & 1;
            const monochrome = thirdByte >> 4 & 1;
            const chromaSubsamplingX = thirdByte >> 3 & 1;
            const chromaSubsamplingY = thirdByte >> 2 & 1;
            const chromaSamplePosition = thirdByte & 3;
            const bitDepth = profile == 2 && highBitDepth ? twelveBit ? 12 : 10 : highBitDepth ? 10 : 8;
            track.info.av1CodecInfo = {
              profile,
              level,
              tier,
              bitDepth,
              monochrome,
              chromaSubsamplingX,
              chromaSubsamplingY,
              chromaSamplePosition
            };
          }
          ;
          break;
        case "colr":
          {
            const track = this.currentTrack;
            assert(track && track.info?.type === "video");
            const colourType = this.metadataReader.readAscii(4);
            if (colourType !== "nclx") {
              break;
            }
            const colourPrimaries = this.metadataReader.readU16();
            const transferCharacteristics = this.metadataReader.readU16();
            const matrixCoefficients = this.metadataReader.readU16();
            const fullRangeFlag = Boolean(this.metadataReader.readU8() & 128);
            track.info.colorSpace = {
              primaries: COLOR_PRIMARIES_MAP_INVERSE[colourPrimaries],
              transfer: TRANSFER_CHARACTERISTICS_MAP_INVERSE[transferCharacteristics],
              matrix: MATRIX_COEFFICIENTS_MAP_INVERSE[matrixCoefficients],
              fullRange: fullRangeFlag
            };
          }
          ;
          break;
        case "wave":
          {
            this.readContiguousBoxes(boxInfo.contentSize);
          }
          ;
          break;
        case "esds":
          {
            const track = this.currentTrack;
            assert(track && track.info?.type === "audio");
            this.metadataReader.pos += 4;
            const tag = this.metadataReader.readU8();
            assert(tag === 3);
            this.metadataReader.readIsomVariableInteger();
            this.metadataReader.pos += 2;
            const mixed = this.metadataReader.readU8();
            const streamDependenceFlag = (mixed & 128) !== 0;
            const urlFlag = (mixed & 64) !== 0;
            const ocrStreamFlag = (mixed & 32) !== 0;
            if (streamDependenceFlag) {
              this.metadataReader.pos += 2;
            }
            if (urlFlag) {
              const urlLength = this.metadataReader.readU8();
              this.metadataReader.pos += urlLength;
            }
            if (ocrStreamFlag) {
              this.metadataReader.pos += 2;
            }
            const decoderConfigTag = this.metadataReader.readU8();
            assert(decoderConfigTag === 4);
            const decoderConfigDescriptorLength = this.metadataReader.readIsomVariableInteger();
            const payloadStart = this.metadataReader.pos;
            const objectTypeIndication = this.metadataReader.readU8();
            if (objectTypeIndication === 64 || objectTypeIndication === 103) {
              track.info.codec = "aac";
              track.info.aacCodecInfo = { isMpeg2: objectTypeIndication === 103 };
            } else if (objectTypeIndication === 105 || objectTypeIndication === 107) {
              track.info.codec = "mp3";
            } else if (objectTypeIndication === 221) {
              track.info.codec = "vorbis";
            } else {
              console.warn(
                `Unsupported audio codec (objectTypeIndication ${objectTypeIndication}) - discarding track.`
              );
            }
            this.metadataReader.pos += 1 + 3 + 4 + 4;
            if (decoderConfigDescriptorLength > this.metadataReader.pos - payloadStart) {
              const decoderSpecificInfoTag = this.metadataReader.readU8();
              assert(decoderSpecificInfoTag === 5);
              const decoderSpecificInfoLength = this.metadataReader.readIsomVariableInteger();
              track.info.codecDescription = this.metadataReader.readBytes(decoderSpecificInfoLength);
              if (track.info.codec === "aac") {
                const audioSpecificConfig = parseAacAudioSpecificConfig(track.info.codecDescription);
                if (audioSpecificConfig.numberOfChannels !== null) {
                  track.info.numberOfChannels = audioSpecificConfig.numberOfChannels;
                }
                if (audioSpecificConfig.sampleRate !== null) {
                  track.info.sampleRate = audioSpecificConfig.sampleRate;
                }
              }
            }
          }
          ;
          break;
        case "enda":
          {
            const track = this.currentTrack;
            assert(track && track.info?.type === "audio");
            const littleEndian = this.metadataReader.readU16() & 255;
            if (littleEndian) {
              if (track.info.codec === "pcm-s16be") {
                track.info.codec = "pcm-s16";
              } else if (track.info.codec === "pcm-s24be") {
                track.info.codec = "pcm-s24";
              } else if (track.info.codec === "pcm-s32be") {
                track.info.codec = "pcm-s32";
              } else if (track.info.codec === "pcm-f32be") {
                track.info.codec = "pcm-f32";
              } else if (track.info.codec === "pcm-f64be") {
                track.info.codec = "pcm-f64";
              }
            }
          }
          ;
          break;
        case "pcmC":
          {
            const track = this.currentTrack;
            assert(track && track.info?.type === "audio");
            this.metadataReader.pos += 1 + 3;
            const formatFlags = this.metadataReader.readU8();
            const isLittleEndian = Boolean(formatFlags & 1);
            const pcmSampleSize = this.metadataReader.readU8();
            if (track.info.codec === "pcm-s16be") {
              if (isLittleEndian) {
                if (pcmSampleSize === 16) {
                  track.info.codec = "pcm-s16";
                } else if (pcmSampleSize === 24) {
                  track.info.codec = "pcm-s24";
                } else if (pcmSampleSize === 32) {
                  track.info.codec = "pcm-s32";
                } else {
                  console.warn(`Invalid ipcm sample size ${pcmSampleSize}.`);
                  track.info.codec = null;
                }
              } else {
                if (pcmSampleSize === 16) {
                  track.info.codec = "pcm-s16be";
                } else if (pcmSampleSize === 24) {
                  track.info.codec = "pcm-s24be";
                } else if (pcmSampleSize === 32) {
                  track.info.codec = "pcm-s32be";
                } else {
                  console.warn(`Invalid ipcm sample size ${pcmSampleSize}.`);
                  track.info.codec = null;
                }
              }
            } else if (track.info.codec === "pcm-f32be") {
              if (isLittleEndian) {
                if (pcmSampleSize === 32) {
                  track.info.codec = "pcm-f32";
                } else if (pcmSampleSize === 64) {
                  track.info.codec = "pcm-f64";
                } else {
                  console.warn(`Invalid fpcm sample size ${pcmSampleSize}.`);
                  track.info.codec = null;
                }
              } else {
                if (pcmSampleSize === 32) {
                  track.info.codec = "pcm-f32be";
                } else if (pcmSampleSize === 64) {
                  track.info.codec = "pcm-f64be";
                } else {
                  console.warn(`Invalid fpcm sample size ${pcmSampleSize}.`);
                  track.info.codec = null;
                }
              }
            }
            break;
          }
          ;
        case "dOps":
          {
            const track = this.currentTrack;
            assert(track && track.info?.type === "audio");
            this.metadataReader.pos += 1;
            const outputChannelCount = this.metadataReader.readU8();
            const preSkip = this.metadataReader.readU16();
            const inputSampleRate = this.metadataReader.readU32();
            const outputGain = this.metadataReader.readI16();
            const channelMappingFamily = this.metadataReader.readU8();
            let channelMappingTable;
            if (channelMappingFamily !== 0) {
              channelMappingTable = this.metadataReader.readBytes(2 + outputChannelCount);
            } else {
              channelMappingTable = new Uint8Array(0);
            }
            const description = new Uint8Array(8 + 1 + 1 + 2 + 4 + 2 + 1 + channelMappingTable.byteLength);
            const view2 = new DataView(description.buffer);
            view2.setUint32(0, 1332770163, false);
            view2.setUint32(4, 1214603620, false);
            view2.setUint8(8, 1);
            view2.setUint8(9, outputChannelCount);
            view2.setUint16(10, preSkip, true);
            view2.setUint32(12, inputSampleRate, true);
            view2.setInt16(16, outputGain, true);
            view2.setUint8(18, channelMappingFamily);
            description.set(channelMappingTable, 19);
            track.info.codecDescription = description;
            track.info.numberOfChannels = outputChannelCount;
            track.info.sampleRate = inputSampleRate;
          }
          ;
          break;
        case "dfLa":
          {
            const track = this.currentTrack;
            assert(track && track.info?.type === "audio");
            this.metadataReader.pos += 4;
            const BLOCK_TYPE_MASK = 127;
            const LAST_METADATA_BLOCK_FLAG_MASK = 128;
            const startPos2 = this.metadataReader.pos;
            while (this.metadataReader.pos < boxEndPos) {
              const flagAndType = this.metadataReader.readU8();
              const metadataBlockLength = this.metadataReader.readU24();
              const type = flagAndType & BLOCK_TYPE_MASK;
              if (type === 0) {
                this.metadataReader.pos += 10;
                const word = this.metadataReader.readU32();
                const sampleRate = word >>> 12;
                const numberOfChannels = (word >> 9 & 7) + 1;
                track.info.sampleRate = sampleRate;
                track.info.numberOfChannels = numberOfChannels;
                this.metadataReader.pos += 20;
              } else {
                this.metadataReader.pos += metadataBlockLength;
              }
              if (flagAndType & LAST_METADATA_BLOCK_FLAG_MASK) {
                break;
              }
            }
            const endPos = this.metadataReader.pos;
            this.metadataReader.pos = startPos2;
            const bytes2 = this.metadataReader.readBytes(endPos - startPos2);
            const description = new Uint8Array(4 + bytes2.byteLength);
            const view2 = new DataView(description.buffer);
            view2.setUint32(0, 1716281667, false);
            description.set(bytes2, 4);
            track.info.codecDescription = description;
          }
          ;
          break;
        case "stts":
          {
            const track = this.currentTrack;
            assert(track);
            if (!track.sampleTable) {
              break;
            }
            this.metadataReader.pos += 4;
            const entryCount = this.metadataReader.readU32();
            let currentIndex = 0;
            let currentTimestamp = 0;
            for (let i = 0; i < entryCount; i++) {
              const sampleCount = this.metadataReader.readU32();
              const sampleDelta = this.metadataReader.readU32();
              track.sampleTable.sampleTimingEntries.push({
                startIndex: currentIndex,
                startDecodeTimestamp: currentTimestamp,
                count: sampleCount,
                delta: sampleDelta
              });
              currentIndex += sampleCount;
              currentTimestamp += sampleCount * sampleDelta;
            }
          }
          ;
          break;
        case "ctts":
          {
            const track = this.currentTrack;
            assert(track);
            if (!track.sampleTable) {
              break;
            }
            this.metadataReader.pos += 1 + 3;
            const entryCount = this.metadataReader.readU32();
            let sampleIndex = 0;
            for (let i = 0; i < entryCount; i++) {
              const sampleCount = this.metadataReader.readU32();
              const sampleOffset = this.metadataReader.readI32();
              track.sampleTable.sampleCompositionTimeOffsets.push({
                startIndex: sampleIndex,
                count: sampleCount,
                offset: sampleOffset
              });
              sampleIndex += sampleCount;
            }
          }
          ;
          break;
        case "stsz":
          {
            const track = this.currentTrack;
            assert(track);
            if (!track.sampleTable) {
              break;
            }
            this.metadataReader.pos += 4;
            const sampleSize = this.metadataReader.readU32();
            const sampleCount = this.metadataReader.readU32();
            if (sampleSize === 0) {
              for (let i = 0; i < sampleCount; i++) {
                const sampleSize2 = this.metadataReader.readU32();
                track.sampleTable.sampleSizes.push(sampleSize2);
              }
            } else {
              track.sampleTable.sampleSizes.push(sampleSize);
            }
          }
          ;
          break;
        case "stz2":
          {
            const track = this.currentTrack;
            assert(track);
            if (!track.sampleTable) {
              break;
            }
            this.metadataReader.pos += 4;
            this.metadataReader.pos += 3;
            const fieldSize = this.metadataReader.readU8();
            const sampleCount = this.metadataReader.readU32();
            const bytes2 = this.metadataReader.readBytes(Math.ceil(sampleCount * fieldSize / 8));
            const bitstream = new Bitstream(bytes2);
            for (let i = 0; i < sampleCount; i++) {
              const sampleSize = bitstream.readBits(fieldSize);
              track.sampleTable.sampleSizes.push(sampleSize);
            }
          }
          ;
          break;
        case "stss":
          {
            const track = this.currentTrack;
            assert(track);
            if (!track.sampleTable) {
              break;
            }
            this.metadataReader.pos += 4;
            track.sampleTable.keySampleIndices = [];
            const entryCount = this.metadataReader.readU32();
            for (let i = 0; i < entryCount; i++) {
              const sampleIndex = this.metadataReader.readU32() - 1;
              track.sampleTable.keySampleIndices.push(sampleIndex);
            }
          }
          ;
          break;
        case "stsc":
          {
            const track = this.currentTrack;
            assert(track);
            if (!track.sampleTable) {
              break;
            }
            this.metadataReader.pos += 4;
            const entryCount = this.metadataReader.readU32();
            for (let i = 0; i < entryCount; i++) {
              const startChunkIndex = this.metadataReader.readU32() - 1;
              const samplesPerChunk = this.metadataReader.readU32();
              const sampleDescriptionIndex = this.metadataReader.readU32();
              track.sampleTable.sampleToChunk.push({
                startSampleIndex: -1,
                startChunkIndex,
                samplesPerChunk,
                sampleDescriptionIndex
              });
            }
            let startSampleIndex = 0;
            for (let i = 0; i < track.sampleTable.sampleToChunk.length; i++) {
              track.sampleTable.sampleToChunk[i].startSampleIndex = startSampleIndex;
              if (i < track.sampleTable.sampleToChunk.length - 1) {
                const nextChunk = track.sampleTable.sampleToChunk[i + 1];
                const chunkCount = nextChunk.startChunkIndex - track.sampleTable.sampleToChunk[i].startChunkIndex;
                startSampleIndex += chunkCount * track.sampleTable.sampleToChunk[i].samplesPerChunk;
              }
            }
          }
          ;
          break;
        case "stco":
          {
            const track = this.currentTrack;
            assert(track);
            if (!track.sampleTable) {
              break;
            }
            this.metadataReader.pos += 4;
            const entryCount = this.metadataReader.readU32();
            for (let i = 0; i < entryCount; i++) {
              const chunkOffset = this.metadataReader.readU32();
              track.sampleTable.chunkOffsets.push(chunkOffset);
            }
          }
          ;
          break;
        case "co64":
          {
            const track = this.currentTrack;
            assert(track);
            if (!track.sampleTable) {
              break;
            }
            this.metadataReader.pos += 4;
            const entryCount = this.metadataReader.readU32();
            for (let i = 0; i < entryCount; i++) {
              const chunkOffset = this.metadataReader.readU64();
              track.sampleTable.chunkOffsets.push(chunkOffset);
            }
          }
          ;
          break;
        case "mvex":
          {
            this.isFragmented = true;
            this.readContiguousBoxes(boxInfo.contentSize);
          }
          ;
          break;
        case "mehd":
          {
            const version = this.metadataReader.readU8();
            this.metadataReader.pos += 3;
            const fragmentDuration = version === 1 ? this.metadataReader.readU64() : this.metadataReader.readU32();
            this.movieDurationInTimescale = fragmentDuration;
          }
          ;
          break;
        case "trex":
          {
            this.metadataReader.pos += 4;
            const trackId = this.metadataReader.readU32();
            const defaultSampleDescriptionIndex = this.metadataReader.readU32();
            const defaultSampleDuration = this.metadataReader.readU32();
            const defaultSampleSize = this.metadataReader.readU32();
            const defaultSampleFlags = this.metadataReader.readU32();
            this.fragmentTrackDefaults.push({
              trackId,
              defaultSampleDescriptionIndex,
              defaultSampleDuration,
              defaultSampleSize,
              defaultSampleFlags
            });
          }
          ;
          break;
        case "tfra":
          {
            const version = this.metadataReader.readU8();
            this.metadataReader.pos += 3;
            const trackId = this.metadataReader.readU32();
            const track = this.tracks.find((x2) => x2.id === trackId);
            if (!track) {
              break;
            }
            track.fragmentLookupTable = [];
            const word = this.metadataReader.readU32();
            const lengthSizeOfTrafNum = (word & 48) >> 4;
            const lengthSizeOfTrunNum = (word & 12) >> 2;
            const lengthSizeOfSampleNum = word & 3;
            const x = this.metadataReader;
            const functions = [x.readU8.bind(x), x.readU16.bind(x), x.readU24.bind(x), x.readU32.bind(x)];
            const readTrafNum = functions[lengthSizeOfTrafNum];
            const readTrunNum = functions[lengthSizeOfTrunNum];
            const readSampleNum = functions[lengthSizeOfSampleNum];
            const numberOfEntries = this.metadataReader.readU32();
            for (let i = 0; i < numberOfEntries; i++) {
              const time = version === 1 ? this.metadataReader.readU64() : this.metadataReader.readU32();
              const moofOffset = version === 1 ? this.metadataReader.readU64() : this.metadataReader.readU32();
              const trafNumber = readTrafNum();
              const trunNumber = readTrunNum();
              const sampleNumber = readSampleNum();
              track.fragmentLookupTable.push({
                timestamp: time,
                moofOffset
              });
            }
          }
          ;
          break;
        case "moof":
          {
            this.currentFragment = {
              moofOffset: startPos,
              moofSize: boxInfo.totalSize,
              implicitBaseDataOffset: startPos,
              trackData: /* @__PURE__ */ new Map(),
              dataStart: Infinity,
              dataEnd: 0,
              nextFragment: null,
              isKnownToBeFirstFragment: false
            };
            this.readContiguousBoxes(boxInfo.contentSize);
            insertSorted(this.fragments, this.currentFragment, (x) => x.moofOffset);
            for (const [, trackData] of this.currentFragment.trackData) {
              const firstSample = trackData.samples[0];
              const lastSample = last(trackData.samples);
              this.currentFragment.dataStart = Math.min(
                this.currentFragment.dataStart,
                firstSample.byteOffset
              );
              this.currentFragment.dataEnd = Math.max(
                this.currentFragment.dataEnd,
                lastSample.byteOffset + lastSample.byteSize
              );
            }
            this.currentFragment = null;
          }
          ;
          break;
        case "traf":
          {
            assert(this.currentFragment);
            this.readContiguousBoxes(boxInfo.contentSize);
            if (this.currentTrack) {
              const trackData = this.currentFragment.trackData.get(this.currentTrack.id);
              if (trackData) {
                insertSorted(this.currentTrack.fragments, this.currentFragment, (x) => x.moofOffset);
                const hasKeyFrame = trackData.firstKeyFrameTimestamp !== null;
                if (hasKeyFrame) {
                  insertSorted(
                    this.currentTrack.fragmentsWithKeyFrame,
                    this.currentFragment,
                    (x) => x.moofOffset
                  );
                }
                const { currentFragmentState } = this.currentTrack;
                assert(currentFragmentState);
                if (currentFragmentState.startTimestamp !== null) {
                  offsetFragmentTrackDataByTimestamp(trackData, currentFragmentState.startTimestamp);
                  trackData.startTimestampIsFinal = true;
                }
              }
              this.currentTrack.currentFragmentState = null;
              this.currentTrack = null;
            }
          }
          ;
          break;
        case "tfhd":
          {
            assert(this.currentFragment);
            this.metadataReader.pos += 1;
            const flags = this.metadataReader.readU24();
            const baseDataOffsetPresent = Boolean(flags & 1);
            const sampleDescriptionIndexPresent = Boolean(flags & 2);
            const defaultSampleDurationPresent = Boolean(flags & 8);
            const defaultSampleSizePresent = Boolean(flags & 16);
            const defaultSampleFlagsPresent = Boolean(flags & 32);
            const durationIsEmpty = Boolean(flags & 65536);
            const defaultBaseIsMoof = Boolean(flags & 131072);
            const trackId = this.metadataReader.readU32();
            const track = this.tracks.find((x) => x.id === trackId);
            if (!track) {
              break;
            }
            const defaults = this.fragmentTrackDefaults.find((x) => x.trackId === trackId);
            this.currentTrack = track;
            track.currentFragmentState = {
              baseDataOffset: this.currentFragment.implicitBaseDataOffset,
              sampleDescriptionIndex: defaults?.defaultSampleDescriptionIndex ?? null,
              defaultSampleDuration: defaults?.defaultSampleDuration ?? null,
              defaultSampleSize: defaults?.defaultSampleSize ?? null,
              defaultSampleFlags: defaults?.defaultSampleFlags ?? null,
              startTimestamp: null
            };
            if (baseDataOffsetPresent) {
              track.currentFragmentState.baseDataOffset = this.metadataReader.readU64();
            } else if (defaultBaseIsMoof) {
              track.currentFragmentState.baseDataOffset = this.currentFragment.moofOffset;
            }
            if (sampleDescriptionIndexPresent) {
              track.currentFragmentState.sampleDescriptionIndex = this.metadataReader.readU32();
            }
            if (defaultSampleDurationPresent) {
              track.currentFragmentState.defaultSampleDuration = this.metadataReader.readU32();
            }
            if (defaultSampleSizePresent) {
              track.currentFragmentState.defaultSampleSize = this.metadataReader.readU32();
            }
            if (defaultSampleFlagsPresent) {
              track.currentFragmentState.defaultSampleFlags = this.metadataReader.readU32();
            }
            if (durationIsEmpty) {
              track.currentFragmentState.defaultSampleDuration = 0;
            }
          }
          ;
          break;
        case "tfdt":
          {
            const track = this.currentTrack;
            if (!track) {
              break;
            }
            assert(track.currentFragmentState);
            const version = this.metadataReader.readU8();
            this.metadataReader.pos += 3;
            const baseMediaDecodeTime = version === 0 ? this.metadataReader.readU32() : this.metadataReader.readU64();
            track.currentFragmentState.startTimestamp = baseMediaDecodeTime;
          }
          ;
          break;
        case "trun":
          {
            const track = this.currentTrack;
            if (!track) {
              break;
            }
            assert(this.currentFragment);
            assert(track.currentFragmentState);
            if (this.currentFragment.trackData.has(track.id)) {
              console.warn("Can't have two trun boxes for the same track in one fragment. Ignoring...");
              break;
            }
            const version = this.metadataReader.readU8();
            const flags = this.metadataReader.readU24();
            const dataOffsetPresent = Boolean(flags & 1);
            const firstSampleFlagsPresent = Boolean(flags & 4);
            const sampleDurationPresent = Boolean(flags & 256);
            const sampleSizePresent = Boolean(flags & 512);
            const sampleFlagsPresent = Boolean(flags & 1024);
            const sampleCompositionTimeOffsetsPresent = Boolean(flags & 2048);
            const sampleCount = this.metadataReader.readU32();
            let dataOffset = track.currentFragmentState.baseDataOffset;
            if (dataOffsetPresent) {
              dataOffset += this.metadataReader.readI32();
            }
            let firstSampleFlags = null;
            if (firstSampleFlagsPresent) {
              firstSampleFlags = this.metadataReader.readU32();
            }
            let currentOffset = dataOffset;
            if (sampleCount === 0) {
              this.currentFragment.implicitBaseDataOffset = currentOffset;
              break;
            }
            let currentTimestamp = 0;
            const trackData = {
              startTimestamp: 0,
              endTimestamp: 0,
              firstKeyFrameTimestamp: null,
              samples: [],
              presentationTimestamps: [],
              startTimestampIsFinal: false
            };
            this.currentFragment.trackData.set(track.id, trackData);
            for (let i = 0; i < sampleCount; i++) {
              let sampleDuration;
              if (sampleDurationPresent) {
                sampleDuration = this.metadataReader.readU32();
              } else {
                assert(track.currentFragmentState.defaultSampleDuration !== null);
                sampleDuration = track.currentFragmentState.defaultSampleDuration;
              }
              let sampleSize;
              if (sampleSizePresent) {
                sampleSize = this.metadataReader.readU32();
              } else {
                assert(track.currentFragmentState.defaultSampleSize !== null);
                sampleSize = track.currentFragmentState.defaultSampleSize;
              }
              let sampleFlags;
              if (sampleFlagsPresent) {
                sampleFlags = this.metadataReader.readU32();
              } else {
                assert(track.currentFragmentState.defaultSampleFlags !== null);
                sampleFlags = track.currentFragmentState.defaultSampleFlags;
              }
              if (i === 0 && firstSampleFlags !== null) {
                sampleFlags = firstSampleFlags;
              }
              let sampleCompositionTimeOffset = 0;
              if (sampleCompositionTimeOffsetsPresent) {
                if (version === 0) {
                  sampleCompositionTimeOffset = this.metadataReader.readU32();
                } else {
                  sampleCompositionTimeOffset = this.metadataReader.readI32();
                }
              }
              const isKeyFrame = !(sampleFlags & 65536);
              trackData.samples.push({
                presentationTimestamp: currentTimestamp + sampleCompositionTimeOffset,
                duration: sampleDuration,
                byteOffset: currentOffset,
                byteSize: sampleSize,
                isKeyFrame
              });
              currentOffset += sampleSize;
              currentTimestamp += sampleDuration;
            }
            trackData.presentationTimestamps = trackData.samples.map((x, i) => ({ presentationTimestamp: x.presentationTimestamp, sampleIndex: i })).sort((a, b) => a.presentationTimestamp - b.presentationTimestamp);
            for (let i = 0; i < trackData.presentationTimestamps.length; i++) {
              const currentEntry = trackData.presentationTimestamps[i];
              const currentSample = trackData.samples[currentEntry.sampleIndex];
              if (trackData.firstKeyFrameTimestamp === null && currentSample.isKeyFrame) {
                trackData.firstKeyFrameTimestamp = currentSample.presentationTimestamp;
              }
              if (i < trackData.presentationTimestamps.length - 1) {
                const nextEntry = trackData.presentationTimestamps[i + 1];
                currentSample.duration = nextEntry.presentationTimestamp - currentEntry.presentationTimestamp;
              }
            }
            const firstSample = trackData.samples[trackData.presentationTimestamps[0].sampleIndex];
            const lastSample = trackData.samples[last(trackData.presentationTimestamps).sampleIndex];
            trackData.startTimestamp = firstSample.presentationTimestamp;
            trackData.endTimestamp = lastSample.presentationTimestamp + lastSample.duration;
            this.currentFragment.implicitBaseDataOffset = currentOffset;
          }
          ;
          break;
      }
      this.metadataReader.pos = boxEndPos;
    }
  };
  var IsobmffTrackBacking = class {
    constructor(internalTrack) {
      this.internalTrack = internalTrack;
      this.packetToSampleIndex = /* @__PURE__ */ new WeakMap();
      this.packetToFragmentLocation = /* @__PURE__ */ new WeakMap();
    }
    getId() {
      return this.internalTrack.id;
    }
    getCodec() {
      throw new Error("Not implemented on base class.");
    }
    getLanguageCode() {
      return this.internalTrack.languageCode;
    }
    getTimeResolution() {
      return this.internalTrack.timescale;
    }
    async computeDuration() {
      const lastPacket = await this.getPacket(Infinity, { metadataOnly: true });
      return (lastPacket?.timestamp ?? 0) + (lastPacket?.duration ?? 0);
    }
    async getFirstTimestamp() {
      const firstPacket = await this.getFirstPacket({ metadataOnly: true });
      return firstPacket?.timestamp ?? 0;
    }
    async getFirstPacket(options) {
      const regularPacket = await this.fetchPacketForSampleIndex(0, options);
      if (regularPacket || !this.internalTrack.demuxer.isFragmented) {
        return regularPacket;
      }
      return this.performFragmentedLookup(
        () => {
          const startFragment = this.internalTrack.demuxer.fragments[0] ?? null;
          if (startFragment?.isKnownToBeFirstFragment) {
            let currentFragment = startFragment;
            while (currentFragment) {
              const trackData = currentFragment.trackData.get(this.internalTrack.id);
              if (trackData) {
                return {
                  fragmentIndex: binarySearchExact(
                    this.internalTrack.fragments,
                    currentFragment.moofOffset,
                    (x) => x.moofOffset
                  ),
                  sampleIndex: 0,
                  correctSampleFound: true
                };
              }
              currentFragment = currentFragment.nextFragment;
            }
          }
          return {
            fragmentIndex: -1,
            sampleIndex: -1,
            correctSampleFound: false
          };
        },
        -Infinity,
        // Use -Infinity as a search timestamp to avoid using the lookup entries
        Infinity,
        options
      );
    }
    mapTimestampIntoTimescale(timestamp) {
      return roundToPrecision(timestamp * this.internalTrack.timescale, 14) + this.internalTrack.editListOffset;
    }
    async getPacket(timestamp, options) {
      const timestampInTimescale = this.mapTimestampIntoTimescale(timestamp);
      const sampleTable = this.internalTrack.demuxer.getSampleTableForTrack(this.internalTrack);
      const sampleIndex = getSampleIndexForTimestamp(sampleTable, timestampInTimescale);
      const regularPacket = await this.fetchPacketForSampleIndex(sampleIndex, options);
      if (!sampleTableIsEmpty(sampleTable) || !this.internalTrack.demuxer.isFragmented) {
        return regularPacket;
      }
      return this.performFragmentedLookup(
        () => this.findSampleInFragmentsForTimestamp(timestampInTimescale),
        timestampInTimescale,
        timestampInTimescale,
        options
      );
    }
    async getNextPacket(packet, options) {
      const regularSampleIndex = this.packetToSampleIndex.get(packet);
      if (regularSampleIndex !== void 0) {
        return this.fetchPacketForSampleIndex(regularSampleIndex + 1, options);
      }
      const locationInFragment = this.packetToFragmentLocation.get(packet);
      if (locationInFragment === void 0) {
        throw new Error("Packet was not created from this track.");
      }
      const trackData = locationInFragment.fragment.trackData.get(this.internalTrack.id);
      const fragmentIndex = binarySearchExact(
        this.internalTrack.fragments,
        locationInFragment.fragment.moofOffset,
        (x) => x.moofOffset
      );
      assert(fragmentIndex !== -1);
      return this.performFragmentedLookup(
        () => {
          if (locationInFragment.sampleIndex + 1 < trackData.samples.length) {
            return {
              fragmentIndex,
              sampleIndex: locationInFragment.sampleIndex + 1,
              correctSampleFound: true
            };
          } else {
            let currentFragment = locationInFragment.fragment;
            while (currentFragment.nextFragment) {
              currentFragment = currentFragment.nextFragment;
              const trackData2 = currentFragment.trackData.get(this.internalTrack.id);
              if (trackData2) {
                const fragmentIndex2 = binarySearchExact(
                  this.internalTrack.fragments,
                  currentFragment.moofOffset,
                  (x) => x.moofOffset
                );
                assert(fragmentIndex2 !== -1);
                return {
                  fragmentIndex: fragmentIndex2,
                  sampleIndex: 0,
                  correctSampleFound: true
                };
              }
            }
            return {
              fragmentIndex,
              sampleIndex: -1,
              correctSampleFound: false
            };
          }
        },
        -Infinity,
        // Use -Infinity as a search timestamp to avoid using the lookup entries
        Infinity,
        options
      );
    }
    async getKeyPacket(timestamp, options) {
      const timestampInTimescale = this.mapTimestampIntoTimescale(timestamp);
      const sampleTable = this.internalTrack.demuxer.getSampleTableForTrack(this.internalTrack);
      const sampleIndex = getSampleIndexForTimestamp(sampleTable, timestampInTimescale);
      const keyFrameSampleIndex = sampleIndex === -1 ? -1 : getRelevantKeyframeIndexForSample(sampleTable, sampleIndex);
      const regularPacket = await this.fetchPacketForSampleIndex(keyFrameSampleIndex, options);
      if (!sampleTableIsEmpty(sampleTable) || !this.internalTrack.demuxer.isFragmented) {
        return regularPacket;
      }
      return this.performFragmentedLookup(
        () => this.findKeySampleInFragmentsForTimestamp(timestampInTimescale),
        timestampInTimescale,
        timestampInTimescale,
        options
      );
    }
    async getNextKeyPacket(packet, options) {
      const regularSampleIndex = this.packetToSampleIndex.get(packet);
      if (regularSampleIndex !== void 0) {
        const sampleTable = this.internalTrack.demuxer.getSampleTableForTrack(this.internalTrack);
        const nextKeyFrameSampleIndex = getNextKeyframeIndexForSample(sampleTable, regularSampleIndex);
        return this.fetchPacketForSampleIndex(nextKeyFrameSampleIndex, options);
      }
      const locationInFragment = this.packetToFragmentLocation.get(packet);
      if (locationInFragment === void 0) {
        throw new Error("Packet was not created from this track.");
      }
      const trackData = locationInFragment.fragment.trackData.get(this.internalTrack.id);
      const fragmentIndex = binarySearchExact(
        this.internalTrack.fragments,
        locationInFragment.fragment.moofOffset,
        (x) => x.moofOffset
      );
      assert(fragmentIndex !== -1);
      return this.performFragmentedLookup(
        () => {
          const nextKeyFrameIndex = trackData.samples.findIndex(
            (x, i) => x.isKeyFrame && i > locationInFragment.sampleIndex
          );
          if (nextKeyFrameIndex !== -1) {
            return {
              fragmentIndex,
              sampleIndex: nextKeyFrameIndex,
              correctSampleFound: true
            };
          } else {
            let currentFragment = locationInFragment.fragment;
            while (currentFragment.nextFragment) {
              currentFragment = currentFragment.nextFragment;
              const trackData2 = currentFragment.trackData.get(this.internalTrack.id);
              if (trackData2 && trackData2.firstKeyFrameTimestamp !== null) {
                const fragmentIndex2 = binarySearchExact(
                  this.internalTrack.fragments,
                  currentFragment.moofOffset,
                  (x) => x.moofOffset
                );
                assert(fragmentIndex2 !== -1);
                const keyFrameIndex = trackData2.samples.findIndex((x) => x.isKeyFrame);
                assert(keyFrameIndex !== -1);
                return {
                  fragmentIndex: fragmentIndex2,
                  sampleIndex: keyFrameIndex,
                  correctSampleFound: true
                };
              }
            }
            return {
              fragmentIndex,
              sampleIndex: -1,
              correctSampleFound: false
            };
          }
        },
        -Infinity,
        // Use -Infinity as a search timestamp to avoid using the lookup entries
        Infinity,
        options
      );
    }
    async fetchPacketForSampleIndex(sampleIndex, options) {
      if (sampleIndex === -1) {
        return null;
      }
      const sampleTable = this.internalTrack.demuxer.getSampleTableForTrack(this.internalTrack);
      const sampleInfo = getSampleInfo(sampleTable, sampleIndex);
      if (!sampleInfo) {
        return null;
      }
      let data;
      if (options.metadataOnly) {
        data = PLACEHOLDER_DATA;
      } else {
        await this.internalTrack.demuxer.chunkReader.reader.loadRange(
          sampleInfo.chunkOffset,
          sampleInfo.chunkOffset + sampleInfo.chunkSize
        );
        this.internalTrack.demuxer.chunkReader.pos = sampleInfo.sampleOffset;
        data = this.internalTrack.demuxer.chunkReader.readBytes(sampleInfo.sampleSize);
      }
      const timestamp = (sampleInfo.presentationTimestamp - this.internalTrack.editListOffset) / this.internalTrack.timescale;
      const duration = sampleInfo.duration / this.internalTrack.timescale;
      const packet = new EncodedPacket(
        data,
        sampleInfo.isKeyFrame ? "key" : "delta",
        timestamp,
        duration,
        sampleIndex,
        sampleInfo.sampleSize
      );
      this.packetToSampleIndex.set(packet, sampleIndex);
      return packet;
    }
    async fetchPacketInFragment(fragment, sampleIndex, options) {
      if (sampleIndex === -1) {
        return null;
      }
      const trackData = fragment.trackData.get(this.internalTrack.id);
      const fragmentSample = trackData.samples[sampleIndex];
      assert(fragmentSample);
      let data;
      if (options.metadataOnly) {
        data = PLACEHOLDER_DATA;
      } else {
        await this.internalTrack.demuxer.chunkReader.reader.loadRange(fragment.dataStart, fragment.dataEnd);
        this.internalTrack.demuxer.chunkReader.pos = fragmentSample.byteOffset;
        data = this.internalTrack.demuxer.chunkReader.readBytes(fragmentSample.byteSize);
      }
      const timestamp = (fragmentSample.presentationTimestamp - this.internalTrack.editListOffset) / this.internalTrack.timescale;
      const duration = fragmentSample.duration / this.internalTrack.timescale;
      const packet = new EncodedPacket(
        data,
        fragmentSample.isKeyFrame ? "key" : "delta",
        timestamp,
        duration,
        fragment.moofOffset + sampleIndex,
        fragmentSample.byteSize
      );
      this.packetToFragmentLocation.set(packet, { fragment, sampleIndex });
      return packet;
    }
    findSampleInFragmentsForTimestamp(timestampInTimescale) {
      const fragmentIndex = binarySearchLessOrEqual(
        // This array is technically not sorted by start timestamp, but for any reasonable file, it basically is.
        this.internalTrack.fragments,
        timestampInTimescale,
        (x) => x.trackData.get(this.internalTrack.id).startTimestamp
      );
      let sampleIndex = -1;
      let correctSampleFound = false;
      if (fragmentIndex !== -1) {
        const fragment = this.internalTrack.fragments[fragmentIndex];
        const trackData = fragment.trackData.get(this.internalTrack.id);
        const index = binarySearchLessOrEqual(
          trackData.presentationTimestamps,
          timestampInTimescale,
          (x) => x.presentationTimestamp
        );
        assert(index !== -1);
        sampleIndex = trackData.presentationTimestamps[index].sampleIndex;
        correctSampleFound = timestampInTimescale < trackData.endTimestamp;
      }
      return { fragmentIndex, sampleIndex, correctSampleFound };
    }
    findKeySampleInFragmentsForTimestamp(timestampInTimescale) {
      const indexInKeyFrameFragments = binarySearchLessOrEqual(
        // This array is technically not sorted by start timestamp, but for any reasonable file, it basically is.
        this.internalTrack.fragmentsWithKeyFrame,
        timestampInTimescale,
        (x) => x.trackData.get(this.internalTrack.id).startTimestamp
      );
      let fragmentIndex = -1;
      let sampleIndex = -1;
      let correctSampleFound = false;
      if (indexInKeyFrameFragments !== -1) {
        const fragment = this.internalTrack.fragmentsWithKeyFrame[indexInKeyFrameFragments];
        fragmentIndex = binarySearchExact(
          this.internalTrack.fragments,
          fragment.moofOffset,
          (x) => x.moofOffset
        );
        assert(fragmentIndex !== -1);
        const trackData = fragment.trackData.get(this.internalTrack.id);
        const index = findLastIndex(trackData.presentationTimestamps, (x) => {
          const sample = trackData.samples[x.sampleIndex];
          return sample.isKeyFrame && x.presentationTimestamp <= timestampInTimescale;
        });
        assert(index !== -1);
        const entry = trackData.presentationTimestamps[index];
        sampleIndex = entry.sampleIndex;
        correctSampleFound = timestampInTimescale < trackData.endTimestamp;
      }
      return { fragmentIndex, sampleIndex, correctSampleFound };
    }
    /** Looks for a packet in the fragments while trying to load as few fragments as possible to retrieve it. */
    async performFragmentedLookup(getBestMatch, searchTimestamp, latestTimestamp, options) {
      const demuxer = this.internalTrack.demuxer;
      const release = await demuxer.fragmentLookupMutex.acquire();
      try {
        const { fragmentIndex, sampleIndex, correctSampleFound } = getBestMatch();
        if (correctSampleFound) {
          const fragment = this.internalTrack.fragments[fragmentIndex];
          return this.fetchPacketInFragment(fragment, sampleIndex, options);
        }
        const metadataReader = demuxer.metadataReader;
        const sourceSize = await metadataReader.reader.source.getSize();
        let prevFragment = null;
        let bestFragmentIndex = fragmentIndex;
        let bestSampleIndex = sampleIndex;
        const lookupEntryIndex = this.internalTrack.fragmentLookupTable ? binarySearchLessOrEqual(
          this.internalTrack.fragmentLookupTable,
          searchTimestamp,
          (x) => x.timestamp
        ) : -1;
        const lookupEntry = lookupEntryIndex !== -1 ? this.internalTrack.fragmentLookupTable[lookupEntryIndex] : null;
        let nextFragmentIsFirstFragment = false;
        if (fragmentIndex === -1) {
          metadataReader.pos = lookupEntry?.moofOffset ?? 0;
          nextFragmentIsFirstFragment = metadataReader.pos === 0;
        } else {
          const fragment = this.internalTrack.fragments[fragmentIndex];
          if (!lookupEntry || fragment.moofOffset >= lookupEntry.moofOffset) {
            metadataReader.pos = fragment.moofOffset + fragment.moofSize;
            prevFragment = fragment;
          } else {
            metadataReader.pos = lookupEntry.moofOffset;
          }
        }
        while (metadataReader.pos < sourceSize) {
          if (prevFragment) {
            const trackData = prevFragment.trackData.get(this.internalTrack.id);
            if (trackData && trackData.startTimestamp > latestTimestamp) {
              break;
            }
            if (prevFragment.nextFragment) {
              metadataReader.pos = prevFragment.nextFragment.moofOffset + prevFragment.nextFragment.moofSize;
              prevFragment = prevFragment.nextFragment;
              continue;
            }
          }
          await metadataReader.reader.loadRange(metadataReader.pos, metadataReader.pos + MAX_BOX_HEADER_SIZE);
          const startPos = metadataReader.pos;
          const boxInfo = metadataReader.readBoxHeader();
          if (boxInfo.name === "moof") {
            const index = binarySearchExact(demuxer.fragments, startPos, (x) => x.moofOffset);
            let fragment;
            if (index === -1) {
              metadataReader.pos = startPos;
              fragment = await demuxer.readFragment();
            } else {
              fragment = demuxer.fragments[index];
            }
            if (prevFragment) prevFragment.nextFragment = fragment;
            prevFragment = fragment;
            if (nextFragmentIsFirstFragment) {
              fragment.isKnownToBeFirstFragment = true;
              nextFragmentIsFirstFragment = false;
            }
            const { fragmentIndex: fragmentIndex2, sampleIndex: sampleIndex2, correctSampleFound: correctSampleFound2 } = getBestMatch();
            if (correctSampleFound2) {
              const fragment2 = this.internalTrack.fragments[fragmentIndex2];
              return this.fetchPacketInFragment(fragment2, sampleIndex2, options);
            }
            if (fragmentIndex2 !== -1) {
              bestFragmentIndex = fragmentIndex2;
              bestSampleIndex = sampleIndex2;
            }
          }
          metadataReader.pos = startPos + boxInfo.totalSize;
        }
        let result = null;
        const bestFragment = bestFragmentIndex !== -1 ? this.internalTrack.fragments[bestFragmentIndex] : null;
        if (bestFragment) {
          result = await this.fetchPacketInFragment(bestFragment, bestSampleIndex, options);
        }
        if (!result && lookupEntry && (!bestFragment || bestFragment.moofOffset < lookupEntry.moofOffset)) {
          const previousLookupEntry = this.internalTrack.fragmentLookupTable[lookupEntryIndex - 1];
          const newSearchTimestamp = previousLookupEntry?.timestamp ?? -Infinity;
          return this.performFragmentedLookup(getBestMatch, newSearchTimestamp, latestTimestamp, options);
        }
        return result;
      } finally {
        release();
      }
    }
  };
  var IsobmffVideoTrackBacking = class extends IsobmffTrackBacking {
    constructor(internalTrack) {
      super(internalTrack);
      this.decoderConfigPromise = null;
      this.internalTrack = internalTrack;
    }
    getCodec() {
      return this.internalTrack.info.codec;
    }
    getCodedWidth() {
      return this.internalTrack.info.width;
    }
    getCodedHeight() {
      return this.internalTrack.info.height;
    }
    getRotation() {
      return this.internalTrack.rotation;
    }
    async getColorSpace() {
      return {
        primaries: this.internalTrack.info.colorSpace?.primaries,
        transfer: this.internalTrack.info.colorSpace?.transfer,
        matrix: this.internalTrack.info.colorSpace?.matrix,
        fullRange: this.internalTrack.info.colorSpace?.fullRange
      };
    }
    async getDecoderConfig() {
      if (!this.internalTrack.info.codec) {
        return null;
      }
      return this.decoderConfigPromise ??= (async () => {
        if (this.internalTrack.info.codec === "vp9" && !this.internalTrack.info.vp9CodecInfo) {
          const firstPacket = await this.getFirstPacket({});
          this.internalTrack.info.vp9CodecInfo = firstPacket && extractVp9CodecInfoFromPacket(firstPacket.data);
        } else if (this.internalTrack.info.codec === "av1" && !this.internalTrack.info.av1CodecInfo) {
          const firstPacket = await this.getFirstPacket({});
          this.internalTrack.info.av1CodecInfo = firstPacket && extractAv1CodecInfoFromPacket(firstPacket.data);
        }
        return {
          codec: extractVideoCodecString(this.internalTrack.info),
          codedWidth: this.internalTrack.info.width,
          codedHeight: this.internalTrack.info.height,
          description: this.internalTrack.info.codecDescription ?? void 0,
          colorSpace: this.internalTrack.info.colorSpace ?? void 0
        };
      })();
    }
  };
  var IsobmffAudioTrackBacking = class extends IsobmffTrackBacking {
    constructor(internalTrack) {
      super(internalTrack);
      this.decoderConfig = null;
      this.internalTrack = internalTrack;
    }
    getCodec() {
      return this.internalTrack.info.codec;
    }
    getNumberOfChannels() {
      return this.internalTrack.info.numberOfChannels;
    }
    getSampleRate() {
      return this.internalTrack.info.sampleRate;
    }
    async getDecoderConfig() {
      if (!this.internalTrack.info.codec) {
        return null;
      }
      return this.decoderConfig ??= {
        codec: extractAudioCodecString(this.internalTrack.info),
        numberOfChannels: this.internalTrack.info.numberOfChannels,
        sampleRate: this.internalTrack.info.sampleRate,
        description: this.internalTrack.info.codecDescription ?? void 0
      };
    }
  };
  var getSampleIndexForTimestamp = (sampleTable, timescaleUnits) => {
    if (sampleTable.presentationTimestamps) {
      const index = binarySearchLessOrEqual(
        sampleTable.presentationTimestamps,
        timescaleUnits,
        (x) => x.presentationTimestamp
      );
      if (index === -1) {
        return -1;
      }
      return sampleTable.presentationTimestamps[index].sampleIndex;
    } else {
      const index = binarySearchLessOrEqual(
        sampleTable.sampleTimingEntries,
        timescaleUnits,
        (x) => x.startDecodeTimestamp
      );
      if (index === -1) {
        return -1;
      }
      const entry = sampleTable.sampleTimingEntries[index];
      return entry.startIndex + Math.min(Math.floor((timescaleUnits - entry.startDecodeTimestamp) / entry.delta), entry.count - 1);
    }
  };
  var getSampleInfo = (sampleTable, sampleIndex) => {
    const timingEntryIndex = binarySearchLessOrEqual(sampleTable.sampleTimingEntries, sampleIndex, (x) => x.startIndex);
    const timingEntry = sampleTable.sampleTimingEntries[timingEntryIndex];
    if (!timingEntry || timingEntry.startIndex + timingEntry.count <= sampleIndex) {
      return null;
    }
    const decodeTimestamp = timingEntry.startDecodeTimestamp + (sampleIndex - timingEntry.startIndex) * timingEntry.delta;
    let presentationTimestamp = decodeTimestamp;
    const offsetEntryIndex = binarySearchLessOrEqual(
      sampleTable.sampleCompositionTimeOffsets,
      sampleIndex,
      (x) => x.startIndex
    );
    const offsetEntry = sampleTable.sampleCompositionTimeOffsets[offsetEntryIndex];
    if (offsetEntry && sampleIndex - offsetEntry.startIndex < offsetEntry.count) {
      presentationTimestamp += offsetEntry.offset;
    }
    const sampleSize = sampleTable.sampleSizes[Math.min(sampleIndex, sampleTable.sampleSizes.length - 1)];
    const chunkEntryIndex = binarySearchLessOrEqual(sampleTable.sampleToChunk, sampleIndex, (x) => x.startSampleIndex);
    const chunkEntry = sampleTable.sampleToChunk[chunkEntryIndex];
    assert(chunkEntry);
    const chunkIndex = chunkEntry.startChunkIndex + Math.floor((sampleIndex - chunkEntry.startSampleIndex) / chunkEntry.samplesPerChunk);
    const chunkOffset = sampleTable.chunkOffsets[chunkIndex];
    const startSampleIndexOfChunk = chunkEntry.startSampleIndex + (chunkIndex - chunkEntry.startChunkIndex) * chunkEntry.samplesPerChunk;
    let chunkSize = 0;
    let sampleOffset = chunkOffset;
    if (sampleTable.sampleSizes.length === 1) {
      sampleOffset += sampleSize * (sampleIndex - startSampleIndexOfChunk);
      chunkSize += sampleSize * chunkEntry.samplesPerChunk;
    } else {
      for (let i = startSampleIndexOfChunk; i < startSampleIndexOfChunk + chunkEntry.samplesPerChunk; i++) {
        const sampleSize2 = sampleTable.sampleSizes[i];
        if (i < sampleIndex) {
          sampleOffset += sampleSize2;
        }
        chunkSize += sampleSize2;
      }
    }
    let duration = timingEntry.delta;
    if (sampleTable.presentationTimestamps) {
      const presentationIndex = sampleTable.presentationTimestampIndexMap[sampleIndex];
      assert(presentationIndex !== void 0);
      if (presentationIndex < sampleTable.presentationTimestamps.length - 1) {
        const nextEntry = sampleTable.presentationTimestamps[presentationIndex + 1];
        const nextPresentationTimestamp = nextEntry.presentationTimestamp;
        duration = nextPresentationTimestamp - presentationTimestamp;
      }
    }
    return {
      presentationTimestamp,
      duration,
      sampleOffset,
      sampleSize,
      chunkOffset,
      chunkSize,
      isKeyFrame: sampleTable.keySampleIndices ? binarySearchExact(sampleTable.keySampleIndices, sampleIndex, (x) => x) !== -1 : true
    };
  };
  var getRelevantKeyframeIndexForSample = (sampleTable, sampleIndex) => {
    if (!sampleTable.keySampleIndices) {
      return sampleIndex;
    }
    const index = binarySearchLessOrEqual(sampleTable.keySampleIndices, sampleIndex, (x) => x);
    return sampleTable.keySampleIndices[index] ?? -1;
  };
  var getNextKeyframeIndexForSample = (sampleTable, sampleIndex) => {
    if (!sampleTable.keySampleIndices) {
      return sampleIndex + 1;
    }
    const index = binarySearchLessOrEqual(sampleTable.keySampleIndices, sampleIndex, (x) => x);
    return sampleTable.keySampleIndices[index + 1] ?? -1;
  };
  var offsetFragmentTrackDataByTimestamp = (trackData, timestamp) => {
    trackData.startTimestamp += timestamp;
    trackData.endTimestamp += timestamp;
    for (const sample of trackData.samples) {
      sample.presentationTimestamp += timestamp;
    }
    for (const entry of trackData.presentationTimestamps) {
      entry.presentationTimestamp += timestamp;
    }
  };
  var extractRotationFromMatrix = (matrix) => {
    const [m11, , , m21] = matrix;
    const scaleX = Math.hypot(m11, m21);
    const cosTheta = m11 / scaleX;
    const sinTheta = m21 / scaleX;
    return -Math.atan2(sinTheta, cosTheta) * (180 / Math.PI);
  };
  var sampleTableIsEmpty = (sampleTable) => {
    return sampleTable.sampleSizes.length === 0;
  };

  // src/matroska/matroska-demuxer.ts
  var METADATA_ELEMENTS = [
    { id: 290298740 /* SeekHead */, flag: "seekHeadSeen" },
    { id: 357149030 /* Info */, flag: "infoSeen" },
    { id: 374648427 /* Tracks */, flag: "tracksSeen" },
    { id: 475249515 /* Cues */, flag: "cuesSeen" }
  ];
  var MatroskaDemuxer = class extends Demuxer {
    constructor(input) {
      super(input);
      this.readMetadataPromise = null;
      this.segments = [];
      this.currentSegment = null;
      this.currentTrack = null;
      this.currentCluster = null;
      this.currentBlock = null;
      this.currentCueTime = null;
      this.isWebM = false;
      this.metadataReader = new EBMLReader(input._mainReader);
      this.clusterReader = new EBMLReader(new Reader(input.source, 64 * 2 ** 20));
    }
    async computeDuration() {
      const tracks = await this.getTracks();
      const trackDurations = await Promise.all(tracks.map((x) => x.computeDuration()));
      return Math.max(0, ...trackDurations);
    }
    async getTracks() {
      await this.readMetadata();
      return this.segments.flatMap((segment) => segment.tracks.map((track) => track.inputTrack));
    }
    async getMimeType() {
      await this.readMetadata();
      const tracks = await this.getTracks();
      const codecStrings = await Promise.all(tracks.map((x) => x.getCodecParameterString()));
      return buildMatroskaMimeType({
        isWebM: this.isWebM,
        hasVideo: this.segments.some((segment) => segment.tracks.some((x) => x.info?.type === "video")),
        hasAudio: this.segments.some((segment) => segment.tracks.some((x) => x.info?.type === "audio")),
        codecStrings: codecStrings.filter(Boolean)
      });
    }
    readMetadata() {
      return this.readMetadataPromise ??= (async () => {
        this.metadataReader.pos = 0;
        const fileSize = await this.input.source.getSize();
        while (this.metadataReader.pos <= fileSize - MIN_HEADER_SIZE) {
          await this.metadataReader.reader.loadRange(
            this.metadataReader.pos,
            this.metadataReader.pos + MAX_HEADER_SIZE
          );
          const header = this.metadataReader.readElementHeader();
          const id = header.id;
          let size = header.size;
          const startPos = this.metadataReader.pos;
          if (id === 440786851 /* EBML */) {
            assertDefinedSize(size);
            await this.metadataReader.reader.loadRange(this.metadataReader.pos, this.metadataReader.pos + size);
            this.readContiguousElements(this.metadataReader, size);
          } else if (id === 408125543 /* Segment */) {
            await this.readSegment(size);
            if (size === null) {
              break;
            }
          } else if (id === 524531317 /* Cluster */) {
            if (size === null) {
              const nextElementPos = await this.clusterReader.searchForNextElementId(
                LEVEL_0_AND_1_EBML_IDS,
                fileSize
              );
              size = (nextElementPos ?? fileSize) - startPos;
            }
            const lastSegment = last(this.segments);
            if (lastSegment) {
              lastSegment.elementEndPos = startPos + size;
            }
          }
          assertDefinedSize(size);
          this.metadataReader.pos = startPos + size;
        }
      })();
    }
    async readSegment(dataSize) {
      const segmentDataStart = this.metadataReader.pos;
      this.currentSegment = {
        seekHeadSeen: false,
        infoSeen: false,
        tracksSeen: false,
        cuesSeen: false,
        timestampScale: -1,
        timestampFactor: -1,
        duration: -1,
        seekEntries: [],
        tracks: [],
        cuePoints: [],
        dataStartPos: segmentDataStart,
        elementEndPos: dataSize === null ? await this.input.source.getSize() : segmentDataStart + dataSize,
        clusterSeekStartPos: segmentDataStart,
        clusters: [],
        clusterLookupMutex: new AsyncMutex()
      };
      this.segments.push(this.currentSegment);
      await this.metadataReader.reader.loadRange(
        this.metadataReader.pos,
        this.metadataReader.pos + 2 ** 14
      );
      let clusterEncountered = false;
      while (this.metadataReader.pos < this.currentSegment.elementEndPos) {
        await this.metadataReader.reader.loadRange(
          this.metadataReader.pos,
          this.metadataReader.pos + MAX_HEADER_SIZE
        );
        const elementStartPos = this.metadataReader.pos;
        const { id, size } = this.metadataReader.readElementHeader();
        const dataStartPos = this.metadataReader.pos;
        const metadataElementIndex = METADATA_ELEMENTS.findIndex((x) => x.id === id);
        if (metadataElementIndex !== -1) {
          const field = METADATA_ELEMENTS[metadataElementIndex].flag;
          this.currentSegment[field] = true;
          assertDefinedSize(size);
          await this.metadataReader.reader.loadRange(this.metadataReader.pos, this.metadataReader.pos + size);
          this.readContiguousElements(this.metadataReader, size);
        } else if (id === 524531317 /* Cluster */) {
          if (!clusterEncountered) {
            clusterEncountered = true;
            this.currentSegment.clusterSeekStartPos = elementStartPos;
          }
        }
        if (this.currentSegment.infoSeen && this.currentSegment.tracksSeen && this.currentSegment.cuesSeen) {
          break;
        }
        if (this.currentSegment.seekHeadSeen) {
          let hasInfo = this.currentSegment.infoSeen;
          let hasTracks = this.currentSegment.tracksSeen;
          let hasCues = this.currentSegment.cuesSeen;
          for (const entry of this.currentSegment.seekEntries) {
            if (entry.id === 357149030 /* Info */) {
              hasInfo = true;
            } else if (entry.id === 374648427 /* Tracks */) {
              hasTracks = true;
            } else if (entry.id === 475249515 /* Cues */) {
              hasCues = true;
            }
          }
          if (hasInfo && hasTracks && hasCues) {
            break;
          }
        }
        if (size === null) {
          break;
        }
        this.metadataReader.pos = dataStartPos + size;
        if (!clusterEncountered) {
          this.currentSegment.clusterSeekStartPos = this.metadataReader.pos;
        }
      }
      for (const target of METADATA_ELEMENTS) {
        if (this.currentSegment[target.flag]) continue;
        const seekEntry = this.currentSegment.seekEntries.find((entry) => entry.id === target.id);
        if (!seekEntry) continue;
        this.metadataReader.pos = segmentDataStart + seekEntry.segmentPosition;
        await this.metadataReader.reader.loadRange(
          this.metadataReader.pos,
          this.metadataReader.pos + 2 ** 12
          // Load a larger range, assuming the correct element will be there
        );
        const { id, size } = this.metadataReader.readElementHeader();
        if (id !== target.id) continue;
        assertDefinedSize(size);
        this.currentSegment[target.flag] = true;
        await this.metadataReader.reader.loadRange(this.metadataReader.pos, this.metadataReader.pos + size);
        this.readContiguousElements(this.metadataReader, size);
      }
      if (this.currentSegment.timestampScale === -1) {
        this.currentSegment.timestampScale = 1e6;
        this.currentSegment.timestampFactor = 1e9 / 1e6;
      }
      this.currentSegment.tracks.sort((a, b) => Number(b.isDefault) - Number(a.isDefault));
      this.currentSegment.cuePoints.sort((a, b) => a.clusterPosition - b.clusterPosition);
      const allTrackIds = this.currentSegment.tracks.map((x) => x.id);
      const remainingTrackIds = /* @__PURE__ */ new Set();
      let lastClusterPosition = null;
      let lastCuePoint = null;
      for (const cuePoint of this.currentSegment.cuePoints) {
        if (cuePoint.clusterPosition !== lastClusterPosition) {
          for (const id of remainingTrackIds) {
            assert(lastCuePoint);
            const track2 = this.currentSegment.tracks.find((x) => x.id === id);
            track2.cuePoints.push(lastCuePoint);
          }
          for (const id of allTrackIds) {
            remainingTrackIds.add(id);
          }
        }
        lastCuePoint = cuePoint;
        if (!remainingTrackIds.has(cuePoint.trackId)) {
          continue;
        }
        const track = this.currentSegment.tracks.find((x) => x.id === cuePoint.trackId);
        track.cuePoints.push(cuePoint);
        remainingTrackIds.delete(cuePoint.trackId);
        lastClusterPosition = cuePoint.clusterPosition;
      }
      for (const id of remainingTrackIds) {
        assert(lastCuePoint);
        const track = this.currentSegment.tracks.find((x) => x.id === id);
        track.cuePoints.push(lastCuePoint);
      }
      for (const track of this.currentSegment.tracks) {
        track.cuePoints.sort((a, b) => a.time - b.time);
      }
      this.currentSegment = null;
    }
    async readCluster(segment) {
      await this.metadataReader.reader.loadRange(this.metadataReader.pos, this.metadataReader.pos + MAX_HEADER_SIZE);
      const elementStartPos = this.metadataReader.pos;
      const elementHeader = this.metadataReader.readElementHeader();
      const id = elementHeader.id;
      let size = elementHeader.size;
      const dataStartPos = this.metadataReader.pos;
      if (size === null) {
        this.clusterReader.pos = dataStartPos;
        const nextElementPos = await this.clusterReader.searchForNextElementId(
          LEVEL_0_AND_1_EBML_IDS,
          segment.elementEndPos
        );
        size = (nextElementPos ?? segment.elementEndPos) - dataStartPos;
      }
      assert(id === 524531317 /* Cluster */);
      this.clusterReader.pos = dataStartPos;
      await this.clusterReader.reader.loadRange(this.clusterReader.pos, this.clusterReader.pos + size);
      const cluster = {
        elementStartPos,
        elementEndPos: dataStartPos + size,
        dataStartPos,
        timestamp: -1,
        trackData: /* @__PURE__ */ new Map(),
        nextCluster: null,
        isKnownToBeFirstCluster: false
      };
      this.currentCluster = cluster;
      this.readContiguousElements(this.clusterReader, size);
      for (const [trackId, trackData] of cluster.trackData) {
        const track = segment.tracks.find((x) => x.id === trackId) ?? null;
        assert(trackData.blocks.length > 0);
        let blockReferencesExist = false;
        let hasLacedBlocks = false;
        for (let i = 0; i < trackData.blocks.length; i++) {
          const block = trackData.blocks[i];
          block.timestamp += cluster.timestamp;
          blockReferencesExist ||= block.referencedTimestamps.length > 0;
          hasLacedBlocks ||= block.lacing !== 0 /* None */;
        }
        if (blockReferencesExist) {
          trackData.blocks = sortBlocksByReferences(trackData.blocks);
        }
        trackData.presentationTimestamps = trackData.blocks.map((block, i) => ({ timestamp: block.timestamp, blockIndex: i })).sort((a, b) => a.timestamp - b.timestamp);
        for (let i = 0; i < trackData.presentationTimestamps.length; i++) {
          const currentEntry = trackData.presentationTimestamps[i];
          const currentBlock = trackData.blocks[currentEntry.blockIndex];
          if (trackData.firstKeyFrameTimestamp === null && currentBlock.isKeyFrame) {
            trackData.firstKeyFrameTimestamp = currentBlock.timestamp;
          }
          if (i < trackData.presentationTimestamps.length - 1) {
            const nextEntry = trackData.presentationTimestamps[i + 1];
            currentBlock.duration = nextEntry.timestamp - currentBlock.timestamp;
          } else if (currentBlock.duration === 0) {
            if (track?.defaultDuration != null) {
              if (currentBlock.lacing === 0 /* None */) {
                currentBlock.duration = track.defaultDuration;
              } else {
              }
            }
          }
        }
        if (hasLacedBlocks) {
          this.expandLacedBlocks(trackData.blocks, track);
          trackData.presentationTimestamps = trackData.blocks.map((block, i) => ({ timestamp: block.timestamp, blockIndex: i })).sort((a, b) => a.timestamp - b.timestamp);
        }
        const firstBlock = trackData.blocks[trackData.presentationTimestamps[0].blockIndex];
        const lastBlock = trackData.blocks[last(trackData.presentationTimestamps).blockIndex];
        trackData.startTimestamp = firstBlock.timestamp;
        trackData.endTimestamp = lastBlock.timestamp + lastBlock.duration;
        if (track) {
          insertSorted(track.clusters, cluster, (x) => x.elementStartPos);
          const hasKeyFrame = trackData.firstKeyFrameTimestamp !== null;
          if (hasKeyFrame) {
            insertSorted(track.clustersWithKeyFrame, cluster, (x) => x.elementStartPos);
          }
        }
      }
      insertSorted(segment.clusters, cluster, (x) => x.elementStartPos);
      this.currentCluster = null;
      return cluster;
    }
    getTrackDataInCluster(cluster, trackNumber) {
      let trackData = cluster.trackData.get(trackNumber);
      if (!trackData) {
        trackData = {
          startTimestamp: 0,
          endTimestamp: 0,
          firstKeyFrameTimestamp: null,
          blocks: [],
          presentationTimestamps: []
        };
        cluster.trackData.set(trackNumber, trackData);
      }
      return trackData;
    }
    expandLacedBlocks(blocks, track) {
      for (let blockIndex = 0; blockIndex < blocks.length; blockIndex++) {
        const originalBlock = blocks[blockIndex];
        if (originalBlock.lacing === 0 /* None */) {
          continue;
        }
        const data = originalBlock.data;
        let pos = 0;
        const frameSizes = [];
        const frameCount = data[pos] + 1;
        pos++;
        switch (originalBlock.lacing) {
          case 1 /* Xiph */:
            {
              let totalUsedSize = 0;
              for (let i = 0; i < frameCount - 1; i++) {
                let frameSize = 0;
                while (pos < data.length) {
                  const value = data[pos];
                  frameSize += value;
                  pos++;
                  if (value < 255) {
                    frameSizes.push(frameSize);
                    totalUsedSize += frameSize;
                    break;
                  }
                }
              }
              frameSizes.push(data.length - (pos + totalUsedSize));
            }
            ;
            break;
          case 2 /* FixedSize */:
            {
              const totalDataSize = data.length - 1;
              const frameSize = Math.floor(totalDataSize / frameCount);
              for (let i = 0; i < frameCount; i++) {
                frameSizes.push(frameSize);
              }
            }
            ;
            break;
          case 3 /* Ebml */:
            {
              const firstResult = readVarInt(data, pos);
              let currentSize = firstResult.value;
              frameSizes.push(currentSize);
              pos += firstResult.width;
              let totalUsedSize = currentSize;
              for (let i = 1; i < frameCount - 1; i++) {
                const diffResult = readVarInt(data, pos);
                const unsignedDiff = diffResult.value;
                const bias = (1 << diffResult.width * 7 - 1) - 1;
                const diff = unsignedDiff - bias;
                currentSize += diff;
                frameSizes.push(currentSize);
                pos += diffResult.width;
                totalUsedSize += currentSize;
              }
              frameSizes.push(data.length - (pos + totalUsedSize));
            }
            ;
            break;
          default:
            assert(false);
        }
        assert(frameSizes.length === frameCount);
        blocks.splice(blockIndex, 1);
        let dataOffset = pos;
        for (let i = 0; i < frameCount; i++) {
          const frameSize = frameSizes[i];
          const frameData = data.subarray(dataOffset, dataOffset + frameSize);
          const blockDuration = originalBlock.duration || frameCount * (track?.defaultDuration ?? 0);
          const frameTimestamp = originalBlock.timestamp + blockDuration * i / frameCount;
          const frameDuration = blockDuration / frameCount;
          blocks.splice(blockIndex + i, 0, {
            timestamp: frameTimestamp,
            duration: frameDuration,
            isKeyFrame: originalBlock.isKeyFrame,
            referencedTimestamps: originalBlock.referencedTimestamps,
            data: frameData,
            lacing: 0 /* None */
          });
          dataOffset += frameSize;
        }
        blockIndex += frameCount;
        blockIndex--;
      }
    }
    readContiguousElements(reader, totalSize) {
      const startIndex = reader.pos;
      while (reader.pos - startIndex <= totalSize - MIN_HEADER_SIZE) {
        this.traverseElement(reader);
      }
    }
    traverseElement(reader) {
      const { id, size } = reader.readElementHeader();
      const dataStartPos = reader.pos;
      assertDefinedSize(size);
      switch (id) {
        case 17026 /* DocType */:
          {
            this.isWebM = reader.readString(size) === "webm";
          }
          ;
          break;
        case 19899 /* Seek */:
          {
            if (!this.currentSegment) break;
            const seekEntry = { id: -1, segmentPosition: -1 };
            this.currentSegment.seekEntries.push(seekEntry);
            this.readContiguousElements(reader, size);
            if (seekEntry.id === -1 || seekEntry.segmentPosition === -1) {
              this.currentSegment.seekEntries.pop();
            }
          }
          ;
          break;
        case 21419 /* SeekID */:
          {
            const lastSeekEntry = this.currentSegment?.seekEntries[this.currentSegment.seekEntries.length - 1];
            if (!lastSeekEntry) break;
            lastSeekEntry.id = reader.readUnsignedInt(size);
          }
          ;
          break;
        case 21420 /* SeekPosition */:
          {
            const lastSeekEntry = this.currentSegment?.seekEntries[this.currentSegment.seekEntries.length - 1];
            if (!lastSeekEntry) break;
            lastSeekEntry.segmentPosition = reader.readUnsignedInt(size);
          }
          ;
          break;
        case 2807729 /* TimestampScale */:
          {
            if (!this.currentSegment) break;
            this.currentSegment.timestampScale = reader.readUnsignedInt(size);
            this.currentSegment.timestampFactor = 1e9 / this.currentSegment.timestampScale;
          }
          ;
          break;
        case 17545 /* Duration */:
          {
            if (!this.currentSegment) break;
            this.currentSegment.duration = reader.readFloat(size);
          }
          ;
          break;
        case 174 /* TrackEntry */:
          {
            if (!this.currentSegment) break;
            this.currentTrack = {
              id: -1,
              segment: this.currentSegment,
              demuxer: this,
              clusters: [],
              clustersWithKeyFrame: [],
              cuePoints: [],
              isDefault: false,
              inputTrack: null,
              codecId: null,
              codecPrivate: null,
              defaultDuration: null,
              languageCode: UNDETERMINED_LANGUAGE,
              info: null
            };
            this.readContiguousElements(reader, size);
            if (this.currentTrack && this.currentTrack.id !== -1 && this.currentTrack.codecId && this.currentTrack.info) {
              const slashIndex = this.currentTrack.codecId.indexOf("/");
              const codecIdWithoutSuffix = slashIndex === -1 ? this.currentTrack.codecId : this.currentTrack.codecId.slice(0, slashIndex);
              if (this.currentTrack.info.type === "video" && this.currentTrack.info.width !== -1 && this.currentTrack.info.height !== -1) {
                if (this.currentTrack.codecId === CODEC_STRING_MAP.avc) {
                  this.currentTrack.info.codec = "avc";
                  this.currentTrack.info.codecDescription = this.currentTrack.codecPrivate;
                } else if (this.currentTrack.codecId === CODEC_STRING_MAP.hevc) {
                  this.currentTrack.info.codec = "hevc";
                  this.currentTrack.info.codecDescription = this.currentTrack.codecPrivate;
                } else if (codecIdWithoutSuffix === CODEC_STRING_MAP.vp8) {
                  this.currentTrack.info.codec = "vp8";
                } else if (codecIdWithoutSuffix === CODEC_STRING_MAP.vp9) {
                  this.currentTrack.info.codec = "vp9";
                } else if (codecIdWithoutSuffix === CODEC_STRING_MAP.av1) {
                  this.currentTrack.info.codec = "av1";
                }
                const videoTrack = this.currentTrack;
                const inputTrack = new InputVideoTrack(new MatroskaVideoTrackBacking(videoTrack));
                this.currentTrack.inputTrack = inputTrack;
                this.currentSegment.tracks.push(this.currentTrack);
              } else if (this.currentTrack.info.type === "audio" && this.currentTrack.info.numberOfChannels !== -1 && this.currentTrack.info.sampleRate !== -1) {
                if (codecIdWithoutSuffix === CODEC_STRING_MAP.aac) {
                  this.currentTrack.info.codec = "aac";
                  this.currentTrack.info.aacCodecInfo = {
                    isMpeg2: this.currentTrack.codecId.includes("MPEG2")
                  };
                  this.currentTrack.info.codecDescription = this.currentTrack.codecPrivate;
                } else if (this.currentTrack.codecId === CODEC_STRING_MAP.mp3) {
                  this.currentTrack.info.codec = "mp3";
                } else if (codecIdWithoutSuffix === CODEC_STRING_MAP.opus) {
                  this.currentTrack.info.codec = "opus";
                  this.currentTrack.info.codecDescription = this.currentTrack.codecPrivate;
                } else if (codecIdWithoutSuffix === CODEC_STRING_MAP.vorbis) {
                  this.currentTrack.info.codec = "vorbis";
                  this.currentTrack.info.codecDescription = this.currentTrack.codecPrivate;
                } else if (codecIdWithoutSuffix === CODEC_STRING_MAP.flac) {
                  this.currentTrack.info.codec = "flac";
                  this.currentTrack.info.codecDescription = this.currentTrack.codecPrivate;
                } else if (this.currentTrack.codecId === "A_PCM/INT/LIT") {
                  if (this.currentTrack.info.bitDepth === 8) {
                    this.currentTrack.info.codec = "pcm-u8";
                  } else if (this.currentTrack.info.bitDepth === 16) {
                    this.currentTrack.info.codec = "pcm-s16";
                  } else if (this.currentTrack.info.bitDepth === 24) {
                    this.currentTrack.info.codec = "pcm-s24";
                  } else if (this.currentTrack.info.bitDepth === 32) {
                    this.currentTrack.info.codec = "pcm-s32";
                  }
                } else if (this.currentTrack.codecId === "A_PCM/INT/BIG") {
                  if (this.currentTrack.info.bitDepth === 8) {
                    this.currentTrack.info.codec = "pcm-u8";
                  } else if (this.currentTrack.info.bitDepth === 16) {
                    this.currentTrack.info.codec = "pcm-s16be";
                  } else if (this.currentTrack.info.bitDepth === 24) {
                    this.currentTrack.info.codec = "pcm-s24be";
                  } else if (this.currentTrack.info.bitDepth === 32) {
                    this.currentTrack.info.codec = "pcm-s32be";
                  }
                } else if (this.currentTrack.codecId === "A_PCM/FLOAT/IEEE") {
                  if (this.currentTrack.info.bitDepth === 32) {
                    this.currentTrack.info.codec = "pcm-f32";
                  } else if (this.currentTrack.info.bitDepth === 64) {
                    this.currentTrack.info.codec = "pcm-f64";
                  }
                }
                const audioTrack = this.currentTrack;
                const inputTrack = new InputAudioTrack(new MatroskaAudioTrackBacking(audioTrack));
                this.currentTrack.inputTrack = inputTrack;
                this.currentSegment.tracks.push(this.currentTrack);
              }
            }
            this.currentTrack = null;
          }
          ;
          break;
        case 215 /* TrackNumber */:
          {
            if (!this.currentTrack) break;
            this.currentTrack.id = reader.readUnsignedInt(size);
          }
          ;
          break;
        case 131 /* TrackType */:
          {
            if (!this.currentTrack) break;
            const type = reader.readUnsignedInt(size);
            if (type === 1) {
              this.currentTrack.info = {
                type: "video",
                width: -1,
                height: -1,
                rotation: 0,
                codec: null,
                codecDescription: null,
                colorSpace: null
              };
            } else if (type === 2) {
              this.currentTrack.info = {
                type: "audio",
                numberOfChannels: -1,
                sampleRate: -1,
                bitDepth: -1,
                codec: null,
                codecDescription: null,
                aacCodecInfo: null
              };
            }
          }
          ;
          break;
        case 185 /* FlagEnabled */:
          {
            if (!this.currentTrack) break;
            const enabled = reader.readUnsignedInt(size);
            if (!enabled) {
              this.currentSegment.tracks.pop();
              this.currentTrack = null;
            }
          }
          ;
          break;
        case 136 /* FlagDefault */:
          {
            if (!this.currentTrack) break;
            this.currentTrack.isDefault = !!reader.readUnsignedInt(size);
          }
          ;
          break;
        case 134 /* CodecID */:
          {
            if (!this.currentTrack) break;
            this.currentTrack.codecId = reader.readString(size);
          }
          ;
          break;
        case 25506 /* CodecPrivate */:
          {
            if (!this.currentTrack) break;
            this.currentTrack.codecPrivate = reader.readBytes(size);
          }
          ;
          break;
        case 2352003 /* DefaultDuration */:
          {
            if (!this.currentTrack) break;
            this.currentTrack.defaultDuration = this.currentTrack.segment.timestampFactor * reader.readUnsignedInt(size) / 1e9;
          }
          ;
          break;
        case 2274716 /* Language */:
          {
            if (!this.currentTrack) break;
            this.currentTrack.languageCode = reader.readString(size);
            if (!isIso639Dash2LanguageCode(this.currentTrack.languageCode)) {
              this.currentTrack.languageCode = UNDETERMINED_LANGUAGE;
            }
          }
          ;
          break;
        case 224 /* Video */:
          {
            if (this.currentTrack?.info?.type !== "video") break;
            this.readContiguousElements(reader, size);
          }
          ;
          break;
        case 176 /* PixelWidth */:
          {
            if (this.currentTrack?.info?.type !== "video") break;
            this.currentTrack.info.width = reader.readUnsignedInt(size);
          }
          ;
          break;
        case 186 /* PixelHeight */:
          {
            if (this.currentTrack?.info?.type !== "video") break;
            this.currentTrack.info.height = reader.readUnsignedInt(size);
          }
          ;
          break;
        case 21936 /* Colour */:
          {
            if (this.currentTrack?.info?.type !== "video") break;
            this.currentTrack.info.colorSpace = {};
            this.readContiguousElements(reader, size);
          }
          ;
          break;
        case 21937 /* MatrixCoefficients */:
          {
            if (this.currentTrack?.info?.type !== "video" || !this.currentTrack.info.colorSpace) break;
            const matrixCoefficients = reader.readUnsignedInt(size);
            const mapped = MATRIX_COEFFICIENTS_MAP_INVERSE[matrixCoefficients] ?? null;
            this.currentTrack.info.colorSpace.matrix = mapped;
          }
          ;
          break;
        case 21945 /* Range */:
          {
            if (this.currentTrack?.info?.type !== "video" || !this.currentTrack.info.colorSpace) break;
            this.currentTrack.info.colorSpace.fullRange = reader.readUnsignedInt(size) === 2;
          }
          ;
          break;
        case 21946 /* TransferCharacteristics */:
          {
            if (this.currentTrack?.info?.type !== "video" || !this.currentTrack.info.colorSpace) break;
            const transferCharacteristics = reader.readUnsignedInt(size);
            const mapped = TRANSFER_CHARACTERISTICS_MAP_INVERSE[transferCharacteristics] ?? null;
            this.currentTrack.info.colorSpace.transfer = mapped;
          }
          ;
          break;
        case 21947 /* Primaries */:
          {
            if (this.currentTrack?.info?.type !== "video" || !this.currentTrack.info.colorSpace) break;
            const primaries = reader.readUnsignedInt(size);
            const mapped = COLOR_PRIMARIES_MAP_INVERSE[primaries] ?? null;
            this.currentTrack.info.colorSpace.primaries = mapped;
          }
          ;
          break;
        case 30320 /* Projection */:
          {
            if (this.currentTrack?.info?.type !== "video") break;
            this.readContiguousElements(reader, size);
          }
          ;
          break;
        case 30325 /* ProjectionPoseRoll */:
          {
            if (this.currentTrack?.info?.type !== "video") break;
            const rotation = reader.readFloat(size);
            const flippedRotation = -rotation;
            try {
              this.currentTrack.info.rotation = normalizeRotation(flippedRotation);
            } catch {
            }
          }
          ;
          break;
        case 225 /* Audio */:
          {
            if (this.currentTrack?.info?.type !== "audio") break;
            this.readContiguousElements(reader, size);
          }
          ;
          break;
        case 181 /* SamplingFrequency */:
          {
            if (this.currentTrack?.info?.type !== "audio") break;
            this.currentTrack.info.sampleRate = reader.readFloat(size);
          }
          ;
          break;
        case 159 /* Channels */:
          {
            if (this.currentTrack?.info?.type !== "audio") break;
            this.currentTrack.info.numberOfChannels = reader.readUnsignedInt(size);
          }
          ;
          break;
        case 25188 /* BitDepth */:
          {
            if (this.currentTrack?.info?.type !== "audio") break;
            this.currentTrack.info.bitDepth = reader.readUnsignedInt(size);
          }
          ;
          break;
        case 187 /* CuePoint */:
          {
            if (!this.currentSegment) break;
            this.readContiguousElements(reader, size);
            this.currentCueTime = null;
          }
          ;
          break;
        case 179 /* CueTime */:
          {
            this.currentCueTime = reader.readUnsignedInt(size);
          }
          ;
          break;
        case 183 /* CueTrackPositions */:
          {
            if (this.currentCueTime === null) break;
            assert(this.currentSegment);
            const cuePoint = { time: this.currentCueTime, trackId: -1, clusterPosition: -1 };
            this.currentSegment.cuePoints.push(cuePoint);
            this.readContiguousElements(reader, size);
            if (cuePoint.trackId === -1 || cuePoint.clusterPosition === -1) {
              this.currentSegment.cuePoints.pop();
            }
          }
          ;
          break;
        case 247 /* CueTrack */:
          {
            const lastCuePoint = this.currentSegment?.cuePoints[this.currentSegment.cuePoints.length - 1];
            if (!lastCuePoint) break;
            lastCuePoint.trackId = reader.readUnsignedInt(size);
          }
          ;
          break;
        case 241 /* CueClusterPosition */:
          {
            const lastCuePoint = this.currentSegment?.cuePoints[this.currentSegment.cuePoints.length - 1];
            if (!lastCuePoint) break;
            assert(this.currentSegment);
            lastCuePoint.clusterPosition = this.currentSegment.dataStartPos + reader.readUnsignedInt(size);
          }
          ;
          break;
        case 231 /* Timestamp */:
          {
            if (!this.currentCluster) break;
            this.currentCluster.timestamp = reader.readUnsignedInt(size);
          }
          ;
          break;
        case 163 /* SimpleBlock */:
          {
            if (!this.currentCluster) break;
            const trackNumber = reader.readVarInt();
            const relativeTimestamp = reader.readS16();
            const flags = reader.readU8();
            const isKeyFrame = !!(flags & 128);
            const lacing = flags >> 1 & 3;
            const trackData = this.getTrackDataInCluster(this.currentCluster, trackNumber);
            trackData.blocks.push({
              timestamp: relativeTimestamp,
              // We'll add the cluster's timestamp to this later
              duration: 0,
              // Will set later
              isKeyFrame,
              referencedTimestamps: [],
              data: reader.readBytes(size - (reader.pos - dataStartPos)),
              lacing
            });
          }
          ;
          break;
        case 160 /* BlockGroup */:
          {
            if (!this.currentCluster) break;
            this.readContiguousElements(reader, size);
            if (this.currentBlock) {
              for (let i = 0; i < this.currentBlock.referencedTimestamps.length; i++) {
                this.currentBlock.referencedTimestamps[i] += this.currentBlock.timestamp;
              }
              this.currentBlock = null;
            }
          }
          ;
          break;
        case 161 /* Block */:
          {
            if (!this.currentCluster) break;
            const trackNumber = reader.readVarInt();
            const relativeTimestamp = reader.readS16();
            const flags = reader.readU8();
            const lacing = flags >> 1 & 3;
            const trackData = this.getTrackDataInCluster(this.currentCluster, trackNumber);
            this.currentBlock = {
              timestamp: relativeTimestamp,
              // We'll add the cluster's timestamp to this later
              duration: 0,
              // Will set later
              isKeyFrame: true,
              referencedTimestamps: [],
              data: reader.readBytes(size - (reader.pos - dataStartPos)),
              lacing
            };
            trackData.blocks.push(this.currentBlock);
          }
          ;
          break;
        case 155 /* BlockDuration */:
          {
            if (!this.currentBlock) break;
            this.currentBlock.duration = reader.readUnsignedInt(size);
          }
          ;
          break;
        case 251 /* ReferenceBlock */:
          {
            if (!this.currentBlock) break;
            this.currentBlock.isKeyFrame = false;
            const relativeTimestamp = reader.readSignedInt(size);
            this.currentBlock.referencedTimestamps.push(relativeTimestamp);
          }
          ;
          break;
      }
      reader.pos = dataStartPos + size;
    }
  };
  var MatroskaTrackBacking = class {
    constructor(internalTrack) {
      this.internalTrack = internalTrack;
      this.packetToClusterLocation = /* @__PURE__ */ new WeakMap();
    }
    getId() {
      return this.internalTrack.id;
    }
    getCodec() {
      throw new Error("Not implemented on base class.");
    }
    async computeDuration() {
      const lastPacket = await this.getPacket(Infinity, { metadataOnly: true });
      return (lastPacket?.timestamp ?? 0) + (lastPacket?.duration ?? 0);
    }
    getLanguageCode() {
      return this.internalTrack.languageCode;
    }
    async getFirstTimestamp() {
      const firstPacket = await this.getFirstPacket({ metadataOnly: true });
      return firstPacket?.timestamp ?? 0;
    }
    getTimeResolution() {
      return this.internalTrack.segment.timestampFactor;
    }
    async getFirstPacket(options) {
      return this.performClusterLookup(
        () => {
          const startCluster = this.internalTrack.segment.clusters[0] ?? null;
          if (startCluster?.isKnownToBeFirstCluster) {
            let currentCluster = startCluster;
            while (currentCluster) {
              const trackData = currentCluster.trackData.get(this.internalTrack.id);
              if (trackData) {
                return {
                  clusterIndex: binarySearchExact(
                    this.internalTrack.clusters,
                    currentCluster.elementStartPos,
                    (x) => x.elementStartPos
                  ),
                  blockIndex: 0,
                  correctBlockFound: true
                };
              }
              currentCluster = currentCluster.nextCluster;
            }
          }
          return {
            clusterIndex: -1,
            blockIndex: -1,
            correctBlockFound: false
          };
        },
        -Infinity,
        // Use -Infinity as a search timestamp to avoid using the cues
        Infinity,
        options
      );
    }
    intoTimescale(timestamp) {
      return roundToPrecision(timestamp * this.internalTrack.segment.timestampFactor, 14);
    }
    async getPacket(timestamp, options) {
      const timestampInTimescale = this.intoTimescale(timestamp);
      return this.performClusterLookup(
        () => this.findBlockInClustersForTimestamp(timestampInTimescale),
        timestampInTimescale,
        timestampInTimescale,
        options
      );
    }
    async getNextPacket(packet, options) {
      const locationInCluster = this.packetToClusterLocation.get(packet);
      if (locationInCluster === void 0) {
        throw new Error("Packet was not created from this track.");
      }
      const trackData = locationInCluster.cluster.trackData.get(this.internalTrack.id);
      const clusterIndex = binarySearchExact(
        this.internalTrack.clusters,
        locationInCluster.cluster.elementStartPos,
        (x) => x.elementStartPos
      );
      assert(clusterIndex !== -1);
      return this.performClusterLookup(
        () => {
          if (locationInCluster.blockIndex + 1 < trackData.blocks.length) {
            return {
              clusterIndex,
              blockIndex: locationInCluster.blockIndex + 1,
              correctBlockFound: true
            };
          } else {
            let currentCluster = locationInCluster.cluster;
            while (currentCluster.nextCluster) {
              currentCluster = currentCluster.nextCluster;
              const trackData2 = currentCluster.trackData.get(this.internalTrack.id);
              if (trackData2) {
                const clusterIndex2 = binarySearchExact(
                  this.internalTrack.clusters,
                  currentCluster.elementStartPos,
                  (x) => x.elementStartPos
                );
                assert(clusterIndex2 !== -1);
                return {
                  clusterIndex: clusterIndex2,
                  blockIndex: 0,
                  correctBlockFound: true
                };
              }
            }
            return {
              clusterIndex,
              blockIndex: -1,
              correctBlockFound: false
            };
          }
        },
        -Infinity,
        // Use -Infinity as a search timestamp to avoid using the cues
        Infinity,
        options
      );
    }
    async getKeyPacket(timestamp, options) {
      const timestampInTimescale = this.intoTimescale(timestamp);
      return this.performClusterLookup(
        () => this.findKeyBlockInClustersForTimestamp(timestampInTimescale),
        timestampInTimescale,
        timestampInTimescale,
        options
      );
    }
    async getNextKeyPacket(packet, options) {
      const locationInCluster = this.packetToClusterLocation.get(packet);
      if (locationInCluster === void 0) {
        throw new Error("Packet was not created from this track.");
      }
      const trackData = locationInCluster.cluster.trackData.get(this.internalTrack.id);
      const clusterIndex = binarySearchExact(
        this.internalTrack.clusters,
        locationInCluster.cluster.elementStartPos,
        (x) => x.elementStartPos
      );
      assert(clusterIndex !== -1);
      return this.performClusterLookup(
        () => {
          const nextKeyFrameIndex = trackData.blocks.findIndex(
            (x, i) => x.isKeyFrame && i > locationInCluster.blockIndex
          );
          if (nextKeyFrameIndex !== -1) {
            return {
              clusterIndex,
              blockIndex: nextKeyFrameIndex,
              correctBlockFound: true
            };
          } else {
            let currentCluster = locationInCluster.cluster;
            while (currentCluster.nextCluster) {
              currentCluster = currentCluster.nextCluster;
              const trackData2 = currentCluster.trackData.get(this.internalTrack.id);
              if (trackData2 && trackData2.firstKeyFrameTimestamp !== null) {
                const clusterIndex2 = binarySearchExact(
                  this.internalTrack.clusters,
                  currentCluster.elementStartPos,
                  (x) => x.elementStartPos
                );
                assert(clusterIndex2 !== -1);
                const keyFrameIndex = trackData2.blocks.findIndex((x) => x.isKeyFrame);
                assert(keyFrameIndex !== -1);
                return {
                  clusterIndex: clusterIndex2,
                  blockIndex: keyFrameIndex,
                  correctBlockFound: true
                };
              }
            }
            return {
              clusterIndex,
              blockIndex: -1,
              correctBlockFound: false
            };
          }
        },
        -Infinity,
        // Use -Infinity as a search timestamp to avoid using the cues
        Infinity,
        options
      );
    }
    async fetchPacketInCluster(cluster, blockIndex, options) {
      if (blockIndex === -1) {
        return null;
      }
      const trackData = cluster.trackData.get(this.internalTrack.id);
      const block = trackData.blocks[blockIndex];
      assert(block);
      const data = options.metadataOnly ? PLACEHOLDER_DATA : block.data;
      const timestamp = block.timestamp / this.internalTrack.segment.timestampFactor;
      const duration = block.duration / this.internalTrack.segment.timestampFactor;
      const packet = new EncodedPacket(
        data,
        block.isKeyFrame ? "key" : "delta",
        timestamp,
        duration,
        cluster.dataStartPos + blockIndex,
        block.data.byteLength
      );
      this.packetToClusterLocation.set(packet, { cluster, blockIndex });
      return packet;
    }
    findBlockInClustersForTimestamp(timestampInTimescale) {
      const clusterIndex = binarySearchLessOrEqual(
        // This array is technically not sorted by start timestamp, but for any reasonable file, it basically is.
        this.internalTrack.clusters,
        timestampInTimescale,
        (x) => x.trackData.get(this.internalTrack.id).startTimestamp
      );
      let blockIndex = -1;
      let correctBlockFound = false;
      if (clusterIndex !== -1) {
        const cluster = this.internalTrack.clusters[clusterIndex];
        const trackData = cluster.trackData.get(this.internalTrack.id);
        const index = binarySearchLessOrEqual(
          trackData.presentationTimestamps,
          timestampInTimescale,
          (x) => x.timestamp
        );
        assert(index !== -1);
        blockIndex = trackData.presentationTimestamps[index].blockIndex;
        correctBlockFound = timestampInTimescale < trackData.endTimestamp;
      }
      return { clusterIndex, blockIndex, correctBlockFound };
    }
    findKeyBlockInClustersForTimestamp(timestampInTimescale) {
      const indexInKeyFrameClusters = binarySearchLessOrEqual(
        // This array is technically not sorted by start timestamp, but for any reasonable file, it basically is.
        this.internalTrack.clustersWithKeyFrame,
        timestampInTimescale,
        (x) => x.trackData.get(this.internalTrack.id).firstKeyFrameTimestamp
      );
      let clusterIndex = -1;
      let blockIndex = -1;
      let correctBlockFound = false;
      if (indexInKeyFrameClusters !== -1) {
        const cluster = this.internalTrack.clustersWithKeyFrame[indexInKeyFrameClusters];
        clusterIndex = binarySearchExact(
          this.internalTrack.clusters,
          cluster.elementStartPos,
          (x) => x.elementStartPos
        );
        assert(clusterIndex !== -1);
        const trackData = cluster.trackData.get(this.internalTrack.id);
        const index = findLastIndex(trackData.presentationTimestamps, (x) => {
          const block = trackData.blocks[x.blockIndex];
          return block.isKeyFrame && x.timestamp <= timestampInTimescale;
        });
        assert(index !== -1);
        const entry = trackData.presentationTimestamps[index];
        blockIndex = entry.blockIndex;
        correctBlockFound = timestampInTimescale < trackData.endTimestamp;
      }
      return { clusterIndex, blockIndex, correctBlockFound };
    }
    /** Looks for a packet in the clusters while trying to load as few clusters as possible to retrieve it. */
    async performClusterLookup(getBestMatch, searchTimestamp, latestTimestamp, options) {
      const { demuxer, segment } = this.internalTrack;
      const release = await segment.clusterLookupMutex.acquire();
      try {
        const { clusterIndex, blockIndex, correctBlockFound } = getBestMatch();
        if (correctBlockFound) {
          const cluster = this.internalTrack.clusters[clusterIndex];
          return this.fetchPacketInCluster(cluster, blockIndex, options);
        }
        const metadataReader = demuxer.metadataReader;
        const clusterReader = demuxer.clusterReader;
        let prevCluster = null;
        let bestClusterIndex = clusterIndex;
        let bestBlockIndex = blockIndex;
        const cuePointIndex = binarySearchLessOrEqual(
          this.internalTrack.cuePoints,
          searchTimestamp,
          (x) => x.time
        );
        const cuePoint = cuePointIndex !== -1 ? this.internalTrack.cuePoints[cuePointIndex] : null;
        let nextClusterIsFirstCluster = false;
        if (clusterIndex === -1) {
          metadataReader.pos = cuePoint?.clusterPosition ?? segment.clusterSeekStartPos;
          nextClusterIsFirstCluster = metadataReader.pos === segment.clusterSeekStartPos;
        } else {
          const cluster = this.internalTrack.clusters[clusterIndex];
          if (!cuePoint || cluster.elementStartPos >= cuePoint.clusterPosition) {
            metadataReader.pos = cluster.elementEndPos;
            prevCluster = cluster;
          } else {
            metadataReader.pos = cuePoint.clusterPosition;
          }
        }
        while (metadataReader.pos < segment.elementEndPos) {
          if (prevCluster) {
            const trackData = prevCluster.trackData.get(this.internalTrack.id);
            if (trackData && trackData.startTimestamp > latestTimestamp) {
              break;
            }
            if (prevCluster.nextCluster) {
              metadataReader.pos = prevCluster.nextCluster.elementEndPos;
              prevCluster = prevCluster.nextCluster;
              continue;
            }
          }
          await metadataReader.reader.loadRange(metadataReader.pos, metadataReader.pos + MAX_HEADER_SIZE);
          const elementStartPos = metadataReader.pos;
          const elementHeader = metadataReader.readElementHeader();
          const id = elementHeader.id;
          let size = elementHeader.size;
          const dataStartPos = metadataReader.pos;
          if (id === 524531317 /* Cluster */) {
            const index = binarySearchExact(segment.clusters, elementStartPos, (x) => x.elementStartPos);
            let cluster;
            if (index === -1) {
              metadataReader.pos = elementStartPos;
              cluster = await demuxer.readCluster(segment);
            } else {
              cluster = segment.clusters[index];
            }
            if (prevCluster) prevCluster.nextCluster = cluster;
            prevCluster = cluster;
            if (nextClusterIsFirstCluster) {
              cluster.isKnownToBeFirstCluster = true;
              nextClusterIsFirstCluster = false;
            }
            const { clusterIndex: clusterIndex2, blockIndex: blockIndex2, correctBlockFound: correctBlockFound2 } = getBestMatch();
            if (correctBlockFound2) {
              const cluster2 = this.internalTrack.clusters[clusterIndex2];
              return this.fetchPacketInCluster(cluster2, blockIndex2, options);
            }
            if (clusterIndex2 !== -1) {
              bestClusterIndex = clusterIndex2;
              bestBlockIndex = blockIndex2;
            }
          }
          if (size === null) {
            if (id === 524531317 /* Cluster */) {
              assert(prevCluster);
              size = prevCluster.elementEndPos - dataStartPos;
            } else {
              clusterReader.pos = dataStartPos;
              const nextElementPos = await clusterReader.searchForNextElementId(
                LEVEL_0_AND_1_EBML_IDS,
                segment.elementEndPos
              );
              size = (nextElementPos ?? segment.elementEndPos) - dataStartPos;
            }
            const endPos = dataStartPos + size;
            if (endPos > segment.elementEndPos - MIN_HEADER_SIZE) {
              break;
            } else {
              clusterReader.pos = endPos;
              const elementId = clusterReader.readElementId();
              if (elementId === 408125543 /* Segment */) {
                segment.elementEndPos = endPos;
                break;
              }
            }
          }
          metadataReader.pos = dataStartPos + size;
        }
        let result = null;
        const bestCluster = bestClusterIndex !== -1 ? this.internalTrack.clusters[bestClusterIndex] : null;
        if (bestCluster) {
          result = await this.fetchPacketInCluster(bestCluster, bestBlockIndex, options);
        }
        if (!result && cuePoint && (!bestCluster || bestCluster.elementStartPos < cuePoint.clusterPosition)) {
          const previousCuePoint = this.internalTrack.cuePoints[cuePointIndex - 1];
          const newSearchTimestamp = previousCuePoint?.time ?? -Infinity;
          return this.performClusterLookup(getBestMatch, newSearchTimestamp, latestTimestamp, options);
        }
        return result;
      } finally {
        release();
      }
    }
  };
  var MatroskaVideoTrackBacking = class extends MatroskaTrackBacking {
    constructor(internalTrack) {
      super(internalTrack);
      this.decoderConfigPromise = null;
      this.internalTrack = internalTrack;
    }
    getCodec() {
      return this.internalTrack.info.codec;
    }
    getCodedWidth() {
      return this.internalTrack.info.width;
    }
    getCodedHeight() {
      return this.internalTrack.info.height;
    }
    getRotation() {
      return this.internalTrack.info.rotation;
    }
    async getColorSpace() {
      return {
        primaries: this.internalTrack.info.colorSpace?.primaries,
        transfer: this.internalTrack.info.colorSpace?.transfer,
        matrix: this.internalTrack.info.colorSpace?.matrix,
        fullRange: this.internalTrack.info.colorSpace?.fullRange
      };
    }
    async getDecoderConfig() {
      if (!this.internalTrack.info.codec) {
        return null;
      }
      return this.decoderConfigPromise ??= (async () => {
        let firstPacket = null;
        const needsPacketForAdditionalInfo = this.internalTrack.info.codec === "vp9" || this.internalTrack.info.codec === "av1" || this.internalTrack.info.codec === "avc" && !this.internalTrack.info.codecDescription || this.internalTrack.info.codec === "hevc" && !this.internalTrack.info.codecDescription;
        if (needsPacketForAdditionalInfo) {
          firstPacket = await this.getFirstPacket({});
        }
        return {
          codec: extractVideoCodecString({
            width: this.internalTrack.info.width,
            height: this.internalTrack.info.height,
            codec: this.internalTrack.info.codec,
            codecDescription: this.internalTrack.info.codecDescription,
            colorSpace: this.internalTrack.info.colorSpace,
            avcCodecInfo: this.internalTrack.info.codec === "avc" && firstPacket ? extractAvcDecoderConfigurationRecord(firstPacket.data) : null,
            hevcCodecInfo: this.internalTrack.info.codec === "hevc" && firstPacket ? extractHevcDecoderConfigurationRecord(firstPacket.data) : null,
            vp9CodecInfo: this.internalTrack.info.codec === "vp9" && firstPacket ? extractVp9CodecInfoFromPacket(firstPacket.data) : null,
            av1CodecInfo: this.internalTrack.info.codec === "av1" && firstPacket ? extractAv1CodecInfoFromPacket(firstPacket.data) : null
          }),
          codedWidth: this.internalTrack.info.width,
          codedHeight: this.internalTrack.info.height,
          description: this.internalTrack.info.codecDescription ?? void 0,
          colorSpace: this.internalTrack.info.colorSpace ?? void 0
        };
      })();
    }
  };
  var MatroskaAudioTrackBacking = class extends MatroskaTrackBacking {
    constructor(internalTrack) {
      super(internalTrack);
      this.decoderConfig = null;
      this.internalTrack = internalTrack;
    }
    getCodec() {
      return this.internalTrack.info.codec;
    }
    getNumberOfChannels() {
      return this.internalTrack.info.numberOfChannels;
    }
    getSampleRate() {
      return this.internalTrack.info.sampleRate;
    }
    async getDecoderConfig() {
      if (!this.internalTrack.info.codec) {
        return null;
      }
      return this.decoderConfig ??= {
        codec: extractAudioCodecString({
          codec: this.internalTrack.info.codec,
          codecDescription: this.internalTrack.info.codecDescription,
          aacCodecInfo: this.internalTrack.info.aacCodecInfo
        }),
        numberOfChannels: this.internalTrack.info.numberOfChannels,
        sampleRate: this.internalTrack.info.sampleRate,
        description: this.internalTrack.info.codecDescription ?? void 0
      };
    }
  };
  var sortBlocksByReferences = (blocks) => {
    const timestampToBlock = /* @__PURE__ */ new Map();
    for (let i = 0; i < blocks.length; i++) {
      const block = blocks[i];
      timestampToBlock.set(block.timestamp, block);
    }
    const processedBlocks = /* @__PURE__ */ new Set();
    const result = [];
    const processBlock = (block) => {
      if (processedBlocks.has(block)) {
        return;
      }
      processedBlocks.add(block);
      for (let j = 0; j < block.referencedTimestamps.length; j++) {
        const timestamp = block.referencedTimestamps[j];
        const otherBlock = timestampToBlock.get(timestamp);
        if (!otherBlock) {
          continue;
        }
        processBlock(otherBlock);
      }
      result.push(block);
    };
    for (let i = 0; i < blocks.length; i++) {
      processBlock(blocks[i]);
    }
    return result;
  };

  // src/mp3/mp3-reader.ts
  var Mp3Reader = class {
    constructor(reader) {
      this.reader = reader;
      this.pos = 0;
      this.fileSize = null;
    }
    readBytes(length) {
      const { view: view2, offset } = this.reader.getViewAndOffset(this.pos, this.pos + length);
      this.pos += length;
      return new Uint8Array(view2.buffer, offset, length);
    }
    readU16() {
      const { view: view2, offset } = this.reader.getViewAndOffset(this.pos, this.pos + 2);
      this.pos += 2;
      return view2.getUint16(offset, false);
    }
    readU32() {
      const { view: view2, offset } = this.reader.getViewAndOffset(this.pos, this.pos + 4);
      this.pos += 4;
      return view2.getUint32(offset, false);
    }
    readAscii(length) {
      const { view: view2, offset } = this.reader.getViewAndOffset(this.pos, this.pos + length);
      this.pos += length;
      let str = "";
      for (let i = 0; i < length; i++) {
        str += String.fromCharCode(view2.getUint8(offset + i));
      }
      return str;
    }
    readId3() {
      const tag = this.readAscii(3);
      if (tag !== "ID3") {
        this.pos -= 3;
        return null;
      }
      this.pos += 3;
      const size = decodeSynchsafe(this.readU32());
      return { size };
    }
    readNextFrameHeader(until) {
      assert(this.fileSize);
      until ??= this.fileSize;
      while (this.pos <= until - FRAME_HEADER_SIZE) {
        const word = this.readU32();
        this.pos -= 4;
        const header = readFrameHeader(word, this);
        if (header) {
          return header;
        }
      }
      return null;
    }
  };
  var decodeSynchsafe = (synchsafed) => {
    let mask = 2130706432;
    let unsynchsafed = 0;
    while (mask !== 0) {
      unsynchsafed >>= 1;
      unsynchsafed |= synchsafed & mask;
      mask >>= 8;
    }
    return unsynchsafed;
  };

  // src/mp3/mp3-demuxer.ts
  var Mp3Demuxer = class extends Demuxer {
    constructor(input) {
      super(input);
      this.metadataPromise = null;
      this.firstFrameHeader = null;
      this.loadedSamples = [];
      // All samples from the start of the file to lastLoadedPos
      this.tracks = [];
      this.loadingMutex = new AsyncMutex();
      this.lastLoadedPos = 0;
      this.fileSize = 0;
      this.nextTimestampInSamples = 0;
      this.reader = new Mp3Reader(input._mainReader);
    }
    async readMetadata() {
      return this.metadataPromise ??= (async () => {
        this.fileSize = await this.input.source.getSize();
        this.reader.fileSize = this.fileSize;
        while (!this.firstFrameHeader && this.lastLoadedPos < this.fileSize) {
          await this.loadNextChunk();
        }
        if (!this.firstFrameHeader) {
          throw new Error("No MP3 frames found.");
        }
        this.tracks = [new InputAudioTrack(new Mp3AudioTrackBacking(this))];
      })();
    }
    /** Loads the next 0.5 MiB of frames. */
    async loadNextChunk() {
      const release = await this.loadingMutex.acquire();
      try {
        assert(this.lastLoadedPos < this.fileSize);
        const chunkSize = 0.5 * 1024 * 1024;
        const endPos = Math.min(this.lastLoadedPos + chunkSize, this.fileSize);
        await this.reader.reader.loadRange(this.lastLoadedPos, endPos);
        this.lastLoadedPos = endPos;
        assert(this.lastLoadedPos <= this.fileSize);
        if (this.reader.pos === 0) {
          const id3Tag = this.reader.readId3();
          if (id3Tag) {
            this.reader.pos += id3Tag.size;
          }
        }
        this.parseFramesFromLoadedData();
      } finally {
        release();
      }
    }
    parseFramesFromLoadedData() {
      while (true) {
        const startPos = this.reader.pos;
        const header = this.reader.readNextFrameHeader();
        if (!header) {
          break;
        }
        if (header.startPos + header.totalSize > this.lastLoadedPos) {
          this.reader.pos = startPos;
          this.lastLoadedPos = startPos;
          break;
        }
        const xingOffset = getXingOffset(header.mpegVersionId, header.channel);
        this.reader.pos = header.startPos + xingOffset;
        const word = this.reader.readU32();
        const isXing = word === XING || word === INFO;
        this.reader.pos = header.startPos + header.totalSize - 1;
        if (isXing) {
          continue;
        }
        if (!this.firstFrameHeader) {
          this.firstFrameHeader = header;
        }
        const sampleDuration = header.audioSamplesInFrame / header.sampleRate;
        const sample = {
          timestamp: this.nextTimestampInSamples / header.sampleRate,
          duration: sampleDuration,
          dataStart: header.startPos,
          dataSize: header.totalSize
        };
        this.loadedSamples.push(sample);
        this.nextTimestampInSamples += header.audioSamplesInFrame;
      }
    }
    async getMimeType() {
      return "audio/mpeg";
    }
    async getTracks() {
      await this.readMetadata();
      return this.tracks;
    }
    async computeDuration() {
      await this.readMetadata();
      const track = this.tracks[0];
      assert(track);
      return track.computeDuration();
    }
  };
  var Mp3AudioTrackBacking = class {
    constructor(demuxer) {
      this.demuxer = demuxer;
    }
    getId() {
      return 1;
    }
    async getFirstTimestamp() {
      return 0;
    }
    getTimeResolution() {
      assert(this.demuxer.firstFrameHeader);
      return this.demuxer.firstFrameHeader.sampleRate / this.demuxer.firstFrameHeader.audioSamplesInFrame;
    }
    async computeDuration() {
      const lastPacket = await this.getPacket(Infinity, { metadataOnly: true });
      return (lastPacket?.timestamp ?? 0) + (lastPacket?.duration ?? 0);
    }
    getLanguageCode() {
      return UNDETERMINED_LANGUAGE;
    }
    getCodec() {
      return "mp3";
    }
    getNumberOfChannels() {
      assert(this.demuxer.firstFrameHeader);
      return this.demuxer.firstFrameHeader.channel === 3 ? 1 : 2;
    }
    getSampleRate() {
      assert(this.demuxer.firstFrameHeader);
      return this.demuxer.firstFrameHeader.sampleRate;
    }
    async getDecoderConfig() {
      assert(this.demuxer.firstFrameHeader);
      return {
        codec: "mp3",
        numberOfChannels: this.demuxer.firstFrameHeader.channel === 3 ? 1 : 2,
        sampleRate: this.demuxer.firstFrameHeader.sampleRate
      };
    }
    getPacketAtIndex(sampleIndex, options) {
      if (sampleIndex === -1) {
        return null;
      }
      const rawSample = this.demuxer.loadedSamples[sampleIndex];
      if (!rawSample) {
        return null;
      }
      let data;
      if (options.metadataOnly) {
        data = PLACEHOLDER_DATA;
      } else {
        this.demuxer.reader.pos = rawSample.dataStart;
        data = this.demuxer.reader.readBytes(rawSample.dataSize);
      }
      return new EncodedPacket(
        data,
        "key",
        rawSample.timestamp,
        rawSample.duration,
        sampleIndex,
        rawSample.dataSize
      );
    }
    async getFirstPacket(options) {
      while (this.demuxer.loadedSamples.length === 0 && this.demuxer.lastLoadedPos < this.demuxer.fileSize) {
        await this.demuxer.loadNextChunk();
      }
      return this.getPacketAtIndex(0, options);
    }
    async getNextPacket(packet, options) {
      const sampleIndex = binarySearchExact(
        this.demuxer.loadedSamples,
        packet.timestamp,
        (x) => x.timestamp
      );
      if (sampleIndex === -1) {
        throw new Error("Packet was not created from this track.");
      }
      const nextIndex = sampleIndex + 1;
      while (nextIndex >= this.demuxer.loadedSamples.length && this.demuxer.lastLoadedPos < this.demuxer.fileSize) {
        await this.demuxer.loadNextChunk();
      }
      return this.getPacketAtIndex(nextIndex, options);
    }
    async getPacket(timestamp, options) {
      while (true) {
        const index = binarySearchLessOrEqual(
          this.demuxer.loadedSamples,
          timestamp,
          (x) => x.timestamp
        );
        if (index === -1 && this.demuxer.loadedSamples.length > 0) {
          return null;
        }
        if (this.demuxer.lastLoadedPos === this.demuxer.fileSize) {
          return this.getPacketAtIndex(index, options);
        }
        if (index >= 0 && index + 1 < this.demuxer.loadedSamples.length) {
          return this.getPacketAtIndex(index, options);
        }
        await this.demuxer.loadNextChunk();
      }
    }
    getKeyPacket(timestamp, options) {
      return this.getPacket(timestamp, options);
    }
    getNextKeyPacket(packet, options) {
      return this.getNextPacket(packet, options);
    }
  };

  // src/ogg/ogg-demuxer.ts
  var OggDemuxer = class extends Demuxer {
    constructor(input) {
      super(input);
      /**
       * Lots of reading operations require multiple async reads and thus need to be mutually exclusive to avoid
       * conflicts in reader position.
       */
      this.readingMutex = new AsyncMutex();
      this.metadataPromise = null;
      this.fileSize = null;
      this.bitstreams = [];
      this.tracks = [];
      this.reader = new OggReader(new Reader(input.source, 64 * 2 ** 20));
    }
    async readMetadata() {
      return this.metadataPromise ??= (async () => {
        this.fileSize = await this.input.source.getSize();
        while (this.reader.pos < this.fileSize - MIN_PAGE_HEADER_SIZE) {
          await this.reader.reader.loadRange(
            this.reader.pos,
            this.reader.pos + MAX_PAGE_HEADER_SIZE
          );
          const page = this.reader.readPageHeader();
          if (!page) {
            break;
          }
          const isBos = !!(page.headerType & 2);
          if (!isBos) {
            break;
          }
          this.bitstreams.push({
            serialNumber: page.serialNumber,
            bosPage: page,
            description: null,
            numberOfChannels: -1,
            sampleRate: -1,
            codecInfo: {
              codec: null,
              vorbisInfo: null,
              opusInfo: null
            },
            lastMetadataPacket: null
          });
          this.reader.pos = page.headerStartPos + page.totalSize;
        }
        for (const bitstream of this.bitstreams) {
          const firstPacket = await this.readPacket(this.reader, bitstream.bosPage, 0);
          if (!firstPacket) {
            continue;
          }
          if (
            // Check for Vorbis
            firstPacket.data.byteLength >= 7 && firstPacket.data[0] === 1 && firstPacket.data[1] === 118 && firstPacket.data[2] === 111 && firstPacket.data[3] === 114 && firstPacket.data[4] === 98 && firstPacket.data[5] === 105 && firstPacket.data[6] === 115
          ) {
            await this.readVorbisMetadata(firstPacket, bitstream);
          } else if (
            // Check for Opus
            firstPacket.data.byteLength >= 8 && firstPacket.data[0] === 79 && firstPacket.data[1] === 112 && firstPacket.data[2] === 117 && firstPacket.data[3] === 115 && firstPacket.data[4] === 72 && firstPacket.data[5] === 101 && firstPacket.data[6] === 97 && firstPacket.data[7] === 100
          ) {
            await this.readOpusMetadata(firstPacket, bitstream);
          }
          if (bitstream.codecInfo.codec !== null) {
            this.tracks.push(new InputAudioTrack(new OggAudioTrackBacking(bitstream, this)));
          }
        }
      })();
    }
    async readVorbisMetadata(firstPacket, bitstream) {
      let nextPacketPosition = await this.findNextPacketStart(this.reader, firstPacket);
      if (!nextPacketPosition) {
        return;
      }
      const secondPacket = await this.readPacket(
        this.reader,
        nextPacketPosition.startPage,
        nextPacketPosition.startSegmentIndex
      );
      if (!secondPacket) {
        return;
      }
      nextPacketPosition = await this.findNextPacketStart(this.reader, secondPacket);
      if (!nextPacketPosition) {
        return;
      }
      const thirdPacket = await this.readPacket(
        this.reader,
        nextPacketPosition.startPage,
        nextPacketPosition.startSegmentIndex
      );
      if (!thirdPacket) {
        return;
      }
      if (secondPacket.data[0] !== 3 || thirdPacket.data[0] !== 5) {
        return;
      }
      const lacingValues = [];
      const addBytesToSegmentTable = (bytes2) => {
        while (true) {
          lacingValues.push(Math.min(255, bytes2));
          if (bytes2 < 255) {
            break;
          }
          bytes2 -= 255;
        }
      };
      addBytesToSegmentTable(firstPacket.data.length);
      addBytesToSegmentTable(secondPacket.data.length);
      const description = new Uint8Array(
        1 + lacingValues.length + firstPacket.data.length + secondPacket.data.length + thirdPacket.data.length
      );
      description[0] = lacingValues.length;
      description.set(
        lacingValues,
        1
      );
      description.set(
        firstPacket.data,
        1 + lacingValues.length
      );
      description.set(
        secondPacket.data,
        1 + lacingValues.length + firstPacket.data.length
      );
      description.set(
        thirdPacket.data,
        1 + lacingValues.length + firstPacket.data.length + secondPacket.data.length
      );
      bitstream.codecInfo.codec = "vorbis";
      bitstream.description = description;
      bitstream.lastMetadataPacket = thirdPacket;
      const view2 = toDataView(firstPacket.data);
      bitstream.numberOfChannels = view2.getUint8(11);
      bitstream.sampleRate = view2.getUint32(12, true);
      const blockSizeByte = view2.getUint8(28);
      bitstream.codecInfo.vorbisInfo = {
        blocksizes: [
          1 << (blockSizeByte & 15),
          1 << (blockSizeByte >> 4)
        ],
        modeBlockflags: parseModesFromVorbisSetupPacket(thirdPacket.data).modeBlockflags
      };
    }
    async readOpusMetadata(firstPacket, bitstream) {
      const nextPacketPosition = await this.findNextPacketStart(this.reader, firstPacket);
      if (!nextPacketPosition) {
        return;
      }
      const secondPacket = await this.readPacket(
        this.reader,
        nextPacketPosition.startPage,
        nextPacketPosition.startSegmentIndex
      );
      if (!secondPacket) {
        return;
      }
      bitstream.codecInfo.codec = "opus";
      bitstream.description = firstPacket.data;
      bitstream.lastMetadataPacket = secondPacket;
      const header = parseOpusIdentificationHeader(firstPacket.data);
      bitstream.numberOfChannels = header.outputChannelCount;
      bitstream.sampleRate = header.inputSampleRate;
      bitstream.codecInfo.opusInfo = {
        preSkip: header.preSkip
      };
    }
    async readPacket(reader, startPage, startSegmentIndex) {
      assert(startSegmentIndex < startPage.lacingValues.length);
      assert(this.fileSize);
      let startDataOffset = 0;
      for (let i = 0; i < startSegmentIndex; i++) {
        startDataOffset += startPage.lacingValues[i];
      }
      let currentPage = startPage;
      let currentDataOffset = startDataOffset;
      let currentSegmentIndex = startSegmentIndex;
      const chunks = [];
      outer:
        while (true) {
          await reader.reader.loadRange(
            currentPage.dataStartPos,
            currentPage.dataStartPos + currentPage.dataSize
          );
          reader.pos = currentPage.dataStartPos;
          const pageData = reader.readBytes(currentPage.dataSize);
          while (true) {
            if (currentSegmentIndex === currentPage.lacingValues.length) {
              chunks.push(pageData.subarray(startDataOffset, currentDataOffset));
              break;
            }
            const lacingValue = currentPage.lacingValues[currentSegmentIndex];
            currentDataOffset += lacingValue;
            if (lacingValue < 255) {
              chunks.push(pageData.subarray(startDataOffset, currentDataOffset));
              break outer;
            }
            currentSegmentIndex++;
          }
          while (true) {
            reader.pos = currentPage.headerStartPos + currentPage.totalSize;
            if (reader.pos >= this.fileSize - MIN_PAGE_HEADER_SIZE) {
              return null;
            }
            await reader.reader.loadRange(reader.pos, reader.pos + MAX_PAGE_HEADER_SIZE);
            const nextPage = reader.readPageHeader();
            if (!nextPage) {
              return null;
            }
            currentPage = nextPage;
            if (currentPage.serialNumber === startPage.serialNumber) {
              break;
            }
          }
          startDataOffset = 0;
          currentDataOffset = 0;
          currentSegmentIndex = 0;
        }
      const totalPacketSize = chunks.reduce((sum, chunk) => sum + chunk.length, 0);
      const packetData = new Uint8Array(totalPacketSize);
      let offset = 0;
      for (let i = 0; i < chunks.length; i++) {
        const chunk = chunks[i];
        packetData.set(chunk, offset);
        offset += chunk.length;
      }
      return {
        data: packetData,
        endPage: currentPage,
        endSegmentIndex: currentSegmentIndex
      };
    }
    async findNextPacketStart(reader, lastPacket) {
      assert(this.fileSize !== null);
      if (lastPacket.endSegmentIndex < lastPacket.endPage.lacingValues.length - 1) {
        return { startPage: lastPacket.endPage, startSegmentIndex: lastPacket.endSegmentIndex + 1 };
      }
      const isEos = !!(lastPacket.endPage.headerType & 4);
      if (isEos) {
        return null;
      }
      reader.pos = lastPacket.endPage.headerStartPos + lastPacket.endPage.totalSize;
      while (true) {
        if (reader.pos >= this.fileSize - MIN_PAGE_HEADER_SIZE) {
          return null;
        }
        await reader.reader.loadRange(reader.pos, reader.pos + MAX_PAGE_HEADER_SIZE);
        const nextPage = reader.readPageHeader();
        if (!nextPage) {
          return null;
        }
        if (nextPage.serialNumber === lastPacket.endPage.serialNumber) {
          return { startPage: nextPage, startSegmentIndex: 0 };
        }
        reader.pos = nextPage.headerStartPos + nextPage.totalSize;
      }
    }
    async getMimeType() {
      await this.readMetadata();
      const codecStrings = await Promise.all(this.tracks.map((x) => x.getCodecParameterString()));
      return buildOggMimeType({
        codecStrings: codecStrings.filter(Boolean)
      });
    }
    async getTracks() {
      await this.readMetadata();
      return this.tracks;
    }
    async computeDuration() {
      const tracks = await this.getTracks();
      const trackDurations = await Promise.all(tracks.map((x) => x.computeDuration()));
      return Math.max(0, ...trackDurations);
    }
  };
  var OggAudioTrackBacking = class {
    constructor(bitstream, demuxer) {
      this.bitstream = bitstream;
      this.demuxer = demuxer;
      this.encodedPacketToMetadata = /* @__PURE__ */ new WeakMap();
      this.internalSampleRate = bitstream.codecInfo.codec === "opus" ? OPUS_INTERNAL_SAMPLE_RATE : bitstream.sampleRate;
    }
    getId() {
      return this.bitstream.serialNumber;
    }
    getNumberOfChannels() {
      return this.bitstream.numberOfChannels;
    }
    getSampleRate() {
      return this.bitstream.sampleRate;
    }
    getTimeResolution() {
      return this.bitstream.sampleRate;
    }
    getCodec() {
      return this.bitstream.codecInfo.codec;
    }
    async getDecoderConfig() {
      assert(this.bitstream.codecInfo.codec);
      return {
        codec: this.bitstream.codecInfo.codec,
        numberOfChannels: this.bitstream.numberOfChannels,
        sampleRate: this.bitstream.sampleRate,
        description: this.bitstream.description ?? void 0
      };
    }
    getLanguageCode() {
      return UNDETERMINED_LANGUAGE;
    }
    async getFirstTimestamp() {
      return 0;
    }
    async computeDuration() {
      const lastPacket = await this.getPacket(Infinity, { metadataOnly: true });
      return (lastPacket?.timestamp ?? 0) + (lastPacket?.duration ?? 0);
    }
    granulePositionToTimestampInSamples(granulePosition) {
      if (this.bitstream.codecInfo.codec === "opus") {
        assert(this.bitstream.codecInfo.opusInfo);
        return granulePosition - this.bitstream.codecInfo.opusInfo.preSkip;
      }
      return granulePosition;
    }
    createEncodedPacketFromOggPacket(packet, additional, options) {
      if (!packet) {
        return null;
      }
      const { durationInSamples, vorbisBlockSize } = extractSampleMetadata(
        packet.data,
        this.bitstream.codecInfo,
        additional.vorbisLastBlocksize
      );
      const encodedPacket = new EncodedPacket(
        options.metadataOnly ? PLACEHOLDER_DATA : packet.data,
        "key",
        Math.max(0, additional.timestampInSamples) / this.internalSampleRate,
        durationInSamples / this.internalSampleRate,
        packet.endPage.headerStartPos + packet.endSegmentIndex,
        packet.data.byteLength
      );
      this.encodedPacketToMetadata.set(encodedPacket, {
        packet,
        timestampInSamples: additional.timestampInSamples,
        durationInSamples,
        vorbisBlockSize
      });
      return encodedPacket;
    }
    async getFirstPacket(options, exclusive = true) {
      const release = exclusive ? await this.demuxer.readingMutex.acquire() : null;
      try {
        assert(this.bitstream.lastMetadataPacket);
        const packetPosition = await this.demuxer.findNextPacketStart(
          this.demuxer.reader,
          this.bitstream.lastMetadataPacket
        );
        if (!packetPosition) {
          return null;
        }
        let timestampInSamples = 0;
        if (this.bitstream.codecInfo.codec === "opus") {
          assert(this.bitstream.codecInfo.opusInfo);
          timestampInSamples -= this.bitstream.codecInfo.opusInfo.preSkip;
        }
        const packet = await this.demuxer.readPacket(
          this.demuxer.reader,
          packetPosition.startPage,
          packetPosition.startSegmentIndex
        );
        return this.createEncodedPacketFromOggPacket(
          packet,
          {
            timestampInSamples,
            vorbisLastBlocksize: null
          },
          options
        );
      } finally {
        release?.();
      }
    }
    async getNextPacket(prevPacket, options) {
      const release = await this.demuxer.readingMutex.acquire();
      try {
        const prevMetadata = this.encodedPacketToMetadata.get(prevPacket);
        if (!prevMetadata) {
          throw new Error("Packet was not created from this track.");
        }
        const packetPosition = await this.demuxer.findNextPacketStart(this.demuxer.reader, prevMetadata.packet);
        if (!packetPosition) {
          return null;
        }
        const timestampInSamples = prevMetadata.timestampInSamples + prevMetadata.durationInSamples;
        const packet = await this.demuxer.readPacket(
          this.demuxer.reader,
          packetPosition.startPage,
          packetPosition.startSegmentIndex
        );
        return this.createEncodedPacketFromOggPacket(
          packet,
          {
            timestampInSamples,
            vorbisLastBlocksize: prevMetadata.vorbisBlockSize
          },
          options
        );
      } finally {
        release();
      }
    }
    async getPacket(timestamp, options) {
      const release = await this.demuxer.readingMutex.acquire();
      try {
        assert(this.demuxer.fileSize !== null);
        const timestampInSamples = roundToPrecision(timestamp * this.internalSampleRate, 14);
        if (timestampInSamples === 0) {
          return this.getFirstPacket(options, false);
        }
        if (timestampInSamples < 0) {
          return null;
        }
        const reader = this.demuxer.reader;
        assert(this.bitstream.lastMetadataPacket);
        const startPosition = await this.demuxer.findNextPacketStart(
          reader,
          this.bitstream.lastMetadataPacket
        );
        if (!startPosition) {
          return null;
        }
        let lowPage = startPosition.startPage;
        let high = this.demuxer.fileSize;
        const lowPages = [lowPage];
        outer:
          while (lowPage.headerStartPos + lowPage.totalSize < high) {
            const low = lowPage.headerStartPos;
            const mid = Math.floor((low + high) / 2);
            let searchStartPos = mid;
            while (true) {
              const until = Math.min(
                searchStartPos + MAX_PAGE_SIZE,
                high - MIN_PAGE_HEADER_SIZE
              );
              await reader.reader.loadRange(searchStartPos, until);
              reader.pos = searchStartPos;
              const found = reader.findNextPageHeader(until);
              if (!found) {
                high = mid + MIN_PAGE_HEADER_SIZE;
                continue outer;
              }
              await reader.reader.loadRange(reader.pos, reader.pos + MAX_PAGE_HEADER_SIZE);
              const page = reader.readPageHeader();
              assert(page);
              let pageValid = false;
              if (page.serialNumber === this.bitstream.serialNumber) {
                pageValid = true;
              } else {
                await reader.reader.loadRange(page.headerStartPos, page.headerStartPos + page.totalSize);
                reader.pos = page.headerStartPos;
                const bytes2 = reader.readBytes(page.totalSize);
                const crc = computeOggPageCrc(bytes2);
                pageValid = crc === page.checksum;
              }
              if (!pageValid) {
                searchStartPos = page.headerStartPos + 4;
                continue;
              }
              if (pageValid && page.serialNumber !== this.bitstream.serialNumber) {
                searchStartPos = page.headerStartPos + page.totalSize;
                continue;
              }
              const isContinuationPage = page.granulePosition === -1;
              if (isContinuationPage) {
                searchStartPos = page.headerStartPos + page.totalSize;
                continue;
              }
              if (this.granulePositionToTimestampInSamples(page.granulePosition) > timestampInSamples) {
                high = page.headerStartPos;
              } else {
                lowPage = page;
                lowPages.push(page);
              }
              continue outer;
            }
          }
        let lowerPage = startPosition.startPage;
        for (const otherLowPage of lowPages) {
          if (otherLowPage.granulePosition === lowPage.granulePosition) {
            break;
          }
          if (!lowerPage || otherLowPage.headerStartPos > lowerPage.headerStartPos) {
            lowerPage = otherLowPage;
          }
        }
        let currentPage = lowerPage;
        const previousPages = [currentPage];
        while (true) {
          if (currentPage.serialNumber === this.bitstream.serialNumber && currentPage.granulePosition === lowPage.granulePosition) {
            break;
          }
          reader.pos = currentPage.headerStartPos + currentPage.totalSize;
          await reader.reader.loadRange(reader.pos, reader.pos + MAX_PAGE_HEADER_SIZE);
          const nextPage = reader.readPageHeader();
          assert(nextPage);
          currentPage = nextPage;
          if (currentPage.serialNumber === this.bitstream.serialNumber) {
            previousPages.push(currentPage);
          }
        }
        assert(currentPage.granulePosition !== -1);
        let currentSegmentIndex = null;
        let currentTimestampInSamples;
        let currentTimestampIsCorrect;
        let endPage = currentPage;
        let endSegmentIndex = 0;
        if (currentPage.headerStartPos === startPosition.startPage.headerStartPos) {
          currentTimestampInSamples = this.granulePositionToTimestampInSamples(0);
          currentTimestampIsCorrect = true;
          currentSegmentIndex = 0;
        } else {
          currentTimestampInSamples = 0;
          currentTimestampIsCorrect = false;
          for (let i = currentPage.lacingValues.length - 1; i >= 0; i--) {
            const value = currentPage.lacingValues[i];
            if (value < 255) {
              currentSegmentIndex = i + 1;
              break;
            }
          }
          if (currentSegmentIndex === null) {
            throw new Error("Invalid page with granule position: no packets end on this page.");
          }
          endSegmentIndex = currentSegmentIndex - 1;
          const pseudopacket = {
            data: PLACEHOLDER_DATA,
            endPage,
            endSegmentIndex
          };
          const nextPosition = await this.demuxer.findNextPacketStart(reader, pseudopacket);
          if (nextPosition) {
            const endPosition = findPreviousPacketEndPosition(previousPages, currentPage, currentSegmentIndex);
            assert(endPosition);
            const startPosition2 = findPacketStartPosition(
              previousPages,
              endPosition.page,
              endPosition.segmentIndex
            );
            if (startPosition2) {
              currentPage = startPosition2.page;
              currentSegmentIndex = startPosition2.segmentIndex;
            }
          } else {
            while (true) {
              const endPosition = findPreviousPacketEndPosition(
                previousPages,
                currentPage,
                currentSegmentIndex
              );
              if (!endPosition) {
                break;
              }
              const startPosition2 = findPacketStartPosition(
                previousPages,
                endPosition.page,
                endPosition.segmentIndex
              );
              if (!startPosition2) {
                break;
              }
              currentPage = startPosition2.page;
              currentSegmentIndex = startPosition2.segmentIndex;
              if (endPosition.page.headerStartPos !== endPage.headerStartPos) {
                endPage = endPosition.page;
                endSegmentIndex = endPosition.segmentIndex;
                break;
              }
            }
          }
        }
        let lastEncodedPacket = null;
        let lastEncodedPacketMetadata = null;
        while (currentPage !== null) {
          assert(currentSegmentIndex !== null);
          const packet = await this.demuxer.readPacket(reader, currentPage, currentSegmentIndex);
          if (!packet) {
            break;
          }
          const skipPacket = currentPage.headerStartPos === startPosition.startPage.headerStartPos && currentSegmentIndex < startPosition.startSegmentIndex;
          if (!skipPacket) {
            let encodedPacket = this.createEncodedPacketFromOggPacket(
              packet,
              {
                timestampInSamples: currentTimestampInSamples,
                vorbisLastBlocksize: lastEncodedPacketMetadata?.vorbisBlockSize ?? null
              },
              options
            );
            assert(encodedPacket);
            let encodedPacketMetadata = this.encodedPacketToMetadata.get(encodedPacket);
            assert(encodedPacketMetadata);
            if (!currentTimestampIsCorrect && packet.endPage.headerStartPos === endPage.headerStartPos && packet.endSegmentIndex === endSegmentIndex) {
              currentTimestampInSamples = this.granulePositionToTimestampInSamples(
                currentPage.granulePosition
              );
              currentTimestampIsCorrect = true;
              encodedPacket = this.createEncodedPacketFromOggPacket(
                packet,
                {
                  timestampInSamples: currentTimestampInSamples - encodedPacketMetadata.durationInSamples,
                  vorbisLastBlocksize: lastEncodedPacketMetadata?.vorbisBlockSize ?? null
                },
                options
              );
              assert(encodedPacket);
              encodedPacketMetadata = this.encodedPacketToMetadata.get(encodedPacket);
              assert(encodedPacketMetadata);
            } else {
              currentTimestampInSamples += encodedPacketMetadata.durationInSamples;
            }
            lastEncodedPacket = encodedPacket;
            lastEncodedPacketMetadata = encodedPacketMetadata;
            if (currentTimestampIsCorrect && // Next timestamp will be too late
            (Math.max(currentTimestampInSamples, 0) > timestampInSamples || Math.max(encodedPacketMetadata.timestampInSamples, 0) === timestampInSamples)) {
              break;
            }
          }
          const nextPosition = await this.demuxer.findNextPacketStart(reader, packet);
          if (!nextPosition) {
            break;
          }
          currentPage = nextPosition.startPage;
          currentSegmentIndex = nextPosition.startSegmentIndex;
        }
        return lastEncodedPacket;
      } finally {
        release();
      }
    }
    getKeyPacket(timestamp, options) {
      return this.getPacket(timestamp, options);
    }
    getNextKeyPacket(packet, options) {
      return this.getNextPacket(packet, options);
    }
  };
  var findPacketStartPosition = (pageList, endPage, endSegmentIndex) => {
    let page = endPage;
    let segmentIndex = endSegmentIndex;
    outer:
      while (true) {
        segmentIndex--;
        for (segmentIndex; segmentIndex >= 0; segmentIndex--) {
          const lacingValue = page.lacingValues[segmentIndex];
          if (lacingValue < 255) {
            segmentIndex++;
            break outer;
          }
        }
        assert(segmentIndex === -1);
        const pageStartsWithFreshPacket = !(page.headerType & 1);
        if (pageStartsWithFreshPacket) {
          segmentIndex = 0;
          break;
        }
        const previousPage = findLast(
          pageList,
          (x) => x.headerStartPos < page.headerStartPos
        );
        if (!previousPage) {
          return null;
        }
        page = previousPage;
        segmentIndex = page.lacingValues.length;
      }
    assert(segmentIndex !== -1);
    if (segmentIndex === page.lacingValues.length) {
      const nextPage = pageList[pageList.indexOf(page) + 1];
      assert(nextPage);
      page = nextPage;
      segmentIndex = 0;
    }
    return { page, segmentIndex };
  };
  var findPreviousPacketEndPosition = (pageList, startPage, startSegmentIndex) => {
    if (startSegmentIndex > 0) {
      return { page: startPage, segmentIndex: startSegmentIndex - 1 };
    }
    const previousPage = findLast(
      pageList,
      (x) => x.headerStartPos < startPage.headerStartPos
    );
    if (!previousPage) {
      return null;
    }
    return { page: previousPage, segmentIndex: previousPage.lacingValues.length - 1 };
  };

  // src/input-format.ts
  var InputFormat = class {
  };
  var IsobmffInputFormat = class extends InputFormat {
    /** @internal */
    async _getMajorBrand(input) {
      const sourceSize = await input._mainReader.source.getSize();
      if (sourceSize < 12) {
        return null;
      }
      const isobmffReader = new IsobmffReader(input._mainReader);
      isobmffReader.pos = 4;
      const fourCc = isobmffReader.readAscii(4);
      if (fourCc !== "ftyp") {
        return null;
      }
      return isobmffReader.readAscii(4);
    }
    /** @internal */
    _createDemuxer(input) {
      return new IsobmffDemuxer(input);
    }
  };
  var Mp4InputFormat = class extends IsobmffInputFormat {
    /** @internal */
    async _canReadInput(input) {
      const majorBrand = await this._getMajorBrand(input);
      return !!majorBrand && majorBrand !== "qt  ";
    }
    get name() {
      return "MP4";
    }
    get mimeType() {
      return "video/mp4";
    }
  };
  var QuickTimeInputFormat = class extends IsobmffInputFormat {
    /** @internal */
    async _canReadInput(input) {
      const majorBrand = await this._getMajorBrand(input);
      return majorBrand === "qt  ";
    }
    get name() {
      return "QuickTime File Format";
    }
    get mimeType() {
      return "video/quicktime";
    }
  };
  var MatroskaInputFormat = class extends InputFormat {
    /** @internal */
    async isSupportedEBMLOfDocType(input, desiredDocType) {
      const sourceSize = await input._mainReader.source.getSize();
      if (sourceSize < 8) {
        return false;
      }
      const ebmlReader = new EBMLReader(input._mainReader);
      const varIntSize = ebmlReader.readVarIntSize();
      if (varIntSize < 1 || varIntSize > 8) {
        return false;
      }
      const id = ebmlReader.readUnsignedInt(varIntSize);
      if (id !== 440786851 /* EBML */) {
        return false;
      }
      const dataSize = ebmlReader.readElementSize();
      if (dataSize === null) {
        return false;
      }
      const startPos = ebmlReader.pos;
      while (ebmlReader.pos < startPos + dataSize) {
        const { id: id2, size } = ebmlReader.readElementHeader();
        const dataStartPos = ebmlReader.pos;
        if (size === null) return false;
        switch (id2) {
          case 17030 /* EBMLVersion */:
            {
              const ebmlVersion = ebmlReader.readUnsignedInt(size);
              if (ebmlVersion !== 1) {
                return false;
              }
            }
            ;
            break;
          case 17143 /* EBMLReadVersion */:
            {
              const ebmlReadVersion = ebmlReader.readUnsignedInt(size);
              if (ebmlReadVersion !== 1) {
                return false;
              }
            }
            ;
            break;
          case 17026 /* DocType */:
            {
              const docType = ebmlReader.readString(size);
              if (docType !== desiredDocType) {
                return false;
              }
            }
            ;
            break;
          case 17031 /* DocTypeVersion */:
            {
              const docTypeVersion = ebmlReader.readUnsignedInt(size);
              if (docTypeVersion > 4) {
                return false;
              }
            }
            ;
            break;
        }
        ebmlReader.pos = dataStartPos + size;
      }
      return true;
    }
    /** @internal */
    _canReadInput(input) {
      return this.isSupportedEBMLOfDocType(input, "matroska");
    }
    /** @internal */
    _createDemuxer(input) {
      return new MatroskaDemuxer(input);
    }
    get name() {
      return "Matroska";
    }
    get mimeType() {
      return "video/x-matroska";
    }
  };
  var WebMInputFormat = class extends MatroskaInputFormat {
    /** @internal */
    _canReadInput(input) {
      return this.isSupportedEBMLOfDocType(input, "webm");
    }
    get name() {
      return "WebM";
    }
    get mimeType() {
      return "video/webm";
    }
  };
  var Mp3InputFormat = class extends InputFormat {
    /** @internal */
    async _canReadInput(input) {
      const sourceSize = await input._mainReader.source.getSize();
      if (sourceSize < 4) {
        return false;
      }
      const mp3Reader = new Mp3Reader(input._mainReader);
      mp3Reader.fileSize = sourceSize;
      const id3Tag = mp3Reader.readId3();
      if (id3Tag) {
        mp3Reader.pos += id3Tag.size;
      }
      const framesStartPos = mp3Reader.pos;
      await mp3Reader.reader.loadRange(mp3Reader.pos, mp3Reader.pos + 4096);
      const firstHeader = mp3Reader.readNextFrameHeader(Math.min(framesStartPos + 4096, sourceSize));
      if (!firstHeader) {
        return false;
      }
      if (id3Tag) {
        return true;
      }
      mp3Reader.pos = firstHeader.startPos + firstHeader.totalSize;
      await mp3Reader.reader.loadRange(mp3Reader.pos, mp3Reader.pos + FRAME_HEADER_SIZE);
      const secondHeader = mp3Reader.readNextFrameHeader(mp3Reader.pos + FRAME_HEADER_SIZE);
      if (!secondHeader) {
        return false;
      }
      if (firstHeader.channel !== secondHeader.channel || firstHeader.sampleRate !== secondHeader.sampleRate) {
        return false;
      }
      return true;
    }
    /** @internal */
    _createDemuxer(input) {
      return new Mp3Demuxer(input);
    }
    get name() {
      return "MP3";
    }
    get mimeType() {
      return "audio/mpeg";
    }
  };
  var WaveInputFormat = class extends InputFormat {
    /** @internal */
    async _canReadInput(input) {
      const sourceSize = await input._mainReader.source.getSize();
      if (sourceSize < 12) {
        return false;
      }
      const riffReader = new RiffReader(input._mainReader);
      const riffType = riffReader.readAscii(4);
      if (riffType !== "RIFF" && riffType !== "RIFX" && riffType !== "RF64") {
        return false;
      }
      riffReader.pos = 8;
      const format = riffReader.readAscii(4);
      return format === "WAVE";
    }
    /** @internal */
    _createDemuxer(input) {
      return new WaveDemuxer(input);
    }
    get name() {
      return "WAVE";
    }
    get mimeType() {
      return "audio/wav";
    }
  };
  var OggInputFormat = class extends InputFormat {
    /** @internal */
    async _canReadInput(input) {
      const sourceSize = await input._mainReader.source.getSize();
      if (sourceSize < 4) {
        return false;
      }
      const oggReader = new OggReader(input._mainReader);
      return oggReader.readAscii(4) === "OggS";
    }
    /** @internal */
    _createDemuxer(input) {
      return new OggDemuxer(input);
    }
    get name() {
      return "Ogg";
    }
    get mimeType() {
      return "application/ogg";
    }
  };
  var MP4 = new Mp4InputFormat();
  var QTFF = new QuickTimeInputFormat();
  var MATROSKA = new MatroskaInputFormat();
  var WEBM = new WebMInputFormat();
  var MP3 = new Mp3InputFormat();
  var WAVE = new WaveInputFormat();
  var OGG = new OggInputFormat();
  var ALL_FORMATS = [MP4, QTFF, MATROSKA, WEBM, WAVE, OGG, MP3];

  // src/input.ts
  var Input = class {
    constructor(options) {
      /** @internal */
      this._demuxerPromise = null;
      /** @internal */
      this._format = null;
      if (!options || typeof options !== "object") {
        throw new TypeError("options must be an object.");
      }
      if (!Array.isArray(options.formats) || options.formats.some((x) => !(x instanceof InputFormat))) {
        throw new TypeError("options.formats must be an array of InputFormat.");
      }
      if (!(options.source instanceof Source)) {
        throw new TypeError("options.source must be a Source.");
      }
      this._formats = options.formats;
      this._source = options.source;
      this._mainReader = new Reader(options.source);
    }
    /** @internal */
    _getDemuxer() {
      return this._demuxerPromise ??= (async () => {
        await this._mainReader.loadRange(0, 4096);
        for (const format of this._formats) {
          const canRead = await format._canReadInput(this);
          if (canRead) {
            this._format = format;
            return format._createDemuxer(this);
          }
        }
        throw new Error("Input has an unsupported or unrecognizable format.");
      })();
    }
    /**
     * Returns the source from which this input file reads its data. This is the same source that was passed to the
     * constructor.
     */
    get source() {
      return this._source;
    }
    /**
     * Returns the format of the input file. You can compare this result directly to the InputFormat singletons or use
     * `instanceof` checks for subset-aware logic (for example, `format instanceof MatroskaInputFormat` is true for
     * both MKV and WebM).
     */
    async getFormat() {
      await this._getDemuxer();
      assert(this._format);
      return this._format;
    }
    /**
     * Computes the duration of the input file, in seconds. More precisely, returns the largest end timestamp among
     * all tracks.
     */
    async computeDuration() {
      const demuxer = await this._getDemuxer();
      return demuxer.computeDuration();
    }
    /** Returns the list of all tracks of this input file. */
    async getTracks() {
      const demuxer = await this._getDemuxer();
      return demuxer.getTracks();
    }
    /** Returns the list of all video tracks of this input file. */
    async getVideoTracks() {
      const tracks = await this.getTracks();
      return tracks.filter((x) => x.isVideoTrack());
    }
    /** Returns the primary video track of this input file, or null if there are no video tracks. */
    async getPrimaryVideoTrack() {
      const tracks = await this.getTracks();
      return tracks.find((x) => x.isVideoTrack()) ?? null;
    }
    /** Returns the list of all audio tracks of this input file. */
    async getAudioTracks() {
      const tracks = await this.getTracks();
      return tracks.filter((x) => x.isAudioTrack());
    }
    /** Returns the primary audio track of this input file, or null if there are no audio tracks. */
    async getPrimaryAudioTrack() {
      const tracks = await this.getTracks();
      return tracks.find((x) => x.isAudioTrack()) ?? null;
    }
    /** Returns the full MIME type of this input file, including track codecs. */
    async getMimeType() {
      const demuxer = await this._getDemuxer();
      return demuxer.getMimeType();
    }
  };

  // src/conversion.ts
  var validateVideoOptions = (videoOptions) => {
    if (videoOptions !== void 0 && (!videoOptions || typeof videoOptions !== "object")) {
      throw new TypeError("options.video, when provided, must be an object.");
    }
    if (videoOptions?.discard !== void 0 && typeof videoOptions.discard !== "boolean") {
      throw new TypeError("options.video.discard, when provided, must be a boolean.");
    }
    if (videoOptions?.forceTranscode !== void 0 && typeof videoOptions.forceTranscode !== "boolean") {
      throw new TypeError("options.video.forceTranscode, when provided, must be a boolean.");
    }
    if (videoOptions?.codec !== void 0 && !VIDEO_CODECS.includes(videoOptions.codec)) {
      throw new TypeError(
        `options.video.codec, when provided, must be one of: ${VIDEO_CODECS.join(", ")}.`
      );
    }
    if (videoOptions?.bitrate !== void 0 && !(videoOptions.bitrate instanceof Quality) && (!Number.isInteger(videoOptions.bitrate) || videoOptions.bitrate <= 0)) {
      throw new TypeError("options.video.bitrate, when provided, must be a positive integer or a quality.");
    }
    if (videoOptions?.width !== void 0 && (!Number.isInteger(videoOptions.width) || videoOptions.width <= 0)) {
      throw new TypeError("options.video.width, when provided, must be a positive integer.");
    }
    if (videoOptions?.height !== void 0 && (!Number.isInteger(videoOptions.height) || videoOptions.height <= 0)) {
      throw new TypeError("options.video.height, when provided, must be a positive integer.");
    }
    if (videoOptions?.fit !== void 0 && !["fill", "contain", "cover"].includes(videoOptions.fit)) {
      throw new TypeError('options.video.fit, when provided, must be one of "fill", "contain", or "cover".');
    }
    if (videoOptions?.width !== void 0 && videoOptions.height !== void 0 && videoOptions.fit === void 0) {
      throw new TypeError(
        "When both options.video.width and options.video.height are provided, options.video.fit must also be provided."
      );
    }
    if (videoOptions?.rotate !== void 0 && ![0, 90, 180, 270].includes(videoOptions.rotate)) {
      throw new TypeError("options.video.rotate, when provided, must be 0, 90, 180 or 270.");
    }
    if (videoOptions?.frameRate !== void 0 && (!Number.isFinite(videoOptions.frameRate) || videoOptions.frameRate <= 0)) {
      throw new TypeError("options.video.frameRate, when provided, must be a finite positive number.");
    }
  };
  var validateAudioOptions = (audioOptions) => {
    if (audioOptions !== void 0 && (!audioOptions || typeof audioOptions !== "object")) {
      throw new TypeError("options.audio, when provided, must be an object.");
    }
    if (audioOptions?.discard !== void 0 && typeof audioOptions.discard !== "boolean") {
      throw new TypeError("options.audio.discard, when provided, must be a boolean.");
    }
    if (audioOptions?.forceTranscode !== void 0 && typeof audioOptions.forceTranscode !== "boolean") {
      throw new TypeError("options.audio.forceTranscode, when provided, must be a boolean.");
    }
    if (audioOptions?.codec !== void 0 && !AUDIO_CODECS.includes(audioOptions.codec)) {
      throw new TypeError(
        `options.audio.codec, when provided, must be one of: ${AUDIO_CODECS.join(", ")}.`
      );
    }
    if (audioOptions?.bitrate !== void 0 && !(audioOptions.bitrate instanceof Quality) && (!Number.isInteger(audioOptions.bitrate) || audioOptions.bitrate <= 0)) {
      throw new TypeError("options.audio.bitrate, when provided, must be a positive integer or a quality.");
    }
    if (audioOptions?.numberOfChannels !== void 0 && (!Number.isInteger(audioOptions.numberOfChannels) || audioOptions.numberOfChannels <= 0)) {
      throw new TypeError("options.audio.numberOfChannels, when provided, must be a positive integer.");
    }
    if (audioOptions?.sampleRate !== void 0 && (!Number.isInteger(audioOptions.sampleRate) || audioOptions.sampleRate <= 0)) {
      throw new TypeError("options.audio.sampleRate, when provided, must be a positive integer.");
    }
  };
  var FALLBACK_NUMBER_OF_CHANNELS = 2;
  var FALLBACK_SAMPLE_RATE = 48e3;
  var Conversion = class _Conversion {
    constructor(options) {
      /** @internal */
      this._addedCounts = {
        video: 0,
        audio: 0,
        subtitle: 0
      };
      /** @internal */
      this._totalTrackCount = 0;
      /** @internal */
      this._trackPromises = [];
      /** @internal */
      this._executed = false;
      /** @internal */
      this._synchronizer = new TrackSynchronizer();
      /** @internal */
      this._totalDuration = null;
      /** @internal */
      this._maxTimestamps = /* @__PURE__ */ new Map();
      // Track ID -> timestamp
      /** @internal */
      this._canceled = false;
      /**
       * A callback that is fired whenever the conversion progresses. Returns a number between 0 and 1, indicating the
       * completion of the conversion. Note that a progress of 1 doesn't necessarily mean the conversion is complete;
       * the conversion is complete once `execute` resolves.
       *
       * In order for progress to be computed, this property must be set before `execute` is called.
       */
      this.onProgress = void 0;
      /** @internal */
      this._computeProgress = false;
      /** @internal */
      this._lastProgress = 0;
      /** The list of tracks that are included in the output file. */
      this.utilizedTracks = [];
      /** The list of tracks from the input file that have been discarded, alongside the discard reason. */
      this.discardedTracks = [];
      if (!options || typeof options !== "object") {
        throw new TypeError("options must be an object.");
      }
      if (!(options.input instanceof Input)) {
        throw new TypeError("options.input must be an Input.");
      }
      if (!(options.output instanceof Output)) {
        throw new TypeError("options.output must be an Output.");
      }
      if (options.output._tracks.length > 0 || options.output.state !== "pending") {
        throw new TypeError("options.output must be fresh: no tracks added and not started.");
      }
      if (typeof options.video !== "function") {
        validateVideoOptions(options.video);
      } else {
      }
      if (typeof options.audio !== "function") {
        validateAudioOptions(options.audio);
      } else {
      }
      if (options.trim !== void 0 && (!options.trim || typeof options.trim !== "object")) {
        throw new TypeError("options.trim, when provided, must be an object.");
      }
      if (options.trim?.start !== void 0 && (!Number.isFinite(options.trim.start) || options.trim.start < 0)) {
        throw new TypeError("options.trim.start, when provided, must be a non-negative number.");
      }
      if (options.trim?.end !== void 0 && (!Number.isFinite(options.trim.end) || options.trim.end < 0)) {
        throw new TypeError("options.trim.end, when provided, must be a non-negative number.");
      }
      if (options.trim?.start !== void 0 && options.trim.end !== void 0 && options.trim.start >= options.trim.end) {
        throw new TypeError("options.trim.start must be less than options.trim.end.");
      }
      this._options = options;
      this.input = options.input;
      this.output = options.output;
      this._startTimestamp = options.trim?.start ?? 0;
      this._endTimestamp = options.trim?.end ?? Infinity;
      const { promise: started, resolve: start } = promiseWithResolvers();
      this._started = started;
      this._start = start;
    }
    /** Initializes a new conversion process without starting the conversion. */
    static async init(options) {
      const conversion = new _Conversion(options);
      await conversion._init();
      return conversion;
    }
    /** @internal */
    async _init() {
      const inputTracks = await this.input.getTracks();
      const outputTrackCounts = this.output.format.getSupportedTrackCounts();
      let nVideo = 1;
      let nAudio = 1;
      for (const track of inputTracks) {
        let trackOptions = void 0;
        if (track.isVideoTrack()) {
          if (this._options.video) {
            if (typeof this._options.video === "function") {
              trackOptions = await this._options.video(track, nVideo);
              validateVideoOptions(trackOptions);
              nVideo++;
            } else {
              trackOptions = this._options.video;
            }
          }
        } else if (track.isAudioTrack()) {
          if (this._options.audio) {
            if (typeof this._options.audio === "function") {
              trackOptions = await this._options.audio(track, nAudio);
              validateAudioOptions(trackOptions);
              nAudio++;
            } else {
              trackOptions = this._options.audio;
            }
          }
        } else {
          assert(false);
        }
        if (trackOptions?.discard) {
          this.discardedTracks.push({
            track,
            reason: "discarded_by_user"
          });
          continue;
        }
        if (this._totalTrackCount === outputTrackCounts.total.max) {
          this.discardedTracks.push({
            track,
            reason: "max_track_count_reached"
          });
          continue;
        }
        if (this._addedCounts[track.type] === outputTrackCounts[track.type].max) {
          this.discardedTracks.push({
            track,
            reason: "max_track_count_of_type_reached"
          });
          continue;
        }
        if (track.isVideoTrack()) {
          await this._processVideoTrack(track, trackOptions ?? {});
        } else if (track.isAudioTrack()) {
          await this._processAudioTrack(track, trackOptions ?? {});
        }
      }
      const unintentionallyDiscardedTracks = this.discardedTracks.filter((x) => x.reason !== "discarded_by_user");
      if (unintentionallyDiscardedTracks.length > 0) {
        console.warn("Some tracks had to be discarded from the conversion:", unintentionallyDiscardedTracks);
      }
    }
    /** Executes the conversion process. Resolves once conversion is complete. */
    async execute() {
      if (this._executed) {
        throw new Error("Conversion cannot be executed twice.");
      }
      this._executed = true;
      if (this.onProgress) {
        this._computeProgress = true;
        this._totalDuration = Math.min(
          await this.input.computeDuration() - this._startTimestamp,
          this._endTimestamp - this._startTimestamp
        );
        this.onProgress?.(0);
      }
      await this.output.start();
      this._start();
      try {
        await Promise.all(this._trackPromises);
      } catch (error) {
        if (!this._canceled) {
          void this.cancel();
        }
        throw error;
      }
      if (this._canceled) {
        await new Promise(() => {
        });
      }
      await this.output.finalize();
      if (this._computeProgress) {
        this.onProgress?.(1);
      }
    }
    /** Cancels the conversion process. Does nothing if the conversion is already complete. */
    async cancel() {
      if (this.output.state === "finalizing" || this.output.state === "finalized") {
        return;
      }
      if (this._canceled) {
        console.warn("Conversion already canceled.");
        return;
      }
      this._canceled = true;
      await this.output.cancel();
    }
    /** @internal */
    async _processVideoTrack(track, trackOptions) {
      const sourceCodec = track.codec;
      if (!sourceCodec) {
        this.discardedTracks.push({
          track,
          reason: "unknown_source_codec"
        });
        return;
      }
      let videoSource;
      const totalRotation = normalizeRotation(track.rotation + (trackOptions.rotate ?? 0));
      const outputSupportsRotation = this.output.format.supportsVideoRotationMetadata;
      const [originalWidth, originalHeight] = totalRotation % 180 === 0 ? [track.codedWidth, track.codedHeight] : [track.codedHeight, track.codedWidth];
      let width = originalWidth;
      let height = originalHeight;
      const aspectRatio = width / height;
      const ceilToMultipleOfTwo = (value) => Math.ceil(value / 2) * 2;
      if (trackOptions.width !== void 0 && trackOptions.height === void 0) {
        width = ceilToMultipleOfTwo(trackOptions.width);
        height = ceilToMultipleOfTwo(Math.round(width / aspectRatio));
      } else if (trackOptions.width === void 0 && trackOptions.height !== void 0) {
        height = ceilToMultipleOfTwo(trackOptions.height);
        width = ceilToMultipleOfTwo(Math.round(height * aspectRatio));
      } else if (trackOptions.width !== void 0 && trackOptions.height !== void 0) {
        width = ceilToMultipleOfTwo(trackOptions.width);
        height = ceilToMultipleOfTwo(trackOptions.height);
      }
      const firstTimestamp = await track.getFirstTimestamp();
      const needsTranscode = !!trackOptions.forceTranscode || this._startTimestamp > 0 || firstTimestamp < 0 || !!trackOptions.frameRate;
      const needsRerender = width !== originalWidth || height !== originalHeight || totalRotation !== 0 && !outputSupportsRotation;
      let videoCodecs = this.output.format.getSupportedVideoCodecs();
      if (!needsTranscode && !trackOptions.bitrate && !needsRerender && videoCodecs.includes(sourceCodec) && (!trackOptions.codec || trackOptions.codec === sourceCodec)) {
        const source = new EncodedVideoPacketSource(sourceCodec);
        videoSource = source;
        this._trackPromises.push((async () => {
          await this._started;
          const sink = new EncodedPacketSink(track);
          const decoderConfig = await track.getDecoderConfig();
          const meta = { decoderConfig: decoderConfig ?? void 0 };
          const endPacket = Number.isFinite(this._endTimestamp) ? await sink.getPacket(this._endTimestamp, { metadataOnly: true }) ?? void 0 : void 0;
          for await (const packet of sink.packets(void 0, endPacket, { verifyKeyPackets: true })) {
            if (this._synchronizer.shouldWait(track.id, packet.timestamp)) {
              await this._synchronizer.wait(packet.timestamp);
            }
            if (this._canceled) {
              return;
            }
            await source.add(packet, meta);
            this._reportProgress(track.id, packet.timestamp + packet.duration);
          }
          source.close();
          this._synchronizer.closeTrack(track.id);
        })());
      } else {
        const canDecode = await track.canDecode();
        if (!canDecode) {
          this.discardedTracks.push({
            track,
            reason: "undecodable_source_codec"
          });
          return;
        }
        if (trackOptions.codec) {
          videoCodecs = videoCodecs.filter((codec) => codec === trackOptions.codec);
        }
        const bitrate = trackOptions.bitrate ?? QUALITY_HIGH;
        const encodableCodec = await getFirstEncodableVideoCodec(videoCodecs, { width, height, bitrate });
        if (!encodableCodec) {
          this.discardedTracks.push({
            track,
            reason: "no_encodable_target_codec"
          });
          return;
        }
        const encodingConfig = {
          codec: encodableCodec,
          bitrate,
          onEncodedPacket: (sample) => this._reportProgress(track.id, sample.timestamp + sample.duration)
        };
        const source = new VideoSampleSource(encodingConfig);
        videoSource = source;
        if (needsRerender) {
          this._trackPromises.push((async () => {
            await this._started;
            const sink = new CanvasSink(track, {
              width,
              height,
              fit: trackOptions.fit ?? "fill",
              rotation: totalRotation,
              // Bake the rotation into the output
              poolSize: 1
            });
            const iterator = sink.canvases(this._startTimestamp, this._endTimestamp);
            const frameRate = trackOptions.frameRate;
            let lastCanvas = null;
            let lastCanvasTimestamp = null;
            let lastCanvasEndTimestamp = null;
            const padFrames = async (until) => {
              assert(lastCanvas);
              assert(frameRate !== void 0);
              const frameDifference = Math.round((until - lastCanvasTimestamp) * frameRate);
              for (let i = 1; i < frameDifference; i++) {
                const sample = new VideoSample(lastCanvas, {
                  timestamp: lastCanvasTimestamp + i / frameRate,
                  duration: 1 / frameRate
                });
                await source.add(sample);
              }
            };
            for await (const { canvas, timestamp, duration } of iterator) {
              if (this._synchronizer.shouldWait(track.id, timestamp)) {
                await this._synchronizer.wait(timestamp);
              }
              if (this._canceled) {
                return;
              }
              let adjustedSampleTimestamp = Math.max(timestamp - this._startTimestamp, 0);
              lastCanvasEndTimestamp = timestamp + duration;
              if (frameRate !== void 0) {
                const alignedTimestamp = Math.floor(adjustedSampleTimestamp * frameRate) / frameRate;
                if (lastCanvas !== null) {
                  if (alignedTimestamp <= lastCanvasTimestamp) {
                    lastCanvas = canvas;
                    lastCanvasTimestamp = alignedTimestamp;
                    continue;
                  } else {
                    await padFrames(alignedTimestamp);
                  }
                }
                adjustedSampleTimestamp = alignedTimestamp;
              }
              const sample = new VideoSample(canvas, {
                timestamp: adjustedSampleTimestamp,
                duration: frameRate !== void 0 ? 1 / frameRate : duration
              });
              await source.add(sample);
              if (frameRate !== void 0) {
                lastCanvas = canvas;
                lastCanvasTimestamp = adjustedSampleTimestamp;
              } else {
                sample.close();
              }
            }
            if (lastCanvas) {
              assert(lastCanvasEndTimestamp !== null);
              assert(frameRate !== void 0);
              await padFrames(Math.floor(lastCanvasEndTimestamp * frameRate) / frameRate);
            }
            source.close();
            this._synchronizer.closeTrack(track.id);
          })());
        } else {
          this._trackPromises.push((async () => {
            await this._started;
            const sink = new VideoSampleSink(track);
            const frameRate = trackOptions.frameRate;
            let lastSample = null;
            let lastSampleTimestamp = null;
            let lastSampleEndTimestamp = null;
            const padFrames = async (until) => {
              assert(lastSample);
              assert(frameRate !== void 0);
              const frameDifference = Math.round((until - lastSampleTimestamp) * frameRate);
              for (let i = 1; i < frameDifference; i++) {
                lastSample.setTimestamp(lastSampleTimestamp + i / frameRate);
                lastSample.setDuration(1 / frameRate);
                await source.add(lastSample);
              }
              lastSample.close();
            };
            for await (const sample of sink.samples(this._startTimestamp, this._endTimestamp)) {
              if (this._synchronizer.shouldWait(track.id, sample.timestamp)) {
                await this._synchronizer.wait(sample.timestamp);
              }
              if (this._canceled) {
                lastSample?.close();
                return;
              }
              let adjustedSampleTimestamp = Math.max(sample.timestamp - this._startTimestamp, 0);
              lastSampleEndTimestamp = sample.timestamp + sample.duration;
              if (frameRate !== void 0) {
                const alignedTimestamp = Math.floor(adjustedSampleTimestamp * frameRate) / frameRate;
                if (lastSample !== null) {
                  if (alignedTimestamp <= lastSampleTimestamp) {
                    lastSample.close();
                    lastSample = sample;
                    lastSampleTimestamp = alignedTimestamp;
                    continue;
                  } else {
                    await padFrames(alignedTimestamp);
                  }
                }
                adjustedSampleTimestamp = alignedTimestamp;
                sample.setDuration(1 / frameRate);
              }
              sample.setTimestamp(adjustedSampleTimestamp);
              await source.add(sample);
              if (frameRate !== void 0) {
                lastSample = sample;
                lastSampleTimestamp = adjustedSampleTimestamp;
              } else {
                sample.close();
              }
            }
            if (lastSample) {
              assert(lastSampleEndTimestamp !== null);
              assert(frameRate !== void 0);
              await padFrames(Math.floor(lastSampleEndTimestamp * frameRate) / frameRate);
            }
            source.close();
            this._synchronizer.closeTrack(track.id);
          })());
        }
      }
      this.output.addVideoTrack(videoSource, {
        frameRate: trackOptions.frameRate,
        languageCode: track.languageCode,
        rotation: needsRerender ? 0 : totalRotation
        // Rerendering will bake the rotation into the output
      });
      this._addedCounts.video++;
      this._totalTrackCount++;
      this.utilizedTracks.push(track);
    }
    /** @internal */
    async _processAudioTrack(track, trackOptions) {
      const sourceCodec = track.codec;
      if (!sourceCodec) {
        this.discardedTracks.push({
          track,
          reason: "unknown_source_codec"
        });
        return;
      }
      let audioSource;
      const originalNumberOfChannels = track.numberOfChannels;
      const originalSampleRate = track.sampleRate;
      const firstTimestamp = await track.getFirstTimestamp();
      let numberOfChannels = trackOptions.numberOfChannels ?? originalNumberOfChannels;
      let sampleRate = trackOptions.sampleRate ?? originalSampleRate;
      let needsResample = numberOfChannels !== originalNumberOfChannels || sampleRate !== originalSampleRate || this._startTimestamp > 0 || firstTimestamp < 0;
      let audioCodecs = this.output.format.getSupportedAudioCodecs();
      if (!trackOptions.forceTranscode && !trackOptions.bitrate && !needsResample && audioCodecs.includes(sourceCodec) && (!trackOptions.codec || trackOptions.codec === sourceCodec)) {
        const source = new EncodedAudioPacketSource(sourceCodec);
        audioSource = source;
        this._trackPromises.push((async () => {
          await this._started;
          const sink = new EncodedPacketSink(track);
          const decoderConfig = await track.getDecoderConfig();
          const meta = { decoderConfig: decoderConfig ?? void 0 };
          const endPacket = Number.isFinite(this._endTimestamp) ? await sink.getPacket(this._endTimestamp, { metadataOnly: true }) ?? void 0 : void 0;
          for await (const packet of sink.packets(void 0, endPacket)) {
            if (this._synchronizer.shouldWait(track.id, packet.timestamp)) {
              await this._synchronizer.wait(packet.timestamp);
            }
            if (this._canceled) {
              return;
            }
            await source.add(packet, meta);
            this._reportProgress(track.id, packet.timestamp + packet.duration);
          }
          source.close();
          this._synchronizer.closeTrack(track.id);
        })());
      } else {
        const canDecode = await track.canDecode();
        if (!canDecode) {
          this.discardedTracks.push({
            track,
            reason: "undecodable_source_codec"
          });
          return;
        }
        let codecOfChoice = null;
        if (trackOptions.codec) {
          audioCodecs = audioCodecs.filter((codec) => codec === trackOptions.codec);
        }
        const bitrate = trackOptions.bitrate ?? QUALITY_HIGH;
        const encodableCodecs = await getEncodableAudioCodecs(audioCodecs, {
          numberOfChannels,
          sampleRate,
          bitrate
        });
        if (!encodableCodecs.some((codec) => NON_PCM_AUDIO_CODECS.includes(codec)) && audioCodecs.some((codec) => NON_PCM_AUDIO_CODECS.includes(codec)) && (numberOfChannels !== FALLBACK_NUMBER_OF_CHANNELS || sampleRate !== FALLBACK_SAMPLE_RATE)) {
          const encodableCodecsWithDefaultParams = await getEncodableAudioCodecs(audioCodecs, {
            numberOfChannels: FALLBACK_NUMBER_OF_CHANNELS,
            sampleRate: FALLBACK_SAMPLE_RATE,
            bitrate
          });
          const nonPcmCodec = encodableCodecsWithDefaultParams.find((codec) => NON_PCM_AUDIO_CODECS.includes(codec));
          if (nonPcmCodec) {
            needsResample = true;
            codecOfChoice = nonPcmCodec;
            numberOfChannels = FALLBACK_NUMBER_OF_CHANNELS;
            sampleRate = FALLBACK_SAMPLE_RATE;
          }
        } else {
          codecOfChoice = encodableCodecs[0] ?? null;
        }
        if (codecOfChoice === null) {
          this.discardedTracks.push({
            track,
            reason: "no_encodable_target_codec"
          });
          return;
        }
        if (needsResample) {
          audioSource = this._resampleAudio(track, codecOfChoice, numberOfChannels, sampleRate, bitrate);
        } else {
          const source = new AudioSampleSource({
            codec: codecOfChoice,
            bitrate,
            onEncodedPacket: (packet) => this._reportProgress(track.id, packet.timestamp + packet.duration)
          });
          audioSource = source;
          this._trackPromises.push((async () => {
            await this._started;
            const sink = new AudioSampleSink(track);
            for await (const sample of sink.samples(void 0, this._endTimestamp)) {
              if (this._synchronizer.shouldWait(track.id, sample.timestamp)) {
                await this._synchronizer.wait(sample.timestamp);
              }
              if (this._canceled) {
                return;
              }
              await source.add(sample);
              sample.close();
            }
            source.close();
            this._synchronizer.closeTrack(track.id);
          })());
        }
      }
      this.output.addAudioTrack(audioSource, {
        languageCode: track.languageCode
      });
      this._addedCounts.audio++;
      this._totalTrackCount++;
      this.utilizedTracks.push(track);
    }
    /** @internal */
    _resampleAudio(track, codec, targetNumberOfChannels, targetSampleRate, bitrate) {
      const source = new AudioSampleSource({
        codec,
        bitrate,
        onEncodedPacket: (packet) => this._reportProgress(track.id, packet.timestamp + packet.duration)
      });
      this._trackPromises.push((async () => {
        await this._started;
        const resampler = new AudioResampler({
          sourceNumberOfChannels: track.numberOfChannels,
          sourceSampleRate: track.sampleRate,
          targetNumberOfChannels,
          targetSampleRate,
          startTime: this._startTimestamp,
          endTime: this._endTimestamp,
          onSample: (sample) => source.add(sample)
        });
        const sink = new AudioSampleSink(track);
        const iterator = sink.samples(this._startTimestamp, this._endTimestamp);
        for await (const sample of iterator) {
          if (this._synchronizer.shouldWait(track.id, sample.timestamp)) {
            await this._synchronizer.wait(sample.timestamp);
          }
          if (this._canceled) {
            return;
          }
          await resampler.add(sample);
        }
        await resampler.finalize();
        source.close();
        this._synchronizer.closeTrack(track.id);
      })());
      return source;
    }
    /** @internal */
    _reportProgress(trackId, endTimestamp) {
      if (!this._computeProgress) {
        return;
      }
      assert(this._totalDuration !== null);
      this._maxTimestamps.set(trackId, Math.max(endTimestamp, this._maxTimestamps.get(trackId) ?? -Infinity));
      let totalTimestamps = 0;
      for (const [, timestamp] of this._maxTimestamps) {
        totalTimestamps += timestamp;
      }
      const averageTimestamp = totalTimestamps / this._totalTrackCount;
      const newProgress = clamp(averageTimestamp / this._totalDuration, 0, 1);
      if (newProgress !== this._lastProgress) {
        this._lastProgress = newProgress;
        this.onProgress?.(newProgress);
      }
    }
  };
  var MAX_TIMESTAMP_GAP = 5;
  var TrackSynchronizer = class {
    constructor() {
      this.maxTimestamps = /* @__PURE__ */ new Map();
      // Track ID -> timestamp
      this.resolvers = [];
    }
    computeMinAndMaybeResolve() {
      let newMin = Infinity;
      for (const [, timestamp] of this.maxTimestamps) {
        newMin = Math.min(newMin, timestamp);
      }
      for (let i = 0; i < this.resolvers.length; i++) {
        const entry = this.resolvers[i];
        if (entry.timestamp - newMin < MAX_TIMESTAMP_GAP) {
          entry.resolve();
          this.resolvers.splice(i, 1);
          i--;
        }
      }
      return newMin;
    }
    shouldWait(trackId, timestamp) {
      this.maxTimestamps.set(trackId, Math.max(timestamp, this.maxTimestamps.get(trackId) ?? -Infinity));
      const newMin = this.computeMinAndMaybeResolve();
      return timestamp - newMin >= MAX_TIMESTAMP_GAP;
    }
    wait(timestamp) {
      const { promise, resolve } = promiseWithResolvers();
      this.resolvers.push({
        timestamp,
        resolve
      });
      return promise;
    }
    closeTrack(trackId) {
      this.maxTimestamps.delete(trackId);
      this.computeMinAndMaybeResolve();
    }
  };
  var AudioResampler = class {
    constructor(options) {
      this.sourceSampleRate = options.sourceSampleRate;
      this.targetSampleRate = options.targetSampleRate;
      this.sourceNumberOfChannels = options.sourceNumberOfChannels;
      this.targetNumberOfChannels = options.targetNumberOfChannels;
      this.startTime = options.startTime;
      this.endTime = options.endTime;
      this.onSample = options.onSample;
      this.bufferSizeInFrames = Math.floor(this.targetSampleRate * 5);
      this.bufferSizeInSamples = this.bufferSizeInFrames * this.targetNumberOfChannels;
      this.outputBuffer = new Float32Array(this.bufferSizeInSamples);
      this.bufferStartFrame = 0;
      this.maxWrittenFrame = -1;
      this.setupChannelMixer();
      this.tempSourceBuffer = new Float32Array(this.sourceSampleRate * this.sourceNumberOfChannels);
    }
    /**
     * Sets up the channel mixer to handle up/downmixing in the case where input and output channel counts don't match.
     */
    setupChannelMixer() {
      const sourceNum = this.sourceNumberOfChannels;
      const targetNum = this.targetNumberOfChannels;
      if (sourceNum === 1 && targetNum === 2) {
        this.channelMixer = (sourceData, sourceFrameIndex) => {
          return sourceData[sourceFrameIndex * sourceNum];
        };
      } else if (sourceNum === 1 && targetNum === 4) {
        this.channelMixer = (sourceData, sourceFrameIndex, targetChannelIndex) => {
          return sourceData[sourceFrameIndex * sourceNum] * +(targetChannelIndex < 2);
        };
      } else if (sourceNum === 1 && targetNum === 6) {
        this.channelMixer = (sourceData, sourceFrameIndex, targetChannelIndex) => {
          return sourceData[sourceFrameIndex * sourceNum] * +(targetChannelIndex === 2);
        };
      } else if (sourceNum === 2 && targetNum === 1) {
        this.channelMixer = (sourceData, sourceFrameIndex) => {
          const baseIdx = sourceFrameIndex * sourceNum;
          return 0.5 * (sourceData[baseIdx] + sourceData[baseIdx + 1]);
        };
      } else if (sourceNum === 2 && targetNum === 4) {
        this.channelMixer = (sourceData, sourceFrameIndex, targetChannelIndex) => {
          return sourceData[sourceFrameIndex * sourceNum + targetChannelIndex] * +(targetChannelIndex < 2);
        };
      } else if (sourceNum === 2 && targetNum === 6) {
        this.channelMixer = (sourceData, sourceFrameIndex, targetChannelIndex) => {
          return sourceData[sourceFrameIndex * sourceNum + targetChannelIndex] * +(targetChannelIndex < 2);
        };
      } else if (sourceNum === 4 && targetNum === 1) {
        this.channelMixer = (sourceData, sourceFrameIndex) => {
          const baseIdx = sourceFrameIndex * sourceNum;
          return 0.25 * (sourceData[baseIdx] + sourceData[baseIdx + 1] + sourceData[baseIdx + 2] + sourceData[baseIdx + 3]);
        };
      } else if (sourceNum === 4 && targetNum === 2) {
        this.channelMixer = (sourceData, sourceFrameIndex, targetChannelIndex) => {
          const baseIdx = sourceFrameIndex * sourceNum;
          return 0.5 * (sourceData[baseIdx + targetChannelIndex] + sourceData[baseIdx + targetChannelIndex + 2]);
        };
      } else if (sourceNum === 4 && targetNum === 6) {
        this.channelMixer = (sourceData, sourceFrameIndex, targetChannelIndex) => {
          const baseIdx = sourceFrameIndex * sourceNum;
          if (targetChannelIndex < 2) return sourceData[baseIdx + targetChannelIndex];
          if (targetChannelIndex === 2 || targetChannelIndex === 3) return 0;
          return sourceData[baseIdx + targetChannelIndex - 2];
        };
      } else if (sourceNum === 6 && targetNum === 1) {
        this.channelMixer = (sourceData, sourceFrameIndex) => {
          const baseIdx = sourceFrameIndex * sourceNum;
          return Math.SQRT1_2 * (sourceData[baseIdx] + sourceData[baseIdx + 1]) + sourceData[baseIdx + 2] + 0.5 * (sourceData[baseIdx + 4] + sourceData[baseIdx + 5]);
        };
      } else if (sourceNum === 6 && targetNum === 2) {
        this.channelMixer = (sourceData, sourceFrameIndex, targetChannelIndex) => {
          const baseIdx = sourceFrameIndex * sourceNum;
          return sourceData[baseIdx + targetChannelIndex] + Math.SQRT1_2 * (sourceData[baseIdx + 2] + sourceData[baseIdx + targetChannelIndex + 4]);
        };
      } else if (sourceNum === 6 && targetNum === 4) {
        this.channelMixer = (sourceData, sourceFrameIndex, targetChannelIndex) => {
          const baseIdx = sourceFrameIndex * sourceNum;
          if (targetChannelIndex < 2) {
            return sourceData[baseIdx + targetChannelIndex] + Math.SQRT1_2 * sourceData[baseIdx + 2];
          }
          return sourceData[baseIdx + targetChannelIndex + 2];
        };
      } else {
        this.channelMixer = (sourceData, sourceFrameIndex, targetChannelIndex) => {
          return targetChannelIndex < sourceNum ? sourceData[sourceFrameIndex * sourceNum + targetChannelIndex] : 0;
        };
      }
    }
    ensureTempBufferSize(requiredSamples) {
      let length = this.tempSourceBuffer.length;
      while (length < requiredSamples) {
        length *= 2;
      }
      if (length !== this.tempSourceBuffer.length) {
        const newBuffer = new Float32Array(length);
        newBuffer.set(this.tempSourceBuffer);
        this.tempSourceBuffer = newBuffer;
      }
    }
    async add(audioSample) {
      if (!audioSample || audioSample._closed) {
        return;
      }
      const requiredSamples = audioSample.numberOfFrames * audioSample.numberOfChannels;
      this.ensureTempBufferSize(requiredSamples);
      const sourceDataSize = audioSample.allocationSize({ planeIndex: 0, format: "f32" });
      const sourceView = new Float32Array(this.tempSourceBuffer.buffer, 0, sourceDataSize / 4);
      audioSample.copyTo(sourceView, { planeIndex: 0, format: "f32" });
      const inputStartTime = audioSample.timestamp - this.startTime;
      const inputDuration = audioSample.numberOfFrames / this.sourceSampleRate;
      const inputEndTime = Math.min(inputStartTime + inputDuration, this.endTime - this.startTime);
      const outputStartFrame = Math.floor(inputStartTime * this.targetSampleRate);
      const outputEndFrame = Math.ceil(inputEndTime * this.targetSampleRate);
      for (let outputFrame = outputStartFrame; outputFrame < outputEndFrame; outputFrame++) {
        if (outputFrame < this.bufferStartFrame) {
          continue;
        }
        while (outputFrame >= this.bufferStartFrame + this.bufferSizeInFrames) {
          await this.finalizeCurrentBuffer();
          this.bufferStartFrame += this.bufferSizeInFrames;
        }
        const bufferFrameIndex = outputFrame - this.bufferStartFrame;
        assert(bufferFrameIndex < this.bufferSizeInFrames);
        const outputTime = outputFrame / this.targetSampleRate;
        const inputTime = outputTime - inputStartTime;
        const sourcePosition = inputTime * this.sourceSampleRate;
        const sourceLowerFrame = Math.floor(sourcePosition);
        const sourceUpperFrame = Math.ceil(sourcePosition);
        const fraction = sourcePosition - sourceLowerFrame;
        for (let targetChannel = 0; targetChannel < this.targetNumberOfChannels; targetChannel++) {
          let lowerSample = 0;
          let upperSample = 0;
          if (sourceLowerFrame >= 0 && sourceLowerFrame < audioSample.numberOfFrames) {
            lowerSample = this.channelMixer(sourceView, sourceLowerFrame, targetChannel);
          }
          if (sourceUpperFrame >= 0 && sourceUpperFrame < audioSample.numberOfFrames) {
            upperSample = this.channelMixer(sourceView, sourceUpperFrame, targetChannel);
          }
          const outputSample = lowerSample + fraction * (upperSample - lowerSample);
          const outputIndex = bufferFrameIndex * this.targetNumberOfChannels + targetChannel;
          this.outputBuffer[outputIndex] += outputSample;
        }
        this.maxWrittenFrame = Math.max(this.maxWrittenFrame, bufferFrameIndex);
      }
    }
    async finalizeCurrentBuffer() {
      if (this.maxWrittenFrame < 0) {
        return;
      }
      const samplesWritten = (this.maxWrittenFrame + 1) * this.targetNumberOfChannels;
      const outputData = new Float32Array(samplesWritten);
      outputData.set(this.outputBuffer.subarray(0, samplesWritten));
      const timestampSeconds = this.bufferStartFrame / this.targetSampleRate;
      const audioSample = new AudioSample({
        format: "f32",
        sampleRate: this.targetSampleRate,
        numberOfChannels: this.targetNumberOfChannels,
        timestamp: timestampSeconds,
        data: outputData
      });
      await this.onSample(audioSample);
      this.outputBuffer.fill(0);
      this.maxWrittenFrame = -1;
    }
    finalize() {
      return this.finalizeCurrentBuffer();
    }
  };
  return __toCommonJS(index_exports);
})();
if ( true && typeof module.exports === "object") Object.assign(module.exports, Mediabunny)


/***/ }),

/***/ "./node_modules/@pucelle/ff/out/base/array.js":
/*!****************************************************!*\
  !*** ./node_modules/@pucelle/ff/out/base/array.js ***!
  \****************************************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.maxIndex = exports.minIndex = exports.max = exports.min = exports.avg = exports.sum = exports.count = exports.aggregate = exports.groupBy = exports.indexBy = exports.orderBy = exports.Order = exports.binaryFindIndexToInsert = exports.binaryFindIndex = exports.binaryFind = exports.difference = exports.intersect = exports.union = exports.unique = exports.removeWhere = exports.removeFirst = exports.remove = exports.add = exports.repeatTimes = void 0;
/**
 * Returns the array of `value` repeat for `count` times.
 * @param item The value to repeat.
 * @param count Count of times to repeat.
 */
function repeatTimes(item, count) {
    let items = [];
    for (let i = 0; i < count; i++) {
        items.push(item);
    }
    return items;
}
exports.repeatTimes = repeatTimes;
/**
 * Add items to `array`, duplicate items will not be added.
 * This method use `includes` to test if an item in array, so it doesn't fit for adding many items to a big array.
 * @param array The array to add items.
 * @param items The items to add to array.
 */
function add(array, ...items) {
    for (let item of items) {
        if (!array.includes(item)) {
            array.push(item);
        }
    }
    return array;
}
exports.add = add;
/**
 * Remove items from `array`. Returns the removed items.
 * Note that this method uses `splice` to remove items, so using `array.filter` to filter out multiple items would be better.
 * @param array The array to remove items.
 * @param items The items removed from array.
 */
function remove(array, ...items) {
    let removed = [];
    for (let item of items) {
        let index = array.indexOf(item);
        if (index > -1) {
            removed.push(...array.splice(index, 1));
        }
    }
    return removed;
}
exports.remove = remove;
/**
 * Remove the first item which match `fn` from `array`. Returns the removed items.
 * @param array The array to remove items.
 * @param fn The function which returns boolean values to determinae whether to remove item.
 */
function removeFirst(array, fn) {
    for (let i = array.length - 1; i >= 0; i--) {
        if (fn(array[i], i)) {
            return array.splice(i, 1)[0];
        }
    }
    return undefined;
}
exports.removeFirst = removeFirst;
/**
 * Remove all the items match `fn` from `array`. Returns the removed items.
 * Note that this method uses `splice` to remove items, so using `array.filter` to filter out multiple items would be better.
 * @param array The array to remove items.
 * @param fn The function which returns boolean values to determinae whether to remove item.
 */
function removeWhere(array, fn) {
    let removed = [];
    for (let i = 0; i < array.length; i++) {
        if (fn(array[i], i)) {
            removed.push(array.splice(i--, 1)[0]);
        }
    }
    return removed;
}
exports.removeWhere = removeWhere;
/**
 * Returns a new array from `array` but removes duplicate items.
 * @param array The array to remove duplicate items.
 */
function unique(array) {
    let set = new Set(array);
    return [...set];
}
exports.unique = unique;
/**
 * Creates an array composed of all the unique values from given `arrays`.
 * @param arrays The arrays to get union from.
 */
function union(...arrays) {
    let set = new Set();
    for (let array of arrays) {
        for (let item of array) {
            set.add(item);
        }
    }
    return [...set];
}
exports.union = union;
/**
 * Creates an array of unique values that are included in all given arrays.
 * @param arrays The arrays to get intersection from.
 */
function intersect(...arrays) {
    let interset = [];
    if (!arrays.length) {
        return interset;
    }
    let map = new Map();
    for (let item of arrays[0]) {
        map.set(item, 1);
    }
    for (let array of arrays.slice(1)) {
        for (let item of array) {
            if (map.has(item)) {
                map.set(item, map.get(item) + 1);
            }
        }
    }
    for (let [item, count] of map.entries()) {
        if (count === arrays.length) {
            interset.push(item);
        }
    }
    return interset;
}
exports.intersect = intersect;
/**
 * Creates a new array from given `array` but exclude items in `excludeArrays`.
 * @param array The array to include items.
 * @param excludeArrays The arrays to exclude items from.
 */
function difference(array, ...excludeArrays) {
    let set = new Set(array);
    for (let difArray of excludeArrays) {
        for (let item of difArray) {
            set.delete(item);
        }
    }
    return [...set];
}
exports.difference = difference;
/**
 * Using binary algorithm to find one item from a sorted array which match `fn`.
 * @param array The sorted array.
 * @param fn The function to accept item in array as argument and returns `-1` to move left, `1` to move right.
 */
function binaryFind(array, fn) {
    let index = binaryFindIndex(array, fn);
    return index === -1 ? undefined : array[index];
}
exports.binaryFind = binaryFind;
/**
 * Using binary algorithm to find index from a sorted array at where the item match `fn`.
 * @param array The sorted array.
 * @param fn The function to accept item in array as argument and returns `-1` to move left, `1` to move right.
 */
function binaryFindIndex(array, fn) {
    if (array.length === 0) {
        return -1;
    }
    let result = fn(array[0]);
    if (result === 0) {
        return 0;
    }
    if (result === -1) {
        return -1;
    }
    if (array.length === 1) {
        return -1;
    }
    result = fn(array[array.length - 1]);
    if (result === 0) {
        return array.length - 1;
    }
    if (result === 1) {
        return -1;
    }
    let start = 0;
    let end = array.length - 1;
    while (end - start > 1) {
        let center = Math.floor((end + start) / 2);
        let result = fn(array[center]);
        if (result === 0) {
            return center;
        }
        else if (result === -1) {
            end = center;
        }
        else {
            start = center;
        }
    }
    return -1;
}
exports.binaryFindIndex = binaryFindIndex;
/**
 * Using binary algorithm to find the closest index from a sorted array in where to insert new item and keep order.
 * Returned index betweens `0 ~ array.length`, and if `array[index]` exist, `fn(array[index]) >= 0`.
 * @param array The sorted array.
 * @param fn The function to accept item in array as argument and returns `-1` to move left, `1` to move right.
 */
function binaryFindIndexToInsert(array, fn) {
    if (array.length === 0) {
        return 0;
    }
    let result = fn(array[0]);
    if (result === 0 || result === -1) {
        return 0;
    }
    if (array.length === 1) {
        return 1;
    }
    result = fn(array[array.length - 1]);
    if (result === 0) {
        return array.length - 1;
    }
    if (result === 1) {
        return array.length;
    }
    let start = 0;
    let end = array.length - 1;
    while (end - start > 1) {
        let center = Math.floor((end + start) / 2);
        let result = fn(array[center]);
        if (result === 0) {
            return center;
        }
        else if (result === -1) {
            end = center;
        }
        else {
            start = center;
        }
    }
    return end;
}
exports.binaryFindIndexToInsert = binaryFindIndexToInsert;
class Order {
    /**
     * Create an order rule, used in `orderBy`, and can also be used to binary search from or binary insert into array with object type items
     * @param orders Rest arguments of type `key` or `OrderFunction` which will return a `key`, or [`key` / `OrderFunction`, `OrderDirection`].
     */
    constructor(...orders) {
        this.orders = [];
        for (let order of orders) {
            if (['string', 'number', 'function'].includes(typeof order)) {
                this.orders.push([order, 1]);
            }
            else if (Array.isArray(order) && ['string', 'number', 'function'].includes(typeof order[0])) {
                this.orders.push([order[0], order[1] === -1 || order[1] === 'desc' ? -1 : 1]);
            }
            else {
                throw new Error(JSON.stringify(orders) + ' doesn\'t specify any valid key or order.');
            }
        }
    }
    /**
     * Sort `array` inside by the order specified by current object.
     * @param array The array to sort.
     */
    sortArray(array) {
        array.sort((a, b) => this.compare(a, b));
    }
    /**
     * Compare two items.
     * When `order` is `1`: returns `0` if they are same; returns `-1` if the first one less that the second one; else returns `1`.
     * When `order` is `-1`: returns `0` if they are same; returns `1` if the first one less that the second one; else returns `-1`.
     * @param a First item.
     * @param b Second item.
     */
    compare(a, b) {
        for (let [keyOrFn, order] of this.orders) {
            let ai;
            let bi;
            if (typeof keyOrFn === 'function') {
                ai = keyOrFn(a);
                bi = keyOrFn(b);
            }
            else {
                ai = a[keyOrFn];
                bi = b[keyOrFn];
            }
            if (ai < bi) {
                return -order;
            }
            if (ai > bi) {
                return order;
            }
            if (ai !== bi) {
                return ai === null || ai === undefined ? -order : order;
            }
        }
        return 0;
    }
    /**
     * Binary find the index of `array` the value at where equals to `item`.
     * Returns `-1` if not found.
     * @param array The array to lookup.
     * @param item The item to search.
     */
    binaryFind(array, item) {
        return binaryFind(array, i => this.compare(item, i));
    }
    /**
     * Binary find an index of `array` to insert `item` and keep current order.
     * Returned value betweens `0 ~ array.length`.
     * @param array The array to lookup.
     * @param item The item to compare.
     */
    binaryFindIndex(array, item) {
        return binaryFindIndex(array, i => this.compare(item, i));
    }
    /**
     * Binary insert an `item` into `array` and keep current order.
     * @param array The array to lookup.
     * @param item The item to insert.
     */
    // `splice` is very slower since it reallocate memory frequently.
    // See https://jsperf.com/splice-vs-filter
    binaryInsert(array, item) {
        let index = binaryFindIndexToInsert(array, i => this.compare(item, i));
        array.splice(index, 0, item);
        return array;
    }
}
exports.Order = Order;
function orderBy(array, order, ...orders) {
    order = order instanceof Order ? order : new Order(order, ...orders);
    order.sortArray(array);
    return array;
}
exports.orderBy = orderBy;
// Compar to map, object has same performance, and is more convinent to use, but will lose number key type.
function indexBy(array, keyOrFn) {
    let index = {};
    if (typeof keyOrFn === 'function') {
        for (let i = 0, len = array.length; i < len; i++) {
            let item = array[i];
            let [key, value] = keyOrFn(item, i);
            index[key] = value;
        }
    }
    else {
        for (let item of array) {
            let key = item[keyOrFn];
            index[key] = item;
        }
    }
    return index;
}
exports.indexBy = indexBy;
/**
 * Creates a map object composed of keys as running `keyOrFn` on each item, and values as item array share the same key.
 * @param array The array to group by.
 * @param keyOrFn The key attribute name of each item whose related value will be used as key. or the function which accepts each item as argument and returns a key.
 */
function groupBy(array, keyOrFn) {
    let index = {};
    for (let item of array) {
        let key;
        if (typeof keyOrFn === 'function') {
            key = keyOrFn(item);
        }
        else {
            key = item[keyOrFn];
        }
        let group = index[key] || (index[key] = []);
        group.push(item);
    }
    return index;
}
exports.groupBy = groupBy;
/**
 * Group and aggregate items in array by group function and aggregate function.
 * @param array The array to aggregate.
 * @param keyOrFn The key attribute name of each item whose related value will be used as key. or the function which accepts each item as argument and returns a key.
 * @param aggregateFn The aggregate function which accepts grouped items and key as arguments, and returns aggregate value.
 */
function aggregate(array, keyOrFn, aggregateFn) {
    let index = groupBy(array, keyOrFn);
    return indexBy(Object.keys(index), (key) => {
        return [key, aggregateFn(index[key], key)];
    });
}
exports.aggregate = aggregate;
/**
 * Returns the length of the array.
 * @param array The array to count length.
 */
// Can't use `array: unknown` here, or it will cause `T` in `aggregate` was inferred as `unknown` and make `CanSortKeys<T>` not working.
function count(array) {
    return array.length;
}
exports.count = count;
/**
 * Returns the sum of all the numbers in `array`.
 * @param array The array of numbers.
 */
function sum(array) {
    return array.reduce((v1, v2) => v1 + v2, 0);
}
exports.sum = sum;
/**
 * Returns the average value of the numbers in `array`. Returns 0 if no items in `array`.
 * @param array The array of numbers.
 */
function avg(array) {
    if (array.length === 0) {
        return 0;
    }
    return sum(array) / array.length;
}
exports.avg = avg;
/**
 * Returns the minimal value of the numbers in `array`. Returns `Infinity` if no items in `array`.
 * @param array The array of numbers.
 */
function min(array) {
    return Math.min(...array);
}
exports.min = min;
/**
 * Returns the maximun value of numbers in `array`. Returns `-Infinity` if no items in `array`.
 * @param array The array of numbers.
 */
function max(array) {
    return Math.max(...array);
}
exports.max = max;
/**
 * Returns the index of the minimal value of the array items. Returns `-1` if no items or all values are `Infinity`.
 * @param array The array of data items.
 * @param map The map function to map each item to a number.
 */
function minIndex(array, map) {
    let values;
    if (map) {
        values = array.map(map);
    }
    else {
        values = array;
    }
    let minIndex = -1;
    let minValue = Infinity;
    for (let i = 0; i < values.length; i++) {
        if (values[i] < minValue) {
            minIndex = i;
            minValue = values[i];
        }
    }
    return minIndex;
}
exports.minIndex = minIndex;
/**
 * Returns the index of the maximun value of the array items. returns `-1` if no items or all values are `-Infinity`.
 * @param array The array of data items.
 * @param map The map function to map each item to a number.
 */
function maxIndex(array, map) {
    let values;
    if (map) {
        values = array.map(map);
    }
    else {
        values = array;
    }
    let maxIndex = -1;
    let maxValue = -Infinity;
    for (let i = 0; i < values.length; i++) {
        if (values[i] > maxValue) {
            maxIndex = i;
            maxValue = values[i];
        }
    }
    return maxIndex;
}
exports.maxIndex = maxIndex;


/***/ }),

/***/ "./node_modules/@pucelle/ff/out/base/date.js":
/*!***************************************************!*\
  !*** ./node_modules/@pucelle/ff/out/base/date.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.formatToShortDate = exports.formatDate = exports.addDurationToDate = exports.cloneDate = exports.getDaysOfMonth = exports.getDaysOfYear = exports.isLeapYear = exports.isValidDate = exports.setDateByUnit = exports.getDateByUnit = void 0;
const duration_1 = __webpack_require__(/*! ./duration */ "./node_modules/@pucelle/ff/out/base/duration.js");
const DateUnits = 'yMdhms';
/**
 * Get one of the date values according to specified `unit`.
 * @param date The date object to get value from.
 * @param unit The unit type, must be one of `'y', 'M', 'd', 'h', 'm', 's'`.
 */
function getDateByUnit(date, unit) {
    switch (unit) {
        case 'y':
            return date.getFullYear();
        case 'M':
            return date.getMonth();
        case 'd':
            return date.getDate();
        case 'h':
            return date.getHours();
        case 'm':
            return date.getMinutes();
        case 's':
            return date.getSeconds();
        default:
            throw new Error(`"${unit}" is not a valid date unit`);
    }
}
exports.getDateByUnit = getDateByUnit;
/**
 * Set one of the date values according to specified `unit`.
 * @param date The date object to set value.
 * @param value The date value to set.
 * @param unit The unit type, must be one of `'y', 'M', 'd', 'h', 'm', 's'`.
 */
function setDateByUnit(date, value, unit) {
    switch (unit) {
        case 'y':
            return date.setFullYear(value);
        case 'M':
            return date.setMonth(value);
        case 'd':
            return date.setDate(value);
        case 'h':
            return date.setHours(value);
        case 'm':
            return date.setMinutes(value);
        case 's':
            return date.setSeconds(value);
        default:
            throw new Error(`"${unit}" is not a valid date unit`);
    }
}
exports.setDateByUnit = setDateByUnit;
/**
 * Returns if date values from year to seconds are associated with a real date.
 * @param y Year count.
 * @param M Month count.
 * @param d Date count.
 * @param h Hour count.
 * @param m Minute count.
 * @param s Second count.
 */
function isValidDate(y, M, d = 1, h = 0, m = 0, s = 0) {
    let date = new Date(y, M, d, h, m, s);
    return y === date.getFullYear() &&
        M === date.getMonth() &&
        d === date.getDate() &&
        h === date.getHours() &&
        m === date.getMinutes() &&
        s === date.getSeconds();
}
exports.isValidDate = isValidDate;
/**
 * Returns if the year of `date` is a leap year, which contains 366 days.
 * @param date The date to test.
 */
function isLeapYear(date) {
    let year = date.getFullYear();
    return year % 4 === 0 && (year % 100 !== 0 || year % 400 === 0);
}
exports.isLeapYear = isLeapYear;
/**
 * Returns the days in the year from `date`, which is 366 for leap year, 365 otherwise.
 * @param date The date to get days from.
 */
function getDaysOfYear(date) {
    return isLeapYear(date) ? 366 : 365;
}
exports.getDaysOfYear = getDaysOfYear;
/**
 * Returns the days in the month from a `date`, which betweens 28-31.
 * @param date The date to get days from.
 */
function getDaysOfMonth(date) {
    let d = new Date(date.getTime());
    d.setDate(32);
    return 32 - d.getDate();
}
exports.getDaysOfMonth = getDaysOfMonth;
/**
 * Clone a date.
 * Can specify `units` to partly clone, values whose unit is included in `units` will be set to minimal value.
 * @param date The date to clone, default value is current date.
 * @param units The units to partly clone, default value is `yMdhms`.
 */
function cloneDate(date = new Date(), units = DateUnits) {
    let dateValues = [...DateUnits].map(unit => {
        if (units.includes(unit)) {
            return getDateByUnit(date, unit);
        }
        else {
            return unit === 'd' ? 1 : 0;
        }
    });
    return new Date(dateValues[0], dateValues[1], dateValues[2], dateValues[3], dateValues[4], dateValues[5]);
}
exports.cloneDate = cloneDate;
/**
 * Add `duration` string to a `date` and returns the new date.
 * @param date The date to add duration.
 * @param duration The duration string to add to date. like `1d1h`.
 */
function addDurationToDate(date, duration) {
    let isMinus = duration[0] === '-';
    if (isMinus) {
        duration = duration.slice(1);
    }
    let flag = isMinus ? -1 : 1;
    let o = duration_1.parseDurationToObject(duration);
    let newDate = new Date(date);
    for (let unit of Object.keys(o)) {
        let value = getDateByUnit(newDate, unit) + o[unit] * flag;
        setDateByUnit(newDate, value, unit);
    }
    return newDate;
}
exports.addDurationToDate = addDurationToDate;
/**
 * Returns a formatted date string from `date` and `format` type.
 * @param date The date to format.
 * @param format The date format type, default value is `'yyyy-MM-dd hh:mm:ss'`.
 */
function formatDate(date, format = 'yyyy-MM-dd hh:mm:ss') {
    return format.replace(/y+|M+|d+|h+|m+|s+/g, m0 => {
        let unit = m0[0];
        let value = getDateByUnit(date, unit[0]);
        if (unit === 'M') {
            value += 1;
        }
        return String(value).padStart(m0.length, '0');
    });
}
exports.formatDate = formatDate;
/**
 * Returns a short date string relative to current time.
 * @param date The date to format.
 * @param format The format object to use, default value is `{y: 'yyyy-MM-dd', M: 'MM-dd', h: 'hh:mm'}`.
 */
function formatToShortDate(date, format = { y: 'yyyy-MM-dd', M: 'MM-dd', h: 'hh:mm' }) {
    let now = new Date();
    let hasDifferentUnit = false;
    let matchFormat = Object.values(format)[0];
    for (let unit of DateUnits) {
        hasDifferentUnit = hasDifferentUnit || getDateByUnit(date, unit) !== getDateByUnit(now, unit);
        matchFormat = format[unit] || matchFormat;
        if (hasDifferentUnit) {
            break;
        }
    }
    return formatDate(date, matchFormat);
}
exports.formatToShortDate = formatToShortDate;


/***/ }),

/***/ "./node_modules/@pucelle/ff/out/base/duration.js":
/*!*******************************************************!*\
  !*** ./node_modules/@pucelle/ff/out/base/duration.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.formatSecondsToTime = exports.formatSecondsToDuration = exports.parseSecondsToDurationObject = exports.parseDurationToSeconds = exports.parseDurationToObject = void 0;
const string_1 = __webpack_require__(/*! ./string */ "./node_modules/@pucelle/ff/out/base/string.js");
const DateUnits = 'yMdhms';
const DATE_UNIT_SECONDS = {
    y: 365 * 24 * 60 * 60,
    M: 30 * 24 * 60 * 60,
    w: 7 * 24 * 60 * 60,
    d: 24 * 60 * 60,
    h: 60 * 60,
    m: 60,
    s: 1,
};
/**
 * Parse `duration` string like `1h1m` or `01:01:00` to object `{y, M, d, h, m, s}`.
 * @param duration string like `1h1m` or `01:01:00`.
 */
function parseDurationToObject(duration) {
    let o = {
        y: 0,
        M: 0,
        d: 0,
        h: 0,
        m: 0,
        s: 0,
    };
    if (duration.includes(':')) {
        let [h, m, s] = string_1.subMatches(duration, /(?:(\d\d):)?(\d\d):(\d\d(?:\.\d+)?)/)[0].map(v => Number(v) || 0);
        o.h = h;
        o.m = m;
        o.s = s;
    }
    else {
        let matches = string_1.subMatches(duration, /(\d+(?:\.\d+)?) ?([yMwdhms])/g);
        for (let [count, unit] of matches) {
            o[unit] = Number(count);
        }
    }
    return o;
}
exports.parseDurationToObject = parseDurationToObject;
/**
 * Parse duration string like `1h1m` or `01:01:00` to second count.
 * @param duration string like `1h1m` or `01:01:00`.
 */
function parseDurationToSeconds(duration) {
    let o = parseDurationToObject(duration);
    let seconds = 0;
    for (let unit of Object.keys(o)) {
        let count = o[unit];
        seconds += count * DATE_UNIT_SECONDS[unit];
    }
    return seconds;
}
exports.parseDurationToSeconds = parseDurationToSeconds;
/**
 * Parse second count to duration object `{y, M, d, h, m, s}`.
 * @param seconds The second count.
 * @param units The unit to use when parsing, default value is `yMdhms`.
 */
function parseSecondsToDurationObject(seconds, units = DateUnits) {
    let o = {
        y: 0,
        M: 0,
        d: 0,
        h: 0,
        m: 0,
        s: 0,
    };
    for (let unit of units) {
        let unitValue = DATE_UNIT_SECONDS[unit];
        let count = Math.floor(seconds / unitValue);
        if (count > 0) {
            o[unit] = count;
            seconds = seconds % unitValue;
        }
    }
    return o;
}
exports.parseSecondsToDurationObject = parseSecondsToDurationObject;
/**
 * Format second count to duration string like `1h1m`.
 * @param units Date unit types like `yMdhms`. Can only specify partial date units like `Md`.
 * @param maxOutputUnitCount Maximun unit count of the duration string. E.g., sepcify to `2` to output like `1y1M`, `1M1d`, `1d1h`, `1s`.
 */
function formatSecondsToDuration(seconds, units = DateUnits, maxOutputUnitCount = units.length) {
    let o = parseSecondsToDurationObject(seconds, units);
    let duration = '';
    let outputUnitCount = 0;
    for (let unit of Object.keys(o)) {
        let count = o[unit];
        if (count > 0) {
            duration += count + unit;
            outputUnitCount++;
        }
        if (outputUnitCount >= maxOutputUnitCount) {
            break;
        }
    }
    return duration;
}
exports.formatSecondsToDuration = formatSecondsToDuration;
/**
 * Format second count to time string like `01:01:01`.
 * @param seconds The second count.
 */
function formatSecondsToTime(seconds) {
    let h = Math.floor(seconds / 3600);
    let m = Math.floor(seconds % 3600 / 60) || 0;
    let s = Math.floor(seconds % 60) || 0;
    return (h ? String(h).padStart(2, '0') + ':' : '')
        + String(m).padStart(2, '0') + ':'
        + String(s).padStart(2, '0');
}
exports.formatSecondsToTime = formatSecondsToTime;


/***/ }),

/***/ "./node_modules/@pucelle/ff/out/base/emitter.js":
/*!******************************************************!*\
  !*** ./node_modules/@pucelle/ff/out/base/emitter.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, exports) => {


// At beginning, we implement a good Emitter by inferring listener arguments and emitting arguments.
// But then we meet a big problem when extending the class, described by:
// https://stackoverflow.com/questions/55813041/problems-on-typescript-event-interface-extends
// We are trying to merge event listener interfaces but failed,
// Guess the main reason is when one of the the event listener interface is generic argument,
// we can't merge two event listener interfaces and infer types of listener arguments for one listener,
// The type of listener becomes `resolved Listener A & unresolved Listener B`, arguments of it can't be inferred.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Emitter = void 0;
/**
 * An event emitter as super class to listen and emit events.
 * @typeparam E Event interface in `{eventName: (...args) => void}` format.
 */
class Emitter {
    constructor() {
        this.__events = new Map();
    }
    __ensureEvents(name) {
        let events = this.__events.get(name);
        if (!events) {
            this.__events.set(name, events = []);
        }
        return events;
    }
    /**
     * Registers an event `listener` to listen specified event `name`.
     * @param name The event name.
     * @param listener The event listener.
     * @param scope The scope will be binded to listener.
     */
    on(name, listener, scope) {
        let events = this.__ensureEvents(name);
        events.push({
            listener,
            scope,
            once: false,
        });
    }
    /**
     * Registers an event `listener` to listen specified event `name`, trigger for only once.
     * @param name The event name.
     * @param listener The event listener.
     * @param scope The scope will be binded to listener.
     */
    once(name, listener, scope) {
        let events = this.__ensureEvents(name);
        events.push({
            listener,
            scope,
            once: true
        });
    }
    /**
     * Remove `listener` from listening specified event `name`.
     * @param name The event name.
     * @param listener The event listener, only matched listener will be removed.
     * @param scope The scope binded to listener. If provided, remove listener only when scope match.
     */
    off(name, listener, scope) {
        let events = this.__events.get(name);
        if (events) {
            for (let i = events.length - 1; i >= 0; i--) {
                let event = events[i];
                if (event.listener === listener && (!scope || event.scope === scope)) {
                    events.splice(i, 1);
                }
            }
        }
    }
    /**
     * Check if `listener` is the list of listening specified event `name`.
     * @param name The event name.
     * @param listener The event listener. If provided, will also check if the listener match.
     * @param scope The scope binded to listener. If provided, will additionally check if the scope match.
     */
    hasListener(name, listener, scope) {
        let events = this.__events.get(name);
        if (!listener) {
            return !!events && events.length > 0;
        }
        else if (events && listener) {
            for (let i = 0, len = events.length; i < len; i++) {
                let event = events[i];
                if (event.listener === listener && (!scope || event.scope === scope)) {
                    return true;
                }
            }
        }
        return false;
    }
    /**
     * Emit specified event `name`, trigger all the listeners related with followed arguments.
     * @param name The event name.
     * @param args The arguments that will be passed to event listeners.
     */
    emit(name, ...args) {
        let events = this.__events.get(name);
        if (events) {
            for (let i = 0; i < events.length; i++) {
                let event = events[i];
                // The listener may call off, so must remove it before handling
                if (event.once === true) {
                    events.splice(i--, 1);
                }
                event.listener.apply(event.scope, args);
            }
        }
    }
    /** Removes all the event listeners. */
    removeAllListeners() {
        this.__events = new Map();
    }
}
exports.Emitter = Emitter;


/***/ }),

/***/ "./node_modules/@pucelle/ff/out/base/es-polyfill.js":
/*!**********************************************************!*\
  !*** ./node_modules/@pucelle/ff/out/base/es-polyfill.js ***!
  \**********************************************************/
/***/ (() => {


/* Polyfill for parts of ECMAScript 2017+, which is not widely supported by modern browsers */
if (!String.prototype.padStart) {
    Object.defineProperty(String.prototype, 'padStart', {
        value: function (length, fillString) {
            let len = this.length;
            let lenPad = fillString.length;
            if (length < len || !lenPad) {
                return String(this);
            }
            else {
                let repeatCount = Math.floor((length - len) / lenPad);
                let additionStr = fillString.slice(0, length - len - repeatCount * lenPad);
                return fillString.repeat(repeatCount) + additionStr + this;
            }
        }
    });
}
if (!String.prototype.padEnd) {
    Object.defineProperty(String.prototype, 'padEnd', {
        value: function (length, fillString) {
            let len = this.length;
            let lenPad = fillString.length;
            if (length < len || !lenPad) {
                return String(this);
            }
            else {
                let repeatCount = Math.floor((length - len) / lenPad);
                let additionStr = fillString.slice(0, length - len - repeatCount * lenPad);
                return this + fillString.repeat(repeatCount) + additionStr;
            }
        }
    });
}
// Still a proposal, but I love it.
if (!RegExp.escape) {
    Object.defineProperty(RegExp, 'escape', {
        value: function (source) {
            return source.replace(/[\-\[\]\/\{\}\(\)\*\+\?\.\\\^\$\|]/g, '\\$&');
        }
    });
}


/***/ }),

/***/ "./node_modules/@pucelle/ff/out/base/function.js":
/*!*******************************************************!*\
  !*** ./node_modules/@pucelle/ff/out/base/function.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.debounce = exports.Debounce = exports.lazilyThrottle = exports.LazilyThrottle = exports.throttle = exports.Throttle = exports.interval = exports.Interval = exports.timeout = exports.Timeout = void 0;
class TimingFunction {
    constructor(fn, ms) {
        this.id = null;
        /** Returns if current timing function has been canceled. */
        this.canceled = false;
        this.fn = fn;
        this.ms = ms;
    }
}
class WrappedTimingFunction extends TimingFunction {
    constructor(fn, ms) {
        super(fn, ms);
        this.wrapped = this.wrap();
        this.wrapped.__original = fn;
    }
}
class Timeout extends TimingFunction {
    /**
     * Just like setTimeout, call `fn` after `ms` millisecons.
     * @param fn The function to call later.
     * @param ms The timeout time in millisecons.
     */
    constructor(fn, ms) {
        super(fn, ms);
        this.reset();
    }
    /** Restart timeout, although it was been called. always returns true. */
    reset() {
        if (this.id) {
            clearTimeout(this.id);
        }
        this.id = setTimeout(this.onTimeout.bind(this), this.ms);
        return true;
    }
    onTimeout() {
        this.id = null;
        this.fn();
    }
    /** Call deferred function immediately if it wasn't been called and returns true. otherwise returns false. */
    flush() {
        if (!this.id) {
            return false;
        }
        clearTimeout(this.id);
        this.id = null;
        this.fn();
        return true;
    }
    /** Cancel deferred function, returns if it was canceled before been called. */
    cancel() {
        if (!this.id) {
            return false;
        }
        clearTimeout(this.id);
        this.id = null;
        return true;
    }
}
exports.Timeout = Timeout;
/**
 * Just like `setTimeout`, call `fn` after `ms` millisecons.
 * @param fn The function to call later.
 * @param ms The timeout time in millisecons.
 */
function timeout(fn, ms = 0) {
    return new Timeout(fn, ms);
}
exports.timeout = timeout;
class Interval extends TimingFunction {
    /**
     * Just like setInterval, call `fn` every `ms` millisecons.
     * @param fn The function to call.
     * @param ms The interval time in millisecons.
     */
    constructor(fn, ms) {
        super(fn, ms);
        this.reset();
    }
    /** Restart interval, although it was been canceled. always returns true. */
    reset() {
        if (this.id) {
            clearInterval(this.id);
        }
        this.id = setInterval(this.onInterval.bind(this), this.ms);
        return true;
    }
    onInterval() {
        this.fn();
    }
    /** Call interval function immediately if it wasn't been canceled and returns true. otherwise returns false. */
    flush() {
        if (!this.id) {
            return false;
        }
        this.fn();
        this.reset();
        return true;
    }
    /** Cancel interval function, returns if it was canceled before been called. */
    cancel() {
        if (!this.id) {
            return false;
        }
        clearInterval(this.id);
        this.id = null;
        return true;
    }
}
exports.Interval = Interval;
/**
 * Just like `setInterval`, call `fn` every `ms` millisecons.
 * @param fn The function to call.
 * @param ms The interval time in millisecons.
 */
function interval(fn, ms) {
    return new Interval(fn, ms);
}
exports.interval = interval;
class Throttle extends WrappedTimingFunction {
    /**
     * Throttle function calls, call returned function twice in `ms` millisecons will only call `fn` for once.
     * Note that it doesn't ensure the last calling.
     * @param fn The function to throttle.
     * @param ms The time period in which only at most one call allowed. If omitted, using `requestAnimationFrame` to throttle.
     */
    constructor(fn, ms = 0) {
        super(fn, ms);
    }
    wrap() {
        let me = this;
        return function (...args) {
            if (me.canceled) {
                me.fn.apply(this, args);
                return;
            }
            if (!me.id) {
                me.setThrottle();
                me.fn.apply(this, args);
            }
        };
    }
    setThrottle() {
        if (this.ms) {
            this.id = setTimeout(this.onTimeout.bind(this), this.ms);
        }
        else {
            this.id = requestAnimationFrame(this.onTimeout.bind(this));
        }
    }
    onTimeout() {
        this.id = null;
    }
    /** Reset throttle timeout, function will be called immediately next time. Will restart throttle if been canceled. */
    reset() {
        if (this.id) {
            this.clearThrottle();
        }
        this.canceled = false;
        return true;
    }
    clearThrottle() {
        if (this.ms) {
            clearTimeout(this.id);
        }
        else {
            cancelAnimationFrame(this.id);
        }
        this.id = null;
    }
    /** Do nothing, always return false. */
    flush() {
        return false;
    }
    /** Cancel throttle, function will be called without limit. Returns true if is not canceled before. */
    cancel() {
        if (this.canceled) {
            return false;
        }
        this.canceled = true;
        return true;
    }
}
exports.Throttle = Throttle;
/**
 * Throttle function calls, call returned function for twice in `ms` milliseconds will only call `fn` for once.
 * It doesn't ensure the last calling.
 * @param fn The function to throttle.
 * @param ms The time period in which only at most one call allowed.
 */
function throttle(fn, ms = 0) {
    return new Throttle(fn, ms);
}
exports.throttle = throttle;
class LazilyThrottle extends WrappedTimingFunction {
    /**
     * Throttle function calls like `throttle`, but will calls `fn` lazily and smooth.
     * It ensures the last calling.
     * @param fn The function to throttle.
     * @param ms The time period in which only at most one call allowed.
     */
    constructor(fn, ms) {
        super(fn, ms);
        this.lastArgs = null;
        this.lastThis = null;
        this.wrapped = this.wrap();
    }
    wrap() {
        let me = this;
        return function (...args) {
            if (me.canceled) {
                me.fn.apply(this, args);
                return;
            }
            me.lastArgs = args;
            me.lastThis = this;
            if (!me.id) {
                me.setThrottle();
            }
        };
    }
    setThrottle() {
        if (this.ms) {
            this.id = setTimeout(this.onTimeout.bind(this), this.ms);
        }
        else {
            this.id = requestAnimationFrame(this.onTimeout.bind(this));
        }
    }
    onTimeout() {
        if (this.lastArgs) {
            this.fn.apply(this.lastThis, this.lastArgs);
            this.lastArgs = null;
            this.lastThis = null;
            this.setThrottle();
        }
        else {
            this.id = null;
        }
    }
    /** Reset throttle timeout and discard deferred call, Will restart throttle if been canceled. */
    reset() {
        if (this.id) {
            this.clearThrottle();
        }
        this.lastArgs = null;
        this.lastThis = null;
        this.canceled = false;
        return true;
    }
    /** Call function immediately if there is a deferred call, and restart throttle timeout. */
    flush() {
        if (this.lastArgs) {
            this.setThrottle();
            this.fn.apply(this.lastThis, this.lastArgs);
            this.lastArgs = null;
            this.lastThis = null;
            return true;
        }
        return false;
    }
    clearThrottle() {
        if (this.ms) {
            clearTimeout(this.id);
        }
        else {
            cancelAnimationFrame(this.id);
        }
        this.id = null;
    }
    /** Cancel throttle, function will be called without limit. Returns true if is not canceled before. */
    cancel() {
        if (this.canceled) {
            return false;
        }
        this.canceled = true;
        return true;
    }
}
exports.LazilyThrottle = LazilyThrottle;
/**
 * Throttle function calls like `throttle`, but will call `fn` lazily and smooth.
 * It ensures the last calling.
 * @param fn The function to throttle.
 * @param ms The time period in which only at most one call allowed.
 */
function lazilyThrottle(fn, ms) {
    return new LazilyThrottle(fn, ms);
}
exports.lazilyThrottle = lazilyThrottle;
class Debounce extends WrappedTimingFunction {
    /**
     * Debounce function calls, call returned function will start a timeout to call `fn`,
     * But call returned function for the second time in `ms` milliseconds will reset timeout.
     * @param fn The function to debounce.
     * @param ms The timeout in milliseconds.
     */
    constructor(fn, ms) {
        super(fn, ms);
        this.lastArgs = null;
        this.lastThis = null;
        this.wrapped = this.wrap();
    }
    wrap() {
        let me = this;
        return function (...args) {
            if (me.canceled) {
                me.fn.apply(this, args);
                return;
            }
            if (me.id) {
                clearTimeout(me.id);
            }
            me.id = setTimeout(me.onTimeout.bind(me), me.ms);
            me.lastArgs = args;
            me.lastThis = this;
        };
    }
    onTimeout() {
        this.id = null;
        if (this.lastArgs) {
            this.fn.apply(this.lastThis, this.lastArgs);
            this.lastArgs = null;
            this.lastThis = null;
        }
    }
    /** Reset debounce timeout and discard deferred call. Will restart debounce if been canceled. */
    reset() {
        if (this.id) {
            clearTimeout(this.id);
            this.id = null;
        }
        this.lastArgs = null;
        this.lastThis = null;
        return true;
    }
    /** Call function immediately there is a deferred call, and restart debounce timeout. */
    flush() {
        if (this.id) {
            clearTimeout(this.id);
            this.id = 0;
        }
        if (this.lastArgs) {
            this.fn.apply(this.lastThis, this.lastArgs);
            this.lastArgs = null;
            this.lastThis = null;
            return true;
        }
        return false;
    }
    /** Cancel debounce, function will be called without limit. Returns true if is not canceled before. */
    cancel() {
        if (this.canceled) {
            return false;
        }
        this.canceled = true;
        return true;
    }
}
exports.Debounce = Debounce;
/**
 * Debounce function calls, call returned function will start a timeout to call `fn`,
 * But call returned function for the second time in `ms` milliseconds will reset timeout.
 * @param fn The function to debounce.
 * @param ms The timeout in milliseconds.
 */
function debounce(fn, ms) {
    return new Debounce(fn, ms);
}
exports.debounce = debounce;


/***/ }),

/***/ "./node_modules/@pucelle/ff/out/base/index.js":
/*!****************************************************!*\
  !*** ./node_modules/@pucelle/ff/out/base/index.js ***!
  \****************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __exportStar = (this && this.__exportStar) || function(m, exports) {
    for (var p in m) if (p !== "default" && !exports.hasOwnProperty(p)) __createBinding(exports, m, p);
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
__webpack_require__(/*! ./es-polyfill */ "./node_modules/@pucelle/ff/out/base/es-polyfill.js");
var object_1 = __webpack_require__(/*! ./object */ "./node_modules/@pucelle/ff/out/base/object.js");
Object.defineProperty(exports, "assign", ({ enumerable: true, get: function () { return object_1.assign; } }));
Object.defineProperty(exports, "assignIf", ({ enumerable: true, get: function () { return object_1.assignIf; } }));
Object.defineProperty(exports, "deepClone", ({ enumerable: true, get: function () { return object_1.deepClone; } }));
Object.defineProperty(exports, "deepEqual", ({ enumerable: true, get: function () { return object_1.deepEqual; } }));
__exportStar(__webpack_require__(/*! ./array */ "./node_modules/@pucelle/ff/out/base/array.js"), exports);
__exportStar(__webpack_require__(/*! ./string */ "./node_modules/@pucelle/ff/out/base/string.js"), exports);
__exportStar(__webpack_require__(/*! ./number */ "./node_modules/@pucelle/ff/out/base/number.js"), exports);
__exportStar(__webpack_require__(/*! ./function */ "./node_modules/@pucelle/ff/out/base/function.js"), exports);
__exportStar(__webpack_require__(/*! ./time */ "./node_modules/@pucelle/ff/out/base/time.js"), exports);
__exportStar(__webpack_require__(/*! ./duration */ "./node_modules/@pucelle/ff/out/base/duration.js"), exports);
__exportStar(__webpack_require__(/*! ./date */ "./node_modules/@pucelle/ff/out/base/date.js"), exports);
__exportStar(__webpack_require__(/*! ./emitter */ "./node_modules/@pucelle/ff/out/base/emitter.js"), exports);
__exportStar(__webpack_require__(/*! ./queue */ "./node_modules/@pucelle/ff/out/base/queue.js"), exports);


/***/ }),

/***/ "./node_modules/@pucelle/ff/out/base/number.js":
/*!*****************************************************!*\
  !*** ./node_modules/@pucelle/ff/out/base/number.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.constrain = exports.mod = exports.toPrecision = exports.toPower = exports.toDecimal = void 0;
/**
 * Like `number.toFixed`, but alway returns a number.
 * @param number The number to fix.
 * @param decimalCount The decimal count that `number` will correct to, default value is 0.
 */
function toDecimal(number, decimalCount = 0) {
    return toPower(number, -decimalCount);
}
exports.toDecimal = toDecimal;
/**
 * Like the opposite of `number.toFixed`, but always returns a number. e.g., `toPower(1234, 2) = 1200`.
 * @param number The number to fix.
 * @param power The power that `number` will correct to, default value is 0.
 */
function toPower(number, power = 0) {
    if (number < 0) {
        return -toPower(-number, power);
    }
    if (number === 0) {
        return 0;
    }
    if (power > 0) {
        let n = Math.pow(10, power);
        return Math.round(number / n) * n;
    }
    // This can avoid `0.1 + 0.2 !== 0.3`
    else {
        let n = Math.pow(10, -power);
        return Math.round(number * n) / n;
    }
}
exports.toPower = toPower;
/**
 * Nearly same with `number.toPrecision`, except here always returns a number.
 * @param number The number to transfer to specified precision.
 * @param precision The precision value betweens 1-21, default value is 1.
 */
function toPrecision(number, precision = 1) {
    return Number(number.toPrecision(precision));
}
exports.toPrecision = toPrecision;
/**
 * Like `a % b`, but always returns positive number. e.g., `mod(-1, 2) = 1`.
 * @param number The number to calculate modulo.
 * @param modulo The modulo of number.
 */
function mod(number, modulo) {
    return (number % modulo + Math.abs(modulo)) % modulo;
}
exports.mod = mod;
/**
 * Returns a new number which is constrained in a minimal and maximum range.
 * @param number The number to constrain.
 * @param min The minimum number.
 * @param max The maximum number.
 */
function constrain(number, min, max) {
    if (min > max) {
        [min, max] = [max, min];
    }
    if (number < min) {
        number = min;
    }
    else if (number > max) {
        number = max;
    }
    return number;
}
exports.constrain = constrain;


/***/ }),

/***/ "./node_modules/@pucelle/ff/out/base/object.js":
/*!*****************************************************!*\
  !*** ./node_modules/@pucelle/ff/out/base/object.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.deepEqual = exports.deepClone = exports.assignIf = exports.assign = void 0;
/**
 * Assign object keys and values from `source` to `target`, will cover values of `target` with same keys.
 * will ignore `undefined` values in `source`.
 * @param target The target that the sources assigned to.
 * @param sources The sources that will assigned to target by order.
 * @param keys If specified, only values whose keys are included will be assigned.
 */
function assign(target, source, keys = Object.keys(source)) {
    for (let key of keys) {
        let value = source[key];
        if (value !== undefined) {
            target[key] = value;
        }
    }
    return target;
}
exports.assign = assign;
/**
 * Assign object keys and values from `source` to `target`, will not cover values of `target` with existing keys.
 * will ignore `undefined` values in `source`,  and `undefined` values in `target` will be treated as not exist.
 * @param target The target that the sources assigned to.
 * @param sources The sources that will assigned to target by order.
 * @param keys If specified, only values whose keys are included will be assigned.
 */
function assignIf(target, source, keys = Object.keys(source)) {
    for (let key of keys) {
        let value = source[key];
        if (value !== undefined && target[key] === undefined) {
            target[key] = value;
        }
    }
    return target;
}
exports.assignIf = assignIf;
// 2x~3x faster than JSON methods, see https://jsperf.com/deep-clone-vs-json-clone
/**
 * Deeply clone an object, array or any value which can also be called with `JSON.stringify`.
 * @param source The source to clone.
 * @param deep Max deep to clone, default value is 10.
 */
function deepClone(source, deep = 10) {
    if (typeof source !== 'object' || !source || deep === 0) {
        return source;
    }
    if (Array.isArray(source)) {
        return source.map(value => {
            if (typeof value !== 'object' || !value) {
                return value;
            }
            else {
                return deepClone(value, deep - 1);
            }
        });
    }
    else {
        let cloned = {};
        for (let key of Object.keys(source)) {
            let value = source[key];
            cloned[key] = deepClone(value, deep - 1);
        }
        return cloned;
    }
}
exports.deepClone = deepClone;
// 1x faster than JSON methods, see https://jsperf.com/deep-equal-vs-json-compare
/**
 * Deeply compare two objects, arraies or any values.
 * @param a Left value.
 * @param b Right value.
 * @param deep Max deep to compare, default value is 10.
 */
function deepEqual(a, b, deep = 10) {
    if (a === b) {
        return true;
    }
    if (deep === 0) {
        return false;
    }
    if (typeof a !== 'object' || typeof b !== 'object' || !a || !b) {
        return false;
    }
    if (a.constructor !== b.constructor) {
        return false;
    }
    let keysA = Object.keys(a);
    let keysB = Object.keys(b);
    if (keysA.length !== keysB.length) {
        return false;
    }
    for (let key of keysA) {
        if (!b.hasOwnProperty(key)) {
            return false;
        }
        let valueA = a[key];
        let valueB = b[key];
        if (!deepEqual(valueA, valueB, deep - 1)) {
            return false;
        }
    }
    return true;
}
exports.deepEqual = deepEqual;


/***/ }),

/***/ "./node_modules/@pucelle/ff/out/base/queue.js":
/*!****************************************************!*\
  !*** ./node_modules/@pucelle/ff/out/base/queue.js ***!
  \****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.queueEvery = exports.queueSome = exports.queueMap = exports.queueEach = exports.Queue = exports.QueueState = void 0;
const object_1 = __webpack_require__(/*! ./object */ "./node_modules/@pucelle/ff/out/base/object.js");
const emitter_1 = __webpack_require__(/*! ./emitter */ "./node_modules/@pucelle/ff/out/base/emitter.js");
var QueueState;
(function (QueueState) {
    /** Not started. */
    QueueState[QueueState["Pending"] = 0] = "Pending";
    /** Any task is running. */
    QueueState[QueueState["Running"] = 1] = "Running";
    /** Been paused. */
    QueueState[QueueState["Paused"] = 2] = "Paused";
    /** All tasks finshed. */
    QueueState[QueueState["Finish"] = 3] = "Finish";
    /** Aborted because of error or by user. */
    QueueState[QueueState["Aborted"] = 4] = "Aborted";
})(QueueState = exports.QueueState || (exports.QueueState = {}));
/**
 * Class to queue tasks and transfer them to handler in specified concurrency.
 * @typeparam T: Type of task.
 * @typeparam V: Type of returned values from handler. This can be inferred from `handler` option normally.
 */
class Queue extends emitter_1.Emitter {
    constructor(options) {
        super();
        /** If provided, can avoid adding duplicate tasks with same keys. */
        this.key = null;
        /** Specify how many tasks to run simultaneously, default value is `5`. */
        this.concurrency = 5;
        /** If true, will continue handling tasks after error occurred. */
        this.continueOnError = false;
        /**
         * Specifies how many times to retry before one task success.
         * If one task's retry times execeed, it will never retry automatically,
         * but you can still retry all failed tasks by calling `retry()` manually.
         * Setting this option to values `> 0` implies `continueOnError` is true.
         */
        this.maxRetryTimes = 0;
        /** The start task array which will be passed to `handler` in order. */
        this.tasks = [];
        /** Returns current working state. */
        this.state = QueueState.Pending;
        this.keysFound = null;
        this.seed = 1;
        this.handledCount = 0;
        this.runningItems = [];
        this.failedItems = [];
        this.resumePromise = null;
        this.resumeResolve = null;
        object_1.assign(this, options, Object.keys(options).filter(key => key !== 'tasks'));
        if (this.key) {
            this.keysFound = new Set();
        }
        if (options.tasks) {
            this.push(...options.tasks);
        }
    }
    /** Returns the tount of total tasks, included handled and unhandled and failed. */
    getTotalCount() {
        return this.getHandledCount() + this.getUnhandledCount() + this.getFailedCount();
    }
    /** Returns the count of handled tasks. */
    getHandledCount() {
        return this.handledCount;
    }
    /** Returns the count of unhandled tasks, not include failed tasks. */
    getUnhandledCount() {
        return this.tasks.length + this.getRunningCount();
    }
    /** Returns the count of running tasks. */
    getRunningCount() {
        return this.runningItems.length;
    }
    /** Returns the count of failed tasks. */
    getFailedCount() {
        return this.failedItems.length;
    }
    /** Returns the unhandled tasks. */
    getUnhandledTasks() {
        return [...this.getRunningTasks(), ...this.tasks];
    }
    /** Returns the running tasks. */
    getRunningTasks() {
        return this.runningItems.map(v => v.task);
    }
    /** Returns the failed tasks. */
    getFailedTasks() {
        return this.failedItems.map(v => v.task);
    }
    /**
     * Start handling tasks. Will emit `finish` event in next tick if no task to run.
     * Returns `true` if queue started.
     */
    start() {
        if (this.state === QueueState.Paused) {
            this.resume();
        }
        else if (this.tasks.length > 0) {
            this.state = QueueState.Running;
            this.mayHandleNextTask();
        }
        else {
            Promise.resolve().then(() => this.onFinish());
        }
        return this.state === QueueState.Running;
    }
    /**
     * Returns a promise which will be resolved after all tasks finished, or be rejected if error happens.
     */
    untilFinish() {
        if (this.getUnhandledCount() > 0) {
            return new Promise((resolve, reject) => {
                this.once('end', err => err ? reject(err) : resolve());
            });
        }
        else {
            return Promise.resolve();
        }
    }
    /**
     * Stop handling tasks, running tasks will not be aborted, but will be locked until `resume()`.
     * Returns `true` if paused from running state.
     */
    pause() {
        if (this.state !== QueueState.Running) {
            return false;
        }
        this.state = QueueState.Paused;
        this.resumePromise = new Promise(resolve => {
            this.resumeResolve = () => {
                this.resumeResolve = null;
                this.resumePromise = null;
                resolve();
            };
        });
        this.emit('pause');
        return true;
    }
    /**
     * Resume handling tasks.
     * Returns `true` if resumed from paused state.
     */
    resume() {
        if (this.state !== QueueState.Paused) {
            return false;
        }
        this.state = QueueState.Running;
        if (this.resumeResolve) {
            this.resumeResolve();
        }
        this.emit('resume');
        this.mayHandleNextTask();
        return true;
    }
    mayHandleNextTask() {
        // State may change after in event handler, so we need to test state here.
        if (this.state !== QueueState.Running) {
            return;
        }
        while (this.getRunningCount() < this.concurrency && this.tasks.length > 0) {
            let task = this.tasks.shift();
            this.handleItem({
                id: this.seed++,
                task,
                retriedTimes: 0,
                abort: null
            });
        }
        if (this.maxRetryTimes > 0 && this.getRunningCount() < this.concurrency && this.failedItems.length) {
            for (let i = 0; i < this.failedItems.length; i++) {
                let item = this.failedItems[i];
                if (item.retriedTimes < this.maxRetryTimes) {
                    item.retriedTimes++;
                    this.failedItems.splice(i--, 1);
                    this.handleItem(item);
                    if (this.getRunningCount() >= this.concurrency) {
                        break;
                    }
                }
            }
        }
        if (this.getRunningCount() === 0) {
            this.onFinish();
        }
    }
    handleItem(item) {
        let { task } = item;
        let onItemFinish = this.onItemFinish.bind(this, item);
        let onItemError = this.onItemError.bind(this, item);
        this.runningItems.push(item);
        let value = this.handler(task);
        if (value && typeof value === 'object' && value.promise instanceof Promise && typeof value.abort === 'function') {
            value.promise.then(onItemFinish, onItemError);
            item.abort = value.abort;
        }
        else if (value instanceof Promise) {
            value.then(onItemFinish, onItemError);
        }
        else {
            Promise.resolve().then(() => onItemFinish(value));
        }
    }
    async onItemFinish(item, value) {
        await this.prepareItem(item);
        if (!this.removeFromRunning(item)) {
            return;
        }
        this.handledCount++;
        if (this.state === QueueState.Running) {
            this.emit('taskfinish', item.task, value);
            this.mayHandleNextTask();
        }
    }
    async onItemError(item, err) {
        await this.prepareItem(item);
        if (!this.removeFromRunning(item)) {
            return;
        }
        this.failedItems.push(item);
        this.emit('error', item.task, err);
        if (!this.continueOnError && this.maxRetryTimes === 0) {
            this.onFatalError(err);
        }
        else {
            this.mayHandleNextTask();
        }
    }
    // Prepare until we can handle it, normally is the state changed from pause to resume.
    async prepareItem(item) {
        item.abort = null;
        if (this.resumePromise) {
            await this.resumePromise;
        }
    }
    removeFromRunning(item) {
        let index = this.runningItems.findIndex(v => v.id === item.id);
        if (index > -1) {
            this.runningItems.splice(index, 1);
            return true;
        }
        return false;
    }
    onFinish() {
        if (this.state === QueueState.Pending || this.state === QueueState.Running) {
            this.state = QueueState.Finish;
            this.emit('finish');
            this.emit('end', null);
        }
    }
    onFatalError(err) {
        this.abort(err);
    }
    /**
     * Retry all failed tasks immediately, ignore their retried times.
     * Returns `true` if has failed tasks and queued them.
     */
    retry() {
        let hasFailedTasks = this.getFailedCount() > 0;
        if (hasFailedTasks) {
            this.tasks.push(...this.getFailedTasks());
            this.failedItems = [];
        }
        let started = this.start();
        return started && hasFailedTasks;
    }
    /**
     * Abort current queue and all running tasks.
     * After aborted, queue can still be started manually by calling `start()`.
     * Returns `true` if queue was successfully aborted.
     */
    abort(err = 'manually') {
        if (!(this.state === QueueState.Running || this.state === QueueState.Paused)) {
            return false;
        }
        this.state = QueueState.Aborted;
        this.failedItems.push(...this.runningItems);
        this.abortRunningItems();
        this.emit('abort', err);
        this.emit('end', err);
        return true;
    }
    abortRunningItems() {
        this.runningItems.map(item => this.abortItem(item));
        this.runningItems = [];
    }
    abortItem(item) {
        let { task, abort } = item;
        if (abort) {
            abort();
        }
        this.emit('taskabort', task);
    }
    /**
     * End and finish queue, abort all running tasks and clear all tasks and handling records.
     * Returns `true` if queue clear successfully.
     */
    clear() {
        if (this.state === QueueState.Aborted) {
            return false;
        }
        this.state = QueueState.Finish;
        this.tasks = [];
        this.failedItems = [];
        this.handledCount = 0;
        this.abortRunningItems();
        this.emit('finish');
        this.emit('end');
        if (this.resumeResolve) {
            this.resumeResolve();
        }
        return true;
    }
    /** Remove all not running tasks. */
    clearNotRunning() {
        this.tasks = [];
        this.failedItems = [];
        this.handledCount = 0;
    }
    /** Push tasks to queue. */
    push(...tasks) {
        if (this.keysFound) {
            for (let task of tasks) {
                this.keysFound.add(task[this.key]);
            }
        }
        this.tasks.push(...tasks);
        if (this.state === QueueState.Finish) {
            this.start();
        }
        this.mayHandleNextTask();
    }
    /** Unshift tasks to queue. */
    unshift(...tasks) {
        if (this.keysFound) {
            for (let task of tasks) {
                this.keysFound.add(task[this.key]);
            }
        }
        this.tasks.unshift(...tasks);
        if (this.state === QueueState.Finish) {
            this.start();
        }
        this.mayHandleNextTask();
    }
    /** Returns true if found same key task. */
    has(task) {
        if (this.keysFound) {
            return this.keysFound.has(task[this.key]);
        }
        else {
            return false;
        }
    }
    /** Push tasks to queue, if not found same key task. */
    add(...tasks) {
        tasks = tasks.filter(t => !this.has(t));
        if (tasks.length > 0) {
            this.push(...tasks);
        }
    }
    /** Unshift tasks to queue, if not found same key task. */
    addToStart(...tasks) {
        tasks = tasks.filter(t => !this.has(t));
        if (tasks.length > 0) {
            this.unshift(...tasks);
        }
    }
    /** Find first task match `fn`, handled tasks can't be found. */
    find(fn) {
        let item = this.runningItems.find(item => fn(item.task));
        if (item) {
            return item.task;
        }
        item = this.failedItems.find(item => fn(item.task));
        if (item) {
            return item.task;
        }
        let task = this.tasks.find(task => fn(task));
        if (task) {
            return task;
        }
        return undefined;
    }
    /**
     * Removes tasks included in `tasksToRemove` list.
     * Only tasks that are running or not been handled can be removed.
     */
    remove(...tasksToRemove) {
        let taskSet = new Set(tasksToRemove);
        return this.removeWhere(task => taskSet.has(task));
    }
    /**
     * Removes all tasks that matched `fn`.
     * Only tasks that are running or not been handled can be removed.
     */
    removeWhere(fn) {
        let toRemove = [];
        this.runningItems = this.runningItems.filter(item => {
            if (fn(item.task)) {
                toRemove.push(item.task);
                return false;
            }
            else {
                return true;
            }
        });
        this.failedItems = this.failedItems.filter(item => {
            if (fn(item.task)) {
                toRemove.push(item.task);
                return false;
            }
            else {
                return true;
            }
        });
        this.tasks = this.tasks.filter(task => {
            if (fn(task)) {
                toRemove.push(task);
                return false;
            }
            else {
                return true;
            }
        });
        this.mayHandleNextTask();
        return toRemove;
    }
}
exports.Queue = Queue;
/**
 * Run tasks in queue, returns a promise which will be resolved after queue finished.
 * @param tasks The task array which will be passed to handler in order.
 * @param handler The handler to handle each task.
 * @param concurrency Specify how many tasks to run simultaneously.
 */
function queueEach(tasks, handler, concurrency) {
    return new Promise((resolve, reject) => {
        let q = new Queue({
            concurrency,
            tasks,
            handler
        });
        q.on('finish', resolve);
        q.on('error', reject);
        q.start();
    });
}
exports.queueEach = queueEach;
/**
 * Run tasks in queue, returns a promise which will be resolved with returned values from handler after queue finished.
 * @param tasks The task array which will be passed to handler in order.
 * @param handler The handler to handle each task. It should returns a value.
 * @param concurrency Specify how many tasks to run simultaneously.
 */
function queueMap(tasks, handler, concurrency) {
    return new Promise((resolve, reject) => {
        let values = [];
        let indexedTasks = tasks.map((task, index) => ({ task, index }));
        let q = new Queue({
            concurrency,
            tasks: indexedTasks,
            handler: async ({ task, index }) => {
                values[index] = await handler(task);
            }
        });
        q.on('finish', () => resolve(values));
        q.on('error', reject);
        q.start();
    });
}
exports.queueMap = queueMap;
/**
 * Run tasks in queue, returns a promise which will be resolved if some tasks match handler.
 * @param tasks The task array which will be passed to handler in order.
 * @param handler The handler to handle each task. It should returns a boolean value.
 * @param concurrency Specify how many tasks to run simultaneously.
 */
function queueSome(tasks, handler, concurrency) {
    return new Promise((resolve, reject) => {
        let q = new Queue({
            concurrency,
            tasks,
            handler
        });
        q.on('taskfinish', (_task, value) => {
            if (value) {
                resolve(true);
                q.clear();
            }
        });
        q.on('finish', () => resolve(false));
        q.on('error', reject);
        q.start();
    });
}
exports.queueSome = queueSome;
/**
 * Run tasks in queue, returns a promise which will be resolved if every tasks match handler.
 * @param tasks The task array which will be passed to handler in order.
 * @param handler The handler to handle each task. It should returns a boolean value.
 * @param concurrency Specify how many tasks to run simultaneously.
 */
function queueEvery(tasks, handler, concurrency) {
    return queueSome(tasks, async (task) => !(await handler(task)), concurrency).then(value => !value);
}
exports.queueEvery = queueEvery;


/***/ }),

/***/ "./node_modules/@pucelle/ff/out/base/string.js":
/*!*****************************************************!*\
  !*** ./node_modules/@pucelle/ff/out/base/string.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.toUnderscoreCase = exports.toDashCase = exports.toCamerCase = exports.capitalize = exports.afterLast = exports.beforeLast = exports.after = exports.before = exports.format = exports.subMatches = exports.subMatchesAt = exports.firstMatch = exports.subMatchAt = exports.selectAll = exports.select = void 0;
/** Replace `$0` to `matches[0]`, `$1` to `matches[1]`... */
function replaceMatchTags(template, match) {
    return template.replace(/\$(?:([$&\d])|<(\w+)>)/g, (_m0, m1, m2) => {
        if (m2) {
            return match.groups ? match.groups[m2] || '' : '';
        }
        else if (m1 === '$') {
            return '$';
        }
        else if (m1 === '&') {
            return match[0];
        }
        else {
            return typeof match[m1] === 'string' ? match[m1] : '';
        }
    });
}
/**
 * Select sub matches from `string` by matching `re`, then format a `template` with sub matches.
 * Returns the format result.
 * @param string The string to select sub matches.
 * @param re The RegExp to execute on string.
 * @param template Replace `$i` or `$<name>` to corresponding match.
 */
function select(string, re, template) {
    let match = re.exec(string);
    return match ? replaceMatchTags(template, match) : '';
}
exports.select = select;
/**
 * Select sub matches from `string` by matching `re`, then format a `template` with sub matches.
 * Returns the format results.
 * @param string The string to select sub matches.
 * @param re The RegExp to execute on string.
 * @param template Replace `$i` or `$<name>` to corresponding match.
 */
function selectAll(string, re, template) {
    if (re.global) {
        let match;
        let matches = [];
        while (match = re.exec(string)) {
            matches.push(replaceMatchTags(template, match));
        }
        return matches;
    }
    else {
        let match = string.match(re);
        if (match) {
            return [replaceMatchTags(template, match)];
        }
        else {
            return [];
        }
    }
}
exports.selectAll = selectAll;
/**
 * Returns specified `index` of sub matches from executing `re` on `string`.
 * @param string The string to select sub match.
 * @param re The RegExp to execute on string.
 * @param index Select the sub match in the index from match resul.
 */
function subMatchAt(string, re, index) {
    let match = re.exec(string);
    if (match) {
        return match[index] || '';
    }
    else {
        return '';
    }
}
exports.subMatchAt = subMatchAt;
/**
 * Returns the first sub match from executing `re` on `string`.
 * @param string The string to select sub match.
 * @param re The RegExp to execute on string.
 */
function firstMatch(string, re) {
    return subMatchAt(string, re, 1);
}
exports.firstMatch = firstMatch;
/**
 * For each match result from executing `re` on `string`, picks specified `index` of sub matches, returns array of them.
 * @param string The string to select sub match.
 * @param re The RegExp to execute on string.
 * @param index Select the sub match in the index from each match result.
 */
function subMatchesAt(string, re, index) {
    if (re.global) {
        let match;
        let matches = [];
        while (match = re.exec(string)) {
            matches.push(match[index] || '');
        }
        return matches;
    }
    else {
        let match = string.match(re);
        if (match) {
            return [match[index] || ''];
        }
        else {
            return [];
        }
    }
}
exports.subMatchesAt = subMatchesAt;
/**
 * Returns array of sub matches from executing `re` on `string`.
 * @param string The string to select sub matches.
 * @param re The RegExp to execute on string.
 * @param sliceIndex Slice each match result from, specify to `0` to include whole match, `1` to only include sub matches, default value is `1`.
 */
function subMatches(string, re, sliceIndex = 1) {
    if (re.global) {
        let match;
        let matches = [];
        while (match = re.exec(string)) {
            matches.push([...match].slice(sliceIndex));
        }
        return matches;
    }
    else {
        let match = string.match(re);
        if (match) {
            return [[...match].slice(sliceIndex)];
        }
        else {
            return [];
        }
    }
}
exports.subMatches = subMatches;
/**
 * Format string to replace placeholders like `{key}` in `template` to `args[key]`.
 * Will keep the placeholder if no match found.
 * @param template String to format
 * @param args The arguments to replace ${...} to.
 */
function format(template, args) {
    return template.replace(/\{(\w+)\}/g, (m0, m1) => {
        let value = args[m1];
        if (value === undefined) {
            value = m0;
        }
        return value;
    });
}
exports.format = format;
/**
 * Get the left part of `string` before `substring`.
 * @param string The string to search substring.
 * @param substring The sub part to search in string.
 * @param greedy If true, when substring can't be found in string, returns the whole string.
 */
function before(string, substring, greedy = false) {
    let index = string.indexOf(substring);
    if (index < 0) {
        return greedy ? string : '';
    }
    else {
        return string.slice(0, index);
    }
}
exports.before = before;
/**
 * Get the right part of `string` before `substring`.
 * @param string The string to search substring.
 * @param substring The sub part to search in string.
 * @param greedy If true, when substring can't be found in string, returns the whole string.
 */
function after(string, substring, greedy = false) {
    let index = string.indexOf(substring);
    if (index < 0) {
        return greedy ? string : '';
    }
    else {
        return string.slice(index + substring.length);
    }
}
exports.after = after;
/**
 * Get the left part of `string` before the last matched `substring`.
 * @param string The string to search substring.
 * @param substring The sub part to search in string.
 * @param greedy If true, when substring can't be found in string, returns the whole string.
 */
function beforeLast(string, substring, greedy = false) {
    let index = string.lastIndexOf(substring);
    if (index < 0) {
        return greedy ? string : '';
    }
    else {
        return string.slice(0, index);
    }
}
exports.beforeLast = beforeLast;
/**
 * Get the right part of `string` before the last matched `substring`.
 * @param string The string to search substring.
 * @param substring The sub part to search in string.
 * @param greedy If true, when substring can't be found in string, returns the whole string.
 */
function afterLast(string, substring, greedy = false) {
    let index = string.lastIndexOf(substring);
    if (index < 0) {
        return greedy ? string : '';
    }
    else {
        return string.slice(index + 1);
    }
}
exports.afterLast = afterLast;
/**
 * Uppercase the first character of `string`.
 * @param string The string to be capitalized.
 */
function capitalize(string) {
    return string.slice(0, 1).toUpperCase() + string.slice(1).toLowerCase();
}
exports.capitalize = capitalize;
/**
 * Transform `string` to camer case type.
 * @param string The string to transform.
 */
function toCamerCase(string) {
    return string.replace(/[-_ ][a-z]/gi, m0 => m0[1].toUpperCase());
}
exports.toCamerCase = toCamerCase;
/**
 * Transform `string` to dash case type by spliting words with `-`.
 * @param string The string to transform.
 */
function toDashCase(string) {
    return string.replace(/(^|.)([A-Z]+)/g, (m0, charBefore, upperChars) => {
        if (charBefore && /[a-z ]/i.test(charBefore)) {
            return charBefore + '-' + upperChars.toLowerCase();
        }
        else {
            return m0.toLowerCase();
        }
    })
        .replace(/_/g, '-');
}
exports.toDashCase = toDashCase;
/**
 * Transform `string` to dash case by spliting words with `_`.
 * @param string The string to transform.
 */
function toUnderscoreCase(string) {
    return toDashCase(string).replace(/-/g, '_');
}
exports.toUnderscoreCase = toUnderscoreCase;


/***/ }),

/***/ "./node_modules/@pucelle/ff/out/base/time.js":
/*!***************************************************!*\
  !*** ./node_modules/@pucelle/ff/out/base/time.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.sleep = void 0;
/**
 * Returns a promise which will be resolved after `ms` milliseconds.
 * @param ms The sleep time in milliseconds.
 */
function sleep(ms = 0) {
    return new Promise(resolve => setTimeout(resolve, ms));
}
exports.sleep = sleep;


/***/ }),

/***/ "./node_modules/@pucelle/ff/out/dom/align.js":
/*!***************************************************!*\
  !*** ./node_modules/@pucelle/ff/out/dom/align.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.alignToEvent = exports.getMainAlignDirection = exports.Aligner = exports.align = void 0;
const style_1 = __webpack_require__(/*! ./style */ "./node_modules/@pucelle/ff/out/dom/style.js");
const element_1 = __webpack_require__(/*! ./element */ "./node_modules/@pucelle/ff/out/dom/element.js");
const util_1 = __webpack_require__(/*! ./util */ "./node_modules/@pucelle/ff/out/dom/util.js");
/**
 * Align `el` to `target` element by specified position.
 * If no enough space, will adjust align position automatically.
 * Note that this mathod will always cause reflow.
 * @param el The element to align, it's position should be fixed or absolute.
 * @param target The target element to align to.
 * @param position The position that aligning according to, `[Y of el][X of el]-[Y of target][X of target]` or `[Touch][Align]` or `[Touch]`.
 * @param options Additional options.
 */
function align(el, target, position, options = {}) {
    new Aligner(el, target, position, options);
}
exports.align = align;
class Aligner {
    constructor(el, target, position, options = {}) {
        this.triangleRect = null;
        this.x = 0;
        this.y = 0;
        this.el = el;
        this.target = target;
        this.triangle = options.triangle || null;
        this.canShrinkInY = !!options.canShrinkInY;
        this.fixTriangle = !!options.fixTriangle;
        if (this.triangle) {
            this.triangle.style.transform = '';
            this.triangleRect = this.triangle ? element_1.getRect(this.triangle) : null;
        }
        this.rect = element_1.getRect(this.el);
        this.position = parseAlignPosition(position);
        this.direction = this.getDirections();
        this.margin = this.parseMargin(options.margin || 0);
        this.targetRect = this.getExtendedRect();
        this.targetInViewport = inViewport(this.targetRect);
        if (this.canShrinkInY && !this.triangle) {
            this.rect.height = this.getNaturalHeight();
        }
        this.align();
    }
    align() {
        // If target not affected by document scrolling, el should same
        if (util_1.getClosestFixedElement(this.target)) {
            this.el.style.position = 'fixed';
        }
        let anchor1 = this.getElRelativeAnchor();
        let anchor2 = this.getTargetAbsoluteAnchor();
        this.y = anchor2[1] - anchor1[1];
        let overflowYSet = this.alignVertical();
        // If scrollbar appeared, width of el may change
        if (overflowYSet) {
            this.rect = element_1.getRect(this.el);
            anchor1 = this.getElRelativeAnchor();
        }
        this.x = anchor2[0] - anchor1[0];
        this.alignHerizontal();
        // Handle triangle position
        if (this.triangle) {
            this.alignTriangle();
        }
        // If is not fixed, minus coordinates relative to offsetParent
        if (getComputedStyle(this.el).position !== 'fixed' && this.target !== document.body && this.target !== document.documentElement) {
            var offsetParent = this.el.offsetParent;
            // If we use body's top postion, it will cause a bug when body has a margin top (even from margin collapse)
            if (offsetParent) {
                var parentRect = offsetParent.getBoundingClientRect();
                this.x -= parentRect.left;
                this.y -= parentRect.top;
            }
        }
        this.el.style.left = this.x + 'px';
        this.el.style.top = this.y + 'px';
    }
    /** Zero, one or two values be `true`. */
    getDirections() {
        return {
            top: this.position[0].includes('b') && this.position[1].includes('t'),
            right: this.position[0].includes('l') && this.position[1].includes('r'),
            bottom: this.position[0].includes('t') && this.position[1].includes('b'),
            left: this.position[0].includes('r') && this.position[1].includes('l'),
        };
    }
    /**
     * top [right] [bottom] [left] -> [t, r, b, l].
     * If align to a top position of target, unique number will be parsed as 0 in left and right position.
     */
    parseMargin(marginOption) {
        let margin = [];
        if (typeof marginOption === 'number') {
            margin[0] = this.direction.top || this.direction.bottom ? marginOption : 0;
            margin[1] = this.direction.left || this.direction.right ? marginOption : 0;
        }
        else {
            margin.push(...marginOption);
        }
        margin[0] = margin[0] || 0;
        margin[1] = margin[1] !== undefined ? margin[1] || 0 : margin[0];
        margin[2] = margin[2] !== undefined ? margin[2] || 0 : margin[0];
        margin[3] = margin[3] !== undefined ? margin[3] || 0 : margin[1];
        if (this.triangleRect) {
            if (this.direction.top || this.direction.bottom) {
                margin[0] += this.triangleRect.height;
                margin[2] += this.triangleRect.height;
            }
            if (this.direction.left || this.direction.right) {
                margin[1] += this.triangleRect.width;
                margin[3] += this.triangleRect.width;
            }
        }
        return margin;
    }
    getExtendedRect() {
        let rect = element_1.getRect(this.target);
        rect.top -= this.margin[0];
        rect.height += this.margin[0] + this.margin[2];
        rect.bottom = rect.top + rect.height;
        rect.left -= this.margin[3];
        rect.width += this.margin[1] + this.margin[3];
        rect.right = rect.left + rect.width;
        return rect;
    }
    /**
     * When el can be scrolled, if we just expend it to test its natural height, it's scrolled position will lost.
     * So we get `scrollHeight - clientHeight` as a diff and add it to it's current height as it's natural height.
     * Note that the `triangle` will cause `scrollHeight` plus for it's height.
     * Otherwise may not el but child is scrolled.
     */
    getNaturalHeight() {
        let h = this.rect.height;
        let diffHeight = this.el.scrollHeight - this.el.clientHeight;
        let maxAllowdDiffWhenNotScrolled = this.triangleRect ? this.triangleRect.height : 0;
        if (diffHeight <= maxAllowdDiffWhenNotScrolled) {
            diffHeight = Math.max(...[...this.el.children].map(child => child.scrollHeight - child.clientHeight));
        }
        if (diffHeight > 0) {
            h = h + diffHeight;
        }
        else {
            this.el.style.height = '';
            h = this.el.offsetHeight;
        }
        return h;
    }
    /** get relative anchor position of the axis of an element. */
    getElRelativeAnchor() {
        let rect = this.rect;
        let anchor = this.position[0];
        let x = anchor.includes('l') ? 0 : anchor.includes('r') ? rect.width : rect.width / 2;
        let y = anchor.includes('t') ? 0 : anchor.includes('b') ? rect.height : rect.height / 2;
        if (this.fixTriangle && this.triangleRect) {
            if ((this.direction.top || this.direction.bottom) && this.position[1][1] === 'c') {
                x = this.triangleRect.left + this.triangleRect.width / 2 - rect.left;
            }
            else if ((this.direction.left || this.direction.right) && this.position[1][0] === 'c') {
                y = this.triangleRect.top + this.triangleRect.height / 2 - rect.top;
            }
        }
        return [x, y];
    }
    /** get absolute anchor position in scrolling page */
    getTargetAbsoluteAnchor() {
        let rect = this.targetRect;
        let anchor = this.position[1];
        let x = anchor.includes('l') ? 0 : anchor.includes('r') ? rect.width : rect.width / 2;
        let y = anchor.includes('t') ? 0 : anchor.includes('b') ? rect.height : rect.height / 2;
        x += rect.left;
        y += rect.top;
        return [x, y];
    }
    alignVertical() {
        let dh = document.documentElement.clientHeight;
        let spaceTop = this.targetRect.top;
        let spaceBottom = dh - this.targetRect.bottom;
        let overflowYSet = false;
        let h = this.rect.height;
        let y = this.y;
        if (this.targetInViewport) {
            if (this.direction.top || this.direction.bottom) {
                if (this.direction.top && y < 0 && spaceTop < spaceBottom) {
                    y = this.targetRect.bottom;
                    this.direction.top = false;
                    this.direction.bottom = true;
                }
                else if (y + h > dh && spaceTop > spaceBottom) {
                    y = this.targetRect.top - h;
                    this.direction.top = true;
                    this.direction.bottom = false;
                }
            }
            else {
                if (y + h > dh) {
                    let minY = this.targetRect.top + this.margin[1] + (this.triangleRect ? this.triangleRect.height : 0) - h;
                    y = Math.max(dh - h, minY);
                }
                if (y < 0) {
                    let maxY = this.targetRect.bottom - this.margin[2] - (this.triangleRect ? this.triangleRect.height : 0);
                    y = Math.min(0, maxY);
                }
            }
            if (y < 0) {
                if (this.direction.top && this.canShrinkInY) {
                    y = 0;
                    this.el.style.height = spaceTop + 'px';
                    overflowYSet = true;
                }
            }
            else if (this.direction.bottom && y + h > dh) {
                if (this.canShrinkInY) {
                    this.el.style.height = spaceBottom + 'px';
                    overflowYSet = true;
                }
            }
            this.y = y;
        }
        return overflowYSet;
    }
    alignHerizontal() {
        let dw = document.documentElement.clientWidth;
        let spaceLeft = this.targetRect.left;
        let spaceRight = dw - this.targetRect.right;
        let w = this.rect.width;
        let x = this.x;
        if (this.targetInViewport) {
            if (this.direction.left || this.direction.right) {
                if (this.direction.left && x < 0 && spaceLeft < spaceRight) {
                    x = this.targetRect.right;
                    this.direction.left = false;
                    this.direction.right = true;
                }
                else if (this.direction.right && x > dw - w && spaceLeft > spaceRight) {
                    x = this.targetRect.left - w;
                    this.direction.left = true;
                    this.direction.right = false;
                }
            }
            else {
                if (x + w > dw) {
                    let minX = this.targetRect.left + this.margin[3] + (this.triangleRect ? this.triangleRect.width : 0) - w;
                    x = Math.max(dw - w, minX);
                }
                if (x < 0) {
                    let minX = this.targetRect.right - this.margin[1] - (this.triangleRect ? this.triangleRect.width : 0);
                    x = Math.min(0, minX);
                }
            }
            this.x = x;
        }
    }
    alignTriangle() {
        let triangle = this.triangle;
        let triangleRect = this.triangleRect;
        let transforms = [];
        let w = this.rect.width;
        let h = this.rect.height;
        if (this.direction.top) {
            triangle.style.top = 'auto';
            triangle.style.bottom = -triangleRect.height + 'px';
            transforms.push('rotateX(180deg)');
        }
        else if (this.direction.bottom) {
            triangle.style.top = -triangleRect.height + 'px';
            triangle.style.bottom = '';
        }
        else if (this.direction.left) {
            triangle.style.left = 'auto';
            triangle.style.right = -triangleRect.width + 'px';
            transforms.push('rotateY(180deg)');
        }
        else if (this.direction.right) {
            triangle.style.left = -triangleRect.width + 'px';
            triangle.style.right = '';
        }
        if (this.direction.top || this.direction.bottom) {
            let halfTriangleWidth = triangleRect.width / 2;
            let x;
            // Triangle in the center of the edge of target
            if ((w >= this.targetRect.width || this.fixTriangle) && this.position[1][1] === 'c') {
                x = this.targetRect.left + this.targetRect.width / 2 - this.x - halfTriangleWidth;
            }
            // Triangle in the center of the edge of el
            else {
                x = w / 2 - halfTriangleWidth;
            }
            x = Math.max(x, halfTriangleWidth);
            x = Math.min(x, this.rect.width - triangleRect.width - halfTriangleWidth);
            if (this.fixTriangle) {
                x -= triangleRect.left - this.rect.left;
                transforms.push(`translateX(${x}px)`);
            }
            else {
                triangle.style.left = x + 'px';
            }
            triangle.style.right = '';
        }
        if (this.direction.left || this.direction.right) {
            let halfTriangleHeight = triangleRect.height / 2;
            let y;
            if ((h >= this.targetRect.height || this.fixTriangle) && this.position[1][0] === 'c') {
                y = this.targetRect.top + this.targetRect.height / 2 - this.y - halfTriangleHeight;
            }
            else {
                y = h / 2 - halfTriangleHeight;
            }
            y = Math.max(y, halfTriangleHeight);
            y = Math.min(y, this.rect.height - triangleRect.height - halfTriangleHeight);
            if (this.fixTriangle) {
                y -= triangleRect.top - this.rect.top;
                transforms.push(`translateY(${y}px)`);
            }
            else {
                triangle.style.top = y + 'px';
            }
            triangle.style.bottom = '';
        }
        triangle.style.transform = transforms.join(' ');
    }
}
exports.Aligner = Aligner;
/**
 * Full type is `[tbc][lrc]-[tbc][lrc]`, means `[Y of el][X of el]-[Y of target][X of target]`.
 * Shorter type should be `[Touch][Align]` or `[Touch]`.
 * E.g.: `t` is short for `tc` or `b-t` or `bc-tc`, which means align el to the top-center of target.
 * E.g.: `tl` is short for `bl-tl`, which means align el to the top-left of target.
 * E.g.: `lt` is short for `tr-tl`, which means align el to the left-top of target.
 */
function parseAlignPosition(position) {
    const ALIGN_POS_OPPOSITE = {
        t: 'b',
        b: 't',
        c: 'c',
        l: 'r',
        r: 'l',
    };
    if (!/^(?:[tbc][lrc]-[tbc][lrc]|[tbclr]-[tbclr]|[tbc][lrc]|[tbclr])/.test(position)) {
        throw `"${position}" is not a valid position`;
    }
    if (position.length === 1) {
        // t -> bc-tc
        if ('tb'.includes(position)) {
            position = ALIGN_POS_OPPOSITE[position] + 'c-' + position + 'c';
        }
        // l -> cr-cl
        // c -> cc-cc
        else {
            position = 'c' + ALIGN_POS_OPPOSITE[position] + '-c' + position;
        }
    }
    else if (position.length === 2) {
        // tl -> bl-tl
        if ('tb'.includes(position[0])) {
            position = ALIGN_POS_OPPOSITE[position[0]] + position[1] + '-' + position;
        }
        // lt -> tr-tl
        else {
            position = position[1] + ALIGN_POS_OPPOSITE[position[0]] + '-' + position[1] + position[0];
        }
    }
    let posArray = position.split('-');
    return [completeAlignPosition(posArray[0]), completeAlignPosition(posArray[1])];
}
function completeAlignPosition(pos) {
    if (pos.length === 1) {
        pos = 'tb'.includes(pos) ? pos + 'c' : 'c' + pos;
    }
    return pos;
}
/**
 * Get main align direction from align position string, can be used to set triangle styles.
 * @param pos Align position like `t`, `tc`, `bc-tc`.
 */
function getMainAlignDirection(pos) {
    let position = pos.length < 5 ? parseAlignPosition(pos) : pos;
    if (position[0].includes('b') && position[1].includes('t')) {
        return 't';
    }
    else if (position[0].includes('l') && position[1].includes('r')) {
        return 'r';
    }
    else if (position[0].includes('t') && position[1].includes('b')) {
        return 'b';
    }
    else if (position[0].includes('r') && position[1].includes('l')) {
        return 'l';
    }
    else if (position[0] === 'cc' && position[1] === 'cc') {
        return 'c';
    }
    else {
        return '';
    }
}
exports.getMainAlignDirection = getMainAlignDirection;
function inViewport(rect) {
    let w = document.documentElement.clientWidth;
    let h = document.documentElement.clientHeight;
    return rect.left < w && rect.right > 0 && rect.top < h && rect.bottom > 0;
}
/**
 * Align element to a mouse event.
 * @param el A fixed position element to align.
 * @param event A mouse event to align to.
 * @param offset `[x, y]` offset to adjust align position.
 */
function alignToEvent(el, event, offset = [0, 0]) {
    if (style_1.getStyle(el, 'position') !== 'fixed') {
        throw new Error(`Element to call "alignToEvent" must be fixed layout`);
    }
    let dw = document.documentElement.clientWidth;
    let dh = document.documentElement.clientHeight;
    let w = el.offsetWidth;
    let h = el.offsetHeight;
    let ex = event.clientX;
    let ey = event.clientY;
    let x = ex + offset[0];
    let y = ey + offset[1];
    if (x + w > dw) {
        x = dw - w;
    }
    if (y + h > dh) {
        y = dh - h;
    }
    el.style.left = Math.round(x) + 'px';
    el.style.top = Math.round(y) + 'px';
}
exports.alignToEvent = alignToEvent;


/***/ }),

/***/ "./node_modules/@pucelle/ff/out/dom/animate.js":
/*!*****************************************************!*\
  !*** ./node_modules/@pucelle/ff/out/dom/animate.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.isPlayingAnimation = exports.stopAnimation = exports.animateToNextFrame = exports.animateTo = exports.animateFrom = exports.animate = exports.animateByFunction = exports.animatePropertyTo = exports.animatePropertyFrom = exports.animateProperty = exports.getEasing = exports.getEasingFunction = exports.defaultAnimationEasing = exports.defaultAnimationDuration = void 0;
const style_1 = __webpack_require__(/*! ./style */ "./node_modules/@pucelle/ff/out/dom/style.js");
const util_1 = __webpack_require__(/*! ./util */ "./node_modules/@pucelle/ff/out/dom/util.js");
exports.defaultAnimationDuration = 200;
exports.defaultAnimationEasing = 'ease-out-quad';
const ElementAnimationMap = new WeakMap();
// Copied from `Bourbon` source codes.
const CUBIC_BEZIER_EASINGS = {
    // BASE
    'ease': [0.250, 0.100, 0.250, 1.000],
    'ease-in': [0.420, 0.000, 1.000, 1.000],
    'ease-out': [0.000, 0.000, 0.580, 1.000],
    'ease-in-out': [0.420, 0.000, 0.580, 1.000],
    // EASE IN
    'ease-in-quad': [0.550, 0.085, 0.680, 0.530],
    'ease-in-cubic': [0.550, 0.055, 0.675, 0.190],
    'ease-in-quart': [0.895, 0.030, 0.685, 0.220],
    'ease-in-quint': [0.755, 0.050, 0.855, 0.060],
    'ease-in-sine': [0.470, 0.000, 0.745, 0.715],
    'ease-in-expo': [0.950, 0.050, 0.795, 0.035],
    'ease-in-circ': [0.600, 0.040, 0.980, 0.335],
    'ease-in-back': [0.600, -0.280, 0.735, 0.045],
    // EASE OUT
    'ease-out-quad': [0.250, 0.460, 0.450, 0.940],
    'ease-out-cubic': [0.215, 0.610, 0.355, 1.000],
    'ease-out-quart': [0.165, 0.840, 0.440, 1.000],
    'ease-out-quint': [0.230, 1.000, 0.320, 1.000],
    'ease-out-sine': [0.390, 0.575, 0.565, 1.000],
    'ease-out-expo': [0.190, 1.000, 0.220, 1.000],
    'ease-out-circ': [0.075, 0.820, 0.165, 1.000],
    'ease-out-back': [0.175, 0.885, 0.320, 1.275],
    // EASE IN OUT
    'ease-in-out-quad': [0.455, 0.030, 0.515, 0.955],
    'ease-in-out-cubic': [0.645, 0.045, 0.355, 1.000],
    'ease-in-out-quart': [0.770, 0.000, 0.175, 1.000],
    'ease-in-out-quint': [0.860, 0.000, 0.070, 1.000],
    'ease-in-out-sine': [0.445, 0.050, 0.550, 0.950],
    'ease-in-out-expo': [1.000, 0.000, 0.000, 1.000],
    'ease-in-out-circ': [0.785, 0.135, 0.150, 0.860],
    'ease-in-out-back': [0.680, -0.550, 0.265, 1.550],
};
const easingFns = {
    linear: function (x) {
        return x;
    }
};
/**
 * Get a `(x) => y` function from easing name.
 * @param easing The extended easing name.
 */
function getEasingFunction(name) {
    if (name === 'linear') {
        return easingFns[name];
    }
    else {
        return easingFns[name] = getCubicBezierEasingFunction(name);
    }
}
exports.getEasingFunction = getEasingFunction;
/**
 * Get `cubic-bezier(...)` from easing name.
 * @param easing The extended easing name.
 */
function getEasing(easing) {
    return CUBIC_BEZIER_EASINGS.hasOwnProperty(easing)
        ? 'cubic-bezier(' + CUBIC_BEZIER_EASINGS[easing].join(', ') + ')'
        : easing;
}
exports.getEasing = getEasing;
/**
F(t)  = (1-t)^3 * P0 + 3t(1-t)^2 * P1 + 3t^2(1-t)^2 * P2 + t^3 * P3, t in [0, 1]

Get the x axis projecting function, and knows x0 = 0, x3 = 1, got:
Cx(t) = 3t(1-t)^2 * x1 + 3t^2(1-t) * x2 + t^3
      = (3x1 - 3x2 + 1) * t^3 + (-6x1 + 3x2) * t^2 + 3x1 * t

From Cx(t) = x, got t by binary iteration algorithm, then pass it to y axis projecting function:
Cy(t) = (3y1 - 3y2 + 1) * t^3 + (-6y1 + 3y2) * t^2 + 3y1 * t

*/
function getCubicBezierEasingFunction(name) {
    let [x1, y1, x2, y2] = CUBIC_BEZIER_EASINGS[name];
    let a = 3 * x1 - 3 * x2 + 1;
    let b = -6 * x1 + 3 * x2;
    let c = 3 * x1;
    let ay = 3 * y1 - 3 * y2 + 1;
    let by = -6 * y1 + 3 * y2;
    let cy = 3 * y1;
    return function (x) {
        if (x === 0) {
            return 0;
        }
        else if (x === 1) {
            return 1;
        }
        let d = -x;
        let t1 = 0;
        let t2 = 1;
        let t = (t1 + t2) / 2;
        while (t2 - t1 > 0.0001) {
            let v = ((a * t + b) * t + c) * t + d;
            if (v < 0) {
                t1 = t;
            }
            else {
                t2 = t;
            }
            t = (t1 + t2) / 2;
        }
        return ((ay * t + by) * t + cy) * t;
    };
}
function playIntervalAnimation(duration = exports.defaultAnimationDuration, easing = exports.defaultAnimationEasing, onInterval, onEnd) {
    let startTimestamp = performance.now();
    let easingFn = getEasingFunction(easing);
    let frameId = 0;
    let runNextFrame = () => {
        frameId = requestAnimationFrame((timestamp) => {
            let timeDiff = timestamp - startTimestamp;
            let x = timeDiff / duration;
            if (x >= 1) {
                frameId = 0;
                onInterval(1);
                if (onEnd) {
                    onEnd(true);
                }
            }
            else {
                let y = easingFn(x);
                onInterval(y);
                runNextFrame();
            }
        });
    };
    runNextFrame();
    return () => {
        if (frameId) {
            cancelAnimationFrame(frameId);
            if (onEnd) {
                onEnd(false);
            }
        }
    };
}
/**
 * Animate numberic style property or `scrollLeft` and `scrollTop` on `el`.
 * Execute animation by setting values in `requestAnimationFrame`.
 * @param el The element to animate.
 * @param property The style property or `scrollLeft` and `scrollTop`.
 * @param startValue The start value of `property`.
 * @param endValue  The end value of `property`.
 * @param duration The animation duration.
 * @param easing  The animation easing.
 */
function animateProperty(el, property, startValue, endValue, duration, easing = exports.defaultAnimationEasing) {
    let stop;
    let promise = new Promise((resolve) => {
        stop = playIntervalAnimation(duration, easing, (y) => {
            let value = startValue + (endValue - startValue) * y;
            if (property === 'scrollTop' || property === 'scrollLeft') {
                el[property] = value;
            }
            else {
                style_1.setStyle(el, property, value);
            }
        }, resolve);
    });
    return {
        promise,
        stop,
    };
}
exports.animateProperty = animateProperty;
/**
 * Animate numberic style property or `scrollLeft` and `scrollTop` on `el`.
 * Execute animation by setting values in `requestAnimationFrame`.
 * @param el The element to animate.
 * @param property The style property or `scrollLeft` and `scrollTop`.
 * @param startValue The start value.
 * @param duration The animation duration.
 * @param easing  The animation easing.
 */
function animatePropertyFrom(el, property, startValue, duration, easing = exports.defaultAnimationEasing) {
    let endValue;
    if (property === 'scrollTop' || property === 'scrollLeft') {
        endValue = el[property];
    }
    else {
        endValue = style_1.getStyleAsNumber(el, property);
    }
    return animateProperty(el, property, startValue, endValue, duration, easing);
}
exports.animatePropertyFrom = animatePropertyFrom;
/**
 * Animate numberic style property or `scrollLeft` and `scrollTop` on `el`.
 * Execute animation by setting values in `requestAnimationFrame`.
 * @param el The element to animate.
 * @param property The style property or `scrollLeft` and `scrollTop`.
 * @param endValue The end value.
 * @param duration The animation duration.
 * @param easing  The animation easing.
 */
function animatePropertyTo(el, property, endValue, duration, easing = exports.defaultAnimationEasing) {
    let startValue;
    if (property === 'scrollTop' || property === 'scrollLeft') {
        startValue = el[property];
    }
    else {
        startValue = style_1.getStyleAsNumber(el, property);
    }
    return animateProperty(el, property, startValue, endValue, duration, easing);
}
exports.animatePropertyTo = animatePropertyTo;
/**
 * Animate by a value range, `fn` recives current value as argument.
 * @param fn The function which will got a current state number value as argument.
 * @param startValue The start value.
 * @param endValue  The end value.
 * @param duration The animation duration.
 * @param easing  The animation easing.
 */
function animateByFunction(fn, startValue, endValue, duration, easing = exports.defaultAnimationEasing) {
    let stop;
    let promise = new Promise((resolve) => {
        stop = playIntervalAnimation(duration, easing, (y) => {
            fn(startValue + (endValue - startValue) * y);
        }, resolve);
    });
    return {
        promise,
        stop,
    };
}
exports.animateByFunction = animateByFunction;
/**
 * Execute standard web animation on element.
 * After animation end, the state of element will go back to the start state.
 * @param el The element to execute web animation.
 * @param startFrame The start frame.
 * @param endFrame The end frame.
 * @param duration The animation duration.
 * @param easing  The animation easing.
 */
function animate(el, startFrame, endFrame, duration = exports.defaultAnimationDuration, easing = exports.defaultAnimationEasing) {
    if (!el.animate) {
        return Promise.resolve(false);
    }
    stopAnimation(el);
    startFrame = util_1.normativeStyleObject(startFrame);
    endFrame = util_1.normativeStyleObject(endFrame);
    let cubicEasing = getEasing(easing);
    let animation = el.animate([startFrame, endFrame], {
        easing: cubicEasing,
        duration,
    });
    ElementAnimationMap.set(el, animation);
    return new Promise((resolve) => {
        animation.addEventListener('finish', () => {
            ElementAnimationMap.delete(el);
            resolve(true);
        }, false);
        animation.addEventListener('cancel', () => {
            ElementAnimationMap.delete(el);
            resolve(false);
        }, false);
    });
}
exports.animate = animate;
/** The default style of element, which is not 0 */
const DEFAULT_STYLE = {
    transform: 'none'
};
/**
 * Execute standard web animation on element with start frame specified, the end frame will be set as zero or empty values.
 * @param el The element to execute web animation.
 * @param startFrame The start frame.
 * @param duration The animation duration.
 * @param easing  The animation easing.
 */
function animateFrom(el, startFrame, duration = exports.defaultAnimationDuration, easing = exports.defaultAnimationEasing) {
    let endFrame = {};
    let style = getComputedStyle(el);
    for (let property in startFrame) {
        endFrame[property] = style[property] || DEFAULT_STYLE[property] || '0';
    }
    return animate(el, startFrame, endFrame, duration, easing);
}
exports.animateFrom = animateFrom;
/**
 * Execute standard web animation on element with end frame specified, the end frame will be specified as values of current state.
 * After animation executed, will apply end frame values to element.
 * @param el The element to execute web animation.
 * @param endFrame The end frame.
 * @param duration The animation duration.
 * @param easing  The animation easing.
 */
async function animateTo(el, endFrame, duration = exports.defaultAnimationDuration, easing = exports.defaultAnimationEasing) {
    let startFrame = {};
    let style = getComputedStyle(el);
    // Fix '' to `0` or `none`
    let standardEndFrame = Object.assign({}, endFrame);
    for (let property in standardEndFrame) {
        if (standardEndFrame[property] === '') {
            standardEndFrame[property] = DEFAULT_STYLE[property] || '0';
        }
    }
    for (let property in endFrame) {
        startFrame[property] = style[property] || DEFAULT_STYLE[property] || '0';
    }
    let finish = await animate(el, startFrame, standardEndFrame, duration, easing);
    if (finish) {
        style_1.setStyle(el, endFrame);
    }
    return finish;
}
exports.animateTo = animateTo;
/** Execute standard web animation, capture current state as start frame, and capture a new state later as end frame.
 * @param el The element to execute web animation.
 * @param properties The style properties to capture.
 * @param duration The animation duration.
 * @param easing  The animation easing.
 */
function animateToNextFrame(el, properties, duration = exports.defaultAnimationDuration, easing = exports.defaultAnimationEasing) {
    if (!el.animate) {
        return Promise.resolve(false);
    }
    stopAnimation(el);
    if (typeof properties === 'string') {
        properties = [properties];
    }
    let startFrame = {};
    let style = getComputedStyle(el);
    for (let property of properties) {
        startFrame[property] = style[property];
    }
    return new Promise(resolve => {
        requestAnimationFrame(() => {
            animateFrom(el, startFrame, duration, easing).then(resolve);
        });
    });
}
exports.animateToNextFrame = animateToNextFrame;
/**
 * Stop executing animation on element.
 * @param el The element to stop animation.
 */
function stopAnimation(el) {
    let animation = ElementAnimationMap.get(el);
    if (animation) {
        animation.cancel();
        ElementAnimationMap.delete(el);
    }
}
exports.stopAnimation = stopAnimation;
/**
 * Test if element is playing an animation.
 * @param el The element to test animation.
 */
function isPlayingAnimation(el) {
    let animation = ElementAnimationMap.get(el);
    return !!animation;
}
exports.isPlayingAnimation = isPlayingAnimation;


/***/ }),

/***/ "./node_modules/@pucelle/ff/out/dom/element.js":
/*!*****************************************************!*\
  !*** ./node_modules/@pucelle/ff/out/dom/element.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.isInViewport = exports.getRect = exports.getOuterHeight = exports.getOuterWidth = exports.getInnerHeight = exports.getInnerWidth = exports.getElementIndex = exports.getNodeIndex = void 0;
const style_1 = __webpack_require__(/*! ./style */ "./node_modules/@pucelle/ff/out/dom/style.js");
/**
 * Returns the index of node in it's node siblings.
 * @param node The node.
 */
function getNodeIndex(node) {
    if (node.parentNode) {
        let i = 0;
        for (let child of node.parentNode.childNodes) {
            if (child === node) {
                return i;
            }
            i++;
        }
    }
    return -1;
}
exports.getNodeIndex = getNodeIndex;
/**
 * Returns the index of element in it's element siblings.
 * @param el The node.
 */
function getElementIndex(el) {
    if (el.parentNode) {
        let i = 0;
        for (let child of el.parentNode.children) {
            if (child === el) {
                return i;
            }
            i++;
        }
    }
    return -1;
}
exports.getElementIndex = getElementIndex;
/**
 * Returns inner width of element, which equals `clientWidth - paddingWidths` or `width - paddingWidths - scrollbarWidth`.
 * Note that this method may cause page reflow.
 * @param el The element to get width.
 */
function getInnerWidth(el) {
    let w = el.clientWidth;
    if (w) {
        return el.clientWidth - style_1.getStyleAsNumber(el, 'paddingLeft') - style_1.getStyleAsNumber(el, 'paddingRight');
    }
    else {
        return 0;
    }
}
exports.getInnerWidth = getInnerWidth;
/**
 * Returns inner height of element, which equals to `clientHeight - paddingHeights` or `height - paddingHeights - scrollbarHeight`.
 * Note that this method may cause page reflow.
 * @param el The element to get height.
 */
function getInnerHeight(el) {
    let h = el.clientHeight;
    if (h) {
        return h - style_1.getStyleAsNumber(el, 'paddingTop') - style_1.getStyleAsNumber(el, 'paddingBottom');
    }
    else {
        return 0;
    }
}
exports.getInnerHeight = getInnerHeight;
/**
 * Returns outer width of element, which equals `offsetWidth + marginWidths`.
 * Note that this method may cause page reflow.
 * @param el The element to get width.
 */
function getOuterWidth(el) {
    let w = el.offsetWidth;
    if (w) {
        return w + style_1.getStyleAsNumber(el, 'marginLeft') + style_1.getStyleAsNumber(el, 'marginRight');
    }
    else {
        return 0;
    }
}
exports.getOuterWidth = getOuterWidth;
/**
 * Returns inner height of element, which equals `offsetHeight + marginHeights`.
 * Note that this method may cause page reflow.
 * @param el The element to get height.
 */
function getOuterHeight(el) {
    let h = el.offsetHeight;
    if (h) {
        return h + style_1.getStyleAsNumber(el, 'marginTop') + style_1.getStyleAsNumber(el, 'marginBottom');
    }
    else {
        return 0;
    }
}
exports.getOuterHeight = getOuterHeight;
/**
 * Returns an object like `getBoundingClientRect`, the didderence is it always returns the rect of visible part for `<html>`.
 * Note that this method may cause page reflow.
 * @param el The element to get rect size.
 */
function getRect(el) {
    if (el === document.documentElement) {
        let dw = document.documentElement.clientWidth;
        let dh = document.documentElement.clientHeight;
        return {
            top: 0,
            right: dw,
            bottom: dh,
            left: 0,
            width: dw,
            height: dh
        };
    }
    else {
        let rect = el.getBoundingClientRect();
        return {
            top: rect.top,
            right: rect.right,
            bottom: rect.bottom,
            left: rect.left,
            width: rect.width,
            height: rect.height
        };
    }
}
exports.getRect = getRect;
/**
 * Check if element is visible in current viewport, Otherwise element can't be covered.
 * Note that this method may cause page reflow.
 * @param el The element to check if is in view.
 * @param percentage Specify how much percentage of el size implies in view.
 */
function isInViewport(el, percentage = 0.5) {
    let dw = document.documentElement.clientWidth;
    let dh = document.documentElement.clientHeight;
    let rect = getRect(el);
    let xIntersect = Math.min(dw, rect.right) - Math.max(0, rect.left);
    let yIntersect = Math.min(dh, rect.bottom) - Math.max(0, rect.top);
    let inRange = xIntersect / Math.min(rect.width, dw) > percentage
        && yIntersect / Math.min(rect.height, dh) > percentage;
    if (inRange) {
        if (el.disabled) {
            return true;
        }
        let notBeenCovered = el.contains(document.elementFromPoint(rect.left + rect.width / 2, rect.top + rect.height / 2));
        if (notBeenCovered) {
            return true;
        }
    }
    return false;
}
exports.isInViewport = isInViewport;


/***/ }),

/***/ "./node_modules/@pucelle/ff/out/dom/file.js":
/*!**************************************************!*\
  !*** ./node_modules/@pucelle/ff/out/dom/file.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.getFilesFromTransfer = exports.selectMultipleFolder = exports.selectFolder = exports.selectMultipleFile = exports.selectFile = exports.downloadText = exports.downloadURL = void 0;
const base_1 = __webpack_require__(/*! ../base */ "./node_modules/@pucelle/ff/out/base/index.js");
/**
 * Download url as a file with specified `fileName`.
 * Not that `fileName` may not working for cross domain resources.
 * The final behavior depends on browser.
 * @param url The URL to download.
 * @param fileName The file name.
 */
function downloadURL(url, fileName) {
    let a = document.createElement('a');
    a.hidden = true;
    a.href = url;
    if (fileName) {
        a.download = fileName;
    }
    document.body.appendChild(a);
    a.click();
    a.remove();
}
exports.downloadURL = downloadURL;
/**
 * Download string as a file with specified `fileName`.
 * @param fileName The file name.
 * @param text The text to download.
 * @param mime The MIME type of file.
 */
function downloadText(fileName, text, type = 'text/plain') {
    let blob = new Blob([text], { type });
    let fs = new FileReader;
    fs.onload = () => {
        fs.onload = null;
        let a = document.createElement('a');
        a.download = fileName;
        a.href = fs.result;
        document.body.append(a);
        a.click();
        a.remove();
    };
    fs.readAsDataURL(blob);
}
exports.downloadText = downloadText;
/**
 * Select single file match MIME type by `<input type="file">`.
 * @param The MIME type of files.
 */
function selectFile(mime) {
    return selectFileOrFolder(mime, false, false);
}
exports.selectFile = selectFile;
/**
 * Select multiple files match MIME type by `<input type="file" multiple">`.
 * @param The MIME type of files.
 */
function selectMultipleFile(mime) {
    return selectFileOrFolder(mime, false, true);
}
exports.selectMultipleFile = selectMultipleFile;
/**
 * Select single folder by `<input type="file"directory>`.
 */
function selectFolder() {
    return selectFileOrFolder("*", true, false);
}
exports.selectFolder = selectFolder;
/**
 * Select multiple folder by `<input type="file" directory multiple>`.
 */
function selectMultipleFolder() {
    return selectFileOrFolder("*", true, true);
}
exports.selectMultipleFolder = selectMultipleFolder;
function selectFileOrFolder(mime, isFolder, isMultiple) {
    return new Promise((resolve) => {
        let input = document.createElement('input');
        input.type = 'file';
        input.hidden = true;
        input.accept = mime;
        input.multiple = isMultiple;
        if (isFolder) {
            input.setAttribute('directory', '');
            input.setAttribute('webkitdirectory', '');
        }
        input.onchange = () => {
            if (input.files) {
                resolve(isMultiple ? [...input.files] : input.files[0] || null);
            }
            else {
                resolve(null);
            }
        };
        async function onDomFocus() {
            await base_1.sleep(1000);
            document.removeEventListener('focus', onDomFocus, false);
            input.onchange = null;
            input.remove();
        }
        document.addEventListener('focus', onDomFocus, false);
        document.body.appendChild(input);
        input.click();
    });
}
/**
 * Get files in DataTransfer object captured from drop event.
 * Only work on Chrome.
 * @param transfer The ` DataTransfer` object from drop event.
 */
async function getFilesFromTransfer(transfer) {
    let transferFiles = [...transfer.files];
    let files = [];
    if (transfer.items && typeof DataTransferItem === 'function' && (DataTransferItem.prototype.hasOwnProperty('getAsEntry') || DataTransferItem.prototype.webkitGetAsEntry)) {
        let items = [...transfer.items].filter(item => item.kind === 'file');
        try {
            for (let item of items) {
                let entry = item.hasOwnProperty('getAsEntry') ? item.getAsEntry() : item.webkitGetAsEntry();
                files.push(...await readFilesFromEntry(entry));
            }
        }
        catch (err) {
            files = transferFiles;
        }
    }
    // Can only read files
    else {
        files = transferFiles;
    }
    return files;
}
exports.getFilesFromTransfer = getFilesFromTransfer;
async function readFilesFromEntry(entry) {
    let files = [];
    return new Promise(async (resolve, reject) => {
        if (!entry) {
            resolve();
        }
        else if (entry.isFile) {
            entry.file((file) => {
                file.path = file.path || entry.fullPath;
                files.push(file);
                resolve(files);
            }, reject);
        }
        else if (entry.isDirectory) {
            let reader = entry.createReader();
            try {
                while (true) {
                    let filesInFolder = await readFilesFromDirectoryReader(reader);
                    files.push(...filesInFolder);
                    if (!filesInFolder.length) {
                        break;
                    }
                }
            }
            catch (err) {
                reject(err);
            }
            resolve(files);
        }
    });
}
function readFilesFromDirectoryReader(reader) {
    return new Promise((resolve, reject) => {
        let files = [];
        // readEntries API can only read at most 100 files each time, so if reader isn't completed, still read it.
        reader.readEntries(async (entries) => {
            if (entries && entries.length) {
                try {
                    for (let entry of entries) {
                        files.push(...await readFilesFromEntry(entry));
                    }
                }
                catch (err) {
                    reject(err);
                }
                resolve(files);
            }
            else {
                resolve(files);
            }
        }, reject);
    });
}


/***/ }),

/***/ "./node_modules/@pucelle/ff/out/dom/html.js":
/*!**************************************************!*\
  !*** ./node_modules/@pucelle/ff/out/dom/html.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.decodeHTML = exports.encodeHTML = void 0;
/**
 * Encode `<>` to `&...` to makesure HTML codes safe to append into document.
 * @param code Text to be encoded.
 */
function encodeHTML(code) {
    return code.replace(/&lt;/g, '<').replace(/&gt;/g, '>');
}
exports.encodeHTML = encodeHTML;
/**
 * Decode HTML codes which includes `&...` to mapped readable characters.
 * @param code Encoded HTML codes.
 */
function decodeHTML(code) {
    let parser = new DOMParser();
    let dom = parser.parseFromString(`<!DOCTYPE html><body>${code}</body></html>`, 'text/html');
    return dom.body.textContent;
}
exports.decodeHTML = decodeHTML;


/***/ }),

/***/ "./node_modules/@pucelle/ff/out/dom/index.js":
/*!***************************************************!*\
  !*** ./node_modules/@pucelle/ff/out/dom/index.js ***!
  \***************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __exportStar = (this && this.__exportStar) || function(m, exports) {
    for (var p in m) if (p !== "default" && !exports.hasOwnProperty(p)) __createBinding(exports, m, p);
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
__exportStar(__webpack_require__(/*! ./style */ "./node_modules/@pucelle/ff/out/dom/style.js"), exports);
__exportStar(__webpack_require__(/*! ./element */ "./node_modules/@pucelle/ff/out/dom/element.js"), exports);
__exportStar(__webpack_require__(/*! ./align */ "./node_modules/@pucelle/ff/out/dom/align.js"), exports);
__exportStar(__webpack_require__(/*! ./scroll */ "./node_modules/@pucelle/ff/out/dom/scroll.js"), exports);
__exportStar(__webpack_require__(/*! ./animate */ "./node_modules/@pucelle/ff/out/dom/animate.js"), exports);
__exportStar(__webpack_require__(/*! ./mouse-leave */ "./node_modules/@pucelle/ff/out/dom/mouse-leave.js"), exports);
__exportStar(__webpack_require__(/*! ./file */ "./node_modules/@pucelle/ff/out/dom/file.js"), exports);
__exportStar(__webpack_require__(/*! ./query */ "./node_modules/@pucelle/ff/out/dom/query.js"), exports);
__exportStar(__webpack_require__(/*! ./storage */ "./node_modules/@pucelle/ff/out/dom/storage.js"), exports);
__exportStar(__webpack_require__(/*! ./watch-layout */ "./node_modules/@pucelle/ff/out/dom/watch-layout.js"), exports);
__exportStar(__webpack_require__(/*! ./net */ "./node_modules/@pucelle/ff/out/dom/net.js"), exports);
__exportStar(__webpack_require__(/*! ./html */ "./node_modules/@pucelle/ff/out/dom/html.js"), exports);
__exportStar(__webpack_require__(/*! ./timing */ "./node_modules/@pucelle/ff/out/dom/timing.js"), exports);


/***/ }),

/***/ "./node_modules/@pucelle/ff/out/dom/mouse-leave.js":
/*!*********************************************************!*\
  !*** ./node_modules/@pucelle/ff/out/dom/mouse-leave.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.MouseLeave = void 0;
/**
 * It's common that popup2 triggered from an existing popup1,
 * later when mouse moved to popup2, popup1 will disappear because mouse leaves.
 *
 * This is not correct, so we implement a mouse leave stack:
 *   1. When popup2 generated, we check the trigger element if it was contained (not equal) in elements of existing popups.
 *   2. If so, we lock the exist popup until popup2 disappeared.
 *
 * Caution: never forget to unregister mouse leave binding before elements disconnected.
 */
var MouseLeave;
(function (MouseLeave) {
    const Controllers = new Set();
    /**
     * Make sure elements and all their ancestors can't trigger mouse leave callback and becomes invisible.
     * Normally used for contextmenu to keep parent popup showing.
     * @param elOrS Element or array of element.
     */
    function keep(elOrS) {
        let controller = getControllerContains(elOrS);
        if (controller) {
            controller.lock();
        }
        return () => {
            if (controller) {
                controller.unlock();
                controller = null;
            }
        };
    }
    MouseLeave.keep = keep;
    /** Keep parent elements visible. */
    function keepParents(elOrS) {
        let els = Array.isArray(elOrS) ? elOrS : [elOrS];
        let parents = els.map(el => el.parentElement).filter(el => el && el !== document.body);
        return keep(parents);
    }
    /** Get Controller whose related elements contains and or equal one of specified elements. */
    function getControllerContains(elOrS) {
        let els = Array.isArray(elOrS) ? elOrS : [elOrS];
        for (let controller of [...Controllers].reverse()) {
            for (let el of els) {
                if (controller.els.some(controllerEl => controllerEl.contains(el))) {
                    return controller;
                }
            }
        }
        return null;
    }
    /**
     * Check if element or any of it's ancestors was kept to be visible.
     * If element is not been kept, you can destroy or reuse it immediately.
     * It allows `el` equals to controller element.
     * @param el Element to check.
     */
    function inUse(el) {
        for (let controller of [...Controllers].reverse()) {
            if (controller.els.some(controllerEl => controllerEl.contains(el))) {
                return controller.mouseIn;
            }
        }
        return false;
    }
    MouseLeave.inUse = inUse;
    /**
     * Call `callback` after mouse leaves all of the elements for `ms` milliseconds.
     * It's very usefull to handle mouse hover event in menu & submenu.
     * @param elOrS The element array to capture leave at.
     * @param ms If mouse leaves all the element and don't enter elements again, call callback. Default value is 200.
     * @param callback The callback to call after mouse leaves all the elements.
     */
    function on(elOrS, callback, options) {
        let controller = new MouseLeaveController(false, elOrS, callback, options);
        return () => controller.cancel();
    }
    MouseLeave.on = on;
    /**
     * Call `callback` after mouse leaves all of the elements for `ms` milliseconds, only trigger `callback` for once.
     * It's very usefull to handle mouse event in menu & submenu.
     * @param elOrS The element array to capture leave at.
     * @param ms If mouse leaves all the element and don't enter elements again, call callback. Default value is 200.
     * @param callback The callback to call after mouse leaves all the elements.
     */
    function once(elOrS, callback, options) {
        let controller = new MouseLeaveController(true, elOrS, callback, options);
        return () => controller.cancel();
    }
    MouseLeave.once = once;
    class MouseLeaveController {
        constructor(isOnce, elOrS, callback, options) {
            this.mouseIn = false;
            // Why not a boolean property?
            // When a sub popup hide, it will trigger unlock on ontroller later, not immediately.
            // But a new sub popup may trigger lock on ontroller, and then old sub popup trigger unlock.
            // `old lock -> new lock -> old unlock`, cause controller to be canceled.
            this.lockCount = 0;
            this.delay = 200;
            this.ended = false;
            this.timer = null;
            this.isOnce = isOnce;
            this.els = Array.isArray(elOrS) ? elOrS : [elOrS];
            this.callback = callback;
            if (options) {
                Object.assign(this, options);
            }
            this.onMouseEnter = this.onMouseEnter.bind(this);
            this.onMouseLeave = this.onMouseLeave.bind(this);
            for (let el of this.els) {
                el.addEventListener('mouseenter', this.onMouseEnter, false);
                el.addEventListener('mouseleave', this.onMouseLeave, false);
            }
            this.unkeep = keepParents(elOrS);
            Controllers.add(this);
        }
        onMouseEnter() {
            this.mouseIn = true;
            this.clearTimeout();
        }
        onMouseLeave() {
            this.mouseIn = false;
            if (this.lockCount === 0) {
                this.startTimeout();
            }
        }
        startTimeout() {
            this.clearTimeout();
            this.timer = setTimeout(() => this.onTimeout(), this.delay);
        }
        onTimeout() {
            this.timer = null;
            if (!this.mouseIn) {
                this.flush();
            }
        }
        clearTimeout() {
            if (this.timer) {
                clearTimeout(this.timer);
                this.timer = null;
            }
        }
        flush() {
            if (this.ended) {
                return;
            }
            if (this.isOnce) {
                this.cancel();
            }
            this.callback();
        }
        cancel() {
            if (this.ended) {
                return;
            }
            this.clearTimeout();
            for (let el of this.els) {
                el.removeEventListener('mouseenter', this.onMouseEnter, false);
                el.removeEventListener('mouseleave', this.onMouseLeave, false);
            }
            this.ended = true;
            this.unkeep();
            Controllers.delete(this);
        }
        lock() {
            this.clearTimeout();
            this.lockCount++;
        }
        unlock() {
            this.lockCount--;
            if (this.lockCount === 0) {
                if (!this.mouseIn) {
                    this.flush();
                }
            }
        }
    }
})(MouseLeave = exports.MouseLeave || (exports.MouseLeave = {}));


/***/ }),

/***/ "./node_modules/@pucelle/ff/out/dom/net.js":
/*!*************************************************!*\
  !*** ./node_modules/@pucelle/ff/out/dom/net.js ***!
  \*************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ResourceLoader = void 0;
const string_1 = __webpack_require__(/*! ../base/string */ "./node_modules/@pucelle/ff/out/base/string.js");
const base_1 = __webpack_require__(/*! ../base */ "./node_modules/@pucelle/ff/out/base/index.js");
/**
 * Preload resources from their urls, and get total progress notifications.
 * Please beware of the CORS settings at the server.
 * If you want the progress working, please makesure the `content-length` response header.
 */
class ResourceLoader extends base_1.Emitter {
    constructor(options = {}) {
        super();
        /** URL base. */
        this.base = '';
        /** If `true`, will continue request other resource if error occurs, default value is `false` */
        this.continueOnError = false;
        this.blobMap = new Map();
        Object.assign(this, options);
    }
    async load(urls) {
        let normalized = this.normalizeResources(urls);
        let sizes = (await this.getTotalSizes(normalized.map(v => v.url))).map(v => v || 0);
        let totalSize = base_1.sum(sizes);
        let completedSize = 0;
        for (let { name, url, type } of normalized) {
            try {
                let blob = await this.loadOne(name, url, (loaded) => {
                    this.emit('progress', Math.min(completedSize + loaded, totalSize), totalSize);
                });
                completedSize += sizes.shift();
                if (blob) {
                    await this.handleBlob(type, blob);
                }
            }
            catch (err) {
                if (!this.continueOnError) {
                    throw err;
                }
            }
        }
    }
    async getTotalSizes(urls) {
        let promises = [];
        for (let url of urls) {
            promises.push(this.getURLSize(url));
        }
        return await Promise.all(promises);
    }
    async getURLSize(url) {
        let res = await fetch(this.getAbsoluteURL(url), { method: 'HEAD' });
        let length = res.headers.get('content-length');
        return length === null ? null : Number(length) || null;
    }
    getAbsoluteURL(url) {
        if (/^(?:https?:|\/\/)/.test(url) || !this.base) {
            return url;
        }
        return this.base + url;
    }
    normalizeResources(resources) {
        return resources.map(r => {
            if (typeof r === 'string') {
                return {
                    name: this.getBaseNameFromURL(r),
                    url: r,
                    type: this.inferResourceTypeFromURL(r)
                };
            }
            else {
                return {
                    name: r.name || this.getBaseNameFromURL(r.url),
                    url: r.url,
                    type: r.type || 'blob'
                };
            }
        });
    }
    getBaseNameFromURL(url) {
        return string_1.firstMatch(url, /([^\/]+)$/).replace(/\.\w+$/, '');
    }
    inferResourceTypeFromURL(url) {
        let ext = string_1.firstMatch(url, /\.(\w+)(?:\?.*?)?$/).toLowerCase();
        if (['css', 'js'].includes(ext)) {
            return ext;
        }
        else {
            return 'blob';
        }
    }
    async loadOne(name, url, onprogress) {
        let absloteURL = this.getAbsoluteURL(url);
        return new Promise((resolve, reject) => {
            let xhr = new XMLHttpRequest();
            xhr.responseType = 'blob';
            xhr.open('GET', absloteURL);
            xhr.onprogress = (e) => {
                if (e.lengthComputable) {
                    onprogress(e.loaded, e.total);
                }
            };
            xhr.onloadend = () => {
                if (xhr.status >= 200 && xhr.status < 400) {
                    this.blobMap.set(name, xhr.response);
                    this.blobMap.set(url, xhr.response);
                    resolve(xhr.response);
                }
                else {
                    reject();
                }
            };
            xhr.send();
        });
    }
    async handleBlob(type, blob) {
        if (type === 'css') {
            await this.loadStyle(blob);
        }
        else if (type === 'js') {
            await this.loadScript(blob);
        }
    }
    loadStyle(blob) {
        return new Promise((resolve, reject) => {
            let link = document.createElement('link');
            link.rel = 'stylesheet';
            link.href = URL.createObjectURL(blob);
            document.head.append(link);
            link.addEventListener('load', () => resolve());
            link.addEventListener('error', () => reject());
        });
    }
    loadScript(blob) {
        return new Promise((resolve, reject) => {
            let script = document.createElement('script');
            script.async = false;
            script.src = URL.createObjectURL(blob);
            document.head.append(script);
            script.addEventListener('load', () => resolve());
            script.addEventListener('error', () => reject());
        });
    }
    /**
     * Get resource as blob URL.
     * @param name The defined resource name or base name of url.
     */
    getAsBlobURL(name) {
        let blob = this.blobMap.get(name);
        if (!blob) {
            return null;
        }
        return URL.createObjectURL(blob);
    }
    /**
     * Get resource as text.
     * @param name The defined resource name or base name of url.
     */
    getAsText(name) {
        return new Promise(resolve => {
            let blob = this.blobMap.get(name);
            if (!blob) {
                return resolve(null);
            }
            let reader = new FileReader();
            reader.onload = () => {
                resolve(reader.result);
            };
            reader.readAsText(blob);
        });
    }
    /**
     * Get resource as HTML document.
     * @param name The defined resource name or base name of url.
     */
    async getAsHTML(name) {
        let text = await this.getAsText(name);
        if (!text) {
            return null;
        }
        return new DOMParser().parseFromString(text, 'text/html');
    }
    /**
     * Get resource as JSON.
     * @param name The defined resource name or base name of url.
     */
    async getAsJSON(name) {
        let text = await this.getAsText(name);
        if (!text) {
            return null;
        }
        return JSON.parse(text);
    }
    /**
     * Get resource as ArrayBuffer.
     * @param name The defined resource name or base name of url.
     */
    async getAsBuffer(name) {
        return new Promise((resolve, reject) => {
            let blob = this.blobMap.get(name);
            if (!blob) {
                return resolve(null);
            }
            let reader = new FileReader();
            reader.onload = () => {
                resolve(reader.result);
            };
            reader.onerror = err => {
                reject(err);
            };
            reader.readAsArrayBuffer(blob);
        });
    }
    /**
     * Get resource as Image.
     * @param name The defined resource name or base name of url.
     */
    async getAsImage(name) {
        return new Promise((resolve, reject) => {
            let blobURL = this.getAsBlobURL(name);
            if (!blobURL) {
                return resolve(null);
            }
            let img = new Image();
            img.src = blobURL;
            img.onload = () => resolve(img);
            img.onerror = err => reject(err);
        });
    }
    /**
     * Get resource as Video Element.
     * @param name The defined resource name or base name of url.
     */
    async getAsVideo(name) {
        return new Promise((resolve, reject) => {
            let blobURL = this.getAsBlobURL(name);
            if (!blobURL) {
                return resolve(null);
            }
            let video = document.createElement('video');
            video.preload = 'auto';
            video.oncanplaythrough = () => {
                resolve(video);
            };
            video.onerror = err => {
                reject(err);
            };
            video.src = blobURL;
        });
    }
    /**
     * Get resource as Audio Element.
     * @param name The defined resource name or base name of url.
     */
    async getAsAudio(name) {
        return new Promise((resolve, reject) => {
            let blobURL = this.getAsBlobURL(name);
            if (!blobURL) {
                return resolve(null);
            }
            let audio = document.createElement('audio');
            audio.preload = 'auto';
            audio.oncanplaythrough = () => {
                resolve(audio);
            };
            audio.onerror = err => {
                reject(err);
            };
            audio.src = blobURL;
        });
    }
}
exports.ResourceLoader = ResourceLoader;


/***/ }),

/***/ "./node_modules/@pucelle/ff/out/dom/query.js":
/*!***************************************************!*\
  !*** ./node_modules/@pucelle/ff/out/dom/query.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.useQuery = exports.parseQuery = void 0;
/**
 * Parse `url` search part to a query parameter object.
 * @param url The url to parse query parameter.
 */
function parseQuery(url) {
    let match = url.match(/\?(.+)/);
    let pieces = match ? match[1].split('&') : [];
    let q = {};
    for (let piece of pieces) {
        let [key, value] = piece.split('=');
        if (key) {
            value = decodeURIComponent(value || '');
            q[key] = value;
        }
    }
    return q;
}
exports.parseQuery = parseQuery;
/**
 * Combine base `url` and `query` parameters to a new URL.
 * @param url The base url.
 * @param query The query parameter object.
 */
function useQuery(url, query) {
    let hasQuery = url.includes('?');
    if (typeof query === 'string') {
        return url + (hasQuery ? '&' : '?') + query;
    }
    else if (query && typeof query === 'object') {
        for (let key in query) {
            let value = encodeURIComponent(query[key]);
            url += (hasQuery ? '&' : '?') + key + '=' + value;
            hasQuery = true;
        }
    }
    return url;
}
exports.useQuery = useQuery;


/***/ }),

/***/ "./node_modules/@pucelle/ff/out/dom/scroll.js":
/*!****************************************************!*\
  !*** ./node_modules/@pucelle/ff/out/dom/scroll.js ***!
  \****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.scrollToTop = exports.getScrollOffset = exports.getScrollDirection = exports.scrollToView = exports.getClosestScrollWrapper = exports.getScrollbarWidth = exports.isContentOverflow = void 0;
const animate_1 = __webpack_require__(/*! ./animate */ "./node_modules/@pucelle/ff/out/dom/animate.js");
/**
 * Returns if element can scroll.
 * May return `true` although element has no scroll bar.
 * Note that this method may cause reflow.
 * @param el The element to check scrolling.
 */
function isContentOverflow(el) {
    return el.scrollHeight > el.clientHeight || el.scrollWidth > el.clientWidth;
}
exports.isContentOverflow = isContentOverflow;
let scrollBarWidth = null;
/**
 * Get scroll bar width.
 * After first running, the returned value will keep unchanged.
 * Note that this method will cause reflow for the first time.
 */
function getScrollbarWidth() {
    if (scrollBarWidth !== null) {
        return scrollBarWidth;
    }
    let div = document.createElement('div');
    div.style.cssText = 'width:100px; height:100px; overflow:scroll; position:absolute; left:-100px; top:-100px;';
    document.body.append(div);
    scrollBarWidth = div.offsetWidth - div.clientWidth;
    div.remove();
    return scrollBarWidth;
}
exports.getScrollbarWidth = getScrollbarWidth;
/**
 * Find the closest scroll wrapper, which has `overflow: auto / scroll` set.
 * Note that this method may cause reflow.
 * @param el The element to check scrolling from.
 */
function getClosestScrollWrapper(el) {
    while (el
        && el.scrollWidth <= el.clientWidth
        && el.scrollHeight <= el.clientHeight) {
        el = el.parentElement;
    }
    return el;
}
exports.getClosestScrollWrapper = getClosestScrollWrapper;
/**
 * Scroll scrollbars in closest scroll wrapper for minimal distance to let element enter into the viewport area.
 * Returns `true` if scrolled.
 * @param el The element you want to see.
 * @param gap Keep a little distance from the element's edge to the viewport's edge.
 * @param duration If specified, will run an animation when scrolling.
 * @param easing The animation esing.
 */
function scrollToView(el, gap = 0, duration = 0, easing = 'ease-out') {
    let wrapper = getClosestScrollWrapper(el);
    if (!wrapper) {
        return false;
    }
    let direction = getScrollDirection(wrapper);
    if (!direction) {
        return false;
    }
    if (direction === 'y') {
        let oldScrollY = wrapper.scrollTop;
        let newScrollY = null;
        let offsetY = getScrollOffset(el, wrapper, direction);
        // Needs to scroll for pxs to top edges align
        let topOffset = offsetY - gap - oldScrollY;
        // Needs to scroll for pxs to bottom edges align
        let botOffset = offsetY + el.offsetHeight + gap - wrapper.clientHeight - oldScrollY;
        // Needs to scroll up
        if (topOffset < 0 && botOffset < 0) {
            newScrollY = Math.max(topOffset, botOffset) + oldScrollY;
        }
        // Needs to scroll down
        else if (botOffset > 0 && topOffset > 0) {
            newScrollY = Math.min(botOffset, topOffset) + oldScrollY;
        }
        if (newScrollY !== null && newScrollY !== oldScrollY) {
            if (duration) {
                animate_1.animatePropertyTo(wrapper, 'scrollTop', newScrollY, duration, easing);
            }
            else {
                wrapper.scrollTop = newScrollY;
            }
            return true;
        }
        return false;
    }
    if (direction === 'x') {
        let offsetX = getScrollOffset(el, wrapper, direction);
        let scrollX = wrapper.scrollLeft;
        let newScrollX = 0;
        let startOffset = offsetX - gap - scrollX;
        let endOffset = offsetX + el.offsetWidth + gap - scrollX - wrapper.clientWidth;
        if (startOffset < 0 && endOffset < 0 || el.offsetWidth > wrapper.clientWidth) {
            newScrollX = Math.max(0, offsetX - gap);
        }
        else if (endOffset > 0 && startOffset > 0) {
            newScrollX = Math.min(wrapper.scrollWidth, offsetX + el.offsetWidth + gap) - wrapper.clientWidth;
        }
        if (newScrollX !== scrollX) {
            if (duration) {
                animate_1.animatePropertyTo(wrapper, 'scrollLeft', newScrollX, duration, easing);
            }
            else {
                wrapper.scrollLeft = newScrollX;
            }
            return true;
        }
    }
    return false;
}
exports.scrollToView = scrollToView;
/**
 * Returns the scroll direction of scroll wrapper, may be `'x' | 'y' | ''`.
 * @param wrapper The element to get scroll direction.
 */
function getScrollDirection(wrapper) {
    let direction = '';
    if (wrapper.scrollHeight > wrapper.clientHeight) {
        direction = 'y';
    }
    else if (wrapper.scrollWidth > wrapper.clientWidth) {
        direction = 'x';
    }
    return direction;
}
exports.getScrollDirection = getScrollDirection;
/**
 * Get element's position in it's scroll wrapper's scroll area,
 * which also means the scroll wrapper's scrollTop when when top edges align.
 * This value is not affected by current scroll position.
 * @param el The element to test offset.
 * @param wrapper The scroll wrapper.
 * @param direction The scroll direction, `'x' | 'y'`.
 */
function getScrollOffset(el, wrapper, direction) {
    let prop = direction === 'x' ? 'offsetLeft' : 'offsetTop';
    let parent = el.offsetParent;
    let y = el[prop];
    if (!parent || parent === wrapper) { }
    else if (parent.contains(wrapper)) {
        y -= wrapper[prop];
    }
    else {
        while (parent.offsetParent && parent.offsetParent !== wrapper) {
            parent = parent.offsetParent;
            y += parent[prop];
        }
    }
    return y;
}
exports.getScrollOffset = getScrollOffset;
/**
 * Scroll scrollbars to let element in the top of the viewport area.
 * Returns true if scrolled.
 * @param el The element you want to see.
 * @param gap Keep a little distance from the element's edge to the viewport's edge.
 * @param duration If specified, will run an animation when scrolling.
 * @param easing The animation esing.
 */
function scrollToTop(el, gap = 0, duration = 0, easing = 'ease-out') {
    let wrapper = getClosestScrollWrapper(el);
    if (!wrapper) {
        return false;
    }
    let offsetY = getScrollOffset(el, wrapper, 'y');
    let oldScrollY = wrapper.scrollTop;
    let newScrollY = Math.max(0, offsetY - gap);
    if (newScrollY !== oldScrollY) {
        if (duration) {
            animate_1.animatePropertyTo(wrapper, 'scrollTop', newScrollY, duration, easing);
        }
        else {
            wrapper.scrollTop = newScrollY;
        }
        return true;
    }
    return false;
}
exports.scrollToTop = scrollToTop;


/***/ }),

/***/ "./node_modules/@pucelle/ff/out/dom/storage.js":
/*!*****************************************************!*\
  !*** ./node_modules/@pucelle/ff/out/dom/storage.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.storage = void 0;
class JSONStorage {
    constructor(prefix) {
        this.prefix = '';
        this.expireSuffix = '_expires_';
        this.supported = null;
        this.prefix = prefix;
    }
    /**
     * Test if localStorage is supported.
     * Will return `false` in private mode.
     */
    isSupported() {
        if (this.supported !== null) {
            return this.supported;
        }
        try {
            let key = this.prefix + 'test_supported';
            localStorage[key] = 1;
            delete localStorage[key];
            return true;
        }
        catch (e) {
            return false;
        }
    }
    /**
     * Test if has set `key` in localStorage.
     * @param key The key of the data item.
     */
    has(key) {
        if (!this.isSupported()) {
            return null;
        }
        key = this.prefix + key;
        return key in localStorage;
    }
    get(key, defaultValue = null) {
        if (!this.isSupported()) {
            return null;
        }
        key = this.prefix + key;
        let value = localStorage[key];
        if (value === undefined) {
            return defaultValue;
        }
        if (value && typeof value === 'string') {
            try {
                value = JSON.parse(value);
                let expires = localStorage[key + this.expireSuffix];
                if (expires && expires < Date.now()) {
                    delete localStorage[key];
                    delete localStorage[key + this.expireSuffix];
                    return defaultValue;
                }
                else {
                    return value;
                }
            }
            catch (err) {
                return defaultValue;
            }
        }
        else {
            return defaultValue;
        }
    }
    /**
     * Cache json data into localStorage by `key`.
     * Returns `true` if cached.
     * @param key The key of the data item.
     * @param value The json data to cache.
     * @param expires An optional expire time in second.
     */
    set(key, value, expires) {
        if (!this.isSupported()) {
            return null;
        }
        key = this.prefix + key;
        localStorage[key] = JSON.stringify(value);
        if (expires && expires > 0) {
            localStorage[key + this.expireSuffix] = Date.now() + expires * 1000;
        }
        return true;
    }
    /**
     * Delete cached json data in localStorage with specified `key`.
     * Returns `true` if deleted.
     * @param key The key of the data item.
     */
    delete(key) {
        if (!this.isSupported()) {
            return null;
        }
        key = this.prefix + key;
        delete localStorage[key + this.expireSuffix];
        return delete localStorage[key];
    }
    /**
     * Returns a new storage to cache data using `namespace` as prefix of keys.
     * @param namespace The prefix of keys.
     */
    group(namespace) {
        return new JSONStorage(this.prefix + '_' + namespace);
    }
}
/** Like `LocalStorage` very much, except here it read and write JSON datas. */
exports.storage = new JSONStorage('_ff_');


/***/ }),

/***/ "./node_modules/@pucelle/ff/out/dom/style.js":
/*!***************************************************!*\
  !*** ./node_modules/@pucelle/ff/out/dom/style.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.setStyle = exports.getStyle = exports.getStyleAsNumber = void 0;
const util_1 = __webpack_require__(/*! ./util */ "./node_modules/@pucelle/ff/out/dom/util.js");
/**
 * Get computed style value as number from element.
 * Note that this method may cause reflow.
 * @param el The element to get numeric value.
 * @param property The property name in camer case, `backgroundColor` as example.
 */
function getStyleAsNumber(el, property) {
    let value = getStyle(el, property);
    return value ? parseFloat(value) || 0 : 0;
}
exports.getStyleAsNumber = getStyleAsNumber;
/**
 * Get computed style value from element.
 * Note that this method may cause reflow.
 * @param el The element to get style value.
 * @param property The property name in camer case, `backgroundColor` as example.
 */
function getStyle(el, property) {
    return getComputedStyle(el)[property];
}
exports.getStyle = getStyle;
function setStyle(el, propertyOrMap, value) {
    if (typeof propertyOrMap === 'object') {
        for (let prop of Object.keys(propertyOrMap)) {
            setStyle(el, prop, propertyOrMap[prop]);
        }
    }
    else {
        el.style.setProperty(propertyOrMap, util_1.normativeStyleValue(propertyOrMap, value));
    }
}
exports.setStyle = setStyle;


/***/ }),

/***/ "./node_modules/@pucelle/ff/out/dom/timing.js":
/*!****************************************************!*\
  !*** ./node_modules/@pucelle/ff/out/dom/timing.js ***!
  \****************************************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ensureDocumentComplete = exports.ensureWindowLoaded = void 0;
/**
 * Returns a promise which will be resolved after window loaded,
 * Or resolved immediately if window already loaded.
 */
function ensureWindowLoaded() {
    return new Promise(resolve => {
        let entrys = window.performance.getEntriesByType("navigation");
        if (entrys.length > 0 && entrys[0].loadEventEnd > 0) {
            resolve();
        }
        else {
            window.addEventListener('load', () => resolve());
        }
    });
}
exports.ensureWindowLoaded = ensureWindowLoaded;
/**
 * Returns a promise which will be resolved after document completed,
 * Or resolved immediately if document already completed.
 */
function ensureDocumentComplete() {
    return new Promise(resolve => {
        let entrys = window.performance.getEntriesByType("navigation");
        if (entrys.length > 0 && entrys[0].domContentLoadedEventEnd > 0) {
            resolve();
        }
        else {
            document.addEventListener('DOMContentLoaded', () => resolve(), false);
        }
    });
}
exports.ensureDocumentComplete = ensureDocumentComplete;


/***/ }),

/***/ "./node_modules/@pucelle/ff/out/dom/util.js":
/*!**************************************************!*\
  !*** ./node_modules/@pucelle/ff/out/dom/util.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.getClosestFixedElement = exports.normativeStyleObject = exports.normativeStyleValue = void 0;
function normativeStyleValue(property, value) {
    if (typeof value === 'number' && /(?:width|height|left|right|top|bottom|size)$/i.test(property)) {
        value = value + 'px';
    }
    else {
        value = value.toString();
    }
    return value;
}
exports.normativeStyleValue = normativeStyleValue;
function normativeStyleObject(styleObject) {
    for (let property of Object.keys(styleObject)) {
        styleObject[property] = normativeStyleValue(property, styleObject[property]);
    }
    return styleObject;
}
exports.normativeStyleObject = normativeStyleObject;
function getClosestFixedElement(el) {
    while (el && el !== document.documentElement) {
        if (getComputedStyle(el).position === 'fixed') {
            break;
        }
        el = el.parentElement;
    }
    return el === document.documentElement ? null : el;
}
exports.getClosestFixedElement = getClosestFixedElement;


/***/ }),

/***/ "./node_modules/@pucelle/ff/out/dom/watch-layout.js":
/*!**********************************************************!*\
  !*** ./node_modules/@pucelle/ff/out/dom/watch-layout.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.watchLayoutUntil = exports.watchLayoutOnce = exports.watchLayout = void 0;
const element_1 = __webpack_require__(/*! ./element */ "./node_modules/@pucelle/ff/out/dom/element.js");
const base_1 = __webpack_require__(/*! ../base */ "./node_modules/@pucelle/ff/out/base/index.js");
const WATCH_STATE_FN = {
    show(el) {
        return el.offsetWidth > 0 || el.offsetHeight > 0;
    },
    hide(el) {
        return el.offsetWidth === 0 && el.offsetHeight === 0;
    },
    inview(el) {
        return element_1.isInViewport(el);
    },
    outview(el) {
        return !element_1.isInViewport(el);
    },
    size(el) {
        return {
            width: el.clientWidth,
            height: el.clientHeight,
        };
    },
    rect(el) {
        return element_1.getRect(el);
    },
};
/**
 * Watch specified state, trigger `callback` if state changed.
 * Please makesure everything was rendered before call this.
 * Returns a cancel function.
 * Note that this method may slow page speed and cause additional reflow.
 * @param el The element to watch.
 * @param type The state to watch, can be `'show' | 'hide' | 'inview' | 'outview' | 'size' | 'rect'`.
 * @param callback The callback to call when state changed.
 */
function watchLayout(el, type, callback) {
    return bindWatch(false, false, el, type, callback);
}
exports.watchLayout = watchLayout;
/**
 * Watch specified state, trigger `callback` if it changed for only once.
 * Please makesure everything was rendered before call this.
 * Returns a cancel function.
 * Note that this method may slow page speed and cause additional reflow.
 * @param el The element to watch.
 * @param type The state to watch, can be `'show' | 'hide' | 'inview' | 'outview' | 'size' | 'rect'`.
 * @param callback The callback to call when state changed.
 */
function watchLayoutOnce(el, type, callback) {
    return bindWatch(true, false, el, type, callback);
}
exports.watchLayoutOnce = watchLayoutOnce;
/**
 * Watch specified state, trigger `callback` if the state becomes `true` and never trigger again.
 * Please makesure everything was rendered before call this.
 * Returns a cancel function.
 * Note that this method may slow page speed and cause additional reflow.
 * @param el The element to watch.
 * @param type The state to watch, can be `'show' | 'hide' | 'inview' | 'outview'`.
 * @param callback The callback to call when state becomes true.
 */
function watchLayoutUntil(el, type, callback) {
    return bindWatch(true, true, el, type, callback);
}
exports.watchLayoutUntil = watchLayoutUntil;
function bindWatch(isOnce, untilTrue, el, type, callback) {
    let getState = WATCH_STATE_FN[type];
    let oldState;
    let interval = null;
    let observer = null;
    if (!getState) {
        throw new Error(`Failed to watch, type "${type}" is not supported`);
    }
    if (untilTrue) {
        oldState = getState(el);
        if (oldState && untilTrue) {
            callback(oldState);
        }
    }
    if (untilTrue && oldState) {
        return unwatch;
    }
    if (type === 'size' && typeof window.ResizeObserver === 'function') {
        observer = new window.ResizeObserver(onResize);
        observer.observe(el);
    }
    else if ((type === 'inview' || type === 'outview') && typeof IntersectionObserver === 'function') {
        observer = new IntersectionObserver(onInviewChange);
        observer.observe(el);
    }
    else {
        oldState = getState(el);
        // `requestAnimationFrame` is better than `setInterval`,
        // because `setInterval` will either lost frame or trigger multiple times betweens one frame.
        // But check frequently will significantly affect rendering performance.
        interval = new base_1.Interval(() => {
            let newState = getState(el);
            onNewState(newState);
        }, 200);
    }
    function onResize(entries) {
        for (let { contentRect } of entries) {
            onNewState({
                width: contentRect.width,
                height: contentRect.height
            });
        }
    }
    function onInviewChange(entries) {
        for (let { intersectionRatio } of entries) {
            let newState = type === 'inview' ? intersectionRatio > 0 : intersectionRatio === 0;
            onNewState(newState);
        }
    }
    function onNewState(newState) {
        if (!valueOrObjectEqual(newState, oldState)) {
            callback(oldState = newState);
            if (isOnce || untilTrue && newState) {
                unwatch();
            }
        }
    }
    function unwatch() {
        if (interval) {
            interval.cancel();
        }
        else if (observer) {
            observer.unobserve(el);
        }
    }
    return unwatch;
}
function valueOrObjectEqual(a, b) {
    if (a === b) {
        return true;
    }
    if (typeof a !== 'object' || typeof b !== 'object' || !a || !b) {
        return false;
    }
    let keysA = Object.keys(a);
    let keysB = Object.keys(b);
    if (keysA.length !== keysB.length) {
        return false;
    }
    for (let key of keysA) {
        if (!b.hasOwnProperty(key)) {
            return false;
        }
        let valueA = a[key];
        let valueB = b[key];
        if (valueA !== valueB) {
            return false;
        }
    }
    return true;
}


/***/ }),

/***/ "./node_modules/@pucelle/ff/out/index.js":
/*!***********************************************!*\
  !*** ./node_modules/@pucelle/ff/out/index.js ***!
  \***********************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __exportStar = (this && this.__exportStar) || function(m, exports) {
    for (var p in m) if (p !== "default" && !exports.hasOwnProperty(p)) __createBinding(exports, m, p);
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
__exportStar(__webpack_require__(/*! ./base */ "./node_modules/@pucelle/ff/out/base/index.js"), exports);
__exportStar(__webpack_require__(/*! ./dom */ "./node_modules/@pucelle/ff/out/dom/index.js"), exports);


/***/ }),

/***/ "./node_modules/@pucelle/flit-ui/out/bindings/contextmenu.js":
/*!*******************************************************************!*\
  !*** ./node_modules/@pucelle/flit-ui/out/bindings/contextmenu.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.contextmenu = exports.ContextMenuBinding = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
class ContextMenuBinding {
    constructor(el, context) {
        this.popup = null;
        this.unwatchRect = null;
        this.unkeepEl = null;
        this.el = el;
        this.context = context;
        flit_1.on(this.el, 'contextmenu.prevent', this.showMenu, this);
    }
    async update(renderFn) {
        this.renderFn = renderFn;
    }
    async showMenu(e) {
        let popup = this.renderPopup();
        popup.applyAppendTo();
        await flit_1.renderComplete();
        ff_1.alignToEvent(popup.el, e);
        popup.el.focus();
        this.unkeepEl = ff_1.MouseLeave.keep(this.el);
        new flit_1.Transition(popup.el, 'fade').enter();
        flit_1.on(document, 'mousedown', this.onDocMouseDown, this);
        flit_1.once(popup.el, 'click', this.hideContextMenu, this);
        this.unwatchRect = ff_1.watchLayout(this.el, 'rect', this.onElRectChanged.bind(this));
    }
    renderPopup() {
        if (!this.popup) {
            this.popup = flit_1.renderComponent(this.renderFn, this.context).component;
        }
        return this.popup;
    }
    onDocMouseDown(e) {
        let target = e.target;
        if (this.popup && !this.popup.el.contains(target)) {
            this.hideContextMenu();
        }
    }
    hideContextMenu() {
        if (this.popup) {
            flit_1.off(document, 'mousedown', this.onDocMouseDown, this);
            flit_1.off(this.popup.el, 'click', this.hideContextMenu, this);
            new flit_1.Transition(this.popup.el, 'fade').leave().then((finish) => {
                if (finish) {
                    this.popup.el.remove();
                    this.popup = null;
                }
            });
        }
        if (this.unkeepEl) {
            this.unkeepEl();
            this.unkeepEl = null;
        }
        if (this.unwatchRect) {
            this.unwatchRect();
            this.unwatchRect = null;
        }
    }
    onElRectChanged() {
        this.hideContextMenu();
    }
    remove() {
        flit_1.off(this.el, 'contextmenu', this.showMenu, this);
    }
}
exports.ContextMenuBinding = ContextMenuBinding;
/**
 * Popup a contextmenu when right click binded element.
 * @param renderFn Should returns a `<f-contextmenu>` result.
 */
exports.contextmenu = flit_1.defineBinding('contextmenu', ContextMenuBinding);


/***/ }),

/***/ "./node_modules/@pucelle/flit-ui/out/bindings/drag-drop.js":
/*!*****************************************************************!*\
  !*** ./node_modules/@pucelle/flit-ui/out/bindings/drag-drop.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.droppable = exports.DroppableBinding = exports.draggable = exports.DraggableBinding = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
const theme_1 = __webpack_require__(/*! ../style/theme */ "./node_modules/@pucelle/flit-ui/out/style/theme.js");
class DraggableBinding {
    constructor(el) {
        this.name = '';
        this.data = null;
        this.index = -1;
        this.el = el;
        // To avoid image dragging handled be HTML5 drag & drop
        this.el.setAttribute('draggable', 'false');
        this.el.style.cursor = 'grab';
        flit_1.on(this.el, 'mousedown', this.onMouseDown, this);
        flit_1.on(this.el, 'mouseenter', this.onMouseEnter, this);
    }
    update(data, index, options) {
        this.data = data;
        this.index = index;
        if (options) {
            Object.assign(this, options);
        }
    }
    onMouseDown(e) {
        e.preventDefault();
        let isDragging = false;
        let startX = e.clientX;
        let startY = e.clientY;
        let onMouseMove = (e) => {
            if (!isDragging && (Math.abs(e.clientX - startX) > 5 || Math.abs(e.clientY - startY) > 5)) {
                isDragging = true;
                manager.startDragging(this);
            }
            if (isDragging) {
                let moveX = e.clientX - startX;
                let moveY = e.clientY - startY;
                manager.translateDragging(moveX, moveY);
            }
        };
        let onMouseUp = async () => {
            flit_1.off(document, 'mousemove', onMouseMove);
            manager.endDragging();
        };
        flit_1.on(document, 'mousemove', onMouseMove);
        flit_1.once(document, 'mouseup', onMouseUp);
    }
    onMouseEnter() {
        manager.enterDraggable(this);
    }
    remove() {
        flit_1.off(this.el, 'mousedown', this.onMouseDown, this);
        flit_1.off(this.el, 'mouseenter', this.onMouseEnter, this);
    }
}
exports.DraggableBinding = DraggableBinding;
exports.draggable = flit_1.defineBinding('draggable', DraggableBinding);
class DroppableBinding {
    constructor(el) {
        this.name = '';
        this.onenter = null;
        this.onleave = null;
        this.el = el;
        flit_1.on(this.el, 'mouseenter', this.onMouseEnter, this);
    }
    update(ondrop, options) {
        this.ondrop = ondrop;
        if (options) {
            Object.assign(this, options);
        }
    }
    onMouseEnter() {
        manager.enterDroppable(this);
        flit_1.once(this.el, 'mouseleave', this.onMouseLeave, this);
    }
    emitEnter(dragging) {
        if (this.onenter) {
            this.onenter(dragging.data, dragging.index);
        }
    }
    onMouseLeave() {
        manager.leaveDroppable(this);
    }
    emitLeave(dragging) {
        if (this.onleave) {
            this.onleave(dragging.data, dragging.index);
        }
    }
    emitDrop(dragging, index) {
        if (this.ondrop) {
            this.ondrop(dragging.data, index);
        }
    }
    remove() {
        flit_1.off(this.el, 'mouseenter', this.onMouseEnter, this);
    }
}
exports.DroppableBinding = DroppableBinding;
exports.droppable = flit_1.defineBinding('droppable', DroppableBinding);
// Used to:
//   When start dragging, check it's related drop area.
//   When dragging element enters another draggable element, relate them and adjust position using `mover`.
//   When dragging element enters one drop area, give additional space for it.
//   When dragging element leaves one drop area, remove space that belongs to it.
class DragDropRelationshipManager {
    constructor() {
        this.dragging = null;
        this.mover = null;
        // May mouse enter in some drop areas, and start dragging,
        // then we need to check which drop area should trigger enter.
        this.canEnterDrops = new Set();
        this.activeDrop = null;
    }
    startDragging(drag) {
        this.dragging = drag;
        let activeDrop;
        for (let drop of this.canEnterDrops) {
            // May element has been removed
            if (!document.contains(drop.el)) {
                this.canEnterDrops.delete(drop);
            }
            else if (drop.name === name) {
                activeDrop = drop;
                break;
            }
        }
        if (!activeDrop) {
            throw new Error(`Element with ':draggable' must be contained in a ':droppable' elemenet`);
        }
        activeDrop.emitEnter(this.dragging); // will also update direction
        this.activeDrop = activeDrop;
        this.mover = new Mover(this.dragging, activeDrop);
    }
    translateDragging(x, y) {
        if (this.mover) {
            this.mover.translateDraggingElement(x, y);
        }
    }
    enterDraggable(drag) {
        if (this.canSwapWith(drag) && this.mover) {
            this.mover.onEnterDraggable(drag);
        }
    }
    canSwapWith(drag) {
        return this.dragging && this.dragging.name === drag.name && this.dragging !== drag;
    }
    enterDroppable(drop) {
        this.canEnterDrops.add(drop);
        if (this.canDropTo(drop)) {
            drop.emitEnter(this.dragging);
            this.activeDrop = drop;
            this.mover.onEnterDroppable(drop);
        }
    }
    canDropTo(drop) {
        return this.dragging && this.dragging.name === drop.name;
    }
    leaveDroppable(drop) {
        this.canEnterDrops.delete(drop);
        if (this.activeDrop === drop) {
            drop.emitLeave(this.dragging);
            this.activeDrop = null;
            this.mover.onLeaveDroppable(drop);
        }
    }
    endDragging() {
        let mover = this.mover;
        let dragging = this.dragging;
        let activeDrop = this.activeDrop;
        if (mover) {
            mover.playEndDraggingAnimation().then(() => {
                if (mover.willSwapElements()) {
                    activeDrop.emitDrop(dragging, mover.getSwapIndex());
                }
            });
        }
        this.dragging = null;
        this.mover = null;
        this.activeDrop = null;
    }
}
const manager = new DragDropRelationshipManager();
// To handle dragging movements, includes:
// 1. When moved out of the droppable it's inside: All elements below moved up
// 2. When moved in a new droppable: Add a padding as space to contain
// 3. When moved between silbings: Moving items betweens them up or down, include the mouse enter sibling.
// 4. When moved into a already moved sibling: Fallback movements that not betweens them, include the mouse enter sibling.
class Mover {
    constructor(drag, drop) {
        /** Elements align direction */
        this.direction = 'y';
        /** Keeps orignal style of el before starting dragging. */
        this.elStyleText = '';
        this.translate = [0, 0];
        this.dragTo = null;
        this.dragToRect = null;
        this.dragToIndex = -1;
        /** Elements that were moved to right, compare to their auto layout position. */
        this.movedElements = new Set();
        /** Elements that were actually translated. */
        this.translatedElements = new Set();
        this.dropArea = null;
        this.placeholder = null;
        this.dragging = drag;
        this.el = drag.el;
        this.startDropArea = this.dropArea = drop;
        this.autoLayout = ff_1.getStyle(this.el, 'position') !== 'absolute';
        let marginLeft = ff_1.getStyleAsNumber(this.el, 'marginLeft');
        let marginRight = ff_1.getStyleAsNumber(this.el, 'marginRight');
        let marginTop = ff_1.getStyleAsNumber(this.el, 'marginTop');
        let marginBottom = ff_1.getStyleAsNumber(this.el, 'marginBottom');
        this.width = this.el.offsetWidth + (Math.abs(marginLeft) > Math.abs(marginRight) ? marginLeft : marginRight);
        this.height = this.el.offsetHeight + (Math.abs(marginTop) > Math.abs(marginBottom) ? marginTop : marginBottom);
        this.initializeDirection();
        this.setStartDraggingStyle();
        this.giveSpaceForDraggingElement(drop, false);
    }
    initializeDirection() {
        if (this.el.nextElementSibling || this.el.previousElementSibling) {
            let nextRect = ff_1.getRect(this.el.nextElementSibling || this.el.previousElementSibling);
            let currRect = ff_1.getRect(this.el);
            if (Math.abs(nextRect.left - currRect.left) > Math.abs(nextRect.top - currRect.top)) {
                this.direction = 'x';
            }
            else {
                this.direction = 'y';
            }
        }
    }
    setStartDraggingStyle() {
        let rect = ff_1.getRect(this.el);
        document.body.style.cursor = 'grabbing';
        document.body.style.userSelect = 'none';
        this.elStyleText = this.el.style.cssText;
        this.el.style.position = 'fixed';
        this.el.style.zIndex = '9999';
        this.el.style.width = rect.width + 'px';
        this.el.style.height = rect.height + 'px';
        this.el.style.left = rect.left + 'px';
        this.el.style.top = rect.top + 'px';
        this.el.style.boxShadow = `0 0 ${theme_1.theme.popupShadowBlurRadius}px #888`;
        this.el.style.pointerEvents = 'none';
        this.el.style.opacity = '1';
        this.el.style.willChange = 'transform';
    }
    getSiblingsAfter(fromEl) {
        let els = [];
        for (let el = fromEl.nextElementSibling; el; el = el.nextElementSibling) {
            els.push(el);
        }
        return els;
    }
    onEnterDroppable(drop) {
        this.giveSpaceForDraggingElement(drop, true);
        this.dropArea = drop;
    }
    giveSpaceForDraggingElement(drop, playAnimation) {
        let isDraggingInStartArea = this.startDropArea === drop;
        if (isDraggingInStartArea) {
            for (let el of this.getSiblingsAfter(this.el)) {
                this.moveElement(el, 1, playAnimation);
            }
        }
        this.placeholder = document.createElement('div');
        this.placeholder.style.visibility = 'hidden';
        if (this.direction === 'x') {
            this.placeholder.style.width = this.width + 'px';
        }
        else {
            this.placeholder.style.height = this.height + 'px';
        }
        drop.el.append(this.placeholder);
    }
    /**
     * Move element based on a move direction.
     * The `moveDirection` argument considers `autoLayout` always true,
     * So we should fix it inside.
     */
    moveElement(el, moveDirection, playAnimation) {
        if (el === this.el) {
            return;
        }
        let movePx = this.direction === 'x' ? this.width : this.height;
        let translateDirection = moveDirection;
        // in not in `autoLayout` mode, element will not affect the position of it's followed sibling elements,
        // So we make `moveDirection` -= 1 to balance.
        if (!this.autoLayout && this.el.compareDocumentPosition(el) === el.DOCUMENT_POSITION_FOLLOWING) {
            translateDirection -= 1;
        }
        let transform = translateDirection !== 0
            ? `translate${this.direction.toUpperCase()}(${translateDirection * movePx}px)`
            : '';
        if (playAnimation) {
            ff_1.animateTo(el, { transform });
        }
        else {
            el.style.transform = transform;
        }
        if (moveDirection) {
            this.movedElements.add(el);
        }
        else {
            this.movedElements.delete(el);
        }
        if (translateDirection) {
            this.translatedElements.add(el);
        }
        else {
            this.translatedElements.delete(el);
        }
    }
    onEnterDraggable(dragTo) {
        if (!this.dropArea) {
            return;
        }
        // Sometimes element trigger enter event twice when playing animation,
        // Which will cause element accidentaly restore it's position.
        // We should avoid it be do this.
        if (ff_1.isPlayingAnimation(dragTo.el)) {
            return;
        }
        let willMoveElements = new Set([dragTo.el, ...this.getSiblingsAfter(dragTo.el)]);
        willMoveElements.delete(this.el);
        // When the dragged into element has been moved, dragged into it again means that it's movement will be restored.
        if (this.movedElements.has(dragTo.el)) {
            willMoveElements.delete(dragTo.el);
        }
        for (let el of this.movedElements) {
            if (!willMoveElements.has(el)) {
                this.moveElement(el, 0, true);
            }
        }
        // Each element either moves right or down, or keep position.
        for (let el of willMoveElements) {
            if (!this.movedElements.has(el)) {
                this.moveElement(el, 1, true);
            }
        }
        this.dragToIndex = this.generateDraggedToIndex(dragTo, willMoveElements.has(dragTo.el));
        this.dragTo = dragTo;
        this.dragToRect = ff_1.getRect(dragTo.el);
    }
    // Assume we have:
    //	 group 1: 1 2 3
    //   group 2: 4 5 6
    generateDraggedToIndex(drag, beenMoved) {
        let isInSameDropArea = this.startDropArea === this.dropArea;
        let index = drag.index;
        if (isInSameDropArea) {
            // Drag 1 into 3
            if (index > this.dragging.index) {
                if (beenMoved) {
                    return index - 1; // 2 [1] 3, reutnrs index of 3 - 1
                }
                else {
                    return index; // 2 3 [1], returns index of 3
                }
            }
            // Drag 3 into 1
            else {
                if (beenMoved) {
                    return index; // [3] 1 2, reutnrs index of 1
                }
                else {
                    return index + 1; // 1 [3] 2, returns index of 1 + 1
                }
            }
        }
        // Drag 1 into 4
        else {
            if (beenMoved) {
                return index; // [1] 4 5 6, returns index of 4
            }
            else {
                return index + 1; // 4 [1] 5 6, returns index of 4 + 1
            }
        }
    }
    translateDraggingElement(x, y) {
        this.translate = [x, y];
        this.el.style.transform = `translate(${x}px, ${y}px)`;
    }
    willSwapElements() {
        return !!(this.dragTo || this.dropArea && this.startDropArea !== this.dropArea);
    }
    getSwapIndex() {
        return this.dragToIndex;
    }
    onLeaveDroppable(drop) {
        if (drop !== this.dropArea) {
            return;
        }
        for (let el of this.movedElements) {
            this.moveElement(el, 0, true);
        }
        this.dropArea = null;
        this.dragTo = null;
        this.dragToRect = null;
        this.dragToIndex = -1;
    }
    async playEndDraggingAnimation() {
        if (this.willSwapElements()) {
            await this.animateDraggingElementToDropArea();
            this.el.style.transform = '';
        }
        else {
            // When moved dragging element outside
            if (this.dropArea !== this.startDropArea) {
                this.moveSiblingsToGiveSpace(true);
            }
            await ff_1.animateTo(this.el, { transform: '' });
        }
        this.restoreMovedElements(false);
        this.clearDraggingStyle();
    }
    async animateDraggingElementToDropArea() {
        let fromRect = ff_1.getRect(this.el);
        let toRect = this.dragToRect || ff_1.getRect(this.placeholder);
        let x = toRect.left - fromRect.left + this.translate[0];
        let y = toRect.top - fromRect.top + this.translate[1];
        if (this.direction === 'x') {
            // Move from left to right, align at right.
            if (this.dragging.index < this.dragToIndex) {
                x = toRect.right - fromRect.right + this.translate[0];
            }
        }
        else {
            // Move from top to bottom, align at bottom.
            if (this.dragging.index < this.dragToIndex) {
                y = toRect.bottom - fromRect.bottom + this.translate[1];
            }
        }
        let transform = `translate(${x}px, ${y}px)`;
        await ff_1.animateTo(this.el, { transform });
    }
    moveSiblingsToGiveSpace(playAnimation) {
        for (let el of this.getSiblingsAfter(this.el)) {
            this.moveElement(el, 1, playAnimation);
        }
    }
    restoreMovedElements(playAnimation) {
        for (let el of this.translatedElements) {
            if (playAnimation) {
                ff_1.animateTo(el, { transform: '' });
            }
            else {
                ff_1.stopAnimation(el);
                el.style.transform = '';
            }
        }
        this.movedElements = new Set();
        this.translatedElements = new Set();
        if (this.placeholder) {
            this.placeholder.remove();
            this.placeholder = null;
        }
    }
    clearDraggingStyle() {
        document.body.style.cursor = '';
        document.body.style.userSelect = '';
        this.el.style.cssText = this.elStyleText;
    }
}


/***/ }),

/***/ "./node_modules/@pucelle/flit-ui/out/bindings/goto.js":
/*!************************************************************!*\
  !*** ./node_modules/@pucelle/flit-ui/out/bindings/goto.js ***!
  \************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.GotoBinding = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const router_1 = __webpack_require__(/*! ../components/router */ "./node_modules/@pucelle/flit-ui/out/components/router.js");
let GotoBinding = class GotoBinding {
    constructor(el) {
        this.value = '';
        this.router = null;
        this.el = el;
        flit_1.on(this.el, 'click', this.onClick, this);
    }
    update(value) {
        this.value = value;
    }
    onClick() {
        this.ensureRouter();
        this.router.goto(this.value);
    }
    ensureRouter() {
        if (!this.router) {
            this.router = flit_1.getClosestComponent(this.el.parentElement, router_1.Router);
            if (!this.router) {
                throw new Error(`":goto" must be contained in a extended component of "Router"`);
            }
        }
    }
    remove() { }
};
GotoBinding = __decorate([
    flit_1.defineBinding('goto')
], GotoBinding);
exports.GotoBinding = GotoBinding;


/***/ }),

/***/ "./node_modules/@pucelle/flit-ui/out/bindings/loading.js":
/*!***************************************************************!*\
  !*** ./node_modules/@pucelle/flit-ui/out/bindings/loading.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.loading = exports.LoadingBinging = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const defaultLoadingOptions = {
    size: 'medium',
    transition: 'fade',
};
class LoadingBinging {
    constructor(el) {
        this.value = false;
        this.options = new flit_1.Options(defaultLoadingOptions);
        this.cover = null;
        this.el = el;
    }
    update(value, options) {
        this.value = value;
        this.options.update(options);
        let transition = this.options.get('transition');
        if (this.value) {
            if (this.cover) {
                if (transition) {
                    new flit_1.Transition(this.cover, transition).leave().then(finish => {
                        if (finish) {
                            this.cover.remove();
                            this.cover = null;
                        }
                    });
                }
                else {
                    this.cover.remove();
                    this.cover = null;
                }
            }
        }
        else {
            if (!this.cover) {
                this.cover = flit_1.render(flit_1.html `<f-loader .size=${this.options.get('size')} .asCover />`).fragment.firstElementChild;
                this.el.append(this.cover);
            }
            if (transition) {
                new flit_1.Transition(this.cover, transition).enter();
            }
        }
    }
    remove() {
        if (this.cover) {
            this.cover.remove();
        }
    }
}
exports.LoadingBinging = LoadingBinging;
exports.loading = flit_1.defineBinding('loading', LoadingBinging);


/***/ }),

/***/ "./node_modules/@pucelle/flit-ui/out/bindings/popup.js":
/*!*************************************************************!*\
  !*** ./node_modules/@pucelle/flit-ui/out/bindings/popup.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.popup = exports.PopupBinding = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
const NamedPopupCache = new Map();
const NamedPopupsInUse = new Map();
function getPopupCacheFromName(name) {
    let cache = NamedPopupCache.get(name);
    if (cache) {
        let popup = cache.popup;
        // If current popup is in use, not reuse it
        if (ff_1.MouseLeave.inUse(popup.el)) {
            return null;
        }
        return cache;
    }
    return null;
}
const defaultPopupOptions = {
    trigger: 'hover',
    alignPosition: 'b',
    alignMargin: 4,
    showDelay: 0,
    hideDelay: 200,
    triangle: true,
    fixTriangle: false,
    transition: 'fade',
    onOpenedChanged: () => undefined
};
/**
 * `:popup="..."`
 * `popup(title: string, {alignPosition: ..., ...})`
 */
class PopupBinding {
    constructor(el, context) {
        this.options = new flit_1.Options(defaultPopupOptions);
        this.opened = false;
        this.showTimeout = null;
        this.hideTimeout = null;
        this.unwatchRect = null;
        this.unwatchLeave = null;
        this.unwatchResult = null;
        this.popupTemplate = null;
        this.popup = null;
        this.el = el;
        this.context = context;
    }
    /** `renderFn` should never change. */
    update(renderFn, options) {
        let firstlyUpdate = !this.options.updated;
        this.renderFn = renderFn;
        this.options.update(options);
        if (firstlyUpdate) {
            this.bindTrigger();
        }
        else {
            this.updatePopup();
        }
    }
    getOption(key) {
        let value;
        if (this.popup && this.popup.defaultPopupOptions) {
            value = this.popup.defaultPopupOptions[key];
        }
        if (value === undefined) {
            value = this.options.get(key);
        }
        return value;
    }
    bindTrigger() {
        let trigger = this.getOption('trigger');
        if (trigger === 'hover') {
            flit_1.on(this.el, 'mouseenter', this.showPopupLater, this);
        }
        else if (trigger === 'click') {
            flit_1.on(this.el, 'click', this.toggleOpened, this);
        }
        else {
            flit_1.on(this.el, trigger, this.showPopupLater, this);
        }
    }
    remove() {
        flit_1.off(this.el, 'mouseenter', this.showPopupLater, this);
        if (this.popup) {
            this.popup.el.remove();
        }
    }
    toggleOpened() {
        if (this.opened) {
            this.hidePopup();
        }
        else {
            this.showPopup();
        }
    }
    async showPopupLater() {
        if (this.showTimeout) {
            return;
        }
        this.clearHideTimeout();
        if (this.opened) {
            return;
        }
        let trigger = this.getOption('trigger');
        let showDelay = this.getOption('showDelay');
        if (trigger === 'hover' || trigger === 'focus') {
            this.showTimeout = ff_1.timeout(() => {
                this.showTimeout = null;
                this.showPopup();
            }, showDelay);
            if (trigger === 'hover') {
                flit_1.once(this.el, 'mouseleave', this.hidePopupLater, this);
            }
            else if (trigger === 'focus') {
                flit_1.once(this.el, 'blur', this.hidePopupLater, this);
            }
        }
        else {
            this.showPopup();
        }
    }
    showPopup() {
        if (this.opened) {
            return;
        }
        let { popup, inUse } = this.getPopup();
        popup.applyAppendTo();
        popup.el.style.visibility = 'hidden';
        this.setOpened(true);
        // May do something in callback of `setOpened` and `await renderComplete` there.
        flit_1.onRenderComplete(() => {
            if (!this.isPopupInControl()) {
                return;
            }
            this.alignPopup();
            popup.el.style.visibility = '';
            this.mayFocus();
            if (inUse) {
                flit_1.clearTransition(popup.el);
            }
            else {
                new flit_1.Transition(popup.el, this.getOption('transition')).enter();
            }
            let trigger = this.getOption('trigger');
            if (trigger === 'hover') {
                flit_1.off(this.el, 'mouseleave', this.hidePopupLater, this);
            }
            else if (trigger === 'focus') {
                flit_1.off(this.el, 'blur', this.hidePopupLater, this);
            }
            this.bindLeave();
            this.unwatchRect = ff_1.watchLayout(this.el, 'rect', this.onElRectChanged.bind(this));
        });
    }
    mayFocus() {
        let trigger = this.getOption('trigger');
        if ((trigger !== 'hover' && trigger !== 'focus') && this.el.tabIndex >= 0) {
            this.el.focus();
        }
    }
    bindLeave() {
        let trigger = this.getOption('trigger');
        if (trigger === 'hover') {
            // Should not use once to watch, or if the hideLater it triggered was canceled, This can't trigger again.
            this.unwatchLeave = ff_1.MouseLeave.on([this.el, this.popup.el], this.hidePopupLater.bind(this), {
                delay: this.getOption('hideDelay'),
                mouseIn: true,
            });
        }
        else if (trigger === 'click' || trigger === 'contextmenu') {
            flit_1.on(document, 'mousedown', this.onDocMouseDown, this);
        }
    }
    setOpened(opened) {
        this.opened = opened;
        let onOpenedChanged = this.getOption('onOpenedChanged');
        if (onOpenedChanged) {
            onOpenedChanged(opened);
        }
    }
    // If popup is not been reused by another.
    isPopupInControl() {
        if (!this.popup) {
            return false;
        }
        let name = this.getOption('name');
        if (!name) {
            return true;
        }
        return NamedPopupsInUse.get(this.popup) === this;
    }
    clearHideTimeout() {
        if (this.hideTimeout) {
            this.hideTimeout.cancel();
            this.hideTimeout = null;
        }
    }
    getPopup() {
        let result = this.renderFn();
        let name = this.getOption('name');
        let popup = null;
        let template = null;
        let inUse = false;
        if (!(result instanceof flit_1.TemplateResult)) {
            result = flit_1.html `${result}`;
        }
        if (name) {
            let cache = getPopupCacheFromName(name);
            if (cache) {
                ({ popup, template } = cache);
                inUse = NamedPopupsInUse.has(popup);
                if (template.canMergeWith(result)) {
                    template.merge(result);
                }
                else {
                    popup.el.remove();
                    popup = null;
                }
            }
        }
        if (!popup) {
            let renderResult = flit_1.renderComponent(result, this.context);
            template = renderResult.template;
            popup = renderResult.component;
            if (name) {
                NamedPopupCache.set(name, { popup, template });
            }
        }
        if (name) {
            NamedPopupsInUse.set(popup, this);
        }
        this.popup = popup;
        this.popupTemplate = template;
        popup.setPopupBinding(this);
        return { popup, inUse };
    }
    async updatePopup() {
        if (this.isPopupInControl()) {
            let result = this.renderFn();
            let name = this.getOption('name');
            let popup = this.popup;
            let template = this.popupTemplate;
            if (!(result instanceof flit_1.TemplateResult)) {
                result = flit_1.html `${result}`;
            }
            if (template.canMergeWith(result)) {
                template.merge(result);
            }
            else {
                popup.el.remove();
                let renderResult = flit_1.renderComponent(result, this.context);
                template = this.popupTemplate = renderResult.template;
                popup = renderResult.component;
                if (name) {
                    NamedPopupCache.set(name, { popup, template });
                }
            }
            await flit_1.renderComplete();
            this.alignPopup();
        }
    }
    onMouseLeave() {
        this.hidePopupLater();
    }
    onDocMouseDown(e) {
        let target = e.target;
        if (!this.el.contains(target) && !this.popup.el.contains(target)) {
            this.hidePopupLater();
        }
    }
    onElRectChanged() {
        if (ff_1.isInViewport(this.el)) {
            if (this.popup) {
                this.alignPopup();
            }
        }
        else {
            this.onNotInViewport();
        }
    }
    onNotInViewport() {
        this.hidePopupLater();
    }
    alignPopup() {
        let popup = this.popup;
        let alignToFn = this.getOption('alignTo');
        let alignTo = alignToFn ? alignToFn(this.el) : this.el;
        let triangle = this.popup.refs.triangle;
        ff_1.align(popup.el, alignTo, this.getOption('alignPosition'), {
            margin: this.getOption('alignMargin'),
            canShrinkInY: true,
            triangle,
            fixTriangle: this.getOption('fixTriangle'),
        });
    }
    hidePopupLater() {
        if (this.hideTimeout) {
            return;
        }
        this.clearShowTimeout();
        if (!this.opened) {
            return;
        }
        let trigger = this.getOption('trigger');
        let hideDelay = trigger === 'hover' ? 0 : this.getOption('hideDelay');
        if ((trigger === 'hover' || trigger === 'focus') && hideDelay > 0) {
            this.hideTimeout = ff_1.timeout(() => {
                this.hideTimeout = null;
                this.hidePopup();
            }, hideDelay);
        }
        else {
            this.hidePopup();
        }
    }
    clearShowTimeout() {
        if (this.showTimeout) {
            this.showTimeout.cancel();
            this.showTimeout = null;
        }
    }
    hidePopup() {
        if (!this.opened) {
            return;
        }
        // Must unwatch here, not in `hideLater`, or if it was canceled...
        this.unwatch();
        let name = this.getOption('name');
        let popupEl = this.popup.el;
        if (this.isPopupInControl()) {
            if (name) {
                NamedPopupsInUse.delete(this.popup);
            }
            new flit_1.Transition(popupEl, this.getOption('transition')).leave().then((finish) => {
                if (finish) {
                    popupEl.remove();
                }
            });
        }
        this.setOpened(false);
        this.popup = null;
        this.popupTemplate = null;
    }
    unwatch() {
        let trigger = this.getOption('trigger');
        if (this.unwatchRect) {
            this.unwatchRect();
            this.unwatchRect = null;
        }
        if (this.unwatchLeave) {
            this.unwatchLeave();
            this.unwatchLeave = null;
        }
        if (this.unwatchResult) {
            this.unwatchResult();
            this.unwatchResult = null;
        }
        if (trigger === 'click' || trigger === 'contextmenu') {
            flit_1.off(document, 'mousedown', this.onDocMouseDown, this);
        }
    }
}
exports.PopupBinding = PopupBinding;
exports.popup = flit_1.defineBinding('popup', PopupBinding);


/***/ }),

/***/ "./node_modules/@pucelle/flit-ui/out/bindings/tooltip.js":
/*!***************************************************************!*\
  !*** ./node_modules/@pucelle/flit-ui/out/bindings/tooltip.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.tooltip = exports.TooltipBinding = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const popup_1 = __webpack_require__(/*! ./popup */ "./node_modules/@pucelle/flit-ui/out/bindings/popup.js");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
const defaultTooltipOptions = {
    name: 'tooltip',
    alignPosition: 'r',
    alignMargin: 3,
    showDelay: 0,
    hideDelay: 200,
    type: 'default',
};
/**
 * `:tooltip="..."`
 * `tooltip(title, {alignPosition: ..., ...})`
 */
class TooltipBinding extends popup_1.PopupBinding {
    constructor() {
        super(...arguments);
        this.title = '';
    }
    update(title, options = {}) {
        this.title = title;
        if (options.type && ['prompt', 'error'].includes(options.type) && options.name === undefined) {
            options.name = '';
        }
        super.update(this.getRenderFn.bind(this), this.getPopupOptions(options));
    }
    async showPopupLater() {
        // Not popup if no `title` specified.
        if (!this.title) {
            return;
        }
        await super.showPopupLater();
    }
    bindTrigger() {
        if (this.shouldAlwaysKeepVisible()) {
            // If not, page scrolling position may be not determinated yet.
            // So element may be aligned to a wrong position.
            ff_1.ensureWindowLoaded().then(() => {
                this.showPopupLater();
            });
        }
        else {
            super.bindTrigger();
        }
    }
    shouldAlwaysKeepVisible() {
        return ['prompt', 'error'].includes(this.getOption('type'));
    }
    bindLeave() {
        if (this.getOption('type') !== 'prompt') {
            super.bindLeave();
        }
    }
    onNotInViewport() {
        if (!this.shouldAlwaysKeepVisible()) {
            super.onNotInViewport();
        }
    }
    getRenderFn() {
        return flit_1.html `
			<f-tooltip
				.herizontal=${this.isHerizontal()}
				.type=${this.getOption('type')}
			>
				${this.title}
			</f-tooltip>
		`;
    }
    getPopupOptions(options = {}) {
        return ff_1.assignIf(options, defaultTooltipOptions);
    }
    isHerizontal() {
        let direction = ff_1.getMainAlignDirection(this.options.get('alignPosition'));
        return direction === 'l' || direction === 'r';
    }
}
exports.TooltipBinding = TooltipBinding;
exports.tooltip = flit_1.defineBinding('tooltip', TooltipBinding);


/***/ }),

/***/ "./node_modules/@pucelle/flit-ui/out/components/buttongroup.js":
/*!*********************************************************************!*\
  !*** ./node_modules/@pucelle/flit-ui/out/components/buttongroup.js ***!
  \*********************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ButtonGroup = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const theme_1 = __webpack_require__(/*! ../style/theme */ "./node_modules/@pucelle/flit-ui/out/style/theme.js");
let ButtonGroup = class ButtonGroup extends flit_1.Component {
    static style() {
        let { textColor, backgroundColor } = theme_1.theme;
        return flit_1.css `
		:host{
			display: inline-flex;
			vertical-align: top;
		}

		button{
			&:nth-child(n+2){
				margin-left: -1px;
				border-top-left-radius: 0;
				border-bottom-left-radius: 0;
			}
	
			&:nth-last-child(n+2){
				border-top-right-radius: 0;
				border-bottom-right-radius: 0;
			}
	
			&[primary]{
				position: relative;
				z-index: 1;
				background: ${textColor};
				border-color: ${textColor};
				color: ${backgroundColor};
			}

			&:hover{
				position: relative;
				z-index: 1;
			}
		}
		`;
    }
};
ButtonGroup = __decorate([
    flit_1.define('f-buttongroup')
], ButtonGroup);
exports.ButtonGroup = ButtonGroup;


/***/ }),

/***/ "./node_modules/@pucelle/flit-ui/out/components/checkbox.js":
/*!******************************************************************!*\
  !*** ./node_modules/@pucelle/flit-ui/out/components/checkbox.js ***!
  \******************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.CheckboxGroup = exports.Checkbox = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const theme_1 = __webpack_require__(/*! ../style/theme */ "./node_modules/@pucelle/flit-ui/out/style/theme.js");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
let Checkbox = class Checkbox extends flit_1.Component {
    constructor() {
        super(...arguments);
        this.checked = false;
        this.indeterminate = false;
        // Used to compare with `checkboxGroup.value`
        this.value = null;
        this.checkboxGroup = null;
    }
    static style() {
        let { mainColor, focusBlurRadius, adjust } = theme_1.theme;
        return flit_1.css `
		:host{
			display: inline-flex;
			vertical-align: top;
			align-items: center;
			cursor: pointer;

			&:hover{
				color: ${mainColor};
			}

			&:focus{
				color: ${mainColor};

				.icon{
					box-shadow: 0 0 ${focusBlurRadius}px ${mainColor};
				}
			}
		}

		.icon{
			margin-right: ${adjust(6)}px;
			border-radius: 4px;
		}

		.indeterminate, .checked{
			color: ${mainColor};
		}

		.label{
			flex: 1;
			white-space: nowrap;
			overflow: hidden;
			text-overflow: ellipsis;
		}
		`;
    }
    render() {
        let iconType = this.checked ? 'checkbox-checked' : this.indeterminate ? 'checkbox-indeterminate' : 'checkbox-unchecked';
        return flit_1.html `
			<template
				tabindex="0"
				:class.checked=${this.checked}
				:class.indeterminate=${this.indeterminate}
				@@click=${this.onClick}
				@@focus=${this.onFocus}
				@@blur=${this.onBlur}
			>
				<f-icon class="icon" .type=${iconType} />
				<div class="label">
					<slot />
				</div>
			</template>
		`;
    }
    onCreated() {
        let group = flit_1.getClosestComponent(this.el, CheckboxGroup);
        if (group) {
            this.checkboxGroup = group;
            this.checked = this.checkboxGroup.value === this.value;
            this.checkboxGroup.register(this);
        }
    }
    onClick() {
        this.checked = !this.checked;
        this.indeterminate = false;
        this.emit('change', this.checked);
    }
    onFocus() {
        flit_1.on(document, 'keydown.enter', this.onEnter, this);
    }
    onEnter(e) {
        e.preventDefault();
        this.onClick();
    }
    onBlur() {
        flit_1.off(document, 'keydown', this.onEnter, this);
    }
};
Checkbox = __decorate([
    flit_1.define('f-checkbox')
], Checkbox);
exports.Checkbox = Checkbox;
let CheckboxGroup = class CheckboxGroup extends flit_1.Component {
    constructor() {
        super(...arguments);
        this.value = [];
        this.ordered = false;
        this.checkboxs = [];
    }
    register(checkbox) {
        this.checkboxs.push(checkbox);
        checkbox.on('change', this.onCheckboxChange.bind(this, checkbox));
    }
    onCheckboxChange(checkbox) {
        if (checkbox.checked) {
            this.value.push(checkbox.value);
        }
        else {
            ff_1.removeWhere(this.value, value => value == checkbox.value);
        }
        if (this.ordered) {
            let values = this.checkboxs.map(checkbox => checkbox.value);
            ff_1.orderBy(this.value, item => values.findIndex(value => value == item));
        }
        this.emit('change', this.value);
    }
};
CheckboxGroup = __decorate([
    flit_1.define('f-checkboxgroup')
], CheckboxGroup);
exports.CheckboxGroup = CheckboxGroup;


/***/ }),

/***/ "./node_modules/@pucelle/flit-ui/out/components/contextmenu.js":
/*!*********************************************************************!*\
  !*** ./node_modules/@pucelle/flit-ui/out/components/contextmenu.js ***!
  \*********************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ContextMenu = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const theme_1 = __webpack_require__(/*! ../style/theme */ "./node_modules/@pucelle/flit-ui/out/style/theme.js");
const popup_1 = __webpack_require__(/*! ../components/popup */ "./node_modules/@pucelle/flit-ui/out/components/popup.js");
let ContextMenu = class ContextMenu extends popup_1.Popup {
    constructor() {
        super(...arguments);
        this.triangle = false;
    }
    static style() {
        let { adjust } = theme_1.theme;
        return flit_1.css `
		${super.style()}
		:host{
			position: fixed;
			border-radius: 0;
			
			.option__f-list{
				padding: ${adjust(2)}px ${adjust(8)}px;
			}

			f-list{
				border-bottom: none;
			}
		}
		`.extends(super.style());
    }
};
ContextMenu = __decorate([
    flit_1.define('f-contextmenu')
], ContextMenu);
exports.ContextMenu = ContextMenu;


/***/ }),

/***/ "./node_modules/@pucelle/flit-ui/out/components/dialog.js":
/*!****************************************************************!*\
  !*** ./node_modules/@pucelle/flit-ui/out/components/dialog.js ***!
  \****************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.dialog = exports.QuickDialog = exports.Dialog = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const theme_1 = __webpack_require__(/*! ../style/theme */ "./node_modules/@pucelle/flit-ui/out/style/theme.js");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
let Dialog = class Dialog extends flit_1.Component {
    constructor() {
        super(...arguments);
        this.appendTo = 'body';
        this.options = null;
        /** Also as a marker to know if current options are expired. */
        this.resolve = null;
        this.stack = [];
        this.opened = true;
    }
    static style() {
        let { textColor, adjust, adjustFontSize, popupBorderRadius, popupShadowBlurRadius, popupShadowColor, popupBackgroundColor } = theme_1.theme;
        return flit_1.css `
		:host{
			z-index: 1100;	// Higher that modal, popup, tooltip
			width: ${adjust(360)}px;
			position: fixed;
			border-radius: ${popupBorderRadius}px;
			box-shadow: 0 0 ${popupShadowBlurRadius}px ${popupShadowColor};
			background: ${popupBackgroundColor};
			max-width: 96%;
			max-height: 96%;
			padding: ${adjust(8)}px ${adjust(16)}px ${adjust(16)}px;
		}

		.mask{
			position: fixed;
			z-index: 1000;
			left: 0;
			top: 0;
			width: 100%;
			height: 100%;
			background: rgba(0, 0, 0, 0.5);
		}

		.header{
			display: flex;
			line-height: ${adjust(22)}px;
			height: ${adjust(28) + 1}px;
			font-size: ${adjustFontSize(13)}px;
			padding-bottom: ${adjust(6)}px;
			border-bottom: 1px solid ${textColor.alpha(0.8)};
		}

		.title{
			flex: 1;
			min-width: 0;
			padding: 0 ${adjust(16)}px 0 0;
			font-weight: bold;
			overflow: hidden;
			white-space: nowrap;
			text-overflow: ellipsis;
		}

		.content{
			display: flex;
			margin-top: ${adjust(8)}px;
		}

		.icon{
			padding-right: ${adjust(12)}px;
		}

		.message{
			flex: 1;
			min-width: 0;
			line-height: ${adjust(20)}px;
			padding: ${adjust(4)}px 0;
		}

		.list{
			margin: ${adjust(8)}px 0;
			line-height: ${adjust(20)}px;
			list-style-type: square;
			padding-left: ${adjust(28)}px;
		}

		.actions{
			display: flex;
			justify-content: flex-end;
			margin-top: ${adjust(16)}px;

			button{
				margin-left: ${adjust(8)}px;
			}

			.third{
				margin-left: 0;
				margin-right: auto;
			}
		}

		.input{
			margin-top: 8px;
			width: 100%;
		}
		`;
    }
    render() {
        let options = this.options;
        if (!options) {
            return '';
        }
        return flit_1.html `
		<template
			tabindex="0"
			${flit_1.show(this.opened, { transition: 'fade', enterAtStart: true, onend: this.onTransitionEnd })}
		>
			<div class="mask"
				:ref="mask"
				${flit_1.show(this.opened, { transition: 'fade', enterAtStart: true })}
			/>

			${options.title ? flit_1.html `
				<div class="header">
					<div class="title">
						${options.title}
					</div>
				</div>
			` : ''}

			<div class="content">

				${options.icon ? flit_1.html `<div class="icon">
					<f-icon .type="${options.icon}" />
				</div>` : ''}

				<div class="message">
					${options.message}
				</div>

				${options.list && options.list.length > 0 ? flit_1.html `
					<ul class="list">
						${options.list.map(text => flit_1.html `<li>${text}</li>`)}
					</ul>
				` : ''}
			</div>

			${this.renderActions(options.actions)}
		</template>
		`;
    }
    renderActions(actions) {
        if (actions && actions.length > 0) {
            let results = actions.map(action => flit_1.html `
				<button class="action"
					?primary=${action.primary}
					:class.third=${action.third}
					@click=${() => this.onClickActionButton(action)}>
					${action.text}
				</button>
			`);
            return flit_1.html `<div class="actions">${results}</div>`;
        }
        return '';
    }
    onClickActionButton(action) {
        if (this.resolve) {
            this.resolve(action.value);
            this.resolve = null;
        }
        if (this.stack.length > 0) {
            let item = this.stack.shift();
            this.assignOptions(item.options, item.resolve);
        }
        else {
            this.hide();
        }
    }
    triggerAction(value) {
        if (!this.options || !this.options.actions) {
            return;
        }
        let action = this.options.actions.find(action => action.value === value);
        if (action) {
            this.onClickActionButton(action);
        }
    }
    onTransitionEnd(type, finish) {
        if (type === 'leave' && finish) {
            if (this.refs.mask) {
                this.refs.mask.remove();
            }
            this.el.remove();
        }
        else if (type === 'enter') {
            let input = this.el.querySelector('input');
            if (input) {
                input.focus();
            }
        }
    }
    async onConnected() {
        await flit_1.renderComplete();
        if (this.refs.mask && this.el.previousElementSibling !== this.refs.mask) {
            this.el.before(this.refs.mask);
        }
        this.toCenter();
        if (this.el.tabIndex === 0) {
            this.el.focus();
        }
        flit_1.on(window, 'resize', ff_1.debounce(this.onWindowResize, 200).wrapped, this);
    }
    onDisconnected() {
        flit_1.off(window, 'resize', this.onWindowResize, this);
    }
    onWindowResize() {
        if (this.opened) {
            this.toCenter();
        }
    }
    toCenter() {
        ff_1.align(this.el, document.documentElement, 'c');
    }
    show() {
        this.opened = true;
        if (this.appendTo) {
            flit_1.appendTo(this.el, this.appendTo);
        }
    }
    hide() {
        this.opened = false;
    }
    assignOptions(options, resolve) {
        this.options = options;
        this.resolve = resolve;
    }
    async addOptions(options) {
        let resolve;
        let promise = new Promise(scopedResolve => {
            resolve = scopedResolve;
        });
        if (this.resolve) {
            this.stack.push({
                options,
                resolve: resolve,
            });
        }
        else {
            this.assignOptions(options, resolve);
            this.show();
        }
        return promise;
    }
};
Dialog = __decorate([
    flit_1.define('f-dialog')
], Dialog);
exports.Dialog = Dialog;
class QuickDialog {
    constructor() {
        this.dialogComponent = null;
        this.actionLabels = {
            ok: 'OK',
            cancel: 'Cancel',
            yes: 'Yes',
            no: 'No'
        };
    }
    addOptions(options) {
        if (!this.dialogComponent) {
            this.dialogComponent = flit_1.renderComponent(flit_1.html `<f-dialog />`).component;
        }
        return this.dialogComponent.addOptions(options);
    }
    setLabels(labels) {
        Object.assign(this.actionLabels, labels);
    }
    /** Show default type dialog or add it to dialog stack. */
    show(message, options = {}) {
        return this.addOptions(Object.assign({
            message,
            actions: [{ value: 'ok', text: this.actionLabels.ok }],
        }, options));
    }
    /** Show confirm type dialog or add it to dialog stack. */
    confirm(message, options = {}) {
        return this.addOptions(Object.assign({
            icon: 'confirm',
            message,
            actions: [
                { value: 'cancel', text: this.actionLabels.cancel },
                { value: 'ok', text: this.actionLabels.ok, primary: true },
            ],
        }, options));
    }
    /** Show prompt type dialog or add it to dialog stack. */
    async prompt(message, options = {}) {
        let value = options.value ? String(options.value) : '';
        let messageWithInput = flit_1.html `
			${message}
			<f-input class="input" 
				.placeholder=${options.placeholder}
				@input=${(v) => value = v}
				@@keydown.enter=${() => this.dialogComponent.triggerAction('ok')}
			/>
		`;
        let btn = await this.addOptions(Object.assign({
            message: messageWithInput,
            actions: [
                { value: 'cancel', text: this.actionLabels.cancel },
                { value: 'ok', text: this.actionLabels.ok, primary: true },
            ],
        }, options));
        if (btn === 'ok') {
            return value;
        }
        return undefined;
    }
}
exports.QuickDialog = QuickDialog;
exports.dialog = new QuickDialog();


/***/ }),

/***/ "./node_modules/@pucelle/flit-ui/out/components/dropdown.js":
/*!******************************************************************!*\
  !*** ./node_modules/@pucelle/flit-ui/out/components/dropdown.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Dropdown = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const theme_1 = __webpack_require__(/*! ../style/theme */ "./node_modules/@pucelle/flit-ui/out/style/theme.js");
const popup_1 = __webpack_require__(/*! ../bindings/popup */ "./node_modules/@pucelle/flit-ui/out/bindings/popup.js");
/**
 * Contains trigger element and popup content.
 * You should extend it to implement some dropdown type components, like `Select`.
  */
class Dropdown extends flit_1.Component {
    constructor() {
        super(...arguments);
        this.opened = false;
        this.trigger = 'click';
        this.triangle = true;
        this.alignPosition = 'b';
        this.alignMargin = 3;
        this.transition = 'fade';
        this.showDelay = 100;
        this.hideDelay = 100;
        this.popupBinding = null;
    }
    static style() {
        let { mainColor } = theme_1.theme;
        return flit_1.css `
		:host{
			display: inline-flex;
		}

		.opened{
			color: ${mainColor};
		}

		.down-icon{
			margin-right: 6px;
		}

		.popup{
			padding: 5px 0;
		}

		.list{
			overflow-y: auto;
			max-height: 100%;
		}
		`;
    }
    render() {
        let { trigger, triangle, alignPosition, alignMargin, transition, showDelay, hideDelay } = this;
        let onOpenedChanged = this.setOpened.bind(this);
        let toPopup = flit_1.refBinding(popup_1.popup(() => this.renderPopup(), { trigger, triangle, alignPosition, alignMargin, transition, showDelay, hideDelay, onOpenedChanged }), (v) => { this.popupBinding = v; });
        return flit_1.html `
		<template :class.opened=${this.opened} ${toPopup}>
			<slot />
			<f-icon class="down-icon" .type="down" />
		</template>
		`;
    }
    renderPopup() {
        return flit_1.html `
		<f-popup
			class="popup"
			.triangle=${this.triangle}
		/>
		`;
    }
    setOpened(opened) {
        this.opened = opened;
        if (opened) {
            this.onPopupOpened();
        }
    }
    onPopupOpened() { }
    async showPopup() {
        if (this.popupBinding) {
            await this.popupBinding.showPopupLater();
        }
    }
    hidePopup() {
        if (this.popupBinding) {
            this.popupBinding.hidePopupLater();
        }
    }
}
exports.Dropdown = Dropdown;


/***/ }),

/***/ "./node_modules/@pucelle/flit-ui/out/components/form.js":
/*!**************************************************************!*\
  !*** ./node_modules/@pucelle/flit-ui/out/components/form.js ***!
  \**************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Form = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
let Form = class Form extends flit_1.Component {
    constructor() {
        super(...arguments);
        this.valid = true;
        this.inputs = [];
    }
    static style() {
        return flit_1.css `
		:host{
			display: block;
		}
		`;
    }
    register(input) {
        this.inputs.push(input);
        this.valid = this.valid && input.valid !== false;
        input.on('change', this.onInputChange, this);
    }
    onInputChange(_value, valid) {
        if (valid !== this.valid) {
            if (valid) {
                this.valid = this.inputs.every(input => input.valid);
            }
            else {
                this.valid = false;
            }
        }
    }
    validate() {
        for (let input of this.inputs) {
            input.setTouched(true);
        }
    }
    reset() {
        for (let input of this.inputs) {
            input.setTouched(false);
        }
    }
};
Form = __decorate([
    flit_1.define('f-form')
], Form);
exports.Form = Form;


/***/ }),

/***/ "./node_modules/@pucelle/flit-ui/out/components/grid-layout.js":
/*!*********************************************************************!*\
  !*** ./node_modules/@pucelle/flit-ui/out/components/grid-layout.js ***!
  \*********************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ColLayout = exports.RowLayout = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
/**
 * Note these components only used to align, not for responsive layout.
 * Will extend later when needed.
 */
let RowLayout = class RowLayout extends flit_1.Component {
    constructor() {
        super(...arguments);
        this.columnCount = 24;
        this.gutter = 0;
        this.justify = 'start';
        this.cols = [];
    }
    static style() {
        return flit_1.css `
		:host{
			display: flex;
			flex-wrap: wrap;
		}
		`;
    }
    onUpdated() {
        this.el.style.justifyContent = this.justify === 'start' ? '' : this.justify === 'end' ? 'flex-end' : this.justify;
    }
    register(col) {
        this.cols.push(col);
    }
    getLeftColCount(col) {
        let { columnCount } = this;
        let count = 0;
        for (let c of this.cols) {
            if (c === col) {
                break;
            }
            let span = Math.min(c.span, columnCount);
            let offset = c.offset % columnCount;
            count += span + offset;
        }
        return count;
    }
    isFirstCol(col) {
        return col === this.cols[0];
    }
};
RowLayout = __decorate([
    flit_1.define('f-row')
], RowLayout);
exports.RowLayout = RowLayout;
let ColLayout = class ColLayout extends flit_1.Component {
    constructor() {
        super(...arguments);
        this.span = 1;
        this.offset = 0;
    }
    onCreated() {
        let row = flit_1.getComponent(this.el.parentElement);
        if (!(row instanceof RowLayout)) {
            throw new Error(`"<f-col>" must be included in a "<f-row>"`);
        }
        row.register(this);
        this.row = row;
    }
    onUpdated() {
        this.el.style.marginLeft = this.getMarginLeft();
        this.el.style.width = this.getWidth();
    }
    getMarginLeft() {
        let leftColCount = this.row.getLeftColCount(this);
        let { columnCount, gutter } = this.row;
        let offset = this.offset % columnCount;
        let isFirstCol = (leftColCount + offset) % columnCount === 0;
        if (offset > 0) {
            return (offset / gutter) * 100 + '%';
        }
        else {
            return isFirstCol ? '0' : gutter + 'px';
        }
    }
    getWidth() {
        let { gutter, columnCount } = this.row;
        let span = Math.min(this.span, columnCount);
        let percent = span / columnCount;
        let gutterPXs = gutter * (span - 1 - (columnCount - 1) * percent);
        return `calc(${percent * 100}% - ${-gutterPXs}px)`;
    }
};
ColLayout = __decorate([
    flit_1.define('f-col')
], ColLayout);
exports.ColLayout = ColLayout;


/***/ }),

/***/ "./node_modules/@pucelle/flit-ui/out/components/icon.js":
/*!**************************************************************!*\
  !*** ./node_modules/@pucelle/flit-ui/out/components/icon.js ***!
  \**************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.IconLoading = exports.Icon = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const svg_symbol_1 = __webpack_require__(/*! ../icons/svg-symbol */ "./node_modules/@pucelle/flit-ui/out/icons/svg-symbol.js");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
const theme_1 = __webpack_require__(/*! ../style/theme */ "./node_modules/@pucelle/flit-ui/out/style/theme.js");
let Icon = class Icon extends flit_1.Component {
    constructor() {
        super(...arguments);
        this.type = '';
    }
    render() {
        let svgCode = svg_symbol_1.svgSymbols[this.type];
        if (!svgCode) {
            return '';
        }
        let [viewBox, inner] = ff_1.subMatches(svgCode, /<svg viewBox="(.+?)">([\s\S]+?)<\/svg>/)[0];
        let [, , w, h] = viewBox.split(' ');
        let width = theme_1.theme.adjust(Number(w));
        let height = theme_1.theme.adjust(Number(h));
        return flit_1.html `
		<template>
			<svg
				viewBox=${viewBox}
				width=${width}
				height=${height}
				:html=${inner}
			/>
		</template>
		`;
    }
};
Icon.style = flit_1.css `
	:host{
		display: inline-flex;
		stroke: currentColor;
		fill: none;
		margin: auto 0;
		vertical-align: middle;

		svg{
			margin: auto;
		}
	}
	`;
Icon = __decorate([
    flit_1.define('f-icon')
], Icon);
exports.Icon = Icon;
let IconLoading = class IconLoading extends Icon {
    constructor() {
        super(...arguments);
        this.type = 'loading';
        this.loading = false;
        this.playing = false;
    }
    onCreated() {
        this.watchImmediately(() => this.loading, (value) => {
            if (value && !this.playing) {
                this.play();
                this.playing = true;
            }
        });
    }
    play() {
        let fn = (value) => {
            this.el.style.transform = 'rotate(' + value + 'deg)';
        };
        // Playing web animation will cause it becomes fuzzy.
        ff_1.animateByFunction(fn, 0, 360, 1000, 'linear').promise.then(() => {
            if (this.loading) {
                this.play();
            }
            else {
                this.playing = false;
            }
        });
    }
};
IconLoading.style = flit_1.css `
	:host{
		display: inline-flex;
		stroke: currentColor;
		fill: none;
		margin: auto 0;
		vertical-align: top;
		position: relative;
	}`;
IconLoading = __decorate([
    flit_1.define('f-icon-loading')
], IconLoading);
exports.IconLoading = IconLoading;


/***/ }),

/***/ "./node_modules/@pucelle/flit-ui/out/components/input.js":
/*!***************************************************************!*\
  !*** ./node_modules/@pucelle/flit-ui/out/components/input.js ***!
  \***************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Textarea = exports.Input = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const theme_1 = __webpack_require__(/*! ../style/theme */ "./node_modules/@pucelle/flit-ui/out/style/theme.js");
const form_1 = __webpack_require__(/*! ./form */ "./node_modules/@pucelle/flit-ui/out/components/form.js");
let Input = class Input extends flit_1.Component {
    constructor() {
        super(...arguments);
        this.type = 'text';
        this.touched = false;
        this.valid = null;
        this.placeholder = '';
        this.value = '';
        this.validator = null;
        this.error = '';
    }
    static style() {
        let { adjust, adjustFontSize, errorColor, borderColor, backgroundColor, mainColor, successColor, focusBlurRadius } = theme_1.theme;
        return flit_1.css `
		:host{
			display: inline-block;
			vertical-align: top;
			position: relative;
			width: ${adjust(200)}px;
			height: ${adjust(28)}px;
			background: ${backgroundColor.toMiddle(5)};
			box-shadow: inset 0 -1px 0 0 ${borderColor};
		}

		input, textarea{
			width: 100%;
			height: 100%;
			border: none;
			background: none;
			
			&:focus{
				box-shadow: 0 0 ${focusBlurRadius}px ${mainColor.alpha(0.5)};
			}
		}

		input{
			height: 100%;
			padding: 0 0 0 ${adjust(8)}px;
		}

		textarea{
			line-height: ${adjust(20)}px;
			padding: ${adjust(4)}px ${adjust(8)}px;
		}

		.valid{
			box-shadow: inset 0 -1px 0 0 ${successColor};

			input, textarea{
				padding-right: ${adjust(28)}px;

				&:focus{
					box-shadow: 0 0 ${focusBlurRadius}px ${successColor.alpha(0.5)};
				}
			}
		}

		.invalid{
			box-shadow: inset 0 -1px 0 0 ${errorColor};

			input, textarea{
				padding-right: ${adjust(28)}px;

				&:focus{
					box-shadow: 0 0 ${focusBlurRadius}px ${errorColor.alpha(0.5)};
				}
			}
		}

		.valid-icon{
			position: absolute;
			top: 0;
			bottom: 0;
			right: 6px;
			color: ${successColor};
		}

		.error{
			position: absolute;
			left: 0;
			top: 100%;
			margin-bottom: -${adjust(28)}px;
			font-size: ${adjustFontSize(13)}px;
			color: ${errorColor};
		}
		`;
    }
    render() {
        return flit_1.html `
		<template
			:class.valid=${this.touched && this.valid === true}
			:class.invalid=${this.touched && this.valid === false}
		>
			<input type=${this.type}
				placeholder=${this.placeholder || ''}
				.value=${this.value}
				:ref="input"
				@blur=${this.onBlur}
				@input=${(e) => this.onInput(e)}
				@change=${(e) => this.onChange(e)}
			/>
			${this.touched && this.valid === true ? flit_1.html `<f-icon class="valid-icon" .type="checked" />` : ''}
			${this.touched && this.error ? flit_1.html `<div class="error">${this.error}</div>` : ''}
		</template>
		`;
    }
    onBlur() {
        this.touched = true;
    }
    onInput(e) {
        let input = e.target;
        let value = input.value;
        this.emit('input', value);
    }
    onChange(e) {
        let input = e.target;
        let value = this.value = input.value;
        this.validate();
        this.emit('change', value, this.valid);
    }
    onCreated() {
        this.validate();
        let form = flit_1.getClosestComponent(this.el, form_1.Form);
        if (form) {
            form.register(this);
        }
    }
    validate() {
        if (this.validator) {
            this.error = this.validator(this.value);
            this.valid = !this.error;
        }
    }
    setTouched(touched) {
        this.touched = touched;
    }
};
Input = __decorate([
    flit_1.define('f-input')
], Input);
exports.Input = Input;
let Textarea = class Textarea extends Input {
    static style() {
        return flit_1.css `
		:host{
			height: auto;
		}
		`.extends(super.style());
    }
    render() {
        return flit_1.html `
		<textarea
			placeholder=${this.placeholder}
			.value=${this.value}
			:ref="input"
			:class.valid=${this.touched && this.valid === true}
			:class.invalid=${this.touched && this.valid === false}
			@focus=${this.onBlur}
			@input=${(e) => this.onInput(e)}
			@change=${(e) => this.onChange(e)}
		/>
		`;
    }
};
Textarea = __decorate([
    flit_1.define('f-textarea')
], Textarea);
exports.Textarea = Textarea;


/***/ }),

/***/ "./node_modules/@pucelle/flit-ui/out/components/list.js":
/*!**************************************************************!*\
  !*** ./node_modules/@pucelle/flit-ui/out/components/list.js ***!
  \**************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.List = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const theme_1 = __webpack_require__(/*! ../style/theme */ "./node_modules/@pucelle/flit-ui/out/style/theme.js");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
const tooltip_1 = __webpack_require__(/*! ../bindings/tooltip */ "./node_modules/@pucelle/flit-ui/out/bindings/tooltip.js");
/** List shouldn't have many levels, it doesn't have overflow setting like Tree. */
let List = class List extends flit_1.Component {
    constructor() {
        super(...arguments);
        this.type = 'selection';
        this.selectable = false;
        this.multipleSelect = false;
        this.data = [];
        this.selected = [];
        this.active = null;
    }
    static style() {
        let { mainColor, adjust, borderColor, adjustFontSize } = theme_1.theme;
        return flit_1.css `
		:host{
			display: block;
			border-bottom: 1px solid ${borderColor.alpha(0.4)};
		}
		
		.option{
			position: relative;
			display: flex;
			padding-top: ${adjust(2)}px;
			padding-bottom: ${adjust(2)}px;
			cursor: pointer;
			border-top: 1px solid ${borderColor.alpha(0.4)};

			&:first-child{
				border-top: none;
			}

			&:hover{
				color: ${mainColor};
			}

			&.selected{
				color: ${mainColor};
			}

			&.active{
				color: ${mainColor};

				&::after{
					content: '';
					position: absolute;
					top: ${adjust(3)}px;
					bottom: ${adjust(3)}px;
					right: 0;
					width: 2px;
					background: ${mainColor.alpha(0.8)};
				}
			}
		}

		.toggle{
			display: flex;
			width: ${adjust(22)}px;
			opacity: 0.7;
		}

		.icon{
			display: flex;
			width: ${adjust(22)}px;
		}

		.text{
			flex: 1;
			min-width: 0;
			padding-right: 4px;
			white-space: nowrap;
			overflow: hidden;
			text-overflow: ellipsis;
		}

		.selected-icon{
			margin: 0 ${adjust(6)}px;
		}

		.subsection{
			padding-left: ${adjust(22)}px;
			padding-bottom: ${adjust(4)}px;
			overflow: hidden;
			font-size: ${adjustFontSize(13)}px;

			.option{
				padding-top: 0;
				padding-bottom: 0;
				border-top: none;
				line-height: ${adjust(26)}px;
			}

			.subsection{
				padding-top: 0;
				padding-bottom: ${adjust(3)}px;
				margin-bottom: ${adjust(3)}px;
				border-bottom: 1px solid ${borderColor.alpha(0.4)};
			}
		}
		`;
    }
    render() {
        return flit_1.html `${this.renderDataOrChildren(this.data)}`;
    }
    renderDataOrChildren(items) {
        let siblingsHaveIcon = items.some(item => item.icon);
        let siblingsHaveChildren = items.some(item => item.children);
        let options = flit_1.repeat(items, item => this.renderOption(item, siblingsHaveIcon, siblingsHaveChildren));
        return options;
    }
    renderOption(item, siblingsHaveIcon, siblingsHaveChildren) {
        let subsection = item.children && item.opened ? flit_1.html `
			<div class="subsection">${this.renderDataOrChildren(item.children)}</div>
		` : null;
        let tip = item.tip ? tooltip_1.tooltip(item.tip) : null;
        return flit_1.html `
		<div
			class="option"
			:class=${this.renderClassName(item)}
			@click.prevent=${() => this.onClickOption(item)}
			${tip}

		>
			${item.children ? flit_1.html `
				<div class='toggle' @click.stop=${() => this.toggle(item)}>
					<f-icon .type=${item.opened ? 'triangle-down' : 'triangle-right'} />
				</div>
			` : siblingsHaveChildren ? flit_1.html `
				<div class='toggle' />
			` : ''}

			${siblingsHaveIcon ? flit_1.html `
				<div class='icon'>
					<f-icon .type=${item.icon} />
				</div>
			` : ''}
	
			<div class="text">
				${item.text}
			</div>

			${this.isSelected(item) ? flit_1.html `<f-icon class="selected-icon" .type="checked" />` : ''}
		</div>

		${flit_1.play(subsection, { transition: { properties: ['height', 'opacity'] } })}
		`;
    }
    renderClassName(item) {
        if (this.type === 'navigation') {
            if (this.active === item.value) {
                return 'active';
            }
        }
        else {
            if (this.isSelected(item)) {
                return 'selected';
            }
        }
        return '';
    }
    isSelected(item) {
        return this.selected.includes(item.value);
    }
    onClickOption(item) {
        if (this.type === 'navigation') {
            this.active = item.value;
            this.emit('navigate', item.value);
        }
        else if (this.selectable) {
            if (this.multipleSelect) {
                if (this.selected.includes(item.value)) {
                    ff_1.remove(this.selected, item.value);
                }
                else {
                    ff_1.add(this.selected, item.value);
                }
            }
            else {
                this.selected = [item.value];
            }
            this.emit('select', this.selected);
        }
        else {
            this.emit('click', item.value);
        }
    }
    toggle(item) {
        if (item.children) {
            item.opened = !item.opened;
        }
    }
    onCreated() {
        if (this.active) {
            this.ensureActiveItemVisible(this.data);
        }
    }
    ensureActiveItemVisible(items) {
        return items.some(item => {
            if (item.value === this.active) {
                return true;
            }
            if (item.children) {
                let hasActiveChildItem = this.ensureActiveItemVisible(item.children);
                if (hasActiveChildItem) {
                    item.opened = true;
                }
            }
            return item.opened;
        });
    }
};
List = __decorate([
    flit_1.define('f-list')
], List);
exports.List = List;


/***/ }),

/***/ "./node_modules/@pucelle/flit-ui/out/components/loader.js":
/*!****************************************************************!*\
  !*** ./node_modules/@pucelle/flit-ui/out/components/loader.js ***!
  \****************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
var Loader_1;
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Loader = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const theme_1 = __webpack_require__(/*! ../style/theme */ "./node_modules/@pucelle/flit-ui/out/style/theme.js");
let Loader = Loader_1 = class Loader extends flit_1.Component {
    constructor() {
        super(...arguments);
        this.size = 'medium';
        this.asCover = false;
    }
    static style() {
        let { mainColor, backgroundColor } = theme_1.theme;
        return flit_1.css `
		:host{
			display: inline-block;
			vertical-align: top;
			color: ${mainColor};
		}

		.as-cover{
			position: absolute;
			left: 0;
			top: 0;
			right: 0;
			bottom: 0;
			z-index: 10;
			background: ${backgroundColor.alpha(0.9)};
			display: flex;
			flex-direction: column;
			justify-content: center;
			align-items: center;
			text-align: center;
		}

		svg{
			margin: auto;
		}

		path{
			stroke: currentColor;
			fill: none;
			stroke-linecap: square;
		}

		.bg{
			stroke-opacity: 0.3;
		}
		`;
    }
    render() {
        let strokeWidth = this.getStrokeWidth();
        let halfWidth = strokeWidth / 2;
        let size = Loader_1.sizes[this.size];
        let d = `M${halfWidth} ${halfWidth} H${size - halfWidth} V${size - halfWidth} H${halfWidth}Z`;
        let dashArray = `${size - strokeWidth} ${(size - strokeWidth) * 3}`;
        return flit_1.html `
		<template
			:class="size-${this.size}"
			:class.as-cover=${this.asCover}
			:style.width.px=${size}
			:style.height.px=${size}
			:style.animation="loader-snake-${this.size} 2s linear infinite"
		>
			<svg viewBox="0 0 ${size} ${size}" width=${size} height=${size}>
				<path class="bg" d=${d} style="stroke-width: ${strokeWidth}" />
				<path :ref="snake" d=${d} style="stroke-width: ${strokeWidth}; stroke-dasharray: ${dashArray};" />
			</svg>
		</template>
		`;
    }
    getStrokeWidth() {
        return Loader_1.strokeWidths[this.size];
    }
    onReady() {
        let strokeWidth = this.getStrokeWidth();
        let size = Loader_1.sizes[this.size];
        this.refs.snake.animate([
            {
                strokeDashoffset: 0,
            },
            {
                strokeDashoffset: -(size - strokeWidth) * 4,
            }
        ], {
            duration: 1500,
            iterations: Infinity
        });
    }
};
Loader.sizes = {
    small: 18,
    medium: 28,
    large: 48,
};
Loader.strokeWidths = {
    small: 3,
    medium: 4,
    large: 5,
};
Loader = Loader_1 = __decorate([
    flit_1.define('f-loader')
], Loader);
exports.Loader = Loader;


/***/ }),

/***/ "./node_modules/@pucelle/flit-ui/out/components/menu.js":
/*!**************************************************************!*\
  !*** ./node_modules/@pucelle/flit-ui/out/components/menu.js ***!
  \**************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Menu = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const theme_1 = __webpack_require__(/*! ../style/theme */ "./node_modules/@pucelle/flit-ui/out/style/theme.js");
const popup_1 = __webpack_require__(/*! ./popup */ "./node_modules/@pucelle/flit-ui/out/components/popup.js");
// Compare to `<popover>`, it can set title too,but contains a List.
let Menu = class Menu extends popup_1.Popup {
    constructor() {
        super(...arguments);
        this.title = '';
        this.defaultPopupOptions = {
            // `trigger` not work here because when handle it, current component is not created.
            alignPosition: 'bc',
            fixTriangle: true,
        };
    }
    static style() {
        let { adjust, adjustFontSize, textColor } = theme_1.theme;
        return flit_1.css `
		:host{
			min-width: ${adjust(180)}px;
			max-width: ${adjust(320)}px;
			padding: ${adjust(8)}px ${adjust(16)}px;

			f-list{
				border-bottom: none;
				max-height: 100%;
				overflow-y: auto;
			}
		}

		.triangle{
			left: ${adjust(15)}px;
		}

		.header{
			display: flex;
			line-height: ${adjust(22)}px;
			height: ${adjust(28) + 1}px;
			font-size: ${adjustFontSize(13)}px;
			padding-bottom: ${adjust(6)}px;
			border-bottom: 1px solid ${textColor.alpha(0.8)};
		}

		.title{
			flex: 1;
			min-width: 0;
			padding: 0 ${adjust(16)}px 0 0;
			font-weight: bold;
			overflow: hidden;
			white-space: nowrap;
			text-overflow: ellipsis;
		}
		`.extends(super.style());
    }
    render() {
        return flit_1.html `
		<f-popup>	
			${this.renderHead()}
			<slot />
		</f-popup>
		`.extends(super.render());
    }
    renderHead() {
        if (this.title) {
            return flit_1.html `
			<div class="header">
				<div class="title">${this.title}</div>
			</div>
			`;
        }
        return '';
    }
};
Menu = __decorate([
    flit_1.define('f-menu')
], Menu);
exports.Menu = Menu;


/***/ }),

/***/ "./node_modules/@pucelle/flit-ui/out/components/modal.js":
/*!***************************************************************!*\
  !*** ./node_modules/@pucelle/flit-ui/out/components/modal.js ***!
  \***************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Modal = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const theme_1 = __webpack_require__(/*! ../style/theme */ "./node_modules/@pucelle/flit-ui/out/style/theme.js");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
let Modal = class Modal extends flit_1.Component {
    constructor() {
        super(...arguments);
        this.title = '';
        this.opened = true;
        this.appendTo = 'body';
    }
    static style() {
        let { adjustFontSize, textColor, popupBorderRadius, popupShadowBlurRadius, popupBackgroundColor, popupShadowColor, adjust } = theme_1.theme;
        return flit_1.css `
		:host{
			position: fixed;
			display: flex;
			flex-direction: column;
			z-index: 1000;	// Same with popup
			border-radius: ${popupBorderRadius}px;
			box-shadow: 0 0 ${popupShadowBlurRadius}px ${popupShadowColor};
			background: ${popupBackgroundColor};
			max-width: 100%;
			max-height: 100%;
			padding: ${adjust(8)}px ${adjust(16)}px;
			overflow: hidden;
		}

		.mask{
			position: fixed;
			z-index: 1000;
			left: 0;
			top: 0;
			width: 100%;
			height: 100%;
			background: rgba(0, 0, 0, 0.5);
		}

		.header{
			display: flex;
			flex: none;
			height: ${adjust(34) + 1}px;
			font-size: ${adjustFontSize(13)}px;
			padding-bottom: ${adjust(6)}px;
			border-bottom: 1px solid ${textColor.alpha(0.8)};
			margin-bottom: ${adjust(8)}px;
		}

		.title{
			flex: 1;
			min-width: 0;
			font-weight: bold;
			overflow: hidden;
			white-space: nowrap;
			text-overflow: ellipsis;
		}

		.close{
			display: flex;
			width: ${adjust(28)}px;
			height: ${adjust(28)}px;
			margin-top: -${adjust(-6)}px;
			margin-right: ${adjust(-9)}px;
			cursor: pointer;

			&:active{
				transform: translateY(1px);
			}

			f-icon{
				margin: auto;
			}
		}

		.actions{
			margin-left: ${adjust(16)}px;

			button{
				margin-left: ${adjust(8)}px;
			}
		}

		.content{
			flex: 1;
			min-height: 0;
			display: flex;
			flex-direction: column;
			overflow-y: auto;
			margin-right: ${adjust(-16)}px;
			padding-right: ${adjust(16)}px;
		}
	`;
    }
    //extensions may make win wrapped by a mask, so we need a win el
    render() {
        let shouldRenderClose = !this.slots.action;
        return flit_1.html `
		<template
			tabindex="0"
			${flit_1.show(this.opened, { transition: 'fade', enterAtStart: true, onend: this.onTransitionEnd })}
		>
			<div class="mask"
				:ref="mask"
				${flit_1.show(this.opened, { transition: 'fade', enterAtStart: true })}
			/>

			<div class="header">
				<div class="title">${this.title}</div>

				<div class="actions" :show=${this.slots.action}>
					<slot name="action" />
				</div>

				${shouldRenderClose ? flit_1.html `
					<div class="close" @click=${this.hide}>
						<f-icon .type="close" />
					</div>
				` : ''}
			</div>

			<div class="content">
				<slot />
			</div>
		</template>
		`;
    }
    onTransitionEnd(type, finish) {
        if (type === 'leave' && finish) {
            if (this.refs.mask) {
                this.refs.mask.remove();
            }
            this.el.remove();
        }
    }
    async onConnected() {
        await flit_1.renderComplete();
        if (this.refs.mask && this.el.previousElementSibling !== this.refs.mask) {
            this.el.before(this.refs.mask);
        }
        this.toCenter();
        flit_1.on(window, 'resize', ff_1.debounce(this.onWindowResize, 200).wrapped, this);
    }
    onDisconnected() {
        flit_1.off(window, 'resize', this.onWindowResize, this);
    }
    onWindowResize() {
        if (this.opened) {
            this.toCenter();
        }
    }
    toCenter() {
        ff_1.align(this.el, document.documentElement, 'c');
    }
    /**
     * To show the modal, you may `renderCoponent` and then call `show()` or append to `body`.
     * If you want render modal as a child element  and append into document automatically,
     * just call `show` in `onConnected`.
     */
    show() {
        this.opened = true;
        if (this.appendTo) {
            flit_1.appendTo(this.el, this.appendTo);
        }
    }
    hide() {
        this.opened = false;
    }
};
Modal = __decorate([
    flit_1.define('f-modal')
], Modal);
exports.Modal = Modal;


/***/ }),

/***/ "./node_modules/@pucelle/flit-ui/out/components/navigation.js":
/*!********************************************************************!*\
  !*** ./node_modules/@pucelle/flit-ui/out/components/navigation.js ***!
  \********************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Navigation = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const list_1 = __webpack_require__(/*! ./list */ "./node_modules/@pucelle/flit-ui/out/components/list.js");
const theme_1 = __webpack_require__(/*! ../style/theme */ "./node_modules/@pucelle/flit-ui/out/style/theme.js");
let Navigation = class Navigation extends list_1.List {
    constructor() {
        super(...arguments);
        this.type = 'navigation';
        this.title = '';
    }
    static style() {
        let { backgroundColor, adjust, adjustFontSize } = theme_1.theme;
        return flit_1.css `
		:host{
			padding: ${adjust(8)}px ${adjust(16)}px;
			border-bottom: none;
			background: ${backgroundColor.toMiddle(9)};
			overflow-y: auto;
		}

		.title{
			font-size: ${adjustFontSize(18)}px;
			font-weight: 300;
			margin-top: ${adjust(4)}px;
			margin-bottom: ${adjust(8)}px;
		}

		`.extends(super.style());
    }
    render() {
        return flit_1.html `
		<tempalte>
			${this.title ? flit_1.html `
			<div class="title">
				${this.title}
			</div>` : ''}

			${this.renderDataOrChildren(this.data)}
		</tempalte>`;
    }
};
Navigation = __decorate([
    flit_1.define('f-navigation')
], Navigation);
exports.Navigation = Navigation;


/***/ }),

/***/ "./node_modules/@pucelle/flit-ui/out/components/notification.js":
/*!**********************************************************************!*\
  !*** ./node_modules/@pucelle/flit-ui/out/components/notification.js ***!
  \**********************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.notification = exports.UniqueNotification = exports.QuickNotification = exports.Notification = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const theme_1 = __webpack_require__(/*! ../style/theme */ "./node_modules/@pucelle/flit-ui/out/style/theme.js");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
let Notification = class Notification extends flit_1.Component {
    constructor() {
        super(...arguments);
        this.hideDelay = 10000;
        this.appendTo = 'body';
        this.seed = 1;
        this.items = [];
    }
    static style() {
        let { infoColor, adjust, successColor, errorColor, warningColor, popupBorderRadius, popupShadowBlurRadius, adjustFontSize, backgroundColor, textColor, popupShadowColor } = theme_1.theme;
        let types = [
            ['info', infoColor],
            ['warning', warningColor],
            ['error', errorColor],
            ['success', successColor]
        ];
        return flit_1.css `
		:host{
			position: fixed;
			right: ${adjust(12)}px;
			bottom: ${adjust(12)}px;
			min-width: ${adjust(280)}px;
			max-width: ${adjust(480)}px;
			z-index: 1200;	// Higher than message
			font-size: ${adjustFontSize(13)}px;
		}

		.item{
			position: relative;
			display: flex;
			margin-top: ${adjust(12)}px;
			background: ${backgroundColor};
			box-shadow: 0 0 ${popupShadowBlurRadius}px ${popupShadowColor};
			cursor: pointer;
			overflow: hidden;
			border-radius: ${popupBorderRadius}px;
		}

		.stripe{
			width: 4px;
		}

		.left{
			padding: ${adjust(16)}px ${adjust(14)}px ${adjust(16)}px ${adjust(16)}px;
		}

		.type-icon{
			display: block;
			width: ${adjust(20)}px;
			height: ${adjust(20)}px;

			svg{
				width: ${adjust(20)}px;
				height: ${adjust(20)}px;
			}
		}

		.content{
			flex: 1;
			min-width: 0;
			padding: ${adjust(16)}px ${adjust(16)}px ${adjust(8)}px 0;
		}

		.close{
			display: flex;
			width: ${adjust(28)}px;
			height: ${adjust(28)}px;
			color: ${textColor};

			f-icon{
				margin: auto;
			}

			&:hover{
				color: ${textColor.toMiddle(10)};
			}

			&:active{
				transform: translateY(1px);
			}
		}

		.title{
			font-weight: bold;
			line-height: ${adjust(20)}px;
			margin-bottom: ${adjust(4)}px;
		}

		.message{
			flex: 1;
			min-width: 0;
			line-height: ${adjust(20)}px;
			margin-bottom: ${adjust(4)}px;
			text-align: left;
			word-wrap: break-word;

			a{
				font-weight: bold;
			}
		}

		.list{
			margin: ${adjust(8)}px 0;
			line-height: ${adjust(20)}px;
			list-style-type: square;
			padding-left: ${adjust(28)}px;
		}

		.actions{
			margin-top: ${adjust(8)}px;
		}

		.action{
			margin-right: ${adjust(6)}px;
			height: ${adjust(22)}px;
			line-height: ${20}px;
			padding: 0 ${adjust(8)}px;
		}

		${types.map(([type, color]) => flit_1.css `
			.type-${type}{
				&:hover{
					background: ${color.mix(backgroundColor, 95)};
				}

				.stripe{
					background: ${color};
				}
			}
		`)}
		
		`;
    }
    render() {
        return flit_1.repeat(this.items, (item) => flit_1.html `<div class="item"
				:class="type-${item.type}"
				@mouseenter=${() => this.onMouseEnter(item)}
				@mouseleave=${() => this.onMouseLeave(item)}
			>
				<div class="stripe" />

				<div class="left">
					<f-icon class="type-icon" .type=${item.type} />
				</div>

				<div class="content">
					${item.title ? flit_1.html `<div class="title">${item.title}</div>` : ''}

					<div class="message">${item.message}</div>
					
					${item.list && item.list.length > 0 ? flit_1.html `
						<ul class="list">
							${item.list.map(text => flit_1.html `<li>${text}</li>`)}
						</ul>
					` : ''}

					${this.renderActions(item)}
				</div>

				<div class="close" @click=${() => this.onClickClose(item)}>
					<f-icon .type="close" />
				</div>
			</div>`, { transition: 'fade', enterAtStart: true, onend: this.onTransitionEnd });
    }
    renderActions(item) {
        let actions = item.actions;
        if (actions && actions.length > 0) {
            let results = actions.map(action => flit_1.html `
				<button class="action"
					?primary=${action.primary}
					@click=${() => this.onClickActionButton(action, item)}>
					${action.text}
				</button>
			`);
            return flit_1.html `<div class="actions">${results}</div>`;
        }
        return '';
    }
    async onClickActionButton(action, item) {
        if (action.handler) {
            action.handler();
        }
        this.hide(item.id);
    }
    onMouseEnter(item) {
        item.entered = true;
    }
    onMouseLeave(item) {
        item.entered = false;
        if (!item.timeout) {
            this.hideLater(item);
        }
    }
    onClickClose(item) {
        this.hide(item.id);
    }
    onTransitionEnd(type) {
        if (type === 'leave' && this.items.length === 0) {
            this.el.remove();
        }
    }
    show(options) {
        if (options.id) {
            let item = this.items.find(v => v.id === options.id);
            if (item) {
                delete item.hideDelay;
                Object.assign(item, options);
                this.hideLater(item);
                return options.id;
            }
        }
        let item = Object.assign({
            id: this.seed++,
            entered: false,
            timeout: null
        }, options);
        this.items.unshift(item);
        this.hideLater(item);
        if (this.items.length === 1) {
            document.body.append(this.el);
        }
        return item.id;
    }
    hideLater(item) {
        if (item.timeout) {
            item.timeout.cancel();
        }
        item.timeout = ff_1.timeout(() => {
            item.timeout = null;
            if (!item.entered) {
                this.hide(item.id);
            }
        }, item.hideDelay || this.hideDelay);
    }
    hide(id) {
        let item = this.items.find(v => v.id === id);
        if (item) {
            ff_1.remove(this.items, item);
            return true;
        }
        else {
            return false;
        }
    }
    hideAll() {
        this.items = [];
        if (this.items.length === 0) {
            this.el.remove();
        }
    }
};
Notification = __decorate([
    flit_1.define('f-notification')
], Notification);
exports.Notification = Notification;
class QuickNotification {
    constructor() {
        this.noti = null;
    }
    unique() {
        return new UniqueNotification(this);
    }
    showNotification(options) {
        if (!this.noti) {
            this.noti = flit_1.renderComponent(flit_1.html `<f-notification />`).component;
        }
        return this.noti.show(options);
    }
    info(message, options = {}) {
        options.type = 'info';
        options.message = message;
        return this.showNotification(options);
    }
    warn(message, options = {}) {
        options.type = 'warning';
        options.message = message;
        return this.showNotification(options);
    }
    error(message, options = {}) {
        options.type = 'error';
        options.message = message;
        return this.showNotification(options);
    }
    success(message, options = {}) {
        options.type = 'success';
        options.message = message;
        return this.showNotification(options);
    }
    hide(id) {
        return this.noti.hide(id);
    }
    hideAll() {
        return this.noti.hideAll();
    }
}
exports.QuickNotification = QuickNotification;
class UniqueNotification {
    constructor(raw) {
        this.id = null;
        this.raw = raw;
    }
    overwriteNotificationId(options) {
        if (this.id) {
            options.id = this.id;
        }
    }
    info(message, options = {}) {
        this.overwriteNotificationId(options);
        return this.id = this.raw.info(message, options);
    }
    warn(message, options = {}) {
        this.overwriteNotificationId(options);
        return this.id = this.raw.warn(message, options);
    }
    error(message, options = {}) {
        this.overwriteNotificationId(options);
        return this.id = this.raw.error(message, options);
    }
    success(message, options = {}) {
        this.overwriteNotificationId(options);
        return this.id = this.raw.success(message, options);
    }
    hide() {
        if (this.id) {
            return this.raw.hide(this.id);
        }
        else {
            return false;
        }
    }
}
exports.UniqueNotification = UniqueNotification;
exports.notification = new QuickNotification();


/***/ }),

/***/ "./node_modules/@pucelle/flit-ui/out/components/popover.js":
/*!*****************************************************************!*\
  !*** ./node_modules/@pucelle/flit-ui/out/components/popover.js ***!
  \*****************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Popover = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const theme_1 = __webpack_require__(/*! ../style/theme */ "./node_modules/@pucelle/flit-ui/out/style/theme.js");
const popup_1 = __webpack_require__(/*! ./popup */ "./node_modules/@pucelle/flit-ui/out/components/popup.js");
// Compare to `<popup>`, it can set title and actions.
let Popover = class Popover extends popup_1.Popup {
    constructor() {
        super(...arguments);
        this.title = '';
        this.closable = false;
        this.defaultPopupOptions = {
            // `trigger` not work here because when handle it, current component is not created.
            alignPosition: 'bc',
            fixTriangle: true,
        };
    }
    static style() {
        let { adjust, adjustFontSize, textColor } = theme_1.theme;
        return flit_1.css `
		:host{
			padding: ${adjust(8)}px ${adjust(16)}px;
			min-width: ${adjust(240)}px;
			max-width: ${adjust(400)}px;
		}

		.triangle{
			left: ${adjust(12)}px;
		}

		.header{
			display: flex;
			line-height: ${adjust(22)}px;
			height: ${adjust(28) + 1}px;
			font-size: ${adjustFontSize(13)}px;
			padding-bottom: ${adjust(6)}px;
			border-bottom: 1px solid ${textColor.alpha(0.8)};
			margin-bottom: ${adjust(8)}px;
		}

		.title{
			flex: 1;
			min-width: 0;
			font-weight: bold;
			overflow: hidden;
			white-space: nowrap;
			text-overflow: ellipsis;
		}

		.close{
			display: flex;
			width: ${adjust(28)}px;
			height: ${adjust(28)}px;
			margin-top: ${adjust(-6)}px;
			margin-right: ${adjust(-9)}px;
			cursor: pointer;

			&:active{
				transform: translateY(1px);
			}

			f-icon{
				margin: auto;
			}
		}

		.actions{
			margin-left: ${adjust(15)}px;

			button{
				margin-left: ${adjust(6)}px;
				height: ${adjust(22)}px;
				line-height: ${20}px;
				padding: 0 ${adjust(8)}px;
			}
		}

		.content{}
		`.extends(super.style());
    }
    render() {
        return flit_1.html `
		<f-popup>	
			${this.renderHead()}
			<div class="content"><slot /></div>
		</f-popup>
		`.extends(super.render());
    }
    renderHead() {
        if (this.title) {
            let shouldRenderClose = this.closable && !this.slots.action;
            return flit_1.html `
			<div class="header">
				<div class="title">${this.title}</div>

				<div class="actions" :show=${this.slots.action}>
					<slot name="action" />
				</div>

				${shouldRenderClose ? flit_1.html `
					<div class="close" @click=${this.close}>
						<f-icon .type="close" />
					</div>
				` : ''}
			</div>
			`;
        }
        return '';
    }
};
Popover = __decorate([
    flit_1.define('f-popover')
], Popover);
exports.Popover = Popover;


/***/ }),

/***/ "./node_modules/@pucelle/flit-ui/out/components/popup.js":
/*!***************************************************************!*\
  !*** ./node_modules/@pucelle/flit-ui/out/components/popup.js ***!
  \***************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Popup = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const theme_1 = __webpack_require__(/*! ../style/theme */ "./node_modules/@pucelle/flit-ui/out/style/theme.js");
/**It's the base class for all the popup which will align with another element. */
let Popup = class Popup extends flit_1.Component {
    constructor() {
        super(...arguments);
        this.herizontal = false;
        this.triangle = true;
        /**
         * The selector to get HTML element to append to or the HTML element.
         * Note that don't specify this value to `document.body`, it may not prepared when class initialize.
         */
        this.appendTo = 'body';
        /**
         * Used for sub classes to specify default popup options,
         * Such that no need to specify them each time in the `popup()`.
         * Will be overwrite by options in `popup()`.
         */
        this.defaultPopupOptions = null;
        this.binding = null;
    }
    static style() {
        let { popupBorderRadius, popupBackgroundColor, popupShadowBlurRadius, popupShadowColor, adjust } = theme_1.theme;
        let w = adjust(10);
        let h = adjust(7);
        let x = adjust(11);
        return flit_1.css `
		:host{
			position: absolute;
			left: 0;
			top: 0;
			z-index: 1000;	// Same with window, so if in window, we must move it behind the window
			background: ${popupBackgroundColor};
			border-radius: ${popupBorderRadius}px;
			filter: drop-shadow(0 0 ${popupShadowBlurRadius / 2}px ${popupShadowColor});	// 3px nearly equals 6px in box-shadow.
		}

		.triangle{
			// Must be the styles in top position
			position: absolute;
			border-left: ${w / 2}px solid transparent;
			border-right: ${w / 2}px solid transparent;
			border-bottom: ${h}px solid ${popupBackgroundColor};
			top: -${h}px;
			left: ${x}px;	// 11 + 5 = 16

			&-herizontal{
				border-top: ${w / 2}px solid transparent;
				border-bottom: ${w / 2}px solid transparent;
				border-right: ${h}px solid ${popupBackgroundColor};
				border-left: 0;
				top: ${x}px;
				left: -${h}px;
			}
		}
		`;
    }
    render() {
        return flit_1.html `
		<template tabindex="0">
			${this.triangle ? flit_1.html `
				<div class="triangle" :ref="triangle" :class.triangle-herizontal=${this.herizontal} />
			` : ''}
			<slot />
		</template>
		`;
    }
    // Call `update` every time after restored from `cache(...)`.
    onConnected() {
        // Why render `<popup>` to body?
        // It's very common that the `el` is covered or clipped,
        // which will cause the `<popup>` is not fully visible.
        // You can still render the `<popup>` in the same scroller with `<popup>`.
        // Why inserted into body every time?
        // Most popups share same `z-index`, append newly opened `<popup>` will makesure it covers others.
        // Note that:
        // The template `content` can't pass into `<popup>` as an argument,
        // it will cause the template was parsed in `<popup>` context.
        // The `<popup>` will be cached in `<popup>`, and element will be removed when not in use.
        // After restored from `cache`, it will be inserted back into `<popup>`.
        // So here we need to move it to `body` after every time rendered.
        // If there are serval nodes which belong to an template you need to append into another element,
        // Don't forget to move the anchor nodes, or the whole template nodes into the target element,
        // or they will can't be removed because they are outside of the template node ranges.
        // In the future, we may implement a flit directive `renderTo(..., ...)`, 
        // to render elements and it's anchor node to another element.
        this.applyAppendTo();
    }
    applyAppendTo() {
        if (this.appendTo) {
            flit_1.appendTo(this.el, this.appendTo);
        }
    }
    setPopupBinding(binding) {
        this.binding = binding;
    }
    close() {
        if (this.binding) {
            this.binding.hidePopupLater();
        }
        else {
            this.el.remove();
        }
    }
};
Popup = __decorate([
    flit_1.define('f-popup')
], Popup);
exports.Popup = Popup;


/***/ }),

/***/ "./node_modules/@pucelle/flit-ui/out/components/progress.js":
/*!******************************************************************!*\
  !*** ./node_modules/@pucelle/flit-ui/out/components/progress.js ***!
  \******************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Progress = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const theme_1 = __webpack_require__(/*! ../style/theme */ "./node_modules/@pucelle/flit-ui/out/style/theme.js");
const tooltip_1 = __webpack_require__(/*! ../bindings/tooltip */ "./node_modules/@pucelle/flit-ui/out/bindings/tooltip.js");
/** Now only a input, will extend to list suggestted local or remote data in future. */
let Progress = class Progress extends flit_1.Component {
    constructor() {
        super(...arguments);
        /** Betweens 0-1. */
        this.value = 0;
        /** Fixed decimal count of progress text. */
        this.decimalCount = 1;
    }
    static style() {
        let { mainColor, adjust } = theme_1.theme;
        return flit_1.css `
		:host{
			display: inline-block;
			vertical-align: top;
			position: relative;
			width: ${adjust(200)}px;
			height: ${adjust(28)}px;
		}

		.groove{
			position: absolute;
			left: 0;
			right: 0;
			top: 0;
			bottom: 0;
			height: 1px;
			margin: auto 0;
			background: ${mainColor.alpha(0.2)};
		}

		.progress{
			height: 100%;
			background: ${mainColor};
		}

		.tooltip{
			font-family: monospace;
		}
		`;
    }
    render() {
        let tip = tooltip_1.tooltip(this.renderTooltipValue(), {
            alignTo: () => this.refs.progress,
            alignPosition: 'bc-tr',
            alignMargin: [8, 0],
        });
        return flit_1.html `
		<template ${tip}>
			<div class="groove">
				<div class="progress" :ref="progress" :style.width.percent=${Math.min(this.value, 1) * 100}></div>
			</div>
		</template>
		`;
    }
    renderTooltipValue() {
        // 0.5123 -> 51.2%
        let tipText = (Math.min(this.value, 1) * 100).toFixed(this.decimalCount) + '%';
        return flit_1.html `<span class="${this.scopeClassName('tooltip')}">${tipText}</span>`;
    }
};
Progress = __decorate([
    flit_1.define('f-progress')
], Progress);
exports.Progress = Progress;


/***/ }),

/***/ "./node_modules/@pucelle/flit-ui/out/components/radio.js":
/*!***************************************************************!*\
  !*** ./node_modules/@pucelle/flit-ui/out/components/radio.js ***!
  \***************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.RadioGroup = exports.Radio = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const theme_1 = __webpack_require__(/*! ../style/theme */ "./node_modules/@pucelle/flit-ui/out/style/theme.js");
let Radio = class Radio extends flit_1.Component {
    constructor() {
        super(...arguments);
        this.checked = false;
        this.radioGroup = null;
        // Used to compare with `RadioGroup.value`
        this.value = null;
    }
    static style() {
        let { mainColor, adjust, focusBlurRadius } = theme_1.theme;
        return flit_1.css `
		:host{
			display: inline-flex;
			vertical-align: top;
			align-items: center;
			cursor: pointer;

			&:hover{
				color: ${mainColor};
			}

			&:focus{
				color: ${mainColor};

				.icon{
					box-shadow: 0 0 ${focusBlurRadius}px ${mainColor};
				}
			}
		}

		.icon{
			border-radius: 50%;
			margin-right: ${adjust(6)}px;
		}

		.checked{
			color: ${mainColor};
		}
	
		.label{
			flex: 1;
			white-space: nowrap;
			overflow: hidden;
			text-overflow: ellipsis;
		}
		`;
    }
    render() {
        return flit_1.html `
			<template
				tabindex="0"
				:class.checked=${this.checked}
				@@click=${this.onClick}
				@@focus=${this.onFocus}
			>
				<f-icon class="icon" .type=${this.checked ? 'radio-checked' : 'radio-unchecked'} />
				<div class="label">
					<slot />
				</div>
			</template>
		`;
    }
    onCreated() {
        let group = flit_1.getClosestComponent(this.el, RadioGroup);
        if (group) {
            this.radioGroup = group;
            this.checked = this.radioGroup.value == this.value;
            this.radioGroup.register(this);
        }
    }
    onClick() {
        if (!this.checked) {
            this.checked = true;
            this.emit('change', true);
        }
    }
    onFocus() {
        if (!this.checked) {
            flit_1.once(this.el, 'blur', this.onBlur, this);
            flit_1.once(document, 'keydown.enter', this.onEnter, this);
        }
    }
    onBlur() {
        flit_1.off(document, 'keydown', this.onEnter, this);
    }
    onEnter() {
        this.onClick();
    }
};
Radio = __decorate([
    flit_1.define('f-radio')
], Radio);
exports.Radio = Radio;
// Not `radio-group` because we want to correspond with `radiogroup` with `https://www.w3.org/TR/wai-aria-practices-1.2/`.
let RadioGroup = class RadioGroup extends flit_1.Component {
    constructor() {
        super(...arguments);
        this.value = null;
        this.radios = [];
    }
    register(radio) {
        this.radios.push(radio);
        radio.on('change', this.onRadioChange.bind(this, radio));
    }
    onRadioChange(changedRadio) {
        for (let radio of this.radios) {
            if (radio !== changedRadio) {
                radio.checked = false;
            }
        }
        this.value = changedRadio.value;
        this.emit('change', this.value);
    }
};
RadioGroup = __decorate([
    flit_1.define('f-radiogroup')
], RadioGroup);
exports.RadioGroup = RadioGroup;


/***/ }),

/***/ "./node_modules/@pucelle/flit-ui/out/components/resizer.js":
/*!*****************************************************************!*\
  !*** ./node_modules/@pucelle/flit-ui/out/components/resizer.js ***!
  \*****************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Resizer = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
/** Resizer can only adjust in one direction, will extend if needed. */
let Resizer = class Resizer extends flit_1.Component {
    constructor() {
        super(...arguments);
        this.position = 'right';
        this.rate = 1; // You may set this to `2` if element aligns to center .
        this.max = Infinity;
        this.min = 0;
        this.resizedValue = -1;
    }
    static style() {
        return flit_1.css `
		:host{
			position: absolute;
			z-index: 100;
		}

		.top{
			width: 100%;
			height: 10px;
			top: -5px;
			left: 0;
			cursor: ns-resize;
		}

		.bottom{
			width: 100%;
			height: 10px;
			bottom: -5px;
			left: 0;
			cursor: ns-resize;
		}

		.left{
			width: 10px;
			height: 100%;
			top: 0;
			left: -5px;
			cursor: ew-resize;
		}

		.right{
			width: 10px;
			height: 100%;
			top: 0;
			right: -5px;
			cursor: ew-resize;
		}

		.resizing-mask{
			position: fixed;
			z-index: 9999;
			left: 0;
			right: 0;
			top: 0;
			bottom: 0;

			&.herizontal{
				cursor: ew-resize;
			}

			&.vertical{
				cursor: ns-resize;
			}
		}
		`;
    }
    render() {
        return flit_1.html `
		<template
			:class=${this.position}
			@@mousedown=${this.onStartResize}
		/>
		`;
    }
    onReady() {
        if (ff_1.getStyle(this.el.parentElement, 'position') === 'static') {
            throw new Error('Parent of "<f-resizer>" must can\'t have an "static" position');
        }
    }
    onStartResize(e) {
        let startX = e.clientX;
        let startY = e.clientY;
        let startParentWidth = this.el.parentElement.offsetWidth;
        let startParentHeight = this.el.parentElement.offsetHeight;
        let onMouseMove = (e) => {
            e.preventDefault();
            this.resize(startParentWidth, startParentHeight, e.clientX - startX, e.clientY - startY);
        };
        let onMouseUp = () => {
            flit_1.off(document, 'mousemove', onMouseMove);
            cursorMask.remove();
            this.emit('change', this.resizedValue);
        };
        let cursorMask = flit_1.render(flit_1.html `
			<div class="resizing-mask" class="${this.position === 'left' || this.position === 'right' ? 'herizontal' : 'vertical'}"
		/>`, this).fragment.firstElementChild;
        document.body.append(cursorMask);
        flit_1.on(document, 'mousemove', onMouseMove);
        flit_1.once(document, 'mouseup', onMouseUp);
    }
    resize(startParentWidth, startParentHeight, movementX, movementY) {
        let value;
        if (this.position === 'top' || this.position === 'bottom') {
            let flag = this.position === 'bottom' ? 1 : -1;
            value = startParentHeight + flag * movementY * this.rate;
            value = ff_1.constrain(value, this.min, this.max);
            this.el.parentElement.style.height = value + 'px';
        }
        else {
            let flag = this.position === 'right' ? 1 : -1;
            value = startParentWidth + flag * movementX * this.rate;
            value = ff_1.constrain(value, this.min, this.max);
            this.el.parentElement.style.width = value + 'px';
        }
        this.resizedValue = value;
    }
};
Resizer = __decorate([
    flit_1.define('f-resizer')
], Resizer);
exports.Resizer = Resizer;


/***/ }),

/***/ "./node_modules/@pucelle/flit-ui/out/components/router.js":
/*!****************************************************************!*\
  !*** ./node_modules/@pucelle/flit-ui/out/components/router.js ***!
  \****************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Router = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
let Router = class Router extends flit_1.Component {
    constructor() {
        super(...arguments);
        this.prefix = '';
        this.path = '';
    }
    onCreated() {
        this.path = this.getPathFromUri(location.href);
        flit_1.on(window, 'popstate', this.onStateChange, this);
    }
    getPathFromUri(uri) {
        let path = new URL(uri).pathname;
        if (this.prefix && path.startsWith(this.prefix)) {
            path = path.slice(this.prefix.length);
        }
        if (!path) {
            path = '/';
        }
        return path;
    }
    onDisconnected() {
        flit_1.off(window, 'popstate', this.onStateChange, this);
    }
    onStateChange(e) {
        if (e.state) {
            this.redirectTo(e.state.path);
        }
    }
    route(routePath, renderFn, options = {}) {
        if (this.isMatch(routePath)) {
            if (options.title) {
                document.title = options.title;
            }
            let params = this.match(routePath);
            let match = {
                params: params ? params.params : {},
                captures: params ? params.captures : []
            };
            return renderFn(match);
        }
        else {
            return '';
        }
    }
    isMatch(routePath) {
        return PathParser.isMatch(this.path, routePath);
    }
    match(routePath) {
        return PathParser.matchPath(this.path, routePath);
    }
    goto(path) {
        this.path = path;
        let uri = this.getURIFromPath(path);
        history.pushState({ path }, '', uri);
    }
    redirectTo(path) {
        this.path = path;
        let uri = this.getURIFromPath(path);
        history.replaceState({ path }, '', uri);
    }
    getURIFromPath(path) {
        if (!path) {
            path = '/';
        }
        if (this.prefix) {
            path = this.prefix + path;
        }
        return path;
    }
};
Router = __decorate([
    flit_1.define('f-router')
], Router);
exports.Router = Router;
var PathParser;
(function (PathParser) {
    const pathParsedResultMap = new Map();
    function isMatch(path, routePath) {
        let re;
        if (typeof routePath === 'string') {
            re = ensureParsedResult(routePath).re;
        }
        else {
            re = routePath;
        }
        return re.test(path);
    }
    PathParser.isMatch = isMatch;
    function ensureParsedResult(routePath) {
        if (pathParsedResultMap.has(routePath)) {
            return pathParsedResultMap.get(routePath);
        }
        else {
            return parsePath(routePath);
        }
    }
    function matchPath(path, routePath) {
        let params = {};
        let captures = [];
        if (typeof routePath === 'string') {
            let { re, keys } = ensureParsedResult(routePath);
            let m = path.match(re);
            if (!m) {
                return null;
            }
            if (keys) {
                for (let i = 0; i < keys.length; i++) {
                    let key = keys[i];
                    params[key] = m[i + 1];
                }
            }
        }
        else {
            let m = path.match(routePath);
            if (!m) {
                return null;
            }
            captures = [...m];
        }
        return {
            params,
            captures
        };
    }
    PathParser.matchPath = matchPath;
    function parsePath(routePath) {
        let keys = [];
        let re = new RegExp(routePath
            .replace(/\./g, '\\.')
            .replace(/\*/g, '.*?')
            .replace(/(\/?):(\w+)/g, function (_m0, slash, property) {
            if (property) {
                keys.push(property);
            }
            return slash + '?([\\w-]*?)';
        })
            .replace(/^/, '^')
            .replace(/$/, '$'), 'i');
        let parsed = { re, keys };
        pathParsedResultMap.set(routePath, parsed);
        return parsed;
    }
})(PathParser || (PathParser = {}));


/***/ }),

/***/ "./node_modules/@pucelle/flit-ui/out/components/search.js":
/*!****************************************************************!*\
  !*** ./node_modules/@pucelle/flit-ui/out/components/search.js ***!
  \****************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Search = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const theme_1 = __webpack_require__(/*! ../style/theme */ "./node_modules/@pucelle/flit-ui/out/style/theme.js");
/** Now only a input, will extend to list suggestted local or remote data in future. */
let Search = class Search extends flit_1.Component {
    constructor() {
        super(...arguments);
        this.placeholder = '';
        this.value = '';
        this.focused = false;
    }
    static style() {
        let { adjust, borderColor, borderRadius, mainColor, focusBlurRadius } = theme_1.theme;
        return flit_1.css `
		:host{
			display: inline-block;
			vertical-align: top;
			position: relative;
		}

		input{
			width: 100%;
			border: none;
			background: none;
			height: ${adjust(28)}px;
			padding: 0 ${adjust(26)}px 0 ${adjust(26)}px;
			border: 1px solid ${borderColor};
			border-radius: ${borderRadius}px;
			
			&:focus{
				border-color: ${mainColor};
				box-shadow: 0 0 ${focusBlurRadius}px ${mainColor.alpha(0.5)};
			}
		}

		.search-icon{
			position: absolute;
			top: 0;
			bottom: 0;
			left: 8px;
			color: ${borderColor.toMiddle(10)};
		}

		.clear{
			display: flex;
			position: absolute;
			width: ${adjust(28)}px;
			top: 0;
			bottom: 0;
			right: 0px;
			color: ${borderColor.toMiddle(10)};
			cursor: pointer;

			&:hover{
				color: ${mainColor};
			}

			&:active{
				transform: translateY(1px);
			}
		}

		.close-icon{
			margin: auto;
		}
		`;
    }
    render() {
        return flit_1.html `
			<f-icon class="search-icon" .type="search" />

			<input type="text"
				placeholder=${this.placeholder}
				.value=${this.value}
				:ref="input"
				@focus=${this.onFocus}
				@change=${(e) => this.onChange(e)}
			/>

			${this.value && !this.focused ? flit_1.html `
			<div class="clear" @click=${this.clear}>
				<f-icon class="close-icon" .type="close" />
			</div>` : ''}
		`;
    }
    onFocus() {
        this.focused = true;
        flit_1.once(this.refs.input, 'blur', () => this.focused = false);
    }
    onChange(e) {
        let input = e.target;
        let value = this.value = input.value;
        this.emit('change', value);
    }
    clear() {
        this.value = '';
        this.emit('change', '');
    }
};
Search = __decorate([
    flit_1.define('f-search')
], Search);
exports.Search = Search;


/***/ }),

/***/ "./node_modules/@pucelle/flit-ui/out/components/select.js":
/*!****************************************************************!*\
  !*** ./node_modules/@pucelle/flit-ui/out/components/select.js ***!
  \****************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Select = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const theme_1 = __webpack_require__(/*! ../style/theme */ "./node_modules/@pucelle/flit-ui/out/style/theme.js");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
const dropdown_1 = __webpack_require__(/*! ./dropdown */ "./node_modules/@pucelle/flit-ui/out/components/dropdown.js");
let Select = class Select extends dropdown_1.Dropdown {
    constructor() {
        super(...arguments);
        this.trigger = 'click';
        this.triangle = false;
        this.alignMargin = 0;
        this.data = [];
        this.value = null;
        this.multiple = false;
        this.searchable = false;
        this.ordered = false;
        this.placeholder = '';
        this.inputed = '';
        this.editing = false;
    }
    static style() {
        let { mainColor, adjust, borderColor, popupShadowBlurRadius, backgroundColor, popupShadowColor } = theme_1.theme;
        return flit_1.css `
		:host{
			display: inline-flex;
			vertical-align: top;
			width: ${adjust(200)}px;
			height: ${adjust(28)}px;
			background: ${backgroundColor.toMiddle(5)};
			line-height: ${adjust(28)}px;
			justify-content: space-between;
			align-items: center;
			cursor: pointer;
			box-shadow: inset 0 -1px 0 0 ${borderColor};

			&:hover, &.opened{
				box-shadow: inset 0 -1px 0 0 ${mainColor};

				.icon{
					color: ${mainColor};
				}
			}

			&.not-inputable input{
				cursor: pointer;
			}
		}

		.down-icon{
			margin-left: auto;
			margin-right: 4px;
		}
	
		.display, .input{
			flex: 1;
			min-width: 0;
			padding: 0 0 0 ${adjust(8)}px;
			height: 100%;
			border: none;
			background: transparent;
			white-space: nowrap;
			overflow: hidden;
			text-overflow: ellipsis;
			box-shadow: none;

			&:focus{
				box-shadow: none;
			}
		}

		.placeholder{
			opacity: 0.5;
		}
	
		.popup{
			padding: 0;
			border-radius: 0;
			filter: none;
			box-shadow: 0 1px ${popupShadowBlurRadius}px ${popupShadowColor};
		}

		.list{
			border-bottom: none;

			.option__f-list{
				padding-left: ${adjust(8)}px;
				border-top: none;
			}
		}

		.selected-icon{
			margin-right: -4px;
		}
		`.extends(super.style());
    }
    render() {
        return flit_1.html `
		<template :class.not-inputable=${!this.searchable}>
			${this.renderDisplayOrInput()}
		</template>
		`.extends(super.render());
    }
    renderDisplayOrInput() {
        if (this.editing) {
            return flit_1.html `
			<input type="text"
				class="input"
				:ref="input"
				.value=${this.inputed}
				.placeholder=${this.placeholder}
				?readonly=${!this.editing}
				@click=${this.onClick}
				@input=${this.onInput}
			>
			`;
        }
        else {
            let text = this.renderCurrentDisplay();
            return flit_1.html `
			<div
				class="input"
				:class.placeholder=${!text}
				@click=${this.onClick}
			>
				${text || this.placeholder}
			</div>
			`;
        }
    }
    renderPopup() {
        let data = this.getOptionData();
        return flit_1.html `
		<f-popup
			class="popup"
			:ref="popup"
			.triangle="false"
		>
			<f-list class="list"
				:ref="list"
				.type="selection"
				.selectable
				.data=${data}
				.multipleSelect=${this.multiple}
				.selected=${this.multiple ? this.value : [this.value]}
				@select=${this.select}
			/>
		</f-popup>
		`;
    }
    renderCurrentDisplay() {
        if (this.multiple) {
            let displays = [];
            for (let { value, text } of this.data) {
                if (this.value.includes(value)) {
                    // Here may render `<>` tags as value into `input` element
                    displays.push(text.toString());
                }
            }
            return displays.join('; ');
        }
        else {
            for (let { value, text } of this.data) {
                if (this.value === value) {
                    return text;
                }
            }
            return '';
        }
    }
    getOptionData() {
        if (this.searchable && this.inputed) {
            let lowerSearchWord = this.inputed.toLowerCase();
            let filteredData = [];
            for (let item of this.data) {
                if (String(item.value).includes(lowerSearchWord)) {
                    filteredData.push(item);
                }
            }
            return filteredData;
        }
        else {
            return this.data;
        }
    }
    onCreated() {
        this.initValue();
        this.initEditing();
    }
    initValue() {
        if (this.multiple && !Array.isArray(this.value)) {
            this.value = [];
        }
    }
    initEditing() {
        if (this.searchable) {
            this.watch(() => this.opened, (opened) => {
                if (!opened && this.editing) {
                    this.endEditing();
                }
            });
        }
    }
    onClick() {
        if (this.searchable && !this.editing) {
            this.startEditing();
        }
    }
    select(values) {
        if (this.multiple) {
            this.value = values;
        }
        else {
            this.value = values[0];
            this.hidePopup();
        }
        this.emit('change', this.value);
    }
    async startEditing() {
        this.editing = true;
        this.inputed = '';
        await flit_1.renderComplete();
        this.refs.input.focus();
    }
    endEditing() {
        this.editing = false;
    }
    async onPopupOpened() {
        await flit_1.renderComplete();
        if (this.editing && this.refs.input) {
            this.refs.input.focus();
        }
        // We should not ref popup el by `:ref`, or it will can't be released.
        if (this.popupBinding && this.popupBinding.popup) {
            let popupEl = this.popupBinding.popup.el;
            popupEl.style.minWidth = String(this.el.offsetWidth) + 'px';
            await flit_1.renderComplete();
            let el = popupEl.querySelector('.selected__f-list');
            if (el && ff_1.getScrollDirection(this.refs.list) === 'y') {
                ff_1.scrollToTop(el);
            }
        }
    }
    onInput() {
        this.inputed = this.refs.input.value;
        this.showPopup();
    }
};
Select = __decorate([
    flit_1.define('f-select')
], Select);
exports.Select = Select;


/***/ }),

/***/ "./node_modules/@pucelle/flit-ui/out/components/slider.js":
/*!****************************************************************!*\
  !*** ./node_modules/@pucelle/flit-ui/out/components/slider.js ***!
  \****************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Slider = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const theme_1 = __webpack_require__(/*! ../style/theme */ "./node_modules/@pucelle/flit-ui/out/style/theme.js");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
const tooltip_1 = __webpack_require__(/*! ../bindings/tooltip */ "./node_modules/@pucelle/flit-ui/out/bindings/tooltip.js");
let Slider = class Slider extends flit_1.Component {
    constructor() {
        super(...arguments);
        this.vertical = false;
        this.min = 0;
        this.max = 100;
        this.step = 1;
        this.value = 0;
        /** Fixed decimal count of progress text. */
        this.decimalCount = null;
        this.draging = false;
    }
    static style() {
        let { mainColor, borderColor, adjust, adjustFontSize, focusBlurRadius, backgroundColor } = theme_1.theme;
        let grooveSize = 1;
        let ballSize = Math.ceil(adjust(7)) * 2 + grooveSize;
        return flit_1.css `
		:host{
			display: inline-flex;
			vertical-align: top;
			flex-direction: column;
			justify-content: center;
			position: relative;
			width: ${adjust(150)}px;
			height: ${adjust(28)}px;
			font-size: ${adjustFontSize(13)}px;
			cursor: pointer;

			&:focus .ball{
				box-shadow: 0 0 ${focusBlurRadius}px ${mainColor};
				border-color: ${mainColor};
			}
		}

		.groove{
			position: relative;
			height: ${grooveSize}px;
		}

		.groove-bg{
			position: absolute;
			left: 0;
			top: 0;
			width: 100%;
			height: 100%;
			background: ${borderColor};
		}
	
		.progress{
			position: relative;
			background: ${mainColor};
			height: 100%;
		}
	
		.ball{
			position: absolute;
			top: -${(ballSize - grooveSize) / 2}px;
			right: -${Math.round(ballSize / 2)}px;
			will-change: top right;
			border-radius: 50%;
			border: 1px solid ${borderColor};
			background: ${backgroundColor};
			float: right;
			width: ${ballSize}px;
			height: ${ballSize}px;

			&:hover{
				border-color: ${mainColor};
			}
		}

		.dragging{
			.ball{
				border-color: ${mainColor.darken(10)};
				background: ${mainColor.darken(10)};
			}
		}

		:host[vertical]{
			width: ${adjust(30)}px;
			height: ${adjust(150)}px;
			flex-direction: row;

			.groove{
				width: ${grooveSize}px;
				height: 100%;
			}

			.progress{
				position: absolute;
				bottom: 0;
				width: 100%;
				height: 0;
			}

			.ball{
				margin: -${Math.round(ballSize / 2)}px -${(ballSize - grooveSize) / 2}px;
			}
		}

		.tooltip{
			font-family: monospace;
		}
		`;
    }
    render() {
        let tip = tooltip_1.tooltip(this.renderTooltipValue(), {
            alignTo: () => this.refs.ball,
            alignPosition: this.vertical ? 'r' : 't'
        });
        return flit_1.html `
		<template
			tabindex="0"
			:class.dragging=${this.draging}
			${tip}
			@@mousedown=${this.onMouseDown}
			@@focus=${this.onFocus}
			@@blur=${this.onBlur}
		>
			<div class="groove" :ref="groove">
				<div class="groove-bg" />
				<div class="progress"
					:style.width.percent=${this.vertical ? '' : this.getPercent()}
					:style.height.percent=${this.vertical ? this.getPercent() : ''}
				>
					<div class="ball" :ref="ball" />
				</div>
			</div>
		</template>
		`;
    }
    renderTooltipValue() {
        let decimalCount = this.decimalCount;
        if (decimalCount === null) {
            decimalCount = String(this.step).replace(/^\d+\.?/, '').length;
        }
        let tipText = this.value.toFixed(decimalCount);
        return flit_1.html `<span class="${this.scopeClassName('tooltip')}">${tipText}</span>`;
    }
    getPercent() {
        if (this.value === this.min) {
            return 0;
        }
        let percentage = (this.value - this.min) / (this.max - this.min) * 100;
        return ff_1.constrain(percentage, 0, 100);
    }
    onMouseDown(e) {
        let rect = ff_1.getRect(this.refs.groove);
        let unkeep = ff_1.MouseLeave.keep(this.el);
        this.draging = true;
        // If clicked the ball, not move; only move when clicked the groove.
        if (!e.target.matches(this.scopeClassName('.ball'))) {
            this.changeValueByEvent(e, rect);
        }
        let onMouseMove = (e) => {
            // Disable selecting text unexpectedly, and makesure ball not lose focus.
            e.preventDefault();
            this.changeValueByEvent(e, rect);
        };
        flit_1.on(document, 'mousemove', onMouseMove);
        flit_1.once(document, 'mouseup', () => {
            flit_1.off(document, 'mousemove', onMouseMove);
            unkeep();
            this.draging = false;
            this.emit('dragend');
        });
        this.emit('dragstart');
    }
    changeValueByEvent(e, rect) {
        let rate;
        if (this.vertical) {
            rate = ff_1.constrain(1 - (e.clientY - rect.top) / rect.height, 0, 1);
        }
        else {
            rate = ff_1.constrain((e.clientX - rect.left) / rect.width, 0, 1);
        }
        let diff = (this.max - this.min) * rate;
        if (this.step) {
            diff = Math.round(diff / this.step) * this.step;
        }
        let oldValue = this.value;
        let newValue = ff_1.toDecimal(this.min + diff, 4);
        if (newValue !== oldValue) {
            this.emit('change', this.value = newValue);
        }
    }
    onWheel(e) {
        if (!this.step || document.activeElement !== this.el) {
            return;
        }
        let newValue;
        // deltaY < 0 when wheel up
        if (e.deltaY < 0 && this.vertical || e.deltaY > 0 && !this.vertical) {
            newValue = ff_1.toDecimal(Math.min(this.value + this.step, this.max), 4);
        }
        else {
            newValue = ff_1.toDecimal(Math.max(this.value - this.step, this.min), 4);
        }
        if (newValue !== this.value) {
            this.emit('change', this.value = newValue);
        }
    }
    onFocus() {
        this.onBlur();
        flit_1.on(document, 'keydown', this.onKeyDown, this);
        flit_1.on(document, 'wheel.prevent', this.onWheel, this);
    }
    onKeyDown(e) {
        let newValue;
        if (this.vertical) {
            if (e.key === 'ArrowUp') {
                e.preventDefault();
                newValue = Math.min(this.value + this.step, this.max);
            }
            else if (e.key === 'ArrowDown') {
                e.preventDefault();
                newValue = Math.max(this.value - this.step, this.min);
            }
        }
        else {
            if (e.key === 'ArrowLeft') {
                e.preventDefault();
                newValue = Math.max(this.value - this.step, this.min);
            }
            else if (e.key === 'ArrowRight') {
                e.preventDefault();
                newValue = Math.min(this.value + this.step, this.max);
            }
        }
        if (newValue !== undefined && newValue !== this.value) {
            this.emit('change', this.value = newValue);
        }
    }
    onBlur() {
        flit_1.off(document, 'keydown', this.onKeyDown, this);
        flit_1.off(document, 'wheel', this.onWheel, this);
    }
};
Slider = __decorate([
    flit_1.define('f-slider')
], Slider);
exports.Slider = Slider;


/***/ }),

/***/ "./node_modules/@pucelle/flit-ui/out/components/switch.js":
/*!****************************************************************!*\
  !*** ./node_modules/@pucelle/flit-ui/out/components/switch.js ***!
  \****************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Switch = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const theme_1 = __webpack_require__(/*! ../style/theme */ "./node_modules/@pucelle/flit-ui/out/style/theme.js");
let Switch = class Switch extends flit_1.Component {
    constructor() {
        super(...arguments);
        this.checked = false;
    }
    static style() {
        let { mainColor, adjust, focusBlurRadius, backgroundColor } = theme_1.theme;
        let h = adjust(18);
        let w = h * 2 - 8;
        return flit_1.css `
		:host{
			display: inline-block;
			vertical-align: top;
			width: ${w}px;
			height: ${h}px;
			background: ${backgroundColor.toMiddle(23.3)};
			border-radius: ${h / 2}px;
			padding: 1px;
			margin: ${(adjust(28) - h) / 2}px 0;
			transition: background-color 0.2s ${flit_1.getEasing('ease-out-cubic')};
			cursor: pointer;

			&:hover{
				background: ${backgroundColor.toMiddle(33)};
			}
			
			&:focus{
				box-shadow: 0 0 ${focusBlurRadius}px ${mainColor};
			}
		}
	
		.ball{
			width: ${h - 2}px;
			height: ${h - 2}px;
			background: ${backgroundColor};
			border-radius: 50%;
			transition: margin 0.2s ${flit_1.getEasing('ease-out-cubic')};
		}
	
		.on{		
			background: ${mainColor};

			.ball{
				border-color: ${backgroundColor};
				margin-left: calc(100% - ${h - 2}px);
			}

			&:hover{
				background: ${mainColor.darken(10)};
			}
		}
		`;
    }
    render() {
        return flit_1.html `
		<template
			tabindex="0"
			:class.on=${this.checked}
			@@click=${this.onClick}
			@@focus=${this.onFocus}
			@@blur=${this.onBlur}
		>
			<div class="ball"></div>
		</template>
		`;
    }
    onClick() {
        this.checked = !this.checked;
        this.emit('change', this.checked);
    }
    onFocus() {
        flit_1.on(document, 'keydown', this.onKeyDown, this);
    }
    onKeyDown(e) {
        if (e.key === 'Enter') {
            e.preventDefault();
            this.onClick();
        }
        else if (e.key === 'ArrowLeft') {
            if (this.checked) {
                e.preventDefault();
                this.onClick();
            }
        }
        else if (e.key === 'ArrowRight') {
            if (!this.checked) {
                e.preventDefault();
                this.onClick();
            }
        }
    }
    onBlur() {
        flit_1.off(document, 'keydown', this.onKeyDown, this);
    }
};
Switch = __decorate([
    flit_1.define('f-switch')
], Switch);
exports.Switch = Switch;


/***/ }),

/***/ "./node_modules/@pucelle/flit-ui/out/components/table.js":
/*!***************************************************************!*\
  !*** ./node_modules/@pucelle/flit-ui/out/components/table.js ***!
  \***************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Table = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const theme_1 = __webpack_require__(/*! ../style/theme */ "./node_modules/@pucelle/flit-ui/out/style/theme.js");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
const async_store_1 = __webpack_require__(/*! ../store/async-store */ "./node_modules/@pucelle/flit-ui/out/store/async-store.js");
let Table = class Table extends flit_1.Component {
    constructor() {
        super(...arguments);
        /** If `true`, will only render the rows that in viewport. */
        this.live = false;
        /**
         * Works only when `live` is `true`
         * You can understand this as how many items to render.
         */
        this.pageSize = 50;
        /** The index of the first item to be visible, to reflect last scrolling position. */
        this.startIndex = 0;
        /** If what you rendered is very complex and can't complete in an animation frame, set this to true. */
        this.preRendering = false;
        this.resizable = false;
        this.minColumnWidth = 64;
        this.orderColumnName = null;
        this.orderDirection = '';
        this.columnWidths = null;
        this.resizingColumnWidths = null;
        this.columnResized = false;
        this.cachedTotalWidth = 0;
        this.repeatDir = null;
    }
    static style() {
        let { adjustFontSize, adjust, mainColor, textColor, backgroundColor } = theme_1.theme;
        let scrollbarWidth = ff_1.getScrollbarWidth();
        return flit_1.css `
		:host{
			display: flex;
			flex-direction: column;
			height: 200px;
		}

		.head{
			padding-right: ${scrollbarWidth}px;	// Same with defined scrollbar width.
			color: ${textColor.toMiddle(20)};
			font-size: ${adjustFontSize(13)}px;
			font-weight: bold;
			user-select: none;
		}

		.columns{
			display: flex;
		}

		.column{
			position: relative;
			display: flex;
			align-items: stretch;
			padding: 0 ${adjust(8)}px;
			border-bottom: 1px solid ${backgroundColor.toMiddle(20)};

			&:last-child{
				flex: 1;
				min-width: 0;
				padding-right: ${scrollbarWidth}px;
				margin-right: -${scrollbarWidth}px;
			}
		}

		.column-left{
			display: flex;
			flex: 1;
			max-width: 100%;

			&:hover .order{
				visibility: visible;
			}
		}

		.column-title{
			flex: 0 1 auto;
			min-width: 0;
			white-space: nowrap;
			overflow: hidden;
			text-overflow: ellipsis;
		}

		.column-ordered{
			border-bottom-color: ${backgroundColor.toMiddle(40)};
		}

		.resizable .column-title{
			flex: 1;
		}

		.order{
			width: ${adjust(16)}px;
			display: flex;
			flex: none;
			margin-right: ${adjust(-8)}px;	// Gives 16 - 8 = 8px as cell padding-right.
			visibility: hidden;

			f-icon{
				margin: auto;
			}

			&.current{
				visibility: visible;
			}
		}

		.resizer{
			position: relative;
			z-index: 1;
			width: 17px;
			margin-left: auto;
			margin-right: ${adjust(-16)}px;
			cursor: e-resize;

			&::before{
				content: '';
				position: absolute;
				left: 8px;
				top: 6px;
				bottom: 6px;
				width: 1px;
				background: ${backgroundColor.toMiddle(20)};
			}
		}

		.scroller{
			flex: 1;
			overflow-y: scroll;
			overflow-x: hidden;
		}

		.body{
			flex: 1;
			overflow-y: scroll;
			overflow-x: hidden;
			position: relative;
			border-bottom: 1px solid ${backgroundColor.toMiddle(13)};
		}

		.rows{
			table-layout: fixed;
			position: absolute;
			width: 100%;
		}

		tr{
			&:hover{
				background: ${mainColor.alpha(0.05)};
			}

			&.selected{
				background: ${mainColor.alpha(0.1)};
			}

			&:last-child td{
				border-bottom-color: transparent;
			}
		}

		td{
			vertical-align: middle;
			padding: ${adjust(3)}px ${adjust(8)}px;
			border-bottom: 1px solid ${backgroundColor.toMiddle(13)};
			white-space: nowrap;
			overflow: hidden;
			text-overflow: ellipsis;
			cursor: default;
		}

		f-checkbox{
			max-width: 100%;
			height: 100%;

			f-icon{
				margin-right: ${adjust(10)}px;
			}
		}

		.resizing-mask{
			position: fixed;
			z-index: 9999;
			left: 0;
			right: 0;
			top: 0;
			bottom: 0;
			cursor: ew-resize;
		}
		`;
    }
    render() {
        return flit_1.html `
		<div class="head" :ref="head">
			<div class="columns" :ref="columns">
				${this.renderColumns()}
			</div>
		</div>

		<div class="body">
			<table class="rows" :ref="table">
				<colgroup :ref="colgroup">
					${this.columns.map(column => flit_1.html `
						<col :style.text-align=${column.align || ''} />
					`)}
				</colgroup>
				${this.renderRows()}
			</table>
		</div>
		`;
    }
    renderColumns() {
        return this.columns.map((column, index) => {
            let isOrdered = this.orderColumnName === column.name;
            let flexAlign = column.align === 'right' ? 'flex-end' : column.align === 'center' ? 'center' : '';
            return flit_1.html `
			<div class="column"
				:class.column-ordered=${isOrdered}
				@click=${(e) => this.doOrdering(e, index)}
			>
				<div class="column-left" :style.justify-content=${flexAlign}>
					<div class="column-title">${column.title}</div>
					${column.orderBy ? flit_1.html `
						<div class="order" :class.current=${isOrdered && this.orderDirection !== ''}>
							<f-icon .type=${this.getOrderIcon(column.name)} />
						</div>`
                : ''}
				</div>

				${this.resizable && index < this.columns.length - 1 ? flit_1.html `
					<div class="resizer" @mousedown=${(e) => this.onStartResize(e, index)} />`
                : ''}
			</div>`;
        });
    }
    renderRows() {
        if (this.store instanceof async_store_1.AsyncStore) {
            return flit_1.refDirective(flit_1.liveAsyncRepeat({
                key: this.store.key,
                pageSize: this.pageSize,
                startIndex: this.startIndex,
                preRendering: this.preRendering,
                dataCount: this.store.dataCount.bind(this.store),
                dataGetter: this.store.dataGetter.bind(this.store),
                onUpdated: this.onRepeatDataUpdated.bind(this)
            }, this.renderRow.bind(this), this.transition), this.setRepeatDirective.bind(this));
        }
        else if (this.live) {
            return flit_1.refDirective(flit_1.liveRepeat({
                pageSize: this.pageSize,
                startIndex: this.startIndex,
                preRendering: this.preRendering,
                data: this.store.currentData,
                onUpdated: this.onRepeatDataUpdated.bind(this)
            }, this.renderRow.bind(this), this.transition), this.setRepeatDirective.bind(this));
        }
        else {
            return flit_1.repeat(this.store.currentData, this.renderRow.bind(this), this.transition);
        }
    }
    /**
     * Although you can specify this method,
     * I would suggest to define a sub class and overwrite `renderRow`.
     */
    renderRow(item, index) {
        let tds = this.columns.map((column) => {
            let result = item && column.render ? column.render(item, index) : '\xa0';
            return flit_1.html `<td :style.text-align=${column.align || ''}>${result}</td>`;
        });
        return flit_1.html `<tr>${tds}</tr>`;
    }
    setRepeatDirective(dir) {
        this.repeatDir = dir;
        if (this.store instanceof async_store_1.AsyncStore) {
            this.store.setRepeatDirective(dir);
        }
    }
    onRepeatDataUpdated(data, index) {
        this.emit('livedataupdated', data, index);
    }
    getOrderIcon(name) {
        if (name === this.orderColumnName) {
            if (this.orderDirection === 'asc') {
                return 'order-asc';
            }
            else if (this.orderDirection === 'desc') {
                return 'order-desc';
            }
        }
        return 'order-default';
    }
    onCreated() {
        if (this.store instanceof async_store_1.AsyncStore) {
            for (let column of this.columns) {
                if (column.orderBy && typeof column.orderBy !== 'string') {
                    throw new Error(`"orderBy" in "columns" configuration must be string type when using "liveStore"`);
                }
            }
        }
        this.orderColumnName = this.store.orderName;
        this.orderDirection = this.store.orderDirection;
        this.store.on('orderchanged', this.onOrderChanged, this);
    }
    onReady() {
        flit_1.onRenderComplete(() => {
            this.updatColumnWidths();
        });
    }
    onConnected() {
        this.watch(() => flit_1.observeGetter(this, 'columns'), async () => {
            this.restoreOrderedColumn();
            // Here we need it render new `<col>`s.
            await flit_1.renderComplete();
            this.updatColumnWidthsRoughly();
        });
        flit_1.onRenderComplete(() => {
            let unwatchSize = ff_1.watchLayout(this.el, 'size', () => this.updatColumnWidths());
            this.once('disconnected', unwatchSize);
        });
    }
    doOrdering(e, index) {
        if (e.target.closest(this.scopeClassName('.resizer'))) {
            return;
        }
        let columns = this.columns;
        let column = columns[index];
        let canOrder = column.orderBy;
        if (!canOrder) {
            return;
        }
        let direction = '';
        let descFirst = column.descFirst;
        if (column.name === this.orderColumnName) {
            if (descFirst) {
                direction = this.orderDirection === '' ? 'desc' : this.orderDirection === 'desc' ? 'asc' : 'desc';
            }
            else {
                direction = this.orderDirection === '' ? 'asc' : this.orderDirection === 'asc' ? 'desc' : 'asc';
            }
        }
        else {
            direction = descFirst ? 'desc' : 'asc';
        }
        this.orderStore(column, direction);
    }
    orderStore(column, direction) {
        if (direction === '') {
            this.store.clearOrder();
        }
        else {
            this.store.setNamedOrder(column.name, column.orderBy || column.render, direction);
        }
        this.store.reload();
    }
    onOrderChanged(name, direction = '') {
        let columns = this.columns;
        let index = -1;
        for (let i = 0; i < columns.length; i++) {
            if (columns[i].name === name) {
                index = i;
                break;
            }
        }
        if (index > -1) {
            this.orderColumnName = columns[index].name;
            this.orderDirection = direction;
        }
        else {
            this.orderColumnName = '';
            this.orderDirection = '';
        }
    }
    restoreOrderedColumn() {
        if (this.orderColumnName) {
            let index = this.columns.findIndex(column => column.name === this.orderColumnName);
            if (index === -1) {
                this.orderColumnName = '';
                this.orderDirection = '';
            }
        }
    }
    // Resizing part
    updatColumnWidths() {
        let totalWidth = this.refs.head.clientWidth - ff_1.getStyleAsNumber(this.refs.head, 'paddingLeft') - ff_1.getStyleAsNumber(this.refs.head, 'paddingRight');
        this.cachedTotalWidth = totalWidth;
        this.updatColumnWidthsWithTotalWidth(totalWidth);
    }
    // Used to adjust column widths after columns changed.
    // Many elements will be relayout after columns changed, 
    // And `updatColumnWidths` will cause force relayout.
    updatColumnWidthsRoughly() {
        this.updatColumnWidthsWithTotalWidth(this.cachedTotalWidth);
    }
    updatColumnWidthsWithTotalWidth(totalWidth) {
        let widthAndFlexArray = this.columns.map(({ flex, width }, index) => {
            let baseWidthInColumnConfig = Math.max(width || 0, this.minColumnWidth);
            // If column resized, we use the column width percentage to calculate new column width.
            let baseWidth = this.columnResized ? this.columnWidths[index] : baseWidthInColumnConfig;
            let extendFlex = 0;
            let shrinkFlex = 0;
            if (typeof flex === 'string') {
                let flexs = flex.split(/\s+/).map(Number);
                extendFlex = flexs[0] >= 0 ? flexs[0] : 0;
                shrinkFlex = flexs[1] >= 0 ? flexs[1] : extendFlex;
            }
            else if (typeof flex === 'number' && flex >= 0) {
                extendFlex = shrinkFlex = flex;
            }
            return [baseWidth, extendFlex, shrinkFlex];
        });
        let widths = columnWidthCalculator(widthAndFlexArray, totalWidth, this.minColumnWidth);
        this.columnWidths = widths;
        this.setColumnWidths(widths);
    }
    setColumnWidths(widths) {
        let totalWidth = ff_1.sum(widths);
        for (let index = 0; index < widths.length; index++) {
            let isLastColumn = index === widths.length - 1;
            let percent = widths[index] / totalWidth;
            let col = this.refs.colgroup.children[index];
            col.style.width = percent * 100 + '%';
            if (!isLastColumn) {
                let col = this.refs.columns.children[index];
                col.style.width = percent * 100 + '%';
            }
        }
    }
    onStartResize(e, index) {
        let startX = e.clientX;
        let onMouseMove = (e) => {
            e.preventDefault();
            this.resizeColumnByMovementX(e.clientX - startX, index);
        };
        let onMouseUp = () => {
            if (this.resizingColumnWidths) {
                this.columnWidths = this.resizingColumnWidths;
                this.resizingColumnWidths = null;
            }
            flit_1.off(document, 'mousemove', onMouseMove);
            cursorMask.remove();
            this.columnResized = true;
        };
        let cursorMask = flit_1.render(flit_1.html `<div class="resizing-mask" />`, this).fragment.firstElementChild;
        document.body.append(cursorMask);
        flit_1.on(document, 'mousemove', onMouseMove);
        flit_1.once(document, 'mouseup', onMouseUp);
    }
    resizeColumnByMovementX(movementX, index) {
        let widths = [...this.columnWidths];
        let needShrink = Math.abs(movementX);
        let moveLeft = movementX < 0;
        let expandIndex = moveLeft ? index + 1 : index;
        let firstShrinkIndex = moveLeft ? index : index + 1;
        // When move to left, we reduce the width of current and previous columns until the `minWidth`,
        // then we add the reduced width to next column.
        // When move to right, we reduce the width of next columns until the `minWidth`,
        // then we add the reduced width to current column.
        for (let i = firstShrinkIndex; (moveLeft ? i >= 0 : i < this.columns.length) && needShrink > 0; moveLeft ? i-- : i++) {
            let width = widths[i];
            let shrink = needShrink;
            if (width - shrink < this.minColumnWidth) {
                shrink = width - this.minColumnWidth;
            }
            widths[i] -= shrink;
            widths[expandIndex] += shrink; // index <= column count - 2
            needShrink -= shrink;
        }
        this.resizingColumnWidths = widths;
        this.setColumnWidths(widths);
    }
    setStartIndex(index) {
        let isLive = this.live || this.store instanceof async_store_1.AsyncStore;
        if (this.repeatDir) {
            this.repeatDir.setStartIndex(index);
        }
        else if (!isLive) {
            index = Math.min(index, this.store.data.length - 1);
            let row = this.refs.table.rows[index];
            if (row) {
                ff_1.scrollToTop(row);
            }
        }
    }
    scrollToViewIndex(index) {
        let isLive = this.live || this.store instanceof async_store_1.AsyncStore;
        if (this.repeatDir) {
            this.repeatDir.scrollToViewIndex(index);
        }
        else if (!isLive) {
            index = Math.min(index, this.store.data.length - 1);
            let row = this.refs.table.rows[index];
            if (row) {
                ff_1.scrollToView(row);
            }
        }
    }
};
Table = __decorate([
    flit_1.define('f-table')
], Table);
exports.Table = Table;
/**
    Calculate column widths from `{width, minWidth, flex}` values in column config.
    The algorithm is nearly same with the flex layout,
    except that the total column widths will always equal the available client width,
    and no column width should less than `minColumnWidth`.
*/
function columnWidthCalculator(widthAndFlexArray, clientWidth, minColumnWidth) {
    // Not enough space for even `minColumnWidth`, then average `clientWidth` to each column.
    if (clientWidth < minColumnWidth * widthAndFlexArray.length) {
        return ff_1.repeatTimes(clientWidth / widthAndFlexArray.length, widthAndFlexArray.length);
    }
    let totalBaseWidth = 0;
    let totalExtendFlex = 0;
    let totalShrinkFlex = 0;
    let widths = ff_1.repeatTimes(minColumnWidth, widthAndFlexArray.length);
    let excludedIndexSet = new Set();
    for (let [baseWidth, extendFlex, shrinkFlex] of widthAndFlexArray) {
        totalBaseWidth += baseWidth;
        totalExtendFlex += extendFlex;
        totalShrinkFlex += shrinkFlex;
    }
    // If no `flex` set for any column, set `flex` to `1` for all the columns.
    if (totalExtendFlex === 0) {
        totalExtendFlex = widthAndFlexArray.length;
        widthAndFlexArray.forEach(a => a[1] = 1);
    }
    if (totalShrinkFlex === 0) {
        totalShrinkFlex = widthAndFlexArray.length;
        widthAndFlexArray.forEach(a => a[2] = 1);
    }
    while (true) {
        let totalFlex = clientWidth >= totalBaseWidth ? totalExtendFlex : totalShrinkFlex;
        let widthPerFlex = (clientWidth - totalBaseWidth) / totalFlex;
        let moreColumnExcluded = false;
        for (let index = 0; index < widthAndFlexArray.length; index++) {
            if (excludedIndexSet.has(index)) {
                continue;
            }
            let [baseWidth, extendFlex, shrinkFlex] = widthAndFlexArray[index];
            let flex = widthPerFlex >= 0 ? extendFlex : shrinkFlex;
            let width = flex * widthPerFlex + baseWidth;
            if (width < minColumnWidth) {
                clientWidth -= minColumnWidth;
                totalBaseWidth -= minColumnWidth;
                totalExtendFlex -= flex;
                excludedIndexSet.add(index);
                moreColumnExcluded = true;
            }
            else {
                widths[index] = width;
            }
        }
        if (!moreColumnExcluded) {
            break;
        }
    }
    return widths;
}


/***/ }),

/***/ "./node_modules/@pucelle/flit-ui/out/components/tag.js":
/*!*************************************************************!*\
  !*** ./node_modules/@pucelle/flit-ui/out/components/tag.js ***!
  \*************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Tag = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const theme_1 = __webpack_require__(/*! ../style/theme */ "./node_modules/@pucelle/flit-ui/out/style/theme.js");
let Tag = class Tag extends flit_1.Component {
    constructor() {
        super(...arguments);
        this.closable = false;
    }
    static style() {
        let { borderColor, borderRadius, adjust, adjustFontSize } = theme_1.theme;
        return flit_1.css `
		:host{
			display: inline-flex;
			border: 1px solid ${borderColor};
			border-radius: ${borderRadius}px;
			font-size: ${adjustFontSize(13)}px;
			line-height: ${adjust(18)}px;
			height: ${adjust(20)}px;
			padding: 0 ${adjust(6)}px 0 ${adjust(6)}px;
			cursor: pointer;

			&:hover{
				opacity: 0.9;
			}

			&:active{
				opacity: 0.8;
			}
		}
	
		.icon{
			margin-left: ${adjust(4)}px;
			display: inline-flex;

			f-icon{
				margin: auto;
			}
		}
		`;
    }
    render() {
        return flit_1.html `
			<slot />
			${this.closable ? flit_1.html `<div class="icon" @@click=${this.close}><f-icon .type="close" /></div>` : ''}
		`;
    }
    close() {
        this.emit('close');
    }
};
Tag = __decorate([
    flit_1.define('f-tag')
], Tag);
exports.Tag = Tag;


/***/ }),

/***/ "./node_modules/@pucelle/flit-ui/out/components/tooltip.js":
/*!*****************************************************************!*\
  !*** ./node_modules/@pucelle/flit-ui/out/components/tooltip.js ***!
  \*****************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Tooltip = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const theme_1 = __webpack_require__(/*! ../style/theme */ "./node_modules/@pucelle/flit-ui/out/style/theme.js");
const popup_1 = __webpack_require__(/*! ../components/popup */ "./node_modules/@pucelle/flit-ui/out/components/popup.js");
let Tooltip = class Tooltip extends popup_1.Popup {
    constructor() {
        super(...arguments);
        this.type = 'default';
    }
    static style() {
        let { adjust, adjustFontSize, backgroundColor, textColor, errorColor } = theme_1.theme;
        let types = [
            ['default', backgroundColor.toMiddle(5)],
            ['prompt', textColor.toMiddle(30)],
            ['error', errorColor.toMiddle(5)]
        ];
        return flit_1.css `
		:host{
			display: flex;
			font-size: ${adjustFontSize(13)}px;
			max-width: ${adjust(220)}px;
			padding: ${adjust(4)}px ${adjust(8)}px;
			line-height: ${adjust(20)}px;
			pointer-events: none;
		}

		.text{
			flex: 1;
			min-width: 0;
		}

		.close{
			display: flex;
			width: ${adjust(28)}px;
			height: ${adjust(28)}px;
			margin-top: ${adjust(-4)}px;
			margin-bottom: ${adjust(-4)}px;
			margin-right: ${adjust(-8)}px;
			cursor: pointer;

			&:active{
				transform: translateY(1px);
			}

			f-icon{
				margin: auto;
			}
		}

		${types.map(([type, color]) => {
            let textColor = color.getLightness() > 0.5 ? '#000' : '#fff';
            return flit_1.css `
			.type-${type}{
				background: ${color};
				color: ${textColor};

				.triangle{
					border-bottom-color: ${color};

					&-herizontal{
						border-right-color: ${color};
						border-bottom-color: transparent;
					}
				}
			}
			`;
        })}

		.type-prompt{
			pointer-events: auto;
		}

		`.extends(super.style());
    }
    render() {
        return flit_1.html `
		<template class="type-${this.type}">
			<div class="text">
				<slot />
			</div>

			${this.type === 'prompt' ? flit_1.html `
				<div class="close" @click=${this.close}>
					<f-icon .type="close" />
				</div>
			` : ''}
		</template>
		`.extends(super.render());
    }
};
Tooltip = __decorate([
    flit_1.define('f-tooltip')
], Tooltip);
exports.Tooltip = Tooltip;


/***/ }),

/***/ "./node_modules/@pucelle/flit-ui/out/icons/svg-symbol.js":
/*!***************************************************************!*\
  !*** ./node_modules/@pucelle/flit-ui/out/icons/svg-symbol.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.svgSymbols = void 0;
exports.svgSymbols = {
    'checkbox-checked': `
		<svg viewBox="0 0 17 17">
			<path style="fill:currentColor; stroke:none;" d="M3.6,0h9.8c2,0,3.6,1.6,3.6,3.6v9.8c0,2-1.6,3.6-3.6,3.6H3.6c-2,0-3.6-1.6-3.6-3.6V3.6C0,1.6,1.6,0,3.6,0z"/>
			<polyline style="fill:none;stroke:#FFFFFF;" points="13.3,4.8 6.8,12.2 3.7,8.7"/>
		</svg>
	`,
    'checkbox-indeterminate': `
		<svg viewBox="0 0 17 17">
			<path style="fill:currentColor; stroke:none;" d="M3.6,0h9.8c2,0,3.6,1.6,3.6,3.6v9.8c0,2-1.6,3.6-3.6,3.6H3.6c-2,0-3.6-1.6-3.6-3.6V3.6C0,1.6,1.6,0,3.6,0z"/>
			<path style="fill:none;stroke:#FFFFFF;stroke-linecap:square;" d="M4.4,8.5h8.1"/>
		</svg>
	`,
    'checkbox-unchecked': `
		<svg viewBox="0 0 17 17">
			<path style="fill:none;stroke:currentColor;" d="M4.1,0.5H13c2,0,3.6,1.6,3.6,3.6V13c0,2-1.6,3.6-3.6,3.6H4.1c-2,0-3.6-1.6-3.6-3.6V4.1C0.5,2.1,2.1,0.5,4.1,0.5z"/>
		</svg>
	`,
    'checked': `
		<svg viewBox="0 0 15 15">
			<polyline style="fill:none;stroke:currentColor;" points="12.5,3.4 5.7,11.6 2.5,7.8"/>
		</svg>
	`,
    'close': `
		<svg viewBox="0 0 15 15">
			<path style="fill:currentColor; stroke:none;" d="M28.1,12.5c-0.2,0-0.4-0.2-0.4-0.4c0-0.1,0-0.2,0.1-0.3L37,1.7c0.2-0.2,0.4-0.2,0.6,0c0.2,0.2,0.2,0.4,0,0.7l-9.2,10C28.4,12.5,28.2,12.5,28.1,12.5z"/>
			<path style="fill:currentColor; stroke:none;" d="M37.3,12.5c-0.1,0-0.2,0-0.3-0.1L27.9,2.3c-0.1-0.2-0.1-0.4,0-0.6c0.2-0.2,0.4-0.2,0.6,0l9.2,10.1c0.2,0.2,0.2,0.4,0,0.7C37.5,12.4,37.5,12.5,37.3,12.5L37.3,12.5z"/>
			<line style="fill:none;stroke:currentColor;stroke-width:1.0526;" x1="12.5" y1="2.5" x2="2.5" y2="12.5"/>
			<line style="fill:none;stroke:currentColor;stroke-width:1.0526;" x1="12.5" y1="12.5" x2="2.5" y2="2.5"/>
		</svg>
	`,
    'confirm': `
		<svg viewBox="0 0 21 21">
			<rect style="fill:currentColor; stroke:none;" x="9.5" y="14.5" width="2" height="2"/>
			<path style="fill:currentColor; stroke:none;" d="M13.6,6.4c-0.1-0.4-0.3-0.7-0.6-1c-0.3-0.3-0.6-0.5-1-0.7c-0.5-0.2-1-0.3-1.5-0.3c-0.5,0-0.9,0.1-1.3,0.3C8.8,4.9,8.5,5.2,8.2,5.5C7.9,5.8,7.6,6.2,7.5,6.7C7.3,7.2,7.2,7.7,7.2,8.3h1.7c0-0.3,0.1-0.7,0.2-1C9.1,7,9.3,6.8,9.4,6.5c0.1-0.2,0.3-0.4,0.5-0.5c0.2-0.1,0.4-0.2,0.6-0.2c0.2,0,0.4,0,0.6,0.1c0.2,0.1,0.3,0.2,0.5,0.3c0.1,0.1,0.2,0.3,0.3,0.5C12,7,12,7.3,12,7.5C12,7.7,12,8,11.9,8.2c-0.1,0.2-0.3,0.4-0.5,0.6c-0.2,0.2-0.4,0.4-0.6,0.6c-0.2,0.2-0.4,0.4-0.6,0.6c-0.2,0.2-0.3,0.5-0.5,0.7c-0.1,0.3-0.2,0.6-0.2,0.9V12l0,0v1h2v-0.6l0,0v-0.7c0-0.3,0.1-0.5,0.2-0.8c0.1-0.2,0.3-0.4,0.4-0.6c0.2-0.2,0.3-0.4,0.6-0.6c0.2-0.2,0.4-0.4,0.6-0.6c0.2-0.2,0.3-0.5,0.4-0.7c0.1-0.3,0.2-0.6,0.2-0.9C13.8,7.1,13.7,6.7,13.6,6.4z"/>
			<circle style="fill:none;stroke:currentColor;" cx="10.5" cy="10.5" r="10"/>
		</svg>
	`,
    'down': `
		<svg viewBox="0 0 15 15">
			<polygon style="fill:currentColor; stroke:none;" points="7.5,11 3.5,4.4 4.2,4 7.5,9.4 10.8,4 11.5,4.4"/>
		</svg>
	`,
    'error': `
		<svg viewBox="0 0 21 21">
			<circle style="fill:none;stroke:currentColor;" cx="10.5" cy="10.5" r="10"/>
			<line style="fill:none;stroke:currentColor;" x1="14.4" y1="6.6" x2="6.6" y2="14.4"/>
			<line style="fill:none;stroke:currentColor;" x1="14.4" y1="14.4" x2="6.6" y2="6.6"/>
		</svg>
	`,
    'info': `
		<svg viewBox="0 0 21 21">
			<rect style="fill:currentColor; stroke:none;" x="9.5" y="4" width="2" height="2"/>
			<polygon style="fill:currentColor; stroke:none;" points="11.5,9 11.5,8 9.5,8 8.5,8 8.5,9 9.5,9 9.5,16 8.5,16 8.5,17 9.5,17 11.5,17 12.5,17 12.5,16 11.5,16"/>
			<circle style="fill:none;stroke:currentColor;" cx="10.5" cy="10.5" r="10"/>
		</svg>
	`,
    'love': `
		<svg viewBox="0 0 15 15">
			<path style="fill:none;stroke:currentColor;" d="M12.7,3.4c-1.1-1.1-2.8-1.1-3.8,0L7.5,4.7L6.1,3.4c-1.1-1.1-2.8-1.1-3.8,0c-1.1,1.1-1.1,2.8,0,3.8l1.4,1.4l3.8,3.8l3.8-3.8l1.4-1.4C13.8,6.2,13.8,4.4,12.7,3.4z"/>
		</svg>
	`,
    'order-asc': `
		<svg viewBox="0 0 7 14">
			<polygon style="fill:currentColor;stroke:none;fill-opacity:0.4;" points="5.7,8 3.5,11.8 1.3,8 0.2,8 0.1,8 3.5,13.8 6.9,8 6.8,8"/>
			<polygon style="fill:currentColor;stroke:none;" points="3.5,0.3 0.1,6 0.2,6 1.3,6 3.5,2.2 5.7,6 6.8,6 6.9,6"/>
		</svg>
	`,
    'order-default': `
		<svg viewBox="0 0 7 14">
			<polygon style="fill:currentColor;stroke:none;fill-opacity:0.4;" points="5.7,8 3.5,11.8 1.3,8 0.2,8 0.1,8 3.5,13.8 6.9,8 6.8,8"/>
			<polygon style="fill:currentColor;stroke:none;fill-opacity:0.4;" points="3.5,0.3 0.1,6 0.2,6 1.3,6 3.5,2.2 5.7,6 6.8,6 6.9,6"/>
		</svg>
	`,
    'order-desc': `
		<svg viewBox="0 0 7 14">
			<polygon style="fill:currentColor;stroke:none;" points="5.7,8 3.5,11.8 1.3,8 0.2,8 0.1,8 3.5,13.8 6.9,8 6.8,8"/>
			<polygon style="fill:currentColor;stroke:none;fill-opacity:0.4;" points="3.5,0.3 0.1,6 0.2,6 1.3,6 3.5,2.2 5.7,6 6.8,6 6.9,6"/>
		</svg>
	`,
    'radio-checked': `
		<svg viewBox="0 0 17 17">
			<circle style="fill:none;stroke:currentColor;" cx="8.5" cy="8.5" r="8"/>
			<circle style="fill-rule:evenodd;clip-rule:evenodd;fill:currentColor; stroke:none;" cx="8.5" cy="8.5" r="3.5"/>
		</svg>
	`,
    'radio-unchecked': `
		<svg viewBox="0 0 17 17">
			<circle style="fill:none;stroke:currentColor;" cx="8.5" cy="8.5" r="8"/>
		</svg>
	`,
    'right': `
		<svg viewBox="0 0 15 15">
			<polygon style="fill:currentColor; stroke:none;" points="4.4,11.5 4,10.8 9.4,7.5 4,4.2 4.4,3.5 11,7.5"/>
		</svg>
	`,
    'search': `
		<svg viewBox="0 0 15 15">
			<line style="fill:none;stroke:currentColor;stroke-linecap:round;" x1="9.6" y1="9.6" x2="13.9" y2="13.9"/>
			<ellipse transform="matrix(0.7071 -0.7071 0.7071 0.7071 -2.5312 6.1109)" style="fill:none;stroke:currentColor;" cx="6.1" cy="6.1" rx="5" ry="5"/>
		</svg>
	`,
    'success': `
		<svg viewBox="0 0 21 21">
			<circle style="fill:none;stroke:currentColor;" cx="10.5" cy="10.5" r="10"/>
			<polyline style="fill:none;stroke:currentColor;" points="16.2,6.4 9.3,14.6 6.1,10.8"/>
		</svg>
	`,
    'tips': `
		<svg viewBox="0 0 15 15">
			<path style="fill:currentColor; stroke:none;" d="M7,1c3.3,0,6,2.7,6,6s-2.7,6-6,6s-6-2.7-6-6S3.7,1,7,1 M7,0C3.1,0,0,3.1,0,7s3.1,7,7,7s7-3.1,7-7S10.9,0,7,0z"/>
			<rect style="fill:currentColor; stroke:none;" x="6" y="3" width="2" height="2"/>
			<polygon style="fill:currentColor; stroke:none;" points="8,10 8,7 8,6 6,6 5,6 5,7 6,7 6,10 5,10 5,11 6,11 8,11 9,11 9,10"/>
		</svg>
	`,
    'triangle-down': `
		<svg viewBox="0 0 15 15">
			<polygon style="fill:currentColor; stroke:none;" points="7,11 11,3 3,3"/>
		</svg>
	`,
    'triangle-right': `
		<svg viewBox="0 0 15 15">
			<polygon style="fill:currentColor; stroke:none;" points="11,7 3,3 3,11"/>
		</svg>
	`,
    'warning': `
		<svg viewBox="0 0 21 21">
			<line style="fill:none;stroke:currentColor;stroke-width:2;" x1="10.5" y1="7.5" x2="10.5" y2="12.5"/>
			<rect style="fill:currentColor; stroke:none;" x="9.5" y="14" width="2" height="2"/>
			<path style="fill:currentColor; stroke:none;" d="M10.5,3l8.8,15H1.7L10.5,3 M10.5,1L0,19h21L10.5,1L10.5,1z"/>
		</svg>
	`,
};


/***/ }),

/***/ "./node_modules/@pucelle/flit-ui/out/index.js":
/*!****************************************************!*\
  !*** ./node_modules/@pucelle/flit-ui/out/index.js ***!
  \****************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __exportStar = (this && this.__exportStar) || function(m, exports) {
    for (var p in m) if (p !== "default" && !exports.hasOwnProperty(p)) __createBinding(exports, m, p);
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
__webpack_require__(/*! ./style/global-style */ "./node_modules/@pucelle/flit-ui/out/style/global-style.js");
__exportStar(__webpack_require__(/*! ./style/theme */ "./node_modules/@pucelle/flit-ui/out/style/theme.js"), exports);
__exportStar(__webpack_require__(/*! ./style/color */ "./node_modules/@pucelle/flit-ui/out/style/color.js"), exports);
__exportStar(__webpack_require__(/*! ./store/store */ "./node_modules/@pucelle/flit-ui/out/store/store.js"), exports);
__exportStar(__webpack_require__(/*! ./store/async-store */ "./node_modules/@pucelle/flit-ui/out/store/async-store.js"), exports);
__exportStar(__webpack_require__(/*! ./components/buttongroup */ "./node_modules/@pucelle/flit-ui/out/components/buttongroup.js"), exports);
__exportStar(__webpack_require__(/*! ./components/icon */ "./node_modules/@pucelle/flit-ui/out/components/icon.js"), exports);
__exportStar(__webpack_require__(/*! ./components/radio */ "./node_modules/@pucelle/flit-ui/out/components/radio.js"), exports);
__exportStar(__webpack_require__(/*! ./components/checkbox */ "./node_modules/@pucelle/flit-ui/out/components/checkbox.js"), exports);
__exportStar(__webpack_require__(/*! ./components/switch */ "./node_modules/@pucelle/flit-ui/out/components/switch.js"), exports);
__exportStar(__webpack_require__(/*! ./components/slider */ "./node_modules/@pucelle/flit-ui/out/components/slider.js"), exports);
__exportStar(__webpack_require__(/*! ./components/form */ "./node_modules/@pucelle/flit-ui/out/components/form.js"), exports);
__exportStar(__webpack_require__(/*! ./components/input */ "./node_modules/@pucelle/flit-ui/out/components/input.js"), exports);
__exportStar(__webpack_require__(/*! ./components/tag */ "./node_modules/@pucelle/flit-ui/out/components/tag.js"), exports);
__exportStar(__webpack_require__(/*! ./components/search */ "./node_modules/@pucelle/flit-ui/out/components/search.js"), exports);
__exportStar(__webpack_require__(/*! ./components/progress */ "./node_modules/@pucelle/flit-ui/out/components/progress.js"), exports);
__exportStar(__webpack_require__(/*! ./components/popup */ "./node_modules/@pucelle/flit-ui/out/components/popup.js"), exports);
__exportStar(__webpack_require__(/*! ./components/tooltip */ "./node_modules/@pucelle/flit-ui/out/components/tooltip.js"), exports);
__exportStar(__webpack_require__(/*! ./components/popover */ "./node_modules/@pucelle/flit-ui/out/components/popover.js"), exports);
__exportStar(__webpack_require__(/*! ./components/dropdown */ "./node_modules/@pucelle/flit-ui/out/components/dropdown.js"), exports);
__exportStar(__webpack_require__(/*! ./components/list */ "./node_modules/@pucelle/flit-ui/out/components/list.js"), exports);
__exportStar(__webpack_require__(/*! ./components/navigation */ "./node_modules/@pucelle/flit-ui/out/components/navigation.js"), exports);
__exportStar(__webpack_require__(/*! ./components/select */ "./node_modules/@pucelle/flit-ui/out/components/select.js"), exports);
__exportStar(__webpack_require__(/*! ./components/menu */ "./node_modules/@pucelle/flit-ui/out/components/menu.js"), exports);
__exportStar(__webpack_require__(/*! ./components/contextmenu */ "./node_modules/@pucelle/flit-ui/out/components/contextmenu.js"), exports);
__exportStar(__webpack_require__(/*! ./components/notification */ "./node_modules/@pucelle/flit-ui/out/components/notification.js"), exports);
__exportStar(__webpack_require__(/*! ./components/dialog */ "./node_modules/@pucelle/flit-ui/out/components/dialog.js"), exports);
__exportStar(__webpack_require__(/*! ./components/modal */ "./node_modules/@pucelle/flit-ui/out/components/modal.js"), exports);
__exportStar(__webpack_require__(/*! ./components/table */ "./node_modules/@pucelle/flit-ui/out/components/table.js"), exports);
__exportStar(__webpack_require__(/*! ./components/resizer */ "./node_modules/@pucelle/flit-ui/out/components/resizer.js"), exports);
__exportStar(__webpack_require__(/*! ./components/grid-layout */ "./node_modules/@pucelle/flit-ui/out/components/grid-layout.js"), exports);
__exportStar(__webpack_require__(/*! ./components/loader */ "./node_modules/@pucelle/flit-ui/out/components/loader.js"), exports);
__exportStar(__webpack_require__(/*! ./components/router */ "./node_modules/@pucelle/flit-ui/out/components/router.js"), exports);
__exportStar(__webpack_require__(/*! ./bindings/tooltip */ "./node_modules/@pucelle/flit-ui/out/bindings/tooltip.js"), exports);
__exportStar(__webpack_require__(/*! ./bindings/contextmenu */ "./node_modules/@pucelle/flit-ui/out/bindings/contextmenu.js"), exports);
__exportStar(__webpack_require__(/*! ./bindings/popup */ "./node_modules/@pucelle/flit-ui/out/bindings/popup.js"), exports);
__exportStar(__webpack_require__(/*! ./bindings/loading */ "./node_modules/@pucelle/flit-ui/out/bindings/loading.js"), exports);
__exportStar(__webpack_require__(/*! ./bindings/goto */ "./node_modules/@pucelle/flit-ui/out/bindings/goto.js"), exports);
__exportStar(__webpack_require__(/*! ./bindings/drag-drop */ "./node_modules/@pucelle/flit-ui/out/bindings/drag-drop.js"), exports);


/***/ }),

/***/ "./node_modules/@pucelle/flit-ui/out/store/async-store.js":
/*!****************************************************************!*\
  !*** ./node_modules/@pucelle/flit-ui/out/store/async-store.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.AsyncStore = void 0;
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
/**
 * Compare to `Store`, `AsyncStore` loads data for one page each time.
 * And every time after data changed, it refreshs to reload all datas.
 * It's an extension for `liveRepeat` directive, to cache data,
 * you should extends this class and overwrite abstract methods, and may support like column ordering and searching.
 */
class AsyncStore extends ff_1.Emitter {
    constructor() {
        super(...arguments);
        /** Main key property. */
        this.key = '';
        /** The readable name relatated to current ordering state. */
        this.orderName = '';
        /** Current ordered key. */
        this.orderKey = '';
        /** Current ordered direction. */
        this.orderDirection = '';
    }
    setRepeatDirective(dir) {
        this.repeatDir = dir;
    }
    reset(startIndex = 0) {
        if (this.repeatDir) {
            this.repeatDir.reset(startIndex);
        }
        this.emit('change');
    }
    setNamedOrder(name, key, direction) {
        this.orderName = name;
        this.orderKey = key;
        this.orderDirection = direction;
        this.emit('orderchanged', name, direction);
    }
    setOrder(key, direction) {
        this.setNamedOrder(key, key, direction);
    }
    clearOrder() {
        this.orderKey = '';
        this.orderDirection = '';
        this.emit('orderchanged', '', '');
    }
    reload() {
        if (this.repeatDir) {
            this.repeatDir.reload();
        }
        this.emit('change');
    }
    getFirstVisibleIndex() {
        return this.repeatDir.getFirstVisibleIndex();
    }
}
exports.AsyncStore = AsyncStore;


/***/ }),

/***/ "./node_modules/@pucelle/flit-ui/out/store/store.js":
/*!**********************************************************!*\
  !*** ./node_modules/@pucelle/flit-ui/out/store/store.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Store = void 0;
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
/** Used to replace same key items in `Store`. */
class KeyMap {
    constructor(key) {
        if (!key) {
            throw new Error('"key" must be provided when instantiate "KeyMap"!');
        }
        this.key = key;
        this.map = new Map();
    }
    has(item) {
        return this.map.has(item[this.key]);
    }
    get(item) {
        return this.map.get(item[this.key]);
    }
    add(item) {
        this.map.set(item[this.key], item);
    }
    delete(item) {
        this.map.delete(item[this.key]);
    }
    clear() {
        this.map = new Map();
    }
}
/* Used to cache object type data and support selection, ordering and filtering. */
class Store extends ff_1.Emitter {
    constructor(options = {}) {
        super();
        /** The whole data. */
        this.data = [];
        /** Current data after been sorted and filtered. */
        this.currentData = [];
        /** If `key` specified, when different but same key items added, it covers the old one. */
        this.key = null;
        /** Used to search data items. */
        this.filter = null;
        /** Used to sort items, see `ff.orderBy` */
        this.order = null;
        /** The readable name relatated to current ordered state. */
        this.orderName = '';
        /** Current ordered direction. */
        this.orderDirection = '';
        /** Used to select range items by `shift + click`. */
        this.lastTouchItem = null;
        this.selected = [];
        this.map = null;
        this.selectedMap = null;
        if (options.key) {
            this.map = new KeyMap(options.key);
            this.selectedMap = new KeyMap(options.key);
        }
        let data = options.data;
        delete options.data;
        Object.assign(this, options);
        this.initData(data);
    }
    initData(data) {
        if (data) {
            this.addItems(data);
        }
    }
    addItems(items, atStart = false) {
        if (items.length > 0) {
            if (this.map) {
                for (let item of items) {
                    this.map.add(item);
                }
            }
            if (atStart) {
                this.data.unshift(...items);
            }
            else {
                this.data.push(...items);
            }
            let filteredItems = this.filter ? items.filter(this.filter) : items;
            this.addItemsToCurrentData(filteredItems, atStart);
        }
    }
    addItemsToCurrentData(items, atStart = false) {
        if (this.order) {
            if (items.length > 1) {
                let newData = this.currentData.length > 0 ? [...this.currentData, ...items] : items;
                this.order.sortArray(newData);
                this.currentData = newData;
            }
            else {
                for (let item of items) {
                    this.order.binaryInsert(this.currentData, item);
                }
            }
        }
        else {
            if (atStart) {
                this.currentData.unshift(...items);
            }
            else {
                this.currentData.push(...items);
            }
        }
    }
    setNamedOrder(name, by, direction) {
        this.order = new ff_1.Order([by, direction || 'asc']);
        this.orderName = name;
        this.orderDirection = direction;
        this.emit('orderchanged', name, direction);
    }
    setOrder(key, direction) {
        this.setNamedOrder(String(key), key, direction);
    }
    clearOrder() {
        this.order = null;
        this.emit('orderchanged', '', '');
    }
    setFilter(filter) {
        this.filter = filter;
        this.updateCurrentData();
        this.deselectAll();
        this.emit('change');
    }
    clearFilter() {
        this.setFilter(null);
    }
    updateCurrentData() {
        this.clearCurrentData();
        this.addItemsToCurrentData(this.filter ? this.data.filter(this.filter) : this.data);
    }
    clearCurrentData() {
        this.currentData = [];
    }
    add(...items) {
        this.remove(...items);
        this.addItems(items);
        this.emit('change');
    }
    addToStart(...items) {
        this.remove(...items);
        this.addItems(items, true);
        this.emit('change');
    }
    push(...items) {
        this.addItems(items);
        this.emit('change');
    }
    unshift(...items) {
        this.addItems(items, true);
        this.emit('change');
    }
    insert(index, ...items) {
        if (items.length > 0) {
            this.data.splice(index, 0, ...items);
            if (this.map) {
                for (let item of items) {
                    this.map.add(item);
                }
            }
            if (this.order) {
                this.addItemsToCurrentData(this.filter ? items.filter(this.filter) : items);
            }
            else {
                this.updateCurrentData();
            }
        }
        this.emit('change');
    }
    has(item) {
        if (this.map) {
            return this.map.has(item);
        }
        else {
            return this.data.includes(item);
        }
    }
    get(item) {
        if (this.map) {
            return this.map.get(item);
        }
        else {
            return item;
        }
    }
    remove(...items) {
        let toRemoveSet = new Set();
        if (this.map) {
            for (let item of items) {
                if (this.map.has(item)) {
                    toRemoveSet.add(this.map.get(item));
                    this.map.delete(item);
                }
            }
        }
        else {
            for (let item of items) {
                if (this.data.includes(item)) {
                    toRemoveSet.add(item);
                }
            }
        }
        if (toRemoveSet.size > 0) {
            this.data = this.data.filter(item => !toRemoveSet.has(item));
            if (this.map) {
                this.currentData = this.currentData.filter(item => this.map.has(item));
            }
            else {
                this.currentData = this.currentData.filter(item => !toRemoveSet.has(item));
            }
            this.deselect(...toRemoveSet);
            this.emit('change');
        }
        return [...toRemoveSet];
    }
    isSelected(item) {
        if (this.selectedMap) {
            return this.selectedMap.has(item);
        }
        else {
            return this.selected.includes(item);
        }
    }
    isPartlySelected() {
        let selectedCount = this.selected.length;
        return selectedCount > 0 && selectedCount < this.currentData.length;
    }
    isSelectedAll() {
        let selectedCount = this.selected.length;
        return selectedCount > 0 && selectedCount === this.currentData.length;
    }
    getSelectedCount() {
        return this.selected.length;
    }
    select(...items) {
        if (this.selectedMap) {
            for (let item of items) {
                if (!this.selectedMap.has(item)) {
                    this.selected.push(item);
                    this.selectedMap.add(item);
                }
            }
        }
        else {
            for (let item of items) {
                if (!this.selected.includes(item)) {
                    this.selected.push(item);
                }
            }
        }
        this.lastTouchItem = items[0];
    }
    deselect(...items) {
        if (items === this.selected) {
            this.deselectAll();
        }
        else {
            let toRemoveSet = new Set();
            if (this.selectedMap) {
                for (let item of items) {
                    if (this.selectedMap.has(item)) {
                        toRemoveSet.add(this.selectedMap.get(item));
                        this.selectedMap.delete(item);
                    }
                }
            }
            else {
                for (let item of items) {
                    if (this.selected.includes(item)) {
                        toRemoveSet.add(item);
                    }
                }
            }
            if (toRemoveSet.size > 0) {
                this.selected = this.selected.filter(item => !toRemoveSet.has(item));
            }
        }
        this.lastTouchItem = items[0];
    }
    toggleSelect(item) {
        if (this.isSelected(item)) {
            this.deselect(item);
        }
        else {
            this.select(item);
        }
        this.lastTouchItem = item;
    }
    selectByKeyboardEvent(item, event) {
        if (event.shiftKey) {
            this.shiftSelect(item);
        }
        else {
            this.toggleSelect(item);
        }
    }
    shiftSelect(item) {
        let startIndex = Math.max(this.lastTouchItem ? this.getIndex(this.lastTouchItem) : 0, 0);
        let endIndex = this.getIndex(item);
        if (endIndex >= 0) {
            if (startIndex > endIndex) {
                [startIndex, endIndex] = [endIndex, startIndex];
            }
            endIndex += 1;
            if (this.isSelected(item)) {
                this.deselect(...this.currentData.slice(startIndex, endIndex));
            }
            else {
                this.select(...this.currentData.slice(startIndex, endIndex));
            }
        }
    }
    getIndex(item) {
        if (this.map && !this.map.has(item)) {
            return -1;
        }
        return this.data.indexOf(this.get(item));
    }
    selectAll() {
        this.select(...this.currentData);
    }
    deselectAll() {
        this.selected = [];
        if (this.selectedMap) {
            this.selectedMap.clear();
        }
    }
    toggleSelectAll() {
        if (this.isSelectedAll()) {
            this.deselectAll();
        }
        else {
            this.selectAll();
        }
    }
    reload() {
        this.updateCurrentData();
        this.emit('change');
    }
    clear() {
        this.data = [];
        this.clearCurrentData();
        this.deselectAll();
        if (this.map) {
            this.map.clear();
        }
        this.emit('change');
    }
}
exports.Store = Store;


/***/ }),

/***/ "./node_modules/@pucelle/flit-ui/out/style/color.js":
/*!**********************************************************!*\
  !*** ./node_modules/@pucelle/flit-ui/out/style/color.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Color = void 0;
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
/** Class to process colors. */
class Color {
    constructor(value) {
        this.value = value.trim();
    }
    static fromRGBA(r, g, b, a) {
        r = Math.max(Math.min(r, 1), 0);
        g = Math.max(Math.min(g, 1), 0);
        b = Math.max(Math.min(b, 1), 0);
        a = Math.max(Math.min(a, 1), 0);
        if (a === 1) {
            return new Color('#'
                + (Math.round(255 * r)).toString(16).padStart(2, '0')
                + (Math.round(255 * g)).toString(16).padStart(2, '0')
                + (Math.round(255 * b)).toString(16).padStart(2, '0'));
        }
        else {
            return new Color('rgba('
                + (Math.round(255 * r)).toString() + ', '
                + (Math.round(255 * g)).toString() + ', '
                + (Math.round(255 * b)).toString() + ', '
                + ff_1.toPower(a, -2) + ')');
        }
    }
    static fromRGB(r, g, b) {
        return Color.fromRGBA(r, g, b, 1);
    }
    toString() {
        return this.value;
    }
    /** Get [r, g, b, a], all betweens 0 ~ 1. */
    getRGBA() {
        if (/^#[0-9a-fA-F]{3,6}$/.test(this.value)) {
            return [...this.parseNormalColor(this.value), 1];
        }
        let match = this.value.match(/^rgb\(\s*(\d+)\s*,\s*(\d+)\s*,\s*(\d+)\s*\)$/);
        if (match) {
            return [
                Number(match[1]) / 255,
                Number(match[2]) / 255,
                Number(match[3]) / 255,
                1
            ];
        }
        match = this.value.match(/^rgba\(\s*(\d+)\s*,\s*(\d+)\s*,\s*(\d+)\s*,\s*([\d.]+)\s*\)$/);
        if (match) {
            return [
                Number(match[1]) / 255,
                Number(match[2]) / 255,
                Number(match[3]) / 255,
                Number(match[4]),
            ];
        }
        match = this.value.match(/^rgba\(\s*(#[0-9a-fA-F]{3,6})\s*,\s*([\d.]+)\s*\)$/);
        if (match) {
            return [...this.parseNormalColor(match[1]), Number(match[2])];
        }
        throw new Error(`"${this.value}" is not a valid RGB color`);
    }
    /** Get [r, g, b], all betweens 0 ~ 1. */
    getRGB() {
        return this.getRGBA().slice(0, 3);
    }
    parseNormalColor(color) {
        if (color.length === 4) {
            return [
                parseInt(color[1], 16) * 17 / 255,
                parseInt(color[2], 16) * 17 / 255,
                parseInt(color[3], 16) * 17 / 255
            ];
        }
        else {
            return [
                parseInt(color.slice(1, 3), 16) / 255,
                parseInt(color.slice(3, 5), 16) / 255,
                parseInt(color.slice(5, 7), 16) / 255
            ];
        }
    }
    /** Darken current color with percentage value betweens 0-100. */
    darken(percentage) {
        return this.lighten(-percentage);
    }
    /** Lighten current color with percentage value betweens 0-100. */
    lighten(percentage) {
        let [r, g, b, a] = this.getRGBA();
        let p = percentage / 100;
        r += p;
        g += p;
        b += p;
        return Color.fromRGBA(r, g, b, a);
    }
    /**
     * Darken if is a light color, otherwise lighten.
     * Which also means move color to middle.
     */
    toMiddle(percentage) {
        if (this.getLightness() < 0.5) {
            return this.lighten(percentage);
        }
        else {
            return this.darken(percentage);
        }
    }
    /** Returns lightless value of current color, betweens 0 ~ 1. */
    getLightness() {
        let [r, g, b] = this.getRGBA();
        return ff_1.avg([r, g, b]);
    }
    /** Change alpha channel of current color to value betweens 0-1. */
    alpha(a) {
        let [r, g, b] = this.getRGBA();
        return Color.fromRGBA(r, g, b, a);
    }
    /** Mix with another color in percentage value betweens 0-100. */
    mix(color, percentage) {
        let [r, g, b, a] = this.getRGBA();
        if (typeof color === 'string') {
            color = new Color(color);
        }
        let [r2, g2, b2, a2] = color.getRGBA();
        let p = percentage / 100;
        r = r * (1 - p) + r2 * p;
        g = g * (1 - p) + g2 * p;
        b = b * (1 - p) + b2 * p;
        a = a * (1 - p) + a2 * p;
        return Color.fromRGBA(r, g, b, a);
    }
}
exports.Color = Color;


/***/ }),

/***/ "./node_modules/@pucelle/flit-ui/out/style/global-style.js":
/*!*****************************************************************!*\
  !*** ./node_modules/@pucelle/flit-ui/out/style/global-style.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const theme_1 = __webpack_require__(/*! ./theme */ "./node_modules/@pucelle/flit-ui/out/style/theme.js");
flit_1.addGlobalStyle(() => {
    let { mainColor, textColor, borderColor, errorColor, fontSize, borderRadius, focusBlurRadius, adjust, adjustFontSize, backgroundColor } = theme_1.theme;
    return flit_1.css `
	html{
		color: ${textColor};
		font-size: ${fontSize}px;
		line-height: ${adjust(28)}px;
		background-color: ${backgroundColor};
	}

	h1{
		font-size: ${adjustFontSize(68)}px;
		line-height: 1.2;
		font-weight: 700;
	}

	h2{
		font-size: ${adjustFontSize(36)}px;
		line-height: 1.2;
		font-weight: 100;
	}

	h3{
		font-size: ${adjustFontSize(26)}px;
		line-height: 1.2;
		font-weight: 400;
	}

	h4{
		font-size: ${adjustFontSize(22)}px;
		line-height: 1.2;
		font-weight: 400;
	}

	h5{
		font-size: ${adjustFontSize(18)}px;
		line-height: 1.2;
	}

	h6{
		font-size: ${adjustFontSize(14)}px;
		line-height: 1.2;
	}

	button{
		display: inline-flex;
		justify-content: center;
		height: ${adjust(28)}px;
		line-height: ${adjust(28) - 2}px;
		border: 1px solid ${borderColor};
		color: ${textColor};
		border-radius: ${borderRadius}px;
		padding: 0 ${adjust(12)}px;
		background: ${backgroundColor};
		text-align: center;
		cursor: pointer;
		vertical-align: top;
		white-space: nowrap;
		overflow: hidden;
		text-overflow: ellipsis;
		
		&:hover, &:focus{
			border-color: #666;
			background-color: #666;
			color: #fff;
		}

		&:active{
			background: ${textColor};
			border-color: ${textColor};
			color: ${backgroundColor};
		}

		&:focus{
			box-shadow: 0 0 ${focusBlurRadius}px ${mainColor};
		}

		f-icon, f-icon-loading{
			&:first-child{
				margin-right: ${adjust(8)}px;
			}

			&:last-child{
				margin-left: ${adjust(8)}px;
			}

			&:only-child{
				margin-left: 0;
				margin-right: 0;
			}
		}

		&[primary]{
			background: ${mainColor};
			border-color: ${mainColor};
			color: #fff;

			&:hover, &:focus{
				background: ${mainColor.darken(15)};
				border-color: ${mainColor.darken(15)};
			}
		
			&:active{
				background: ${mainColor.darken(30)};
				border-color: ${mainColor.darken(30)};
			}
		}

		&[flat]{
			border: none;
			padding-left: 0;
			padding-right: 0;
			line-height: ${adjust(28)}px;

			&:hover, &:focus{
				background: none;
				color: ${textColor};
			}

			&:active{
				background: none;
			}

			&:focus{
				box-shadow: none;
			}
		}
	}

	a[primary]{
		color: ${mainColor};
	}

	label{
		font-weight: bold;
		font-size: ${adjustFontSize(13)}px;

		&[required]{
			&::after{
				position: relative;
				content: '*';
				color: ${errorColor};
				margin-left: 2px;
				top: ${adjust(-5)}px;
			}
		}

		f-icon{
			margin-left: 4px;
			color: ${textColor.toMiddle(20)};
		}
	}


	.fade-enter, .fade-leave{
		transition: opacity 0.2s ease-out;
	}
	
	.fade-enter-from, .fade-leave-to{
		opacity: 0;
	}
	
	.fade-enter-to, .fade-leave-from{
		opacity: 1;
	}


	::-webkit-scrollbar{
		height: 10px;
		width: 10px;
		background: ${backgroundColor.toMiddle(10)};
	}

	::-webkit-scrollbar-thumb{
		background: ${backgroundColor.toMiddle(30)};

		&:hover{
			background: ${backgroundColor.toMiddle(40)};
		}

		&:active{
			background: ${backgroundColor.toMiddle(50)};
		}
	}
`;
});


/***/ }),

/***/ "./node_modules/@pucelle/flit-ui/out/style/theme.js":
/*!**********************************************************!*\
  !*** ./node_modules/@pucelle/flit-ui/out/style/theme.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.theme = exports.Theme = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
const color_1 = __webpack_require__(/*! ./color */ "./node_modules/@pucelle/flit-ui/out/style/color.js");
class Theme {
    constructor() {
        this.themeMap = new Map();
        this.willUpdate = false;
        this.mode = 'light';
        this.options = Object.assign({}, defaultLightThemeOptions, defaultMediumThemeOptions);
    }
    defineTheme(name, options) {
        this.themeMap.set(name, options);
    }
    getThemeDrakOrLightMode(options) {
        if (options.backgroundColor) {
            let [r, g, b] = new color_1.Color(options.backgroundColor).getRGBA();
            if (ff_1.avg([r, g, b]) < 0.5) {
                return 'dark';
            }
        }
        else if (options.textColor) {
            let [r, g, b] = new color_1.Color(options.textColor).getRGBA();
            if (ff_1.avg([r, g, b]) > 0.5) {
                return 'dark';
            }
        }
        return 'light';
    }
    /** Assigns theme options to current options, so it may keep options of last theme. */
    changeTheme(...names) {
        for (let name of names) {
            if (!this.themeMap.has(name)) {
                throw new Error(`"${name}" is not a defined theme`);
            }
            Object.assign(this.options, this.themeMap.get(name));
        }
        this.mode = this.getThemeDrakOrLightMode(this.options);
        this.update();
    }
    set(key, value) {
        this.options[key] = value;
        this.update();
    }
    async update() {
        if (!this.willUpdate) {
            this.willUpdate = true;
            await Promise.resolve();
            flit_1.updateComponents();
            flit_1.updateStyles();
            this.willUpdate = false;
        }
    }
    getOption(property) {
        return this.options[property];
    }
    /**
     * Pass the px value for `font-size` on default theme settings, returns the size in current theme settings.
     * Returns value will be at least 11.
     */
    get adjustFontSize() {
        return (size) => {
            return Math.max(Math.round(size * this.fontSize / defaultMediumThemeOptions.fontSize), 11);
        };
    }
    /** Pass the px value for `line-height` on default theme settings, returns the line height in current theme settings. */
    get adjust() {
        return (size) => {
            return Math.round(size * this.lineHeight / defaultMediumThemeOptions.lineHeight);
        };
    }
    get mainColor() {
        return new color_1.Color(this.getOption('mainColor'));
    }
    get backgroundColor() {
        return new color_1.Color(this.getOption('backgroundColor'));
    }
    get textColor() {
        return new color_1.Color(this.getOption('textColor'));
    }
    get successColor() {
        return new color_1.Color(this.getOption('successColor'));
    }
    get errorColor() {
        return new color_1.Color(this.getOption('errorColor'));
    }
    get warningColor() {
        return new color_1.Color(this.getOption('warningColor'));
    }
    get infoColor() {
        return new color_1.Color(this.getOption('infoColor'));
    }
    get borderColor() {
        return new color_1.Color(this.getOption('borderColor'));
    }
    get borderRadius() {
        return this.getOption('borderRadius');
    }
    get popupBackgroundColor() {
        return new color_1.Color(this.getOption('popupBackgroundColor'));
    }
    get popupBorderRadius() {
        return this.getOption('popupBorderRadius');
    }
    get popupShadowBlurRadius() {
        return this.getOption('popupShadowBlurRadius');
    }
    get popupShadowColor() {
        return new color_1.Color(this.getOption('popupShadowColor'));
    }
    get focusBlurRadius() {
        return this.getOption('focusBlurRadius');
    }
    get fontSize() {
        return this.getOption('fontSize');
    }
    get lineHeight() {
        return this.getOption('lineHeight');
    }
}
exports.Theme = Theme;
const defaultLightThemeOptions = {
    mainColor: '#3a6cf6',
    backgroundColor: '#fff',
    textColor: '#000',
    infoColor: '#3369fa',
    successColor: '#29bc04',
    errorColor: '#e10000',
    warningColor: '#f3b907',
    borderColor: '#9b9b9b',
    popupBackgroundColor: '#fff',
    popupShadowColor: 'rgba(0, 0, 0, 0.4)',
};
const defaultMediumThemeOptions = {
    borderRadius: 4,
    popupBorderRadius: 4,
    popupShadowBlurRadius: 6,
    focusBlurRadius: 6,
    fontSize: 14,
    lineHeight: 28,
};
exports.theme = new Theme();
exports.theme.defineTheme('light', defaultLightThemeOptions);
exports.theme.defineTheme('dark', {
    mainColor: '#3a6cf6',
    backgroundColor: '#333',
    textColor: '#eee',
    borderColor: '#888',
    popupBackgroundColor: '#333',
    popupShadowColor: 'rgba(0, 0, 0, 0.6)',
});
exports.theme.defineTheme('small', {
    fontSize: 13,
    lineHeight: 24,
});
exports.theme.defineTheme('medium', defaultMediumThemeOptions);
exports.theme.defineTheme('large', {
    fontSize: 16,
    lineHeight: 32,
});
exports.theme.defineTheme('touch', {
    fontSize: 18,
    lineHeight: 46,
});


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/bindings/class.js":
/*!**********************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/bindings/class.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
const define_1 = __webpack_require__(/*! ./define */ "./node_modules/@pucelle/flit/out/bindings/define.js");
const component_1 = __webpack_require__(/*! ../component */ "./node_modules/@pucelle/flit/out/component/index.js");
/**
 * `:class="'class1 class2'"`
 * `:class="[class1, class2]"`
 * `:class="{class1: value1, class2: value2}"`
 * `:class.class-name="value"`
 */
define_1.defineBinding('class', class ClassNameBinding {
    constructor(el, context, modifiers) {
        this.lastClassNames = [];
        if (modifiers) {
            if (modifiers.length > 1) {
                throw new Error(`Modifier "${modifiers.join('.')}" is not allowed, at most one modifier as class name can be specified for ":class"`);
            }
            if (!/^\$?[\w-]+$/.test(modifiers[0])) {
                throw new Error(`Modifier "${modifiers[0]}" is not a valid class name`);
            }
        }
        this.el = el;
        this.modifiers = modifiers;
        this.scopeName = context ? context.el.localName : '';
        this.scopedClassNameSet = this.scopeName ? component_1.getScopedClassNameSet(this.scopeName) : undefined;
    }
    update(value) {
        let newClassNames = [];
        if (value) {
            newClassNames = this.parseClass(value);
        }
        for (let name of this.lastClassNames) {
            if (!newClassNames.includes(name)) {
                this.el.classList.remove(name);
            }
        }
        for (let name of newClassNames) {
            if (!this.lastClassNames.includes(name)) {
                this.el.classList.add(name);
            }
        }
        this.lastClassNames = newClassNames;
    }
    parseClass(value) {
        let o = {};
        if (this.modifiers) {
            if (value) {
                o[this.modifiers[0]] = true;
            }
        }
        else if (Array.isArray(value)) {
            for (let name of value) {
                o[name] = true;
            }
        }
        else if (value && typeof value === 'object') {
            for (let key of Object.keys(value)) {
                o[key] = !!value[key];
            }
        }
        else if (typeof value === 'string') {
            for (let name of value.split(/\s+/)) {
                if (name) {
                    o[name] = true;
                }
            }
        }
        let names = [];
        for (let name in o) {
            if (o[name]) {
                if (this.scopedClassNameSet && this.scopedClassNameSet.has(name)) {
                    name = name + '__' + this.scopeName;
                }
                names.push(name);
            }
        }
        return names;
    }
    remove() {
        if (this.lastClassNames) {
            this.el.classList.remove(...this.lastClassNames);
        }
    }
});


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/bindings/define.js":
/*!***********************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/bindings/define.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.refBinding = exports.createBindingFromResult = exports.BindingResult = exports.defineBinding = void 0;
const definedMap = new Map();
function defineBinding(name, Binding) {
    if (definedMap.has(name)) {
        console.warn(`You are trying to overwrite binding definition "${name}"`);
    }
    if (Binding) {
        definedMap.set(name, Binding);
        return function (...args) {
            return new BindingResult(name, ...args);
        };
    }
    else {
        return (Binding) => {
            return defineBinding(name, Binding);
        };
    }
}
exports.defineBinding = defineBinding;
function getBindingConstructor(name) {
    return definedMap.get(name);
}
/**
 * Returned from calling defined bindings like `show(...)`, `hide(...)`.
 * Used to cache arguments and update template later.
 * @typeparam A Arguments type.
 */
class BindingResult {
    constructor(name, ...args) {
        this.ref = null;
        this.name = name;
        this.args = args;
    }
}
exports.BindingResult = BindingResult;
/** Create binding and add ref on element. */
/** @hidden */
function createBindingFromResult(el, context, result, modifiers) {
    let BindingConstructor = getBindingConstructor(result.name);
    if (!BindingConstructor) {
        throw new Error(`":${result.name}" on "<${el.localName}>" is not a registered binding class`);
    }
    let binding = new BindingConstructor(el, context, modifiers);
    if (result.ref) {
        result.ref(binding);
    }
    binding.update(...result.args);
    return binding;
}
exports.createBindingFromResult = createBindingFromResult;
/** Reference to binding instance after it created and before update. */
function refBinding(result, ref) {
    result.ref = ref;
    return result;
}
exports.refBinding = refBinding;


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/bindings/enable-disable.js":
/*!*******************************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/bindings/enable-disable.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
const define_1 = __webpack_require__(/*! ./define */ "./node_modules/@pucelle/flit/out/bindings/define.js");
/**
 * `:enabled="boolean"`, it's opposite to `:disabled=...`.
 * It can be replaced with `?disabled=!...`, but by the meaning it gives, we should use a direct word `enabled`.
 */
define_1.defineBinding('enable', class EnableBinding {
    constructor(el) {
        this.el = el;
    }
    update(value) {
        if (value) {
            this.el.removeAttribute('disabled');
        }
        else {
            this.el.setAttribute('disabled', '');
        }
    }
    remove() {
        this.el.removeAttribute('disabled');
    }
});
/**
 * `:disabled="boolean"`, it's same with `?disabled=...`.
 */
define_1.defineBinding('disable', class DisabledBinding {
    constructor(el) {
        this.el = el;
    }
    update(value) {
        if (value) {
            this.el.setAttribute('disabled', '');
        }
        else {
            this.el.removeAttribute('disabled');
        }
    }
    remove() {
        this.el.removeAttribute('disabled');
    }
});


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/bindings/html.js":
/*!*********************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/bindings/html.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
const define_1 = __webpack_require__(/*! ./define */ "./node_modules/@pucelle/flit/out/bindings/define.js");
/**
 * `:html="${HTMLCodes}"`
 */
define_1.defineBinding('html', class HTMLBinding {
    constructor(el) {
        this.el = el;
    }
    update(value) {
        this.el.innerHTML = value === null || value === undefined ? '' : String(value);
    }
    remove() {
        this.el.innerHTML = '';
    }
});


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/bindings/index.js":
/*!**********************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/bindings/index.js ***!
  \**********************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __exportStar = (this && this.__exportStar) || function(m, exports) {
    for (var p in m) if (p !== "default" && !exports.hasOwnProperty(p)) __createBinding(exports, m, p);
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
var define_1 = __webpack_require__(/*! ./define */ "./node_modules/@pucelle/flit/out/bindings/define.js");
Object.defineProperty(exports, "defineBinding", ({ enumerable: true, get: function () { return define_1.defineBinding; } }));
Object.defineProperty(exports, "BindingResult", ({ enumerable: true, get: function () { return define_1.BindingResult; } }));
Object.defineProperty(exports, "createBindingFromResult", ({ enumerable: true, get: function () { return define_1.createBindingFromResult; } }));
Object.defineProperty(exports, "refBinding", ({ enumerable: true, get: function () { return define_1.refBinding; } }));
__webpack_require__(/*! ./class */ "./node_modules/@pucelle/flit/out/bindings/class.js");
__webpack_require__(/*! ./style */ "./node_modules/@pucelle/flit/out/bindings/style.js");
__webpack_require__(/*! ./model */ "./node_modules/@pucelle/flit/out/bindings/model.js");
__webpack_require__(/*! ./ref */ "./node_modules/@pucelle/flit/out/bindings/ref.js");
__webpack_require__(/*! ./html */ "./node_modules/@pucelle/flit/out/bindings/html.js");
__webpack_require__(/*! ./enable-disable */ "./node_modules/@pucelle/flit/out/bindings/enable-disable.js");
__webpack_require__(/*! ./src */ "./node_modules/@pucelle/flit/out/bindings/src.js");
__webpack_require__(/*! ./show-hide */ "./node_modules/@pucelle/flit/out/bindings/show-hide.js");
__exportStar(__webpack_require__(/*! ./show-hide */ "./node_modules/@pucelle/flit/out/bindings/show-hide.js"), exports);


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/bindings/model.js":
/*!**********************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/bindings/model.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
const define_1 = __webpack_require__(/*! ./define */ "./node_modules/@pucelle/flit/out/bindings/define.js");
const component_1 = __webpack_require__(/*! ../component */ "./node_modules/@pucelle/flit/out/component/index.js");
const dom_event_1 = __webpack_require__(/*! ../libs/dom-event */ "./node_modules/@pucelle/flit/out/libs/dom-event.js");
const ALLOWED_MODIFIERS = ['lazy', 'number'];
/**
 * Handle `:model="name"`, it binds and auto update a specified property name in current context
 * with the `<input>` or `<com>` which has `value` or `checked` property, and `change` event.
 * Supports `:model="a.b"`.
 * Model bind should only handle fixed model name.
 */
define_1.defineBinding('model', class ModelBinding {
    constructor(el, context, modifiers) {
        this.isBooleanValue = false;
        this.isMultiSelect = false;
        this.unwatch = null;
        if (!context) {
            throw new Error(`A context must be provided when using ":model=property"`);
        }
        if (modifiers) {
            if (modifiers.length > 2) {
                throw new Error(`Modifier "${modifiers.join('.')}" is not allowed, at most two modifiers can be specified for ":model"`);
            }
            for (let modifier of modifiers) {
                if (!ALLOWED_MODIFIERS.includes(modifier)) {
                    throw new Error(`Modifier "${modifiers}" is not allowed, it must be one of ${ALLOWED_MODIFIERS.map(m => `"${m}"`).join(', ')}`);
                }
            }
        }
        this.el = el;
        this.modifiers = modifiers;
        this.context = context;
        this.isComModel = el.localName.includes('-');
        if (this.isComModel) {
            this.property = 'value'; // or checked
            this.eventName = 'change';
        }
        else {
            let isFormField = ['input', 'select', 'textarea'].includes(el.localName);
            let isLazy = modifiers && modifiers[0] === 'lazy';
            this.isBooleanValue = el.localName === 'input' && (el.type === 'checkbox' || el.type === 'radio');
            this.isMultiSelect = el.localName === 'select' && el.multiple;
            if (this.isBooleanValue) {
                this.property = 'checked';
                this.eventName = 'change';
            }
            else if (isFormField) {
                this.property = 'value';
                this.eventName = isLazy ? 'change' : 'input';
            }
            // `div@contendeditable` cant trigger change and blur event but not input event
            else {
                this.property = 'innerHTML';
                this.eventName = isLazy ? 'blur' : 'input';
            }
        }
    }
    // Normally this should only be called for once.
    update(modelName) {
        if (!modelName || typeof modelName !== 'string') {
            throw new Error(`"${modelName}" is not a valid model name`);
        }
        this.modelName = modelName;
        if (this.isComModel) {
            let com = component_1.getComponent(this.el);
            if (com) {
                this.bindCom(com);
            }
            else {
                component_1.onComponentCreatedAt(this.el, this.bindCom.bind(this));
            }
        }
        else {
            this.watchContextModelValue();
            dom_event_1.on(this.el, this.eventName, this.onEventInputOrChange.bind(this));
        }
    }
    bindCom(com) {
        // Avoid bind event twice when model changed.
        if (!this.com) {
            this.com = com;
            // Some component use `checked` property as model value.
            if (com.hasOwnProperty('checked') && typeof com.checked === 'boolean') {
                this.property = 'checked';
            }
            com.on(this.eventName, this.setModelValueToContext, this);
        }
        this.watchContextModelValue();
    }
    watchContextModelValue() {
        if (this.unwatch) {
            this.unwatch();
        }
        // There is a problem here:
        // When the `:model` was included in a `if` part, it can't be unwatch after relatated element removed.
        // `:model` is convient but eval, isn't it?
        this.unwatch = this.context.watchImmediately(this.getModelValueFromContext.bind(this), this.setModelValueToTarget.bind(this));
    }
    getModelValueFromContext() {
        let properties = this.modelName.split('.');
        let value = this.context;
        for (let property of properties) {
            if (value && typeof value === 'object') {
                value = value[property];
            }
            else {
                value = undefined;
                break;
            }
        }
        return value;
    }
    setModelValueToContext(value) {
        let properties = this.modelName.split('.');
        let object = this.context;
        for (let i = 0; i < properties.length; i++) {
            let property = properties[i];
            if (object && typeof object === 'object') {
                if (i < properties.length - 1) {
                    object = object[property];
                }
                else {
                    object[property] = value;
                }
            }
            else {
                break;
            }
        }
    }
    onEventInputOrChange(_e) {
        let value;
        let isNumber = this.modifiers && this.modifiers.includes('number');
        if (this.isMultiSelect) {
            value = Array.from(this.el.options).filter(o => o.selected).map(o => o.value);
            if (isNumber) {
                value = value.map(Number);
            }
        }
        else {
            value = this.el[this.property];
            if (isNumber) {
                value = Number(value);
            }
        }
        this.setModelValueToContext(value);
    }
    setModelValueToTarget(value) {
        if (this.isComModel) {
            let com = this.com;
            if (com[this.property] !== value) {
                com[this.property] = value;
            }
        }
        else {
            this.setInputValue(value);
        }
    }
    setInputValue(value) {
        if (this.isMultiSelect && !Array.isArray(value)) {
            throw new Error(`:model="${this.modelName}" of select[multiple] requires an array as value`);
        }
        if (this.isMultiSelect) {
            for (let option of this.el.options) {
                option.selected = value.includes(option.value);
            }
        }
        else {
            let el = this.el;
            value = value === null || value === undefined ? '' : value;
            // Here need to avoid:
            //   input value changed ->
            //   write value to context ->
            //   trigger watcher ->
            //   write same value to input, which may cause cursor position lost.
            // So we must compare the value firstly.
            if (el[this.property] !== value) {
                el[this.property] = value;
            }
        }
    }
    remove() {
        this.setInputValue('');
    }
});


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/bindings/ref.js":
/*!********************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/bindings/ref.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
const define_1 = __webpack_require__(/*! ./define */ "./node_modules/@pucelle/flit/out/bindings/define.js");
/**
 * `:ref="name"`
 * `:ref="${this.onRef}"`
 */
define_1.defineBinding('ref', class RefBinding {
    constructor(el, context) {
        if (!context) {
            throw new Error(`A context must be provided when using ":ref"`);
        }
        this.el = el;
        this.context = context;
    }
    update(value) {
        if (typeof value === 'string') {
            this.context.refs[value] = this.el;
        }
        else if (typeof value === 'function') {
            value.call(this.context, this.el);
        }
    }
    remove() { }
});


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/bindings/show-hide.js":
/*!**************************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/bindings/show-hide.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.hide = exports.show = void 0;
const define_1 = __webpack_require__(/*! ./define */ "./node_modules/@pucelle/flit/out/bindings/define.js");
const directive_transition_1 = __webpack_require__(/*! ../libs/directive-transition */ "./node_modules/@pucelle/flit/out/libs/directive-transition.js");
/**
 * `:show="boolean"`
 * `show(visible: boolean, transition: TransitionOptions)`
 * `show(visible: boolean, options: {transition: TransitionOptions, enterAtStart, leaveAtStart, onend})`
 */
class ShowBinding {
    constructor(el, context) {
        this.value = undefined;
        this.el = el;
        this.transition = new directive_transition_1.DirectiveTransition(context);
    }
    update(value, options) {
        value = !!value;
        this.transition.updateOptions(options);
        if (value !== this.value) {
            if (value) {
                this.el.hidden = false;
                if (this.transition.shouldPlayEnter()) {
                    this.transition.playEnter(this.el);
                }
            }
            else {
                if (this.transition.shouldPlayLeave()) {
                    this.transition.playLeave(this.el).then(finish => {
                        if (finish) {
                            this.el.hidden = true;
                        }
                    });
                }
                else {
                    this.el.hidden = true;
                }
            }
            this.value = value;
        }
    }
    remove() {
        this.el.hidden = false;
    }
}
exports.show = define_1.defineBinding('show', ShowBinding);
/**
 * `:hide="boolean"`
 * `hide(hidden: boolean, transition: TransitionOptions)`
 * `hide(hidden: boolean, options: {transition: TransitionOptions, enterAtStart, leaveAtStart, onend})`
 */
class HideBinding extends ShowBinding {
    update(value, options) {
        super.update(!value, options);
    }
}
exports.hide = define_1.defineBinding('hide', HideBinding);


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/bindings/src.js":
/*!********************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/bindings/src.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
const define_1 = __webpack_require__(/*! ./define */ "./node_modules/@pucelle/flit/out/bindings/define.js");
const SrcLoadedURLs = new Set();
/**
 * `:src="${URL}"`
 * When reusing an image and reset it's src, it will keep old image until the new one loaded,
 * Which always confuse us.
 */
define_1.defineBinding('src', class SrcBinding {
    constructor(el) {
        /** Current resource location. */
        this.src = '';
        this.el = el;
    }
    update(value) {
        this.src = value;
        if (SrcLoadedURLs.has(value)) {
            this.el.src = value;
        }
        else if (value) {
            this.el.src = '';
            let img = new Image();
            img.onload = () => {
                SrcLoadedURLs.add(value);
                if (value === this.src) {
                    this.el.src = value;
                }
            };
            img.src = value;
        }
        else {
            this.el.src = '';
        }
    }
    remove() {
        this.el.src = '';
    }
});


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/bindings/style.js":
/*!**********************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/bindings/style.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
const define_1 = __webpack_require__(/*! ./define */ "./node_modules/@pucelle/flit/out/bindings/define.js");
const ALLOWED_MODIFIERS = ['px', 'percent', 'url'];
define_1.defineBinding('style', class StyleBinding {
    constructor(el, _context, modifiers) {
        this.lastStyle = {};
        if (modifiers) {
            if (modifiers.length > 2) {
                throw new Error(`Modifier "${modifiers.join('.')}" is not allowed, at most two modifiers (as style name property value modifier) can be specified for ":style"`);
            }
            if (modifiers.length === 2 && !ALLOWED_MODIFIERS.includes(modifiers[1])) {
                throw new Error(`Modifier "${modifiers[1]}" is not allowed, it must be one of ${ALLOWED_MODIFIERS.join(', ')}`);
            }
            if (!/^[\w-]+$/.test(modifiers[0]) || ALLOWED_MODIFIERS.includes(modifiers[0])) {
                throw new Error(`Modifier "${modifiers[0]}" is not a valid style property`);
            }
        }
        this.el = el;
        this.modifiers = modifiers;
    }
    update(value) {
        let oldStyleNames = Object.keys(this.lastStyle);
        let newStyle = this.parseStyle(value);
        let newStyleNames = Object.keys(newStyle);
        for (let name of oldStyleNames) {
            if (!newStyleNames.includes(name)) {
                this.el.style[name] = '';
            }
        }
        for (let name of newStyleNames) {
            if (!oldStyleNames.includes(name) || this.lastStyle[name] !== newStyle[name]) {
                this.setStyle(name, newStyle[name]);
            }
        }
        this.lastStyle = newStyle;
    }
    setStyle(name, value) {
        let unit = this.modifiers ? this.modifiers[1] : '';
        if (value === null || value === undefined) {
            value = '';
        }
        // Units like `s`, `deg` is very rare to use.
        else if (unit === 'px') {
            value = value + 'px';
        }
        else if (unit === 'percent') {
            value = value + '%';
        }
        else if (unit === 'url') {
            value = 'url("' + value + '")';
        }
        if (typeof value === 'number') {
            value = value + 'px';
        }
        this.el.style[name] = value;
    }
    parseStyle(style) {
        let o = {};
        if (this.modifiers) {
            if (style !== '' && style !== null && style !== undefined) {
                o[this.modifiers[0]] = style;
            }
        }
        else if (Array.isArray(style)) {
            for (let item of style.join(';').split(/\s*;\s*/)) {
                let [name, value] = item.split(/\s*:\s*/);
                if (name && value) {
                    o[name] = value;
                }
            }
        }
        else if (style && typeof style === 'object') {
            o = style;
        }
        else if (style && typeof style === 'string') {
            for (let item of style.split(/\s*;\s*/)) {
                let [name, value] = item.split(/\s*:\s*/);
                if (name && value) {
                    o[name] = value;
                }
            }
        }
        return o;
    }
    remove() {
        if (this.lastStyle) {
            for (let name of Object.keys(this.lastStyle)) {
                this.el.style[name] = '';
            }
        }
    }
});


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/component/component.js":
/*!***************************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/component/component.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Component = void 0;
const emitter_1 = __webpack_require__(/*! ../libs/emitter */ "./node_modules/@pucelle/flit/out/libs/emitter.js");
const template_1 = __webpack_require__(/*! ../template */ "./node_modules/@pucelle/flit/out/template/index.js");
const queue_1 = __webpack_require__(/*! ../queue */ "./node_modules/@pucelle/flit/out/queue.js");
const observer_1 = __webpack_require__(/*! ../observer */ "./node_modules/@pucelle/flit/out/observer/index.js");
const watcher_1 = __webpack_require__(/*! ../watcher */ "./node_modules/@pucelle/flit/out/watcher.js");
const style_1 = __webpack_require__(/*! ./style */ "./node_modules/@pucelle/flit/out/component/style.js");
const node_helper_1 = __webpack_require__(/*! ../libs/node-helper */ "./node_modules/@pucelle/flit/out/libs/node-helper.js");
const from_element_1 = __webpack_require__(/*! ./from-element */ "./node_modules/@pucelle/flit/out/component/from-element.js");
const life_cycle_1 = __webpack_require__(/*! ./life-cycle */ "./node_modules/@pucelle/flit/out/component/life-cycle.js");
const slot_1 = __webpack_require__(/*! ./slot */ "./node_modules/@pucelle/flit/out/component/slot.js");
/**
 * Super class of all the components, create automacially from custom elements connected into document.
 * @typeparam E Event interface in `{eventName: (...args) => void}` format.
 */
class Component extends emitter_1.Emitter {
    constructor(el) {
        super();
        /**
         * The reference map object of element inside.
         * You can specify `:ref="refName"` on an element,
         * or using `:ref=${this.onRef}` to call `this.onRef(refElement)` every time when the reference element updated.
         */
        // Should be `Element` type, but in 99% scenarios it's HTMLElement.
        this.refs = {};
        this.slots = {};
        this.__slotProcesser = null;
        this.__rootPart = null;
        this.__updated = false;
        this.__watcherGroup = null;
        this.__connected = false;
        this.__connectedBefore = false;
        this.__mustUpdate = true;
        this.el = el;
        return observer_1.observeComTarget(this);
    }
    /** Not called in constructor because in child classes it doesn't apply instance properties yet. */
    /** @hidden */
    __emitCreated() {
        from_element_1.setComponentAtElement(this.el, this);
        life_cycle_1.emitComponentCreatedCallbacks(this.el, this);
        this.onCreated();
        // A typescript issue here if we want to infer emitter arguments:
        // We accept an `Events` and union it with type `ComponentEvents`,
        // the returned type for `rendered` property will become `Events['rendered'] & () => void`,
        // `Parmaters<...>` of it will return the arguments of `Events['rendered']`.
        // So here show the issue that passed arguments `[]` can't be assigned to it.
        // This can't be fixed right now since we can't implement a type function like `interface overwritting`
        // But finally this was resolved by a newly defined type `ExtendEvents` in `emitter.ts`.
        // this.emit('created')
    }
    /** @hidden */
    __emitConnected() {
        // Not do following things when firstly connected.
        if (this.__connectedBefore) {
            // Must restore before updating, because the restored result may be changed when updating.
            observer_1.restoreAsDependency(this);
            if (this.__watcherGroup) {
                this.__watcherGroup.connect();
            }
        }
        else {
            this.__connectedBefore = true;
        }
        this.__connected = true;
        // Sometimes we may pre render but not connect component,
        // In this condition watchers of component are active and they keep notify component to update.
        // When connect the component, may no need to update.
        // Why `update` here but not `__updateImmediately`?
        // After component created, it may delete element belongs to other components in `onCreated`
        // Then in following micro task, the deleted components's `__connected` becomes false,
        // and they will not been updated finally as expected.
        if (this.__mustUpdate) {
            this.update();
        }
        this.onConnected();
        this.emit('connected');
        life_cycle_1.onComponentConnected(this);
    }
    /** @hidden */
    __emitDisconnected() {
        observer_1.clearDependencies(this);
        observer_1.clearAsDependency(this);
        if (this.__watcherGroup) {
            this.__watcherGroup.disconnect();
        }
        this.__connected = false;
        this.__mustUpdate = true;
        this.onDisconnected();
        this.emit('disconnected');
        life_cycle_1.onComponentDisconnected(this);
    }
    /** May be called in rendering, so we can avoid checking slot elements when no slot rendered. */
    /** @hidden */
    __foundSlotsWhenRendering() {
        // One potential issue here:
        // created -> child component created.
        //         -> element of child component removed, which also used as slot element of current component.
        //         -> render and initialize slots for current component.
        //         -> Can't found slot element because it was removed.
        if (!this.__slotProcesser && this.el.childNodes.length > 0) {
            this.__slotProcesser = new slot_1.SlotProcesser(this);
        }
        if (this.__slotProcesser) {
            this.__slotProcesser.needToFillSlotsLater();
        }
    }
    /** @hidden */
    __updateImmediately(force = false) {
        if (!this.__connected && !force) {
            this.__mustUpdate = true;
            return;
        }
        this.__mustUpdate = false;
        observer_1.startUpdating(this);
        try {
            let result = this.render();
            observer_1.endUpdating(this);
            if (this.__rootPart) {
                this.__rootPart.update(result);
            }
            else if (result !== null) {
                this.__rootPart = new template_1.NodePart(new node_helper_1.NodeAnchor(this.el, node_helper_1.NodeAnchorType.Root), result, this);
            }
        }
        catch (err) {
            observer_1.endUpdating(this);
            console.warn(err);
        }
        if (this.__slotProcesser) {
            this.__slotProcesser.mayFillSlots();
        }
        let firstlyUpdate = !this.__updated;
        if (firstlyUpdate) {
            this.onReady();
            this.__updated = true;
        }
        this.onUpdated();
    }
    /** Force to update all watchers binded to current context. */
    /** @hidden */
    __updateWatcherGroup() {
        if (this.__watcherGroup) {
            this.__watcherGroup.update();
        }
    }
    /**
     * Child class should implement this method, normally returns html`...` or string.
     * You can choose to not overwrite `render()` to keep it returns `null` when you don't want to render any child nodes.
     */
    render() {
        return null;
    }
    /**
     * Call this to partially or fully update asynchronously if needed.
     * You should not overwrite this method until you know what you are doing.
     */
    update() {
        queue_1.enqueueComponentToUpdate(this);
    }
    /**
     * Called when component instance was just created and all properties assigned.
     * Original child nodes are prepared, but slots are not prepared right now.
     * You may changed some data or visit parent nodes or `this.el` and operate them here.
     */
    onCreated() { }
    /**
     * Called after all the data updated for the first time.
     * Child nodes are rendered, slots are prepared, but child components are not.
     * Will keep updating other components, so please don't check computed styles on elements.
     * You may visit child nodes or bind events here.
     */
    onReady() { }
    /**
     * Called after all the data updated.
     * Will keep updating other components, so please don't check computed style on elements.
     */
    onUpdated() { }
    /**
     * Called after all the data updated and elements have rendered.
     * You can visit elemenet layout properties now.
     */
    onRendered() { }
    /**
     * Called when root element was inserted into document.
     * This will be called for each time you insert the element into document.
     * If you need to register global listeners like `resize` when element in document, restore them here.
     */
    onConnected() { }
    /**
     * Called when root element removed from document.
     * This will be called for each time you removed the element into document.
     * If you registered global listeners like `resize`, don't forget to unregister them here.
     */
    onDisconnected() { }
    /**
     * Watch return value of function and trigger callback with this value as argument after it changed.
     * Will set callback scope as this.
     */
    watch(fn, callback) {
        this.__watcherGroup = this.__watcherGroup || new watcher_1.WatcherGroup();
        return this.__watcherGroup.watch(fn, callback.bind(this));
    }
    /**
     * Watch return value of function and trigger callback with this value as argument later and after it changed.
     * Will set callback scope as this.
     */
    watchImmediately(fn, callback) {
        this.__watcherGroup = this.__watcherGroup || new watcher_1.WatcherGroup();
        return this.__watcherGroup.watchImmediately(fn, callback.bind(this));
    }
    /**
     * Watch return value of function and trigger callback with this value as argument. Trigger callback for only once.
     * Will set callback scope as this.
     */
    watchOnce(fn, callback) {
        this.__watcherGroup = this.__watcherGroup || new watcher_1.WatcherGroup();
        return this.__watcherGroup.watchOnce(fn, callback.bind(this));
    }
    /**
     * Watch return value of function and trigger callback with this value as argument. Trigger callback for only once.
     * Will set callback scope as this.
     */
    watchUntil(fn, callback) {
        this.__watcherGroup = this.__watcherGroup || new watcher_1.WatcherGroup();
        return this.__watcherGroup.watchUntil(fn, callback.bind(this));
    }
    /** @hidden */
    __addWatcher(watcher) {
        this.__watcherGroup = this.__watcherGroup || new watcher_1.WatcherGroup();
        this.__watcherGroup.add(watcher);
    }
    /** @hidden */
    __deleteWatcher(watcher) {
        this.__watcherGroup = this.__watcherGroup || new watcher_1.WatcherGroup();
        this.__watcherGroup.delete(watcher);
    }
    /** returns scoped class name E `.name -> .name__com-name` */
    scopeClassName(className) {
        let startsWithDot = className[0] === '.';
        let classNameWithoutDot = startsWithDot ? className.slice(1) : className;
        let scopedClassNameSet = style_1.getScopedClassNameSet(this.el.localName);
        if (scopedClassNameSet && scopedClassNameSet.has(classNameWithoutDot)) {
            return className + '__' + this.el.localName;
        }
        else {
            return className;
        }
    }
}
exports.Component = Component;
/**
 * The static `style` property contains style text used as styles for current component.
 * Styles in it will be partialy scoped, so we have benefits of scoped styles,
 * and also avoid the problems in sharing styles.
 *
 * symbol `$` in class name will be replaced to current component name:
 * `.$title` -> `.title__com-name`
 *
 * tag selector will be nested in com-name selector:
 * `p` -> `com-name p`
 */
Component.style = null;


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/component/constructor.js":
/*!*****************************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/component/constructor.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.getComponentConstructor = exports.defineComponentConstructor = void 0;
/** To cache `name -> component constructor` */
const componentConstructorMap = new Map();
/**
 * Define a component with specified name and class, called by `define()`.
 * @param name The component name, same with `define()`.
 * @param Com The component class.
 */
function defineComponentConstructor(name, Com) {
    if (componentConstructorMap.has(name)) {
        console.warn(`You are trying to overwrite component definition "${name}"`);
    }
    componentConstructorMap.set(name, Com);
}
exports.defineComponentConstructor = defineComponentConstructor;
/**
 * Get component constructor from name, then we can instantiate it.
 * @param name The component name, same with `define()`.
 * @param Com The component class.
 */
function getComponentConstructor(name) {
    return componentConstructorMap.get(name);
}
exports.getComponentConstructor = getComponentConstructor;


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/component/define.js":
/*!************************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/component/define.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.createComponent = exports.define = void 0;
const style_1 = __webpack_require__(/*! ./style */ "./node_modules/@pucelle/flit/out/component/style.js");
const constructor_1 = __webpack_require__(/*! ./constructor */ "./node_modules/@pucelle/flit/out/component/constructor.js");
const from_element_1 = __webpack_require__(/*! ./from-element */ "./node_modules/@pucelle/flit/out/component/from-element.js");
function define(name, Com) {
    if (!name.includes('-')) {
        throw new Error(`"${name}" can't be defined as custom element, it must contain "-"`);
    }
    // Used at `@define` decorator.
    if (!Com) {
        return function (Com) {
            define(name, Com);
        };
    }
    customElements.define(name, class CustomLitElement extends HTMLElement {
        // When `connectedCallback` called on elements in start HTML Document, the child nodes of it is not ready yet.
        // So we must render all the codes in js.
        // Note that it will be called when insert element to a fragment.
        // If we insert bundled js behind all other elements, or with `defer`,
        // because elements were prepared already, then they will be instantiated in component registered order, not in element order.
        // We fix this by the `connectSoonMap`, it output elements in order when iterating.
        connectedCallback() {
            enqueueConnect(this, Com);
        }
        // Moving element using like `append` will also trigger this.
        disconnectedCallback() {
            enqueueDisconnect(this, Com);
        }
    });
    constructor_1.defineComponentConstructor(name, Com);
    return undefined;
}
exports.define = define;
// Using queue to delay the connect and disconnect operations on components.
// Both `connectedCallback` and `disconnectedCallback` may triggered multiple times in DOM removing,
// so we must delay the component connect and disconnect operation by a queue.
let connectSoonMap = new Map();
let disconnectSoonMap = new Map();
function enqueueConnect(el, Com) {
    // When append, trigger disconnect and connect soon.
    if (disconnectSoonMap.has(el)) {
        disconnectSoonMap.delete(el);
    }
    else {
        connectSoonMap.set(el, Com);
        disconnectSoonMap.delete(el);
        if (!willUpdate) {
            enqueueUpdate();
        }
    }
}
function enqueueDisconnect(el, Com) {
    // When inserted into a fragment and then removed.
    if (connectSoonMap.has(el)) {
        connectSoonMap.delete(el);
    }
    else {
        disconnectSoonMap.set(el, Com);
        if (!willUpdate) {
            enqueueUpdate();
        }
    }
}
let willUpdate = false;
function enqueueUpdate() {
    Promise.resolve().then(update);
    willUpdate = true;
}
function update() {
    let connectMap = connectSoonMap;
    // Very import, more connect and disconnect requests may be added when updating.
    // So we must reset `connectSoonMap` and `disconnectSoonMap` and set `willUpdate` to false before updating.
    connectSoonMap = new Map();
    willUpdate = false;
    // `el` was sorted inside map.
    for (let [el, Com] of connectMap.entries()) {
        // `el` may not in document,
        // e.g., inserted into a fragment.
        // No need to worry about forgetting to instantiate it,
        // it will trigger `connectedCallback` again after insert into document.
        // Here also have a small rate document not contains el.
        connectElement(el, Com);
    }
    // We disconnect elements later to avoid it slow following rendering.
    requestAnimationFrame(() => {
        let disconnectMap = disconnectSoonMap;
        disconnectSoonMap = new Map();
        for (let el of disconnectMap.keys()) {
            disconnectElement(el);
        }
    });
}
function connectElement(el, Com) {
    let com = from_element_1.getComponent(el);
    if (!com) {
        com = createComponent(el, Com);
    }
    com.__emitConnected();
}
function disconnectElement(el) {
    let com = from_element_1.getComponent(el);
    if (com) {
        com.__emitDisconnected();
    }
}
/** Export for `renderComponent`, which will create component manually. */
/** @hidden */
function createComponent(el, Com) {
    style_1.ensureComponentStyle(Com, el.localName);
    let com = new Com(el);
    com.__emitCreated();
    return com;
}
exports.createComponent = createComponent;


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/component/from-element.js":
/*!******************************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/component/from-element.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.getClosestComponent = exports.getComponentAsync = exports.getComponent = exports.setComponentAtElement = void 0;
const life_cycle_1 = __webpack_require__(/*! ./life-cycle */ "./node_modules/@pucelle/flit/out/component/life-cycle.js");
/** To cache `el -> com` map */
const elementComponentMap = new WeakMap();
/**
 * Set component instance at root element.
 */
function setComponentAtElement(el, com) {
    elementComponentMap.set(el, com);
}
exports.setComponentAtElement = setComponentAtElement;
/**
 * Get component instance from root element.
 * @param el The element to get component instance at.
 */
function getComponent(el) {
    return elementComponentMap.get(el);
}
exports.getComponent = getComponent;
/**
 * Get component instance from root element asynchronously.
 * @param el The element to get component instance at.
 */
function getComponentAsync(el) {
    if (el.localName.includes('-')) {
        let com = elementComponentMap.get(el);
        if (com) {
            return Promise.resolve(com);
        }
        else {
            return new Promise(resolve => {
                life_cycle_1.onComponentCreatedAt(el, resolve);
            });
        }
    }
    else {
        return Promise.resolve(undefined);
    }
}
exports.getComponentAsync = getComponentAsync;
/**
 * Get closest ancestor component which instanceof `Com`.
 * It's very common that you extend a component and define a new custom element,
 * So you will can't find the parent component from the tag name.
 * Bu you can also search super class by this method.
 * @param el The element to search from it and it's ancestors for component instance.
 * @param Com The component constructor to search.
 */
function getClosestComponent(el, Com) {
    let parent = el;
    while (parent && parent instanceof HTMLElement) {
        if (parent.localName.includes('-')) {
            let com = getComponent(parent);
            if (com instanceof Com) {
                return com;
            }
        }
        parent = parent.parentElement;
    }
    return null;
}
exports.getClosestComponent = getClosestComponent;


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/component/index.js":
/*!***********************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/component/index.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
var constructor_1 = __webpack_require__(/*! ./constructor */ "./node_modules/@pucelle/flit/out/component/constructor.js");
Object.defineProperty(exports, "getComponentConstructor", ({ enumerable: true, get: function () { return constructor_1.getComponentConstructor; } }));
var component_1 = __webpack_require__(/*! ./component */ "./node_modules/@pucelle/flit/out/component/component.js");
Object.defineProperty(exports, "Component", ({ enumerable: true, get: function () { return component_1.Component; } }));
var from_element_1 = __webpack_require__(/*! ./from-element */ "./node_modules/@pucelle/flit/out/component/from-element.js");
Object.defineProperty(exports, "getComponent", ({ enumerable: true, get: function () { return from_element_1.getComponent; } }));
Object.defineProperty(exports, "getComponentAsync", ({ enumerable: true, get: function () { return from_element_1.getComponentAsync; } }));
Object.defineProperty(exports, "getClosestComponent", ({ enumerable: true, get: function () { return from_element_1.getClosestComponent; } }));
var life_cycle_1 = __webpack_require__(/*! ./life-cycle */ "./node_modules/@pucelle/flit/out/component/life-cycle.js");
Object.defineProperty(exports, "onComponentCreatedAt", ({ enumerable: true, get: function () { return life_cycle_1.onComponentCreatedAt; } }));
Object.defineProperty(exports, "updateComponents", ({ enumerable: true, get: function () { return life_cycle_1.updateComponents; } }));
var style_1 = __webpack_require__(/*! ./style */ "./node_modules/@pucelle/flit/out/component/style.js");
Object.defineProperty(exports, "getScopedClassNameSet", ({ enumerable: true, get: function () { return style_1.getScopedClassNameSet; } }));
Object.defineProperty(exports, "addGlobalStyle", ({ enumerable: true, get: function () { return style_1.addGlobalStyle; } }));
Object.defineProperty(exports, "updateStyles", ({ enumerable: true, get: function () { return style_1.updateStyles; } }));
var define_1 = __webpack_require__(/*! ./define */ "./node_modules/@pucelle/flit/out/component/define.js");
Object.defineProperty(exports, "define", ({ enumerable: true, get: function () { return define_1.define; } }));
Object.defineProperty(exports, "createComponent", ({ enumerable: true, get: function () { return define_1.createComponent; } }));


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/component/life-cycle.js":
/*!****************************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/component/life-cycle.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.updateComponents = exports.onComponentDisconnected = exports.onComponentConnected = exports.emitComponentCreatedCallbacks = exports.onComponentCreatedAt = void 0;
const watcher_1 = __webpack_require__(/*! ../watcher */ "./node_modules/@pucelle/flit/out/watcher.js");
/** To cache callbacks after component initialized */
const componentCreatedMap = new WeakMap();
/** Call callbacks after component instance created. */
function onComponentCreatedAt(el, callback) {
    let callbacks = componentCreatedMap.get(el);
    if (!callbacks) {
        componentCreatedMap.set(el, (callbacks = []));
    }
    callbacks.push(callback);
}
exports.onComponentCreatedAt = onComponentCreatedAt;
/** may assign properties from `:props`, or bind component events from `@com-event` */
function emitComponentCreatedCallbacks(el, com) {
    let callbacks = componentCreatedMap.get(el);
    if (callbacks) {
        for (let callback of callbacks) {
            callback(com);
        }
        componentCreatedMap.delete(el);
    }
}
exports.emitComponentCreatedCallbacks = emitComponentCreatedCallbacks;
/** To mark all the connected components */
const connectedComponentSet = new Set();
function onComponentConnected(com) {
    connectedComponentSet.add(com);
}
exports.onComponentConnected = onComponentConnected;
function onComponentDisconnected(com) {
    connectedComponentSet.delete(com);
}
exports.onComponentDisconnected = onComponentDisconnected;
/** Update all components, watchers. e.g., when language changed. */
function updateComponents() {
    watcher_1.globalWatcherGroup.update();
    for (let com of connectedComponentSet) {
        // Why didn't handle watcher group updating in `update`:
        // Component collect dependencies from `render` function and update it by `update`,
        // while each watchers in watcher group do the similar thing.
        com.update();
        com.__updateWatcherGroup();
    }
}
exports.updateComponents = updateComponents;


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/component/slot.js":
/*!**********************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/component/slot.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SlotProcesser = void 0;
const node_helper_1 = __webpack_require__(/*! ../libs/node-helper */ "./node_modules/@pucelle/flit/out/libs/node-helper.js");
class SlotProcesser {
    constructor(com) {
        this.restSlotNodeRange = null;
        // When updated inner templates and found there are slots need to be filled, This value will become `true`.
        // Why not just move slots into template fragment?
        //   1. It will trigger `connectedCallback` when append into fragment.
        //   2. To handle all `<slot>` elements in one query would be better.
        this.hasSlotsToBeFilled = false;
        this.com = com;
        this.initNamedSlotNodes();
        this.initRestSlotRange();
    }
    // Here we cache slot nodes when we detected there is `<slot>` in the template,
    // And only for once..
    // So if those named slot element were removed before or created dynamically in the future,
    // We can't capture this and update name slot elements.
    initNamedSlotNodes() {
        let slots = this.com.slots;
        // We only check `[slot]` in the children, or:
        // <com1><com2><el slot="for com2"></com2></com1>
        // it will cause `slot` for `com2` was captured by `com1`.
        for (let el of [...this.com.el.children]) {
            let slotName = el.getAttribute('slot');
            if (slotName) {
                let els = slots[slotName];
                if (!els) {
                    els = slots[slotName] = [];
                }
                els.push(el);
                // No need to remove `slot` attribute here, bacause we only check child slot elements, not check deeper.
                // So it can avoid been treated as slot element again after moved into an outer component
                el.remove();
            }
        }
    }
    // It's very import to cache rest nodes after child created and before rendering,
    // because these nodes may be changed since child nodes may be removed when child components created.
    // Otherwise those nodes may be firstly removed and then restored from `<slot />`, so we must cache before rendering.
    initRestSlotRange() {
        let fragment = document.createDocumentFragment();
        fragment.append(...this.com.el.childNodes);
        this.restSlotNodeRange = new node_helper_1.NodeRange(fragment);
    }
    needToFillSlotsLater() {
        this.hasSlotsToBeFilled = true;
    }
    mayFillSlots() {
        if (!this.hasSlotsToBeFilled) {
            return;
        }
        let slots = this.com.slots;
        let slotAnchors = this.com.el.querySelectorAll('slot');
        for (let slotAnchor of slotAnchors) {
            let name = slotAnchor.getAttribute('name');
            if (name) {
                if (slots && slots[name] && slotAnchor.firstChild !== slots[name][0]) {
                    while (slotAnchor.firstChild) {
                        slotAnchor.firstChild.remove();
                    }
                    slotAnchor.append(...slots[name]);
                }
            }
            else if (this.restSlotNodeRange && slotAnchor.firstChild !== this.restSlotNodeRange.startNode) {
                while (slotAnchor.firstChild) {
                    slotAnchor.firstChild.remove();
                }
                slotAnchor.append(this.restSlotNodeRange.getFragment());
            }
        }
        this.hasSlotsToBeFilled = false;
    }
}
exports.SlotProcesser = SlotProcesser;


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/component/style.js":
/*!***********************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/component/style.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.getScopedClassNameSet = exports.updateStyles = exports.addGlobalStyle = exports.ensureComponentStyle = void 0;
const queue_1 = __webpack_require__(/*! ../queue */ "./node_modules/@pucelle/flit/out/queue.js");
// At beginning, we remove styles when they are no needed, but later we decided to always keep them,
// because we think that removing style tags will affect rendering performance.
// Here is a benchmark: https://jsperf.com/is-removing-style-affect-rendering-performance
/** Cache `Component` -> {style element, referenced count} */
const componentStyleTagMap = new Map();
const globalStyleTagSet = new Set();
/** Called when component was connected. */
function ensureComponentStyle(Com, name) {
    if (Com.style) {
        if (!componentStyleTagMap.has(Com)) {
            let styleTag = createStyle(Com.style, name);
            componentStyleTagMap.set(Com, styleTag);
        }
    }
}
exports.ensureComponentStyle = ensureComponentStyle;
/** Create <style> tag and insert it into body. */
function createStyle(style, name) {
    let styleTag = document.createElement('style');
    styleTag.setAttribute('name', name);
    styleTag.textContent = getStyleContent(style, name === 'global' ? '' : name);
    document.head.append(styleTag);
    return styleTag;
}
/** Get style text from static style property. */
function getStyleContent(style, scopeName) {
    if (typeof style === 'function') {
        style = style();
    }
    return StyleParser.parse(String(style), scopeName === 'global' ? '' : scopeName);
}
/** Add global style codes. */
function addGlobalStyle(style) {
    let styleTag = createStyle(style, 'global');
    globalStyleTagSet.add([style, styleTag]);
    return styleTag;
}
exports.addGlobalStyle = addGlobalStyle;
/** Update all styles for components, you can update styles after theme changed. */
// `updateStyles` should always been called along with `update`,
// So we may need to makesure `updateStyles` in the same micro task with `update`.
function updateStyles() {
    queue_1.onRenderComplete(() => {
        let styleAndTags = [...globalStyleTagSet];
        for (let [Com, styleTag] of componentStyleTagMap) {
            if (Com.style && styleTag) {
                styleAndTags.push([Com.style, styleTag]);
            }
        }
        for (let [style, styleTag] of styleAndTags) {
            if (typeof style === 'function') {
                let newContent = getStyleContent(style, styleTag.getAttribute('name'));
                if (newContent !== styleTag.textContent) {
                    styleTag.textContent = newContent;
                }
            }
        }
    });
}
exports.updateStyles = updateStyles;
/** Parse style, remove nesting selectors and scope them. */
var StyleParser;
(function (StyleParser) {
    /** Cache `Component` -> {style element, referenced count} */
    StyleParser.scopedClassNameSetMap = new Map();
    function getScopedClassNameSet(comName) {
        return StyleParser.scopedClassNameSetMap.get(comName);
    }
    StyleParser.getScopedClassNameSet = getScopedClassNameSet;
    function parse(text, comName) {
        let re = /(\s*)(?:\/\/.*|\/\*[\s\S]*?\*\/|((?:\(.*?\)|".*?"|'.*?'|[\s\S])*?)([;{}]))/g;
        /*
            \s* - match white spaces in left
            (?:
                \/\/.* - match comment line
                |
                \/\*[\s\S]*?\*\/ - match comment seagment
                |
                (?:
                    \(.*?\) - (...), sass code may include @include fn(${name})
                    ".*?" - double quote string
                    |
                    '.*?' - double quote string
                    |
                    [\s\S] - others
                )*? - declaration or selector
                ([;{}])
            )
        */
        let match;
        let stack = [];
        let current;
        let codes = '';
        let classNameSet;
        let keyframesDeep = 0;
        if (comName) {
            // May add more scoped class name when using `render` or `renderAndUpdate`.
            classNameSet = StyleParser.scopedClassNameSetMap.get(comName);
            if (!classNameSet) {
                classNameSet = new Set();
                StyleParser.scopedClassNameSetMap.set(comName, classNameSet);
            }
        }
        while (match = re.exec(text)) {
            let spaces = match[1];
            let chars = match[2];
            let endChar = match[3];
            if (endChar === '{' && chars) {
                // Commands likes `@media` must in the out most level.
                if (chars[0] === '@' || keyframesDeep > 0) {
                    codes += match[0];
                    if (chars.startsWith('@keyframes')) {
                        keyframesDeep = 1;
                    }
                    else if (keyframesDeep > 0) {
                        keyframesDeep++;
                    }
                }
                else {
                    if (current) {
                        stack.push(current);
                        codes += '}';
                    }
                    let names = current = parseToNames(chars, current, comName);
                    if (comName) {
                        names = current.map(name => scopeClassName(name, comName, classNameSet));
                    }
                    codes += spaces + names.join(', ') + '{';
                }
            }
            // May also be end paren `@media{...}`, but it's can't be included in any selectors.
            else if (endChar === '}') {
                if (keyframesDeep > 0) {
                    keyframesDeep--;
                }
                current = stack.pop();
                // Not add `}` for sass like nesting.
                if (!current) {
                    codes += match[0];
                }
            }
            else {
                // Skip `/*...*/` and `//...`
                let startChar = match[0][spaces.length];
                if (startChar !== '/') {
                    codes += match[0];
                }
            }
        }
        return codes;
    }
    StyleParser.parse = parse;
    function parseToNames(selector, current, comName) {
        let re = /((?:\[.*?\]|\(.*?\)|[\s\S])+?)(?:,|$)/g;
        /*
            (?:
                \[.*?\] - match [...]
                |
                \(.*?\) - match (...)
                |
                . - match other characters
            )
            +?
            (?:,|$) - if match ',' or '$', end
        */
        let match;
        let names = [];
        while (match = re.exec(selector)) {
            let name = match[1].trim();
            if (name) {
                if (!current) {
                    name = scopeTagSelector(name, comName);
                }
                names.push(name);
            }
        }
        if (current) {
            names = combineNestingNames(names, current);
        }
        return names;
    }
    function combineNestingNames(oldNames, parentNames) {
        // Has sass reference `&` if match
        let re = /(^|[\s+>~])&/g; // `/(?<=^|[\s+>~])&/g` should be better, but Firefox not support it.
        let names = [];
        for (let oldName of oldNames) {
            if (re.test(oldName)) {
                for (let parentName of parentNames) {
                    names.push(oldName.replace(re, '$1' + parentName));
                }
            }
            else {
                for (let parentName of parentNames) {
                    names.push(parentName + ' ' + oldName);
                }
            }
        }
        return names;
    }
    // Benchmark about nested selector: https://jsperf.com/is-nesting-selector-slower
    // About 2~4% slower for each nested selector when rendering.
    /** `.name` -> `.name__com-name` */
    function scopeClassName(name, comName, classNameSet) {
        return name.replace(/\.([\w-]+)/g, (m0, name) => {
            if (m0.includes('__')) {
                return m0;
            }
            else {
                classNameSet.add(name);
                return m0 + '__' + comName;
            }
        });
    }
    /**
     * `p` -> `com-name p`.
     * `:host` -> `com-name`.
     * One style may be used in multiple component, `:host` can be replaced to specified `com-name` dynamically.
     */
    function scopeTagSelector(name, comName) {
        return name.replace(/^(?=\w)/g, comName + ' ')
            .replace(/:host/g, comName);
    }
})(StyleParser || (StyleParser = {}));
exports.getScopedClassNameSet = StyleParser.getScopedClassNameSet;


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/directives/cache.js":
/*!************************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/directives/cache.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.cache = exports.CacheDirective = void 0;
const define_1 = __webpack_require__(/*! ./define */ "./node_modules/@pucelle/flit/out/directives/define.js");
const template_1 = __webpack_require__(/*! ../template */ "./node_modules/@pucelle/flit/out/template/index.js");
const node_helper_1 = __webpack_require__(/*! ../libs/node-helper */ "./node_modules/@pucelle/flit/out/libs/node-helper.js");
const directive_transition_1 = __webpack_require__(/*! ../libs/directive-transition */ "./node_modules/@pucelle/flit/out/libs/directive-transition.js");
class CacheDirective {
    constructor(anchor, context) {
        this.templates = [];
        this.currentTemplate = null;
        this.anchor = anchor;
        this.context = context;
        this.transition = new directive_transition_1.DirectiveTransition(context);
    }
    canMergeWith(_result) {
        return true;
    }
    merge(result, options) {
        this.transition.updateOptions(options);
        if (result) {
            if (this.currentTemplate && this.currentTemplate.canMergeWith(result)) {
                this.currentTemplate.merge(result);
            }
            else {
                if (this.currentTemplate) {
                    this.cacheCurrentTemplate();
                }
                let template = this.templates.find(t => t.canMergeWith(result));
                if (template) {
                    template.merge(result);
                    this.anchor.insert(template.range.getFragment());
                    this.playEnterTransition(template);
                    this.currentTemplate = template;
                }
                else {
                    this.initNewResult(result);
                }
            }
        }
        else {
            if (this.currentTemplate) {
                this.cacheCurrentTemplate();
            }
        }
    }
    async playEnterTransition(template) {
        let firstElement = template.range.getFirstElement();
        if (firstElement) {
            await this.transition.playEnter(firstElement);
        }
    }
    initNewResult(result) {
        let template = new template_1.Template(result, this.context);
        let fragment = template.range.getFragment();
        this.anchor.insert(fragment);
        if (this.transition.shouldPlayEnter()) {
            this.playEnterTransition(template);
        }
        this.currentTemplate = template;
        this.templates.push(template);
    }
    async cacheCurrentTemplate() {
        let template = this.currentTemplate;
        let firstElement = template.range.getFirstElement();
        // Cached elements have been moved, reset the anchor node to current parent node.
        if (this.anchor.type === node_helper_1.NodeAnchorType.Next && firstElement && firstElement.parentNode && firstElement.parentNode !== this.anchor.el.parentNode) {
            this.anchor = new node_helper_1.NodeAnchor(firstElement.parentNode, node_helper_1.NodeAnchorType.Parent);
        }
        if (this.transition.shouldPlay() && firstElement) {
            this.transition.playLeave(firstElement).then((finish) => {
                if (finish) {
                    template.range.cacheFragment();
                }
            });
        }
        else {
            template.range.cacheFragment();
        }
        this.currentTemplate = null;
    }
    remove() {
        if (this.currentTemplate) {
            this.currentTemplate.remove();
        }
    }
}
exports.CacheDirective = CacheDirective;
/**
 * When returned vlaue of `result` changed, this directive will try to reuse old rendered elements.
 * Note that when old rendering result restored, the scroll positions in it will fall back to start position.
 * @param result The html`...` result, can be null or empty string. This value may change when rerendering.
 */
exports.cache = define_1.defineDirective(CacheDirective);


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/directives/define.js":
/*!*************************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/directives/define.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.refDirective = exports.createDirectiveFromResult = exports.DirectiveResult = exports.defineDirective = void 0;
let seed = 0;
const directiveMap = new Map();
/**
 * Defines a directive from a class which implements `Directive`.
 * Returns a function call which will generate a `DirectiveResult`.
 * A `Directive` works like Binding, but it used to generate HTML code pieces,
 * not like `Binding` to modify properties of an element.
 */
function defineDirective(Dir) {
    let id = seed++;
    directiveMap.set(id, Dir);
    return function (...args) {
        return new DirectiveResult(id, ...args);
    };
}
exports.defineDirective = defineDirective;
/**
 * Returned from calling directive functions like `repeat`.
 * Used to cache arguments and update template later.
 */
class DirectiveResult {
    constructor(id, ...args) {
        this.ref = null;
        this.id = id;
        this.args = args;
    }
}
exports.DirectiveResult = DirectiveResult;
/** Create directive from directive result. used in `node.ts` */
/** @hidden */
function createDirectiveFromResult(anchor, context, result) {
    let Dir = directiveMap.get(result.id);
    let directive = new Dir(anchor, context);
    if (result.ref) {
        result.ref(directive);
    }
    directive.merge(...result.args);
    return directive;
}
exports.createDirectiveFromResult = createDirectiveFromResult;
/** Reference to directive instance after it created and before merge. */
function refDirective(result, ref) {
    result.ref = ref;
    return result;
}
exports.refDirective = refDirective;


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/directives/index.js":
/*!************************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/directives/index.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
var define_1 = __webpack_require__(/*! ./define */ "./node_modules/@pucelle/flit/out/directives/define.js");
Object.defineProperty(exports, "defineDirective", ({ enumerable: true, get: function () { return define_1.defineDirective; } }));
Object.defineProperty(exports, "refDirective", ({ enumerable: true, get: function () { return define_1.refDirective; } }));
Object.defineProperty(exports, "DirectiveResult", ({ enumerable: true, get: function () { return define_1.DirectiveResult; } }));
Object.defineProperty(exports, "createDirectiveFromResult", ({ enumerable: true, get: function () { return define_1.createDirectiveFromResult; } }));
var cache_1 = __webpack_require__(/*! ./cache */ "./node_modules/@pucelle/flit/out/directives/cache.js");
Object.defineProperty(exports, "cache", ({ enumerable: true, get: function () { return cache_1.cache; } }));
Object.defineProperty(exports, "CacheDirective", ({ enumerable: true, get: function () { return cache_1.CacheDirective; } }));
var play_1 = __webpack_require__(/*! ./play */ "./node_modules/@pucelle/flit/out/directives/play.js");
Object.defineProperty(exports, "play", ({ enumerable: true, get: function () { return play_1.play; } }));
Object.defineProperty(exports, "PalyDirective", ({ enumerable: true, get: function () { return play_1.PlayDirective; } }));
var repeat_1 = __webpack_require__(/*! ./repeat */ "./node_modules/@pucelle/flit/out/directives/repeat.js");
Object.defineProperty(exports, "repeat", ({ enumerable: true, get: function () { return repeat_1.repeat; } }));
Object.defineProperty(exports, "RepeatDirective", ({ enumerable: true, get: function () { return repeat_1.RepeatDirective; } }));
var live_repeat_1 = __webpack_require__(/*! ./live-repeat */ "./node_modules/@pucelle/flit/out/directives/live-repeat.js");
Object.defineProperty(exports, "liveRepeat", ({ enumerable: true, get: function () { return live_repeat_1.liveRepeat; } }));
Object.defineProperty(exports, "LiveRepeatDirective", ({ enumerable: true, get: function () { return live_repeat_1.LiveRepeatDirective; } }));
var live_async_repeat_1 = __webpack_require__(/*! ./live-async-repeat */ "./node_modules/@pucelle/flit/out/directives/live-async-repeat.js");
Object.defineProperty(exports, "liveAsyncRepeat", ({ enumerable: true, get: function () { return live_async_repeat_1.liveAsyncRepeat; } }));
Object.defineProperty(exports, "LiveAsyncRepeatDirective", ({ enumerable: true, get: function () { return live_async_repeat_1.LiveAsyncRepeatDirective; } }));


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/directives/live-async-repeat.js":
/*!************************************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/directives/live-async-repeat.js ***!
  \************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.liveAsyncRepeat = exports.LiveAsyncRepeatDirective = void 0;
const define_1 = __webpack_require__(/*! ./define */ "./node_modules/@pucelle/flit/out/directives/define.js");
const template_1 = __webpack_require__(/*! ../template */ "./node_modules/@pucelle/flit/out/template/index.js");
const live_repeat_1 = __webpack_require__(/*! ./live-repeat */ "./node_modules/@pucelle/flit/out/directives/live-repeat.js");
const page_data_cacher_1 = __webpack_require__(/*! ../libs/page-data-cacher */ "./node_modules/@pucelle/flit/out/libs/page-data-cacher.js");
const observer_1 = __webpack_require__(/*! ../observer */ "./node_modules/@pucelle/flit/out/observer/index.js");
// One issue that is not solved:
// If data changed in backend and cause data duplicating or missing, it's hard to handle handle it.
// Right now we can trigger totally or partially updating from API, if we can detected it.
// Otherwise it's possible to detect data duplicating in frontend by a configuration `key`.
// So we don't show duplicate items for current rendering result.
// What we may do in future?
// When we detected duplicated items, we use them to update old items with same keys, and remove them from current page.
// This will cause we may can't cover current page and need to load more data, but should not frequently.
// And it also cause cached paged data doesn't have fixed size,
// such that we must count size of cached data of each page to fetch the data from `startIndex` to `endIndex`.
/** @hidden */
class LiveAsyncRepeatDirective extends live_repeat_1.LiveRepeatDirective {
    constructor() {
        super(...arguments);
        this.key = null;
        /**
         * Whole data count when using `dataGetter`.
         * `-1` means the total count is not determinated yet.
         * We will try to get the data count value when assigning render options.
         */
        this.knownDataCount = -1;
        /** Need to call `updateSliderPosition` after got `knownDataCount`. */
        this.needToUpdateSliderPositionAfterDataCountKnown = false;
        this.updateId = 0;
    }
    merge(options, templateFn, transitionOptions) {
        let firstlyUpdate = !this.options.updated;
        if (firstlyUpdate) {
            if (options.startIndex > 0) {
                this.startIndex = options.startIndex;
            }
        }
        this.options.update(options);
        this.templateFn = templateFn;
        this.transition.updateOptions(transitionOptions);
        if (firstlyUpdate) {
            this.validateTemplateFn(templateFn);
            this.dataCacher = new page_data_cacher_1.PageDataCacher(options.pageSize);
        }
        this.dataCacher.setDataGetter(options.dataGetter);
        if (firstlyUpdate) {
            if (options.startIndex > 0) {
                this.updateDataCount().then(() => {
                    this.startIndex = this.limitStartIndex(options.startIndex);
                    this.needToApplyStartIndex = true;
                    this.update();
                });
            }
            else {
                this.updateDataCount();
                this.update();
            }
        }
        else {
            this.update();
        }
    }
    validateTemplateFn(templateFn) {
        try {
            let result = templateFn(null, 0);
            if (!(result instanceof template_1.TemplateResult)) {
                throw new Error();
            }
        }
        catch (err) {
            throw new Error(`Please makesure "${templateFn.toString()}" can render "null" value`);
        }
    }
    updateRenderOptions(options) {
        if (options.averageItemHeight) {
            this.averageItemHeight = options.averageItemHeight;
        }
    }
    async updateDataCount() {
        let dataCountFn = this.options.get('dataCount');
        if (!dataCountFn) {
            return;
        }
        this.knownDataCount = -1;
        let dataCount;
        if (typeof dataCountFn === 'function') {
            dataCount = dataCountFn();
        }
        else {
            dataCount = dataCountFn;
        }
        if (dataCount instanceof Promise) {
            this.knownDataCount = await dataCount;
        }
        else {
            this.knownDataCount = dataCount;
        }
        if (this.needToUpdateSliderPositionAfterDataCountKnown) {
            this.updateSliderPosition();
        }
    }
    async update(renderPalceholders = true) {
        this.updateSliderPosition();
        let renderCount = this.options.get('pageSize') * this.options.get('renderPageCount');
        let endIndex = this.limitEndIndex(this.startIndex + renderCount);
        let needToRenderWithFreshData = !renderPalceholders;
        let updateImmediatelyPromise;
        if (renderPalceholders) {
            let { data, fresh } = this.dataCacher.getExistingData(this.startIndex, endIndex);
            updateImmediatelyPromise = this.updateData(data);
            needToRenderWithFreshData = !fresh;
        }
        let updateFreshPromise;
        let updateId = this.updateId += 1;
        if (needToRenderWithFreshData) {
            updateFreshPromise = this.dataCacher.getFreshData(this.startIndex, endIndex).then((data) => {
                if (updateId === this.updateId) {
                    return this.updateData(data);
                }
                else {
                    return Promise.resolve();
                }
            });
        }
        if (updateImmediatelyPromise) {
            await updateImmediatelyPromise;
        }
        if (updateFreshPromise) {
            await updateFreshPromise;
        }
    }
    async updateData(data) {
        if (this.key) {
            data = this.uniqueData(data);
        }
        data = data.map(observer_1.observe);
        await super.updateData(data);
    }
    uniqueData(data) {
        let set = new Set();
        return data.filter(item => {
            if (item) {
                let id = item[this.key];
                if (set.has(id)) {
                    return false;
                }
                else {
                    set.add(id);
                }
            }
            return true;
        });
    }
    updateSliderPosition() {
        if (this.knownDataCount === -1) {
            this.needToUpdateSliderPositionAfterDataCountKnown = true;
        }
        super.updateSliderPosition();
    }
    // Returns `-1` when total count is not determinated.
    getTotalDataCount() {
        return this.knownDataCount;
    }
    async getDataBetweens(startIndex, endIndex) {
        return await this.dataCacher.getFreshData(startIndex, endIndex);
    }
    /** When data ordering changed and you want to keep scroll position, e.g., after sorting by columns. */
    async reload() {
        this.dataCacher.beStale();
        this.updateDataCount();
        await this.update(false);
    }
    /**
     * When data changed completely and you want to move to start scroll position, e.g., after data type changed.
     * @param index Specified the start index you want to set by `setStartIndex`.
     */
    async reset(index = 0) {
        this.dataCacher.clear();
        this.updateDataCount();
        await this.setStartIndex(index);
    }
    getItem(index) {
        return this.dataCacher.getExistingData(index, index + 1).data[0];
    }
    /** Get currently rendered item in index. */
    getRenderedItem(index) {
        let isRendered = index >= this.startIndex && index < this.startIndex + this.data.length;
        if (isRendered) {
            return this.data[index - this.startIndex];
        }
        else {
            return null;
        }
    }
    /** When async items added at index, we need to adjust scrolling position and data count immediately,
     * and may add null item as placeholders for the added items.
     * Such that you will feel no delay after the add or delete operation.
     * After data loaded, new render result should be the same.
     */
    notifyAdded(index, count = 1) {
        this.dataCacher.moveData(index, count);
        this.update();
    }
    notifyDeleted(index, count = 1) {
        this.dataCacher.moveData(index, -count);
        this.update();
    }
}
exports.LiveAsyncRepeatDirective = LiveAsyncRepeatDirective;
/**
 * Gerenate live repeat elements, reuse elements as much as possible when data changed.
 * Compare to `repeat` directive, it will only show partial elements in viewport when you scroll it.
 * @param options Options for live rendering.
 * @param templateFn The fucntion which will return a template from one iterable data and index position.
 * @param transitionOptions The transition options, it can be a transition name, property or properties, or {transition, enterAtStart}.
 */
exports.liveAsyncRepeat = define_1.defineDirective(LiveAsyncRepeatDirective);


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/directives/live-repeat.js":
/*!******************************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/directives/live-repeat.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.liveRepeat = exports.LiveRepeatDirective = void 0;
const define_1 = __webpack_require__(/*! ./define */ "./node_modules/@pucelle/flit/out/directives/define.js");
const watched_template_1 = __webpack_require__(/*! ../libs/watched-template */ "./node_modules/@pucelle/flit/out/libs/watched-template.js");
const dom_event_1 = __webpack_require__(/*! ../libs/dom-event */ "./node_modules/@pucelle/flit/out/libs/dom-event.js");
const watcher_1 = __webpack_require__(/*! ../watcher */ "./node_modules/@pucelle/flit/out/watcher.js");
const repeat_1 = __webpack_require__(/*! ./repeat */ "./node_modules/@pucelle/flit/out/directives/repeat.js");
const queue_1 = __webpack_require__(/*! ../queue */ "./node_modules/@pucelle/flit/out/queue.js");
const util_1 = __webpack_require__(/*! ../libs/util */ "./node_modules/@pucelle/flit/out/libs/util.js");
const observer_1 = __webpack_require__(/*! ../observer */ "./node_modules/@pucelle/flit/out/observer/index.js");
const options_1 = __webpack_require__(/*! ../libs/options */ "./node_modules/@pucelle/flit/out/libs/options.js");
const defaultLiveRepeatOptions = {
    pageSize: 50,
    renderPageCount: 1,
    preRendering: false,
};
// Benchmark about using static layout or absolute layout: https://jsperf.com/is-absolute-layout-faster
// The `liveRepeat` only support render one item in one line.
// At beginning, we supported rendering several items in one line (works like photo album).
// This required us to listen watch the rect of the `scroller`,
// then to adjust a `cellCount` value which specify how many items in one line.
// This is not hard, but it requires us to support `onReconnected` and `onDisconnected` on directive,
// So that we can unregister or restore the watch for scroller size changes.
// This is a break change and needs us to modify `Component`, `NodePart`, `Template`, `defineDirective`, `Directive`.
// So finally we plan to implement a component to support rendering several items in one line.
/** @hidden */
class LiveRepeatDirective extends repeat_1.RepeatDirective {
    constructor(anchor, context) {
        super(anchor, context);
        /**
     * Average item height value, it is used to calculate the position of the `slider`.
     * It will be detected automatically from the first rendering if was not initialized.
     */
        this.averageItemHeight = 0;
        this.options = new options_1.Options(defaultLiveRepeatOptions); // > 1080 / 29
        /**
         * `startIndex` can only be set for once from `options`.
         * Otherwise you should call `setStartIndex`, then `needToApplyStartIndex` will be set to true and wait for next rendering.
         */
        this.needToApplyStartIndex = false;
        /**
         * When we scrolled up or down, we don't know about the height of just inserted or removed elements.
         * But we can keep it's scrolling position by adjusting `top` or `bottom` property of slider element.
         */
        this.continuousScrollDirection = null;
        this.continuousSliderPosition = null;
        this.scrollerBorderTopWidth = 0;
        this.scrollerBorderBottomWidth = 0;
        this.toCompleteRendering = null;
        /** Whole data from options. */
        this.rawData = null;
        /**
         * PreRender renders 3x of templates, includes before, current, after.
         * So it doesn't affect by scrolling direction.
         */
        this.toCompletePreRendering = null;
        this.preRenderStartIndex = 0;
        this.preRendered = new Map();
        this.initElements();
    }
    async initElements() {
        this.slider = this.anchor.el.parentElement;
        this.scroller = this.slider.parentElement;
        if (!this.slider || !this.scroller || this.scroller.children.length !== 1) {
            throw new Error(`"liveRepeat" must be contained in the struct like "
				<div style="overflow: auto | scroll; position: relative" title="as a scroll parent">
					<div title="as a scroll slider" style="position: absolute">
						\${liveRepeat(...)}
					</div>
				</div>
			"`);
        }
        dom_event_1.on(this.scroller, 'scroll.passive', this.onScroll, this);
        queue_1.onRenderComplete(() => {
            let computedStyle = getComputedStyle(this.scroller);
            if (!['scroll', 'auto'].includes(computedStyle.overflowY)) {
                throw `The "overflow-y" value of "scroller" out of "liveRepeat" directive must be "scroll" or "auto"`;
            }
            if (computedStyle.position === 'static') {
                throw `The "position" value of "scroller" out of "liveRepeat" directive must not be "static"`;
            }
            if (getComputedStyle(this.slider).position !== 'absolute') {
                throw `The "position" value of "slider" out of "liveRepeat" directive must not be "absolute"`;
            }
            this.scrollerBorderTopWidth = Number(getComputedStyle(this.scroller).borderTopWidth.replace('px', '')) || 0;
            this.scrollerBorderBottomWidth = Number(getComputedStyle(this.scroller).borderBottomWidth.replace('px', '')) || 0;
        });
    }
    canMergeWith(_options, templateFn) {
        return templateFn.toString() === this.templateFn.toString();
    }
    merge(options, templateFn, transitionOptions) {
        let firstlyUpdate = !this.options.updated;
        this.options.update(options);
        this.templateFn = templateFn;
        this.transition.updateOptions(transitionOptions);
        if (options.data !== undefined) {
            if (firstlyUpdate && options.data && options.startIndex > 0) {
                // `this.data` is not assigned yet, so cant use `limitStartIndex`
                let renderCount = this.options.get('pageSize') * this.options.get('renderPageCount');
                let startIndex = Math.min(options.startIndex, options.data.length - renderCount);
                this.startIndex = Math.max(0, startIndex);
                this.needToApplyStartIndex = true;
            }
            this.watchRawDataAndUpdate(options.data);
        }
    }
    watchRawDataAndUpdate(data) {
        if (this.unwatchData) {
            this.unwatchData();
            this.unwatchData = null;
        }
        if (!data) {
            this.rawData = [];
            return;
        }
        let watchFn = () => {
            return [...data].map(observer_1.observe);
        };
        let onUpdate = (data) => {
            this.rawData = data;
            this.update();
        };
        this.unwatchData = (this.context || watcher_1.globalWatcherGroup).watchImmediately(watchFn, onUpdate);
    }
    async update() {
        this.updateSliderPosition();
        let endIndex = this.getLimitedEndIndex();
        let data = this.rawData ? this.rawData.slice(this.startIndex, endIndex) : [];
        this.toCompleteRendering = this.updateData(data);
        await this.toCompleteRendering;
        this.toCompleteRendering = null;
        if (this.options.get('preRendering')) {
            this.checkPreRendering();
        }
    }
    async updateData(data) {
        super.updateData(data);
        let onUpdated = this.options.get('onUpdated');
        if (onUpdated) {
            onUpdated(this.data, this.startIndex);
        }
        await queue_1.renderComplete();
        if (this.data.length > 0) {
            if (!this.averageItemHeight) {
                this.measureAverageItemHeight();
                this.updateSliderPosition();
            }
            if (this.needToApplyStartIndex && this.averageItemHeight) {
                this.scroller.scrollTop = this.averageItemHeight * this.startIndex || 0;
                this.needToApplyStartIndex = false;
            }
        }
    }
    /** `this.data` must be determinated. */
    limitStartIndex(index) {
        let renderCount = this.options.get('pageSize') * this.options.get('renderPageCount');
        let endIndex = this.limitEndIndex(index + renderCount);
        let startIndex = Math.max(0, endIndex - renderCount);
        return startIndex;
    }
    limitEndIndex(index) {
        let maxCount = this.getTotalDataCount();
        if (maxCount >= 0 && index > maxCount) {
            index = maxCount;
        }
        return index;
    }
    /** `this.startIndex` must be determinated. */
    getLimitedEndIndex() {
        let renderCount = this.options.get('pageSize') * this.options.get('renderPageCount');
        let endIndex = this.limitEndIndex(this.startIndex + renderCount);
        return endIndex;
    }
    getTotalDataCount() {
        if (this.rawData) {
            return this.rawData.length;
        }
        else {
            return 0;
        }
    }
    // If you use two placeholder elements but not top and bottom margin to specify the position of `slider`,
    // There will be a big issue:
    // When no child nodes moved in scroller, expecially when rendering placeholder values [null, ...].
    // updating height of placeholder elements will cause `scroller.scrollTop` reset.
    updateSliderPosition() {
        let countBeforeStart = this.startIndex;
        let countAfterEnd = 0;
        let endIndex = this.getLimitedEndIndex();
        let totalCount = this.getTotalDataCount();
        if (totalCount >= 0) {
            countAfterEnd = Math.max(0, totalCount - endIndex);
        }
        let translateY = this.averageItemHeight * countBeforeStart;
        if (this.continuousScrollDirection && countBeforeStart > 0) {
            translateY = this.continuousSliderPosition;
        }
        let marginBottom = this.averageItemHeight * countAfterEnd;
        if (this.continuousScrollDirection === 'up' && countBeforeStart > 0) {
            if (translateY < this.averageItemHeight) {
                translateY = this.averageItemHeight;
            }
            this.slider.style.top = 'auto';
            this.slider.style.bottom = '-' + this.averageItemHeight * countAfterEnd + 'px';
        }
        else {
            this.slider.style.top = '0';
            this.slider.style.bottom = 'auto';
        }
        this.slider.style.marginBottom = marginBottom + 'px';
        this.slider.style.transform = `translateY(${translateY}px)`;
    }
    measureAverageItemHeight() {
        if (this.data.length === 0) {
            return;
        }
        // Here it is not 100% right when `pageSize` is not big enough.
        // Assume that there is only one `30px` height item with `10px` margin,
        // You will got wrong value 50, not right value 40.
        let sliderHeight = this.slider.offsetHeight;
        if (sliderHeight <= 0) {
            return;
        }
        this.averageItemHeight = Math.round(sliderHeight / this.data.length);
    }
    getElementOfIndex(index) {
        let wtem = this.wtems[index - this.startIndex];
        if (wtem) {
            return wtem.template.range.getFirstElement();
        }
        return null;
    }
    async onScroll() {
        this.checkRenderedRange();
    }
    checkRenderedRange() {
        let scrollerRect = this.scroller.getBoundingClientRect();
        let sliderRect = this.slider.getBoundingClientRect();
        if (scrollerRect.top < sliderRect.top) {
            this.updateToCover('up');
        }
        else if (scrollerRect.bottom > sliderRect.bottom) {
            this.updateToCover('down');
        }
    }
    // `direction` means where we render new items, and also the direction that the value of `startIndex` will change to.
    async updateToCover(scrollDirection) {
        let renderCount = this.options.get('pageSize') * this.options.get('renderPageCount');
        let startIndex = -1;
        if (scrollDirection === 'up') {
            let visibleIndex = this.locateLastVisibleIndex();
            if (visibleIndex > -1) {
                startIndex = visibleIndex + 1 - renderCount;
            }
        }
        else {
            let visibleIndex = this.locateFirstVisibleIndex();
            if (visibleIndex > -1) {
                startIndex = visibleIndex;
            }
        }
        // In this situation two rendering have no sharing part
        if (startIndex === -1) {
            if (scrollDirection === 'up') {
                startIndex = Math.ceil((this.scroller.scrollTop + this.scroller.clientHeight) / this.averageItemHeight) - renderCount;
            }
            else {
                startIndex = Math.floor(this.scroller.scrollTop / this.averageItemHeight);
            }
        }
        startIndex = this.limitStartIndex(startIndex);
        let endIndex = this.limitEndIndex(startIndex + renderCount);
        this.validateContinuousScrolling(scrollDirection, startIndex, endIndex);
        this.startIndex = startIndex;
        this.update();
    }
    locateFirstVisibleIndex() {
        return this.locateVisibleIndex(true);
    }
    locateLastVisibleIndex() {
        return this.locateVisibleIndex(false);
    }
    locateVisibleIndex(isFirst) {
        let scrollerRect = this.scroller.getBoundingClientRect();
        let visibleIndex = util_1.binaryFindIndexToInsert(this.wtems, (wtem) => {
            let firstElement = wtem.template.range.getFirstElement();
            if (firstElement) {
                let rect = firstElement.getBoundingClientRect();
                if (rect.bottom <= scrollerRect.top) {
                    return 1;
                }
                else if (rect.top >= scrollerRect.bottom) {
                    return -1;
                }
                else {
                    return isFirst ? -1 : 1;
                }
            }
            else {
                return -1;
            }
        });
        if (visibleIndex === this.data.length) {
            visibleIndex -= 1;
        }
        if (visibleIndex === -1) {
            return -1;
        }
        let firstElement = this.wtems[visibleIndex].template.range.getFirstElement();
        let firstElementRect = firstElement.getBoundingClientRect();
        // The found index is just an enge index, may the element still outside the visible range.
        if (firstElementRect.bottom <= scrollerRect.top) {
            visibleIndex += 1;
        }
        else if (firstElementRect.top >= scrollerRect.bottom) {
            visibleIndex -= 1;
        }
        if (visibleIndex >= 0 && visibleIndex < this.data.length) {
            return this.startIndex + visibleIndex;
        }
        return -1;
    }
    validateContinuousScrolling(scrollDirection, startIndex, endIndex) {
        let indexToKeepPosition = scrollDirection === 'down' ? startIndex : endIndex;
        let isSameScrollDirection = this.continuousScrollDirection === scrollDirection;
        let el = this.getElementOfIndex(indexToKeepPosition);
        if (el !== null) {
            this.continuousScrollDirection = scrollDirection;
            if (scrollDirection === 'down') {
                let position = isSameScrollDirection ? this.continuousSliderPosition : this.getSliderTopPosition();
                position += el.getBoundingClientRect().top - this.slider.getBoundingClientRect().top;
                this.continuousSliderPosition = position;
            }
            else {
                let position = isSameScrollDirection ? this.continuousSliderPosition : this.getSliderBottomPosition();
                position += el.getBoundingClientRect().bottom - this.slider.getBoundingClientRect().bottom;
                this.continuousSliderPosition = position;
            }
        }
        else {
            this.continuousScrollDirection = null;
        }
    }
    getSliderTopPosition() {
        let scrollerPaddingAreaTop = this.scroller.getBoundingClientRect().top - this.scrollerBorderTopWidth;
        let sliderAreaTop = this.slider.getBoundingClientRect().top;
        return sliderAreaTop - scrollerPaddingAreaTop + this.scroller.scrollTop;
    }
    getSliderBottomPosition() {
        let scrollerPaddingAreaBottom = this.scroller.getBoundingClientRect().bottom + this.scrollerBorderBottomWidth;
        let sliderAreaBottom = this.slider.getBoundingClientRect().bottom;
        return sliderAreaBottom - scrollerPaddingAreaBottom + this.scroller.scrollTop;
    }
    // Handle pre rendering
    async checkPreRendering() {
        if (this.toCompletePreRendering) {
            return;
        }
        this.toCompletePreRendering = this.doingUpdatePreRendering();
        await this.toCompletePreRendering;
        this.toCompletePreRendering = null;
    }
    async doingUpdatePreRendering() {
        // Wait page to layout & render
        await untilNextFrame();
        await this.updatePreRendering();
    }
    async updatePreRendering() {
        let totalCount = this.getTotalDataCount();
        let renderCount = this.options.get('pageSize') * this.options.get('renderPageCount');
        let startIndex = Math.max(0, this.startIndex - renderCount);
        let endIndex = Math.min(totalCount, this.startIndex + renderCount * 2);
        let startTime = performance.now();
        let data = await this.getDataBetweens(startIndex, endIndex);
        let dataSet = new Set(data);
        for (let item of this.preRendered.keys()) {
            if (!dataSet.has(item)) {
                let wtem = this.preRendered.get(item);
                wtem.remove();
                this.preRendered.delete(item);
            }
        }
        for (let i = 0; i < data.length; i++) {
            let item = data[i];
            let index = i + startIndex;
            if (!this.preRendered.has(item)) {
                let wtem = new watched_template_1.WatchedTemplate(this.context, this.templateFn, item, index);
                wtem.template.preRender();
                this.preRendered.set(item, wtem);
            }
            if (i % 10 === 0) {
                let currentTime = performance.now();
                if (currentTime - startTime > 10) {
                    startTime = currentTime;
                    await untilNextFrame();
                    // Is rendering, no need to update,
                    // Will start a new prerendering later.
                    if (this.toCompleteRendering) {
                        return;
                    }
                }
            }
        }
        this.preRenderStartIndex = startIndex;
    }
    async getDataBetweens(startIndex, endIndex) {
        return this.rawData ? this.rawData.slice(startIndex, endIndex) : [];
    }
    // Overwrites methods of super class
    shouldReuse(item) {
        return !this.options.get('preRendering') || !this.preRendered.has(item);
    }
    reuseOne(wtem, item, index) {
        if (this.options.get('preRendering')) {
            this.preRendered.delete(wtem.item);
            this.preRendered.set(item, wtem);
        }
        super.reuseOne(wtem, item, index);
    }
    createWatchedTemplate(item, index) {
        if (this.options.get('preRendering')) {
            if (this.preRendered.has(item)) {
                return this.preRendered.get(item);
            }
            else {
                let wtem = super.createWatchedTemplate(item, index);
                this.preRendered.set(wtem.item, wtem);
                return wtem;
            }
        }
        else {
            return super.createWatchedTemplate(item, index);
        }
    }
    onWatchedTemplateNotInUse(wtem) {
        // Note than we doesn't cache the removed wtem,
        // The reason is the component will trigger disconnect,
        // And when reconnect, it will update, even if we keep watcher alive here.
        if (this.options.get('preRendering')) {
            this.preRendered.delete(wtem.item);
        }
        wtem.remove();
    }
    /** Get `startIndex` property. */
    getStartIndex() {
        return this.startIndex;
    }
    /** Get the index of the first visible element, which can be used to restore scrolling position by `setStartIndex`. */
    getFirstVisibleIndex() {
        return Math.max(0, this.locateFirstVisibleIndex());
    }
    /** Set `startIndex`, and the item in which index will be at the top start position of the viewport. */
    async setStartIndex(index) {
        this.startIndex = this.limitStartIndex(index);
        this.needToApplyStartIndex = true;
        this.continuousScrollDirection = null;
        // It doesn't update immediately because `rawData` may changed and will update soon.
        // Need to wait reset `needToApplyStartIndex` in `updateData`.
        await queue_1.renderComplete();
        if (this.toCompleteRendering) {
            await this.toCompleteRendering;
        }
        if (this.needToApplyStartIndex) {
            await this.update();
        }
    }
    /** Adjust `startIndex` and scroll position to make item in the specified index becomes visible if it's not. */
    async scrollToViewIndex(index) {
        // Only adjust scroll position
        if (this.isIndexRendered(index)) {
            this.scrollToViewRenderedIndex(index);
        }
        else {
            if (index < this.startIndex) {
                await this.setStartIndex(index);
            }
            else {
                let startIndex = Math.max(0, (index + 1) - Math.ceil(this.scroller.clientHeight / this.averageItemHeight));
                await this.setStartIndex(startIndex);
                if (this.isIndexRendered(index)) {
                    this.scrollToViewRenderedIndex(index);
                }
            }
        }
    }
    isIndexRendered(index) {
        return index >= this.startIndex && index < this.startIndex + this.data.length;
    }
    scrollToViewRenderedIndex(index) {
        let el = this.wtems[index - this.startIndex].template.range.getFirstElement();
        let rect = el.getBoundingClientRect();
        let scrollerRect = this.scroller.getBoundingClientRect();
        // Below it, need to scroll up
        if (rect.bottom > scrollerRect.bottom) {
            this.scroller.scrollTop = this.scroller.scrollTop + (scrollerRect.bottom - rect.bottom);
        }
        // Above it, need to scroll down
        else if (rect.top < scrollerRect.top) {
            this.scroller.scrollTop = this.scroller.scrollTop + (scrollerRect.top - rect.top);
        }
    }
    remove() {
        if (this.unwatchData) {
            this.unwatchData();
        }
        if (this.options.get('preRendering')) {
            for (let wtem of this.preRendered.values()) {
                wtem.remove();
            }
        }
        else {
            for (let wtem of this.wtems) {
                wtem.remove();
            }
        }
    }
}
exports.LiveRepeatDirective = LiveRepeatDirective;
/**
 * Gerenate live repeat elements, reuse elements as much as possible when data changed.
 * Compare to `repeat` directive, it will only show partial elements in viewport when you scroll it.
 * @param options Options for live rendering.
 * @param templateFn The fucntion which will return a template from one iterable data and index position.
 * @param transitionOptions The transition options, it can be a transition name, property or properties, or {transition, enterAtStart}.
 */
exports.liveRepeat = define_1.defineDirective(LiveRepeatDirective);
function untilNextFrame() {
    return new Promise(resolve => {
        requestAnimationFrame(resolve);
    });
}


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/directives/play.js":
/*!***********************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/directives/play.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.play = exports.PlayDirective = void 0;
const define_1 = __webpack_require__(/*! ./define */ "./node_modules/@pucelle/flit/out/directives/define.js");
const template_1 = __webpack_require__(/*! ../template */ "./node_modules/@pucelle/flit/out/template/index.js");
const directive_transition_1 = __webpack_require__(/*! ../libs/directive-transition */ "./node_modules/@pucelle/flit/out/libs/directive-transition.js");
/**
 * Compare to `cache`, if we just want to play enter and leave transition,
 * and don't want to cache elements or leave it in document to hide,
 * we will need this directive.
 */
class PlayDirective {
    constructor(anchor, context) {
        this.currentTemplate = null;
        this.anchor = anchor;
        this.context = context;
        this.transition = new directive_transition_1.DirectiveTransition(context);
    }
    canMergeWith(_result) {
        return true;
    }
    merge(result, options) {
        this.transition.updateOptions(options);
        if (result) {
            if (this.currentTemplate && this.currentTemplate.canMergeWith(result)) {
                this.currentTemplate.merge(result);
            }
            else {
                if (this.currentTemplate) {
                    this.playLeaveTransition(this.currentTemplate);
                }
                this.initNewResult(result);
            }
        }
        else {
            if (this.currentTemplate) {
                this.playLeaveTransition(this.currentTemplate);
                this.currentTemplate = null;
            }
        }
    }
    async playEnterTransition(template) {
        let firstElement = template.range.getFirstElement();
        if (firstElement) {
            await this.transition.playEnter(firstElement);
        }
    }
    async playLeaveTransition(template) {
        let firstElement = template.range.getFirstElement();
        if (firstElement) {
            let finish = await this.transition.playLeave(firstElement);
            if (finish) {
                template.range.remove();
            }
        }
    }
    initNewResult(result) {
        let template = new template_1.Template(result, this.context);
        let fragment = template.range.getFragment();
        this.anchor.insert(fragment);
        if (this.transition.shouldPlayEnter()) {
            this.playEnterTransition(template);
        }
        this.currentTemplate = template;
    }
    remove() {
        if (this.currentTemplate) {
            this.currentTemplate.remove();
        }
    }
}
exports.PlayDirective = PlayDirective;
/**
 * Play enter transition when have rendering result, please leave transition when no result anymore.
 * @param result The html`...` result, can be null or empty string.
 */
exports.play = define_1.defineDirective(PlayDirective);


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/directives/repeat.js":
/*!*************************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/directives/repeat.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.repeat = exports.RepeatDirective = void 0;
const define_1 = __webpack_require__(/*! ./define */ "./node_modules/@pucelle/flit/out/directives/define.js");
const watcher_1 = __webpack_require__(/*! ../watcher */ "./node_modules/@pucelle/flit/out/watcher.js");
const directive_transition_1 = __webpack_require__(/*! ../libs/directive-transition */ "./node_modules/@pucelle/flit/out/libs/directive-transition.js");
const watched_template_1 = __webpack_require__(/*! ../libs/watched-template */ "./node_modules/@pucelle/flit/out/libs/watched-template.js");
const observer_1 = __webpack_require__(/*! ../observer */ "./node_modules/@pucelle/flit/out/observer/index.js");
/** @hidden */
class RepeatDirective {
    constructor(anchor, context) {
        this.data = [];
        this.wtems = [];
        this.unwatchData = null;
        /**
         * For `liveRepeat`, specify the the start index of first item in the whole data.
         * It was initialized from start options, and was reset when trigger `scroll` event on `scroller`.
         */
        this.startIndex = 0;
        this.anchor = anchor;
        this.context = context;
        this.transition = new directive_transition_1.DirectiveTransition(context);
    }
    watchAndUpdateDataImmediately(data) {
        // Here if `data` eauqls `lastData`, we still must update watchers.
        // Bacause the old watcher may trigger another update and cause update for twice. 
        if (this.unwatchData) {
            this.unwatchData();
            this.unwatchData = null;
        }
        if (!data) {
            this.updateData([]);
            return;
        }
        // Here need to read each item of the `Iterable<T>` so we can observe changes like `a[i] = xxx`.
        let watchFn = () => {
            return [...data].map(observer_1.observe);
        };
        let onUpdate = (data) => {
            this.updateData(data);
        };
        this.unwatchData = (this.context || watcher_1.globalWatcherGroup).watchImmediately(watchFn, onUpdate);
    }
    canMergeWith(_data, templateFn) {
        return templateFn.toString() === this.templateFn.toString();
    }
    merge(data, templateFn, options) {
        this.templateFn = templateFn;
        this.transition.updateOptions(options);
        this.watchAndUpdateDataImmediately(data);
    }
    // We want to reduce times of moving times, the best way is:
    // http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.4.6927&rep=rep1&type=pdf
    // Another way in `lit-html` is to check from start and end position,
    // it's good when only add or remove somes in one position:
    // https://github.com/Polymer/lit-html/blob/master/src/directives/repeat.ts
    // But here we need to keep the index of template nodes that will be removed,
    // So we check from start position to end position,
    // collected templates which will be removed but keep them in their old position.
    // This algorthim is good when you add or remove data, but a little weak when reordering data.
    // Concepts:
    //   matched: same item, no need to update item. if duplicate items exist, only the first one match.
    //   reuse: reuse not in use item and update item on it.
    updateData(data) {
        let shouldPaly = this.transition.shouldPlay();
        // Old
        let oldData = this.data;
        let oldItemIndexMap = new Map();
        let oldWtems = this.wtems;
        // New
        // Here it's not in updating and we can't capture dependencies,
        // so we need to observe each item manually,
        // then later we can generate templates and automatically update them when properties of item changed.
        let newData = this.data = data;
        let newItemSet = new Set(this.data);
        this.wtems = [];
        // Mark not in use and reused
        let notInUseIndexSet = new Set();
        let usedIndexSet = new Set();
        for (let i = 0; i < oldData.length; i++) {
            let oldItem = oldData[i];
            // Duplicate item or placeholder item, which should not in use.
            if (oldItem === null || oldItemIndexMap.has(oldItem)) {
                notInUseIndexSet.add(i);
            }
            else {
                oldItemIndexMap.set(oldItem, i);
                if (!newItemSet.has(oldItem)) {
                    notInUseIndexSet.add(i);
                }
            }
        }
        // `nextMatchedOldIndex` is the core indicator we moving elements according to,
        // The element at `nextMatchedOldIndex` will keep it's position.
        // When we check other element whose new index before it:
        //   if is a matched one and before it: move it before
        //   if is a matched one and after or is it: leave it and upgrade `nextMatchedOldIndex`
        // If we have upgrade `nextMatchedOldIndex` to new value,
        // we can leave elements between last and new `nextMatchedOldIndex` and reuse them without moving.
        // Note that if we moved an matched item before `nextMatchedOldIndex` element,
        // we need to move all the following items until `nextMatchedOldIndex`.
        function getNextMatchedOldIndex(startIndex) {
            for (let i = startIndex; i < oldData.length; i++) {
                let oldItem = oldData[i];
                if (newItemSet.has(oldItem) && oldItemIndexMap.get(oldItem) === i) {
                    return i;
                }
            }
            return oldData.length;
        }
        let nextMatchedOldIndex = getNextMatchedOldIndex(0);
        let lastStayedOldIndex = -1;
        for (let i = 0; i < newData.length; i++) {
            let item = newData[i];
            let index = i + this.startIndex;
            // May reuse
            if (oldItemIndexMap.has(item)) {
                // Find the old index for item
                let reuseIndex = oldItemIndexMap.get(item);
                // Although template with the index can be reused, but it may be reused already.
                // In this scenario we don't try to find a new index that match item,
                // Such that all the items with duplicate value except the first one will be removed.
                if (usedIndexSet.has(reuseIndex)) {
                    reuseIndex = -1;
                }
                // Already in the right position, no need to move.
                if (reuseIndex >= nextMatchedOldIndex) {
                    this.useMatchedOne(oldWtems[reuseIndex], index);
                    usedIndexSet.add(reuseIndex);
                    lastStayedOldIndex = reuseIndex;
                    nextMatchedOldIndex = getNextMatchedOldIndex(reuseIndex + 1);
                    continue;
                }
                if (reuseIndex > -1) {
                    this.moveOneBefore(oldWtems[reuseIndex], nextMatchedOldIndex < oldData.length ? oldWtems[nextMatchedOldIndex] : null);
                    this.useMatchedOne(oldWtems[reuseIndex], index);
                    usedIndexSet.add(reuseIndex);
                    lastStayedOldIndex = nextMatchedOldIndex;
                    continue;
                }
            }
            // Reuse template that will be removed and rerender it
            if (!shouldPaly && this.shouldReuse(item) && notInUseIndexSet.size > 0) {
                let reuseIndex = notInUseIndexSet.keys().next().value; // index in `notInUseIndexSet` is ordered.
                // If the index betweens `lastStayedOldIndex + 1` and `nextMatchedOldIndex`, no need to move it.
                let canStay = reuseIndex > lastStayedOldIndex && reuseIndex < nextMatchedOldIndex;
                if (!canStay) {
                    this.moveOneBefore(oldWtems[reuseIndex], nextMatchedOldIndex < oldData.length ? oldWtems[nextMatchedOldIndex] : null);
                    lastStayedOldIndex = nextMatchedOldIndex;
                }
                this.reuseOne(oldWtems[reuseIndex], item, index);
                notInUseIndexSet.delete(reuseIndex);
                usedIndexSet.add(reuseIndex);
                continue;
            }
            this.wtems.push(this.createOne(item, index, nextMatchedOldIndex < oldData.length ? oldWtems[nextMatchedOldIndex] : null));
        }
        // Should not follow `notInUseIndexSet` here:
        // e.g., two same items exist, and only first one reused, 
        // the second one needs to be removed but not in `notInUseIndexSet`.
        if (usedIndexSet.size < oldData.length) {
            for (let i = 0; i < oldData.length; i++) {
                if (!usedIndexSet.has(i)) {
                    this.removeOne(oldWtems[i]);
                }
            }
        }
    }
    shouldReuse(_item) {
        return true;
    }
    useMatchedOne(wtem, index) {
        wtem.updateIndex(index);
        this.wtems.push(wtem);
    }
    reuseOne(wtem, item, index) {
        wtem.update(item, index);
        this.wtems.push(wtem);
    }
    moveOneBefore(wtem, nextOldWtem) {
        let fragment = wtem.template.range.getFragment();
        if (nextOldWtem) {
            nextOldWtem.template.range.startNode.before(fragment);
        }
        else {
            this.anchor.insert(fragment);
        }
    }
    createOne(item, index, nextOldWtem) {
        let wtem = this.createWatchedTemplate(item, index);
        let template = wtem.template;
        let fragment = template.range.getFragment();
        let firstElement = null;
        if (this.transition.shouldPlayEnter()) {
            firstElement = fragment.firstElementChild;
        }
        if (nextOldWtem) {
            nextOldWtem.template.range.startNode.before(fragment);
        }
        else {
            this.anchor.insert(fragment);
        }
        if (firstElement) {
            this.transition.playEnter(firstElement);
        }
        return wtem;
    }
    createWatchedTemplate(item, index) {
        return new watched_template_1.WatchedTemplate(this.context, this.templateFn, item, index);
    }
    removeOne(wtem) {
        let template = wtem.template;
        if (this.transition.shouldPlay()) {
            let firstElement = template.range.getFirstElement();
            if (firstElement) {
                this.transition.playLeave(firstElement).then((finish) => {
                    if (finish) {
                        this.onWatchedTemplateNotInUse(wtem);
                    }
                });
            }
            else {
                this.onWatchedTemplateNotInUse(wtem);
            }
        }
        else {
            this.onWatchedTemplateNotInUse(wtem);
        }
    }
    onWatchedTemplateNotInUse(wtem) {
        wtem.remove();
    }
    remove() {
        if (this.unwatchData) {
            this.unwatchData();
        }
        for (let wtem of this.wtems) {
            wtem.remove();
        }
    }
}
exports.RepeatDirective = RepeatDirective;
/**
 * Gerenate repeat elements, it will reuse elements as much as possible when data changed.
 * Currently the repeat directive reuses rendered elements by repeat data items, not `key` can be specified.
 * If data items have changed and you do need to reuse elements by a `key`, try repeat the `key` values.
 * @param items The iterable data, each item in it will pass to `templateFn.`
 * @param templateFn The fucntion which will return a template from one iterable data and index position.
 * @param options The transition options, it can be a transition name, property or properties, or {transition, enterAtStart}.
 */
exports.repeat = define_1.defineDirective(RepeatDirective);


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/emitter.js":
/*!***************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/emitter.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ObservedEmitter = exports.ObservedBaseClass = void 0;
const observer_1 = __webpack_require__(/*! ./observer */ "./node_modules/@pucelle/flit/out/observer/index.js");
const emitter_1 = __webpack_require__(/*! ./libs/emitter */ "./node_modules/@pucelle/flit/out/libs/emitter.js");
/** Observed base class, changes it's sub properties will cause the components depend on them to update. */
class ObservedBaseClass {
    constructor() {
        return observer_1.observeTarget(this);
    }
}
exports.ObservedBaseClass = ObservedBaseClass;
/** Observed emitter class, changes it's sub properties will cause the components depend on them to update. */
class ObservedEmitter extends emitter_1.Emitter {
    constructor() {
        super();
        return observer_1.observeTarget(this);
    }
}
exports.ObservedEmitter = ObservedEmitter;


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/index.js":
/*!*************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/index.js ***!
  \*************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
var emitter_1 = __webpack_require__(/*! ./emitter */ "./node_modules/@pucelle/flit/out/emitter.js");
Object.defineProperty(exports, "ObservedBaseClass", ({ enumerable: true, get: function () { return emitter_1.ObservedBaseClass; } }));
Object.defineProperty(exports, "ObservedEmitter", ({ enumerable: true, get: function () { return emitter_1.ObservedEmitter; } }));
var render_1 = __webpack_require__(/*! ./render */ "./node_modules/@pucelle/flit/out/render.js");
Object.defineProperty(exports, "render", ({ enumerable: true, get: function () { return render_1.render; } }));
Object.defineProperty(exports, "renderComponent", ({ enumerable: true, get: function () { return render_1.renderComponent; } }));
Object.defineProperty(exports, "appendTo", ({ enumerable: true, get: function () { return render_1.appendTo; } }));
var template_1 = __webpack_require__(/*! ./template */ "./node_modules/@pucelle/flit/out/template/index.js");
Object.defineProperty(exports, "html", ({ enumerable: true, get: function () { return template_1.html; } }));
Object.defineProperty(exports, "css", ({ enumerable: true, get: function () { return template_1.css; } }));
Object.defineProperty(exports, "svg", ({ enumerable: true, get: function () { return template_1.svg; } }));
Object.defineProperty(exports, "TemplateResult", ({ enumerable: true, get: function () { return template_1.TemplateResult; } }));
Object.defineProperty(exports, "Template", ({ enumerable: true, get: function () { return template_1.Template; } }));
var component_1 = __webpack_require__(/*! ./component */ "./node_modules/@pucelle/flit/out/component/index.js");
Object.defineProperty(exports, "Component", ({ enumerable: true, get: function () { return component_1.Component; } }));
Object.defineProperty(exports, "define", ({ enumerable: true, get: function () { return component_1.define; } }));
Object.defineProperty(exports, "addGlobalStyle", ({ enumerable: true, get: function () { return component_1.addGlobalStyle; } }));
Object.defineProperty(exports, "updateStyles", ({ enumerable: true, get: function () { return component_1.updateStyles; } }));
Object.defineProperty(exports, "getComponent", ({ enumerable: true, get: function () { return component_1.getComponent; } }));
Object.defineProperty(exports, "getComponentAsync", ({ enumerable: true, get: function () { return component_1.getComponentAsync; } }));
Object.defineProperty(exports, "getClosestComponent", ({ enumerable: true, get: function () { return component_1.getClosestComponent; } }));
Object.defineProperty(exports, "updateComponents", ({ enumerable: true, get: function () { return component_1.updateComponents; } }));
var bindings_1 = __webpack_require__(/*! ./bindings */ "./node_modules/@pucelle/flit/out/bindings/index.js");
Object.defineProperty(exports, "defineBinding", ({ enumerable: true, get: function () { return bindings_1.defineBinding; } }));
Object.defineProperty(exports, "refBinding", ({ enumerable: true, get: function () { return bindings_1.refBinding; } }));
Object.defineProperty(exports, "BindingResult", ({ enumerable: true, get: function () { return bindings_1.BindingResult; } }));
Object.defineProperty(exports, "show", ({ enumerable: true, get: function () { return bindings_1.show; } }));
Object.defineProperty(exports, "hide", ({ enumerable: true, get: function () { return bindings_1.hide; } }));
var dom_event_1 = __webpack_require__(/*! ./libs/dom-event */ "./node_modules/@pucelle/flit/out/libs/dom-event.js");
Object.defineProperty(exports, "on", ({ enumerable: true, get: function () { return dom_event_1.on; } }));
Object.defineProperty(exports, "once", ({ enumerable: true, get: function () { return dom_event_1.once; } }));
Object.defineProperty(exports, "off", ({ enumerable: true, get: function () { return dom_event_1.off; } }));
var observer_1 = __webpack_require__(/*! ./observer */ "./node_modules/@pucelle/flit/out/observer/index.js");
Object.defineProperty(exports, "observe", ({ enumerable: true, get: function () { return observer_1.observe; } }));
Object.defineProperty(exports, "observeGetter", ({ enumerable: true, get: function () { return observer_1.observeGetter; } }));
Object.defineProperty(exports, "getObservedTarget", ({ enumerable: true, get: function () { return observer_1.getObservedTarget; } }));
var watcher_1 = __webpack_require__(/*! ./watcher */ "./node_modules/@pucelle/flit/out/watcher.js");
Object.defineProperty(exports, "watch", ({ enumerable: true, get: function () { return watcher_1.watch; } }));
Object.defineProperty(exports, "watchOnce", ({ enumerable: true, get: function () { return watcher_1.watchOnce; } }));
Object.defineProperty(exports, "watchUntil", ({ enumerable: true, get: function () { return watcher_1.watchUntil; } }));
Object.defineProperty(exports, "watchImmediately", ({ enumerable: true, get: function () { return watcher_1.watchImmediately; } }));
Object.defineProperty(exports, "Watcher", ({ enumerable: true, get: function () { return watcher_1.Watcher; } }));
var queue_1 = __webpack_require__(/*! ./queue */ "./node_modules/@pucelle/flit/out/queue.js");
Object.defineProperty(exports, "onRenderComplete", ({ enumerable: true, get: function () { return queue_1.onRenderComplete; } }));
Object.defineProperty(exports, "renderComplete", ({ enumerable: true, get: function () { return queue_1.renderComplete; } }));
var directives_1 = __webpack_require__(/*! ./directives */ "./node_modules/@pucelle/flit/out/directives/index.js");
Object.defineProperty(exports, "defineDirective", ({ enumerable: true, get: function () { return directives_1.defineDirective; } }));
Object.defineProperty(exports, "refDirective", ({ enumerable: true, get: function () { return directives_1.refDirective; } }));
Object.defineProperty(exports, "RepeatDirective", ({ enumerable: true, get: function () { return directives_1.RepeatDirective; } }));
Object.defineProperty(exports, "PalyDirective", ({ enumerable: true, get: function () { return directives_1.PalyDirective; } }));
Object.defineProperty(exports, "CacheDirective", ({ enumerable: true, get: function () { return directives_1.CacheDirective; } }));
Object.defineProperty(exports, "DirectiveResult", ({ enumerable: true, get: function () { return directives_1.DirectiveResult; } }));
Object.defineProperty(exports, "cache", ({ enumerable: true, get: function () { return directives_1.cache; } }));
Object.defineProperty(exports, "play", ({ enumerable: true, get: function () { return directives_1.play; } }));
Object.defineProperty(exports, "repeat", ({ enumerable: true, get: function () { return directives_1.repeat; } }));
Object.defineProperty(exports, "liveRepeat", ({ enumerable: true, get: function () { return directives_1.liveRepeat; } }));
Object.defineProperty(exports, "LiveRepeatDirective", ({ enumerable: true, get: function () { return directives_1.LiveRepeatDirective; } }));
Object.defineProperty(exports, "liveAsyncRepeat", ({ enumerable: true, get: function () { return directives_1.liveAsyncRepeat; } }));
Object.defineProperty(exports, "LiveAsyncRepeatDirective", ({ enumerable: true, get: function () { return directives_1.LiveAsyncRepeatDirective; } }));
var transition_1 = __webpack_require__(/*! ./libs/transition */ "./node_modules/@pucelle/flit/out/libs/transition.js");
Object.defineProperty(exports, "defineTransion", ({ enumerable: true, get: function () { return transition_1.defineTransion; } }));
Object.defineProperty(exports, "getEasing", ({ enumerable: true, get: function () { return transition_1.getEasing; } }));
Object.defineProperty(exports, "Transition", ({ enumerable: true, get: function () { return transition_1.Transition; } }));
Object.defineProperty(exports, "clearTransition", ({ enumerable: true, get: function () { return transition_1.clearTransition; } }));
var options_1 = __webpack_require__(/*! ./libs/options */ "./node_modules/@pucelle/flit/out/libs/options.js");
Object.defineProperty(exports, "Options", ({ enumerable: true, get: function () { return options_1.Options; } }));


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/libs/directive-transition.js":
/*!*********************************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/libs/directive-transition.js ***!
  \*********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.DirectiveTransition = void 0;
const transition_1 = __webpack_require__(/*! ./transition */ "./node_modules/@pucelle/flit/out/libs/transition.js");
const options_1 = __webpack_require__(/*! ./options */ "./node_modules/@pucelle/flit/out/libs/options.js");
/** Class to manage transition options, expecially to know should play transition when at start. */
class DirectiveTransition {
    constructor(context) {
        this.options = new options_1.Options({});
        this.firstlyUpdate = null;
        this.context = context;
    }
    updateOptions(options) {
        this.options.update(options);
        this.firstlyUpdate = this.firstlyUpdate === null ? true : false;
    }
    shouldPlay() {
        return !!this.options.get('transition');
    }
    shouldPlayEnter() {
        if (!this.shouldPlay()) {
            return false;
        }
        if (this.firstlyUpdate && !this.options.get('enterAtStart')) {
            return false;
        }
        return true;
    }
    shouldPlayLeave() {
        if (!this.shouldPlay()) {
            return false;
        }
        if (this.firstlyUpdate && !this.options.get('leaveAtStart')) {
            return false;
        }
        return true;
    }
    async playEnter(el) {
        if (!this.shouldPlay()) {
            return true;
        }
        let transition = this.options.get('transition');
        let onend = this.options.get('onend');
        let finish = await new transition_1.Transition(el, transition).enter();
        if (onend) {
            onend.call(this.context, 'enter', finish);
        }
        return finish;
    }
    async playLeave(el) {
        if (!this.shouldPlay()) {
            return true;
        }
        let transition = this.options.get('transition');
        let onend = this.options.get('onend');
        let finish = await new transition_1.Transition(el, transition).leave();
        if (onend) {
            onend.call(this.context, 'leave', finish);
        }
        return finish;
    }
}
exports.DirectiveTransition = DirectiveTransition;


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/libs/dom-event.js":
/*!**********************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/libs/dom-event.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.off = exports.once = exports.on = void 0;
const GLOBAL_EVENT_MODIFIERS = ['capture', 'self', 'once', 'prevent', 'stop', 'passive'];
const CONTROL_KEYS = ['ctrl', 'shift', 'alt'];
const CHANGE_FILTERS = ['check', 'uncheck'];
const WHEEL_FILTERS = ['up', 'down'];
const BUTTON_NAME_INDEX = {
    left: 0,
    middle: 1,
    right: 2,
    main: 0,
    auxiliary: 1,
    secondary: 2
};
const EVENT_FILTER_FN = {
    keydown: keyEventFilter,
    keyup: keyEventFilter,
    keypress: keyEventFilter,
    mousedown: mouseEventFilter,
    mousemove: mouseEventFilter,
    mouseup: mouseEventFilter,
    click: mouseEventFilter,
    change: changeEventFilter,
    wheel: wheelEventFilter
};
// Full key list: https://developer.mozilla.org/en-US/docs/Web/API/KeyboardEvent/key/Key_Values
// Capture key at: https://keycode.info/
function keyEventFilter(e, filters) {
    let keyOrCodeFilters = [];
    for (let filter of filters) {
        if (CONTROL_KEYS.includes(filter)) {
            if (!isControlKeyMatchFilters(e, filter)) {
                return false;
            }
            continue;
        }
        keyOrCodeFilters.push(filter);
    }
    return keyOrCodeFilters.length === 0
        || keyOrCodeFilters.includes(e.key.toLowerCase())
        || keyOrCodeFilters.includes(e.code.toLowerCase());
}
function mouseEventFilter(e, filters) {
    let buttonFilters = [];
    for (let filter of filters) {
        if (CONTROL_KEYS.includes(filter)) {
            if (!isControlKeyMatchFilters(e, filter)) {
                return false;
            }
            continue;
        }
        buttonFilters.push(filter);
    }
    if (buttonFilters.length === 0) {
        return true;
    }
    if (buttonFilters.find(f => BUTTON_NAME_INDEX[f] === e.button)) {
        return true;
    }
    return false;
}
function isControlKeyMatchFilters(e, filter) {
    switch (filter) {
        case 'ctrl':
            if (!e.ctrlKey) {
                return false;
            }
            break;
        case 'shift':
            if (!e.shiftKey) {
                return false;
            }
            break;
        case 'alt':
            if (!e.altKey) {
                return false;
            }
            break;
    }
    return true;
}
function changeEventFilter(e, [filter]) {
    let checked = e.target.checked;
    return checked && filter === 'check'
        || checked && filter === 'uncheck';
}
function wheelEventFilter(e, [filter]) {
    return (e.deltaY < 0) && filter === 'up'
        || (e.deltaY > 0) && filter === 'down';
}
function validateModifiers(rawName, name, modifiers) {
    modifiers = modifiers.filter(m => !GLOBAL_EVENT_MODIFIERS.includes(m));
    if (modifiers.length === 0) {
        return true;
    }
    if (name === 'change') {
        if (modifiers.length > 1 || !CHANGE_FILTERS.includes(modifiers[0])) {
            throw new Error(`"${rawName}" is valid, check filter for change event must be one of "${CHANGE_FILTERS.join(',')}"`);
        }
    }
    else if (name === 'wheel') {
        if (modifiers.length > 1 || !WHEEL_FILTERS.includes(modifiers[0])) {
            throw new Error(`"${rawName}" is valid, direction filter for wheel event must be one of "${WHEEL_FILTERS.join(',')}"`);
        }
    }
    else if (name === 'keydown' || name === 'keyup' || name === 'keypress') {
        modifiers = modifiers.filter(m => !CONTROL_KEYS.includes(m));
        if (modifiers.length > 1) {
            throw new Error(`"${rawName}" is valid, only one key name can be specified as key`);
        }
    }
    else if (name === 'mousedown' || name === 'mousemove' || name === 'mouseup' || name === 'click') {
        modifiers = modifiers.filter(m => !CONTROL_KEYS.includes(m));
        if (modifiers.length > 1 || !BUTTON_NAME_INDEX.hasOwnProperty(modifiers[0])) {
            throw new Error(`"${rawName}" is valid, button filter for mouse event must be one of "${Object.keys(BUTTON_NAME_INDEX).join(',')}"`);
        }
    }
    return true;
}
const ElementEventMap = new WeakMap();
/**
 * Register an event handler on element.
 * @param el The element to register listener on.
 * @param name The event name, it can be `click:left` or `keydown:enter`.
 * @param handler The event handler.
 * @param scope The event context used to call handler. You can remove it easily by specify the same scope.
 */
function on(el, name, handler, scope) {
    bindEvent(false, el, name, handler, scope);
}
exports.on = on;
/**
 * Register an event handler on element, it will be triggered only for once.
 * @param el The element to register listener on.
 * @param name The event name, it can be `click:left` or `keydown:enter`.
 * @param handler The event handler.
 * @param scope The event context used to call handler. You can remove it easily by specify the same scope.
 */
function once(el, name, handler, scope) {
    bindEvent(true, el, name, handler, scope);
}
exports.once = once;
function bindEvent(once, el, rawName, handler, scope) {
    let name = rawName;
    let modifiers = null;
    if (rawName.includes('.')) {
        [name, ...modifiers] = rawName.split('.');
        validateModifiers(rawName, name, modifiers);
    }
    let wrappedHandler = wrapHandler(once, modifiers, el, name, handler, scope);
    let capture = !!modifiers && modifiers.includes('capture');
    let passive = !!modifiers && modifiers.includes('passive');
    // Wheel event use passive mode by default and can't be prevented.
    let options = passive || name === 'wheel' ? { capture, passive } : capture;
    let eventMap = ElementEventMap.get(el);
    if (!eventMap) {
        eventMap = {};
        ElementEventMap.set(el, eventMap);
    }
    let events = eventMap[name] || (eventMap[name] = []);
    events.push({
        name: rawName,
        handler,
        wrappedHandler,
        scope,
        capture
    });
    el.addEventListener(name, wrappedHandler, options);
}
/**
 * Unregister an event handler on element.
 * @param el The element to unregister listener on.
 * @param name The event name with or without modifiers.
 * @param handler The event handler.
 * @param scope The event context used to call handler. If specified, it must be match too.
 */
function off(el, name, handler, scope) {
    let eventMap = ElementEventMap.get(el);
    if (!eventMap) {
        return;
    }
    name = name.replace(/\..+/, '');
    let events = eventMap[name];
    if (!events) {
        return;
    }
    for (let i = events.length - 1; i >= 0; i--) {
        let event = events[i];
        let isHandlerMatch = !handler
            || event.handler === handler
            || event.handler.hasOwnProperty('__original') && event.handler.__original === handler;
        if (isHandlerMatch && (!scope || event.scope === scope)) {
            el.removeEventListener(name, event.wrappedHandler, event.capture);
            events.splice(i, 1);
        }
    }
}
exports.off = off;
function wrapHandler(once, modifiers, el, name, handler, scope) {
    let filterModifiers = modifiers ? modifiers.filter(m => !GLOBAL_EVENT_MODIFIERS.includes(m)) : null;
    return function wrappedHandler(e) {
        if (filterModifiers && filterModifiers.length > 0) {
            let filterFn = EVENT_FILTER_FN[name];
            if (!filterFn(e, filterModifiers)) {
                return;
            }
        }
        if (modifiers && modifiers.includes('self') && e.target !== el) {
            return;
        }
        if (modifiers && modifiers.includes('prevent')) {
            e.preventDefault();
        }
        if (modifiers && modifiers.includes('stop')) {
            e.stopPropagation();
        }
        if (once || modifiers && modifiers.includes('once')) {
            off(el, name, handler, scope);
        }
        if (scope) {
            handler.call(scope, e);
        }
        else {
            handler(e);
        }
    };
}


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/libs/emitter.js":
/*!********************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/libs/emitter.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, exports) => {


// This file cloned for https://github.com/pucelle/ff/blob/master/src/base/emitter.ts
// You may visit it to find more descriptions about the implemention.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Emitter = void 0;
class Emitter {
    constructor() {
        this.__events = new Map();
    }
    __ensureEvents(name) {
        let events = this.__events.get(name);
        if (!events) {
            this.__events.set(name, events = []);
        }
        return events;
    }
    on(name, listener, scope) {
        let events = this.__ensureEvents(name);
        events.push({
            listener,
            scope,
            once: false,
        });
    }
    once(name, listener, scope) {
        let events = this.__ensureEvents(name);
        events.push({
            listener,
            scope,
            once: true
        });
    }
    off(name, listener, scope) {
        let events = this.__events.get(name);
        if (events) {
            for (let i = events.length - 1; i >= 0; i--) {
                let event = events[i];
                if (event.listener === listener && (!scope || event.scope === scope)) {
                    events.splice(i, 1);
                }
            }
        }
    }
    hasListener(name, listener, scope) {
        let events = this.__events.get(name);
        if (!listener) {
            return !!events && events.length > 0;
        }
        else if (events && listener) {
            for (let i = 0, len = events.length; i < len; i++) {
                let event = events[i];
                if (event.listener === listener && (!scope || event.scope === scope)) {
                    return true;
                }
            }
        }
        return false;
    }
    emit(name, ...args) {
        let events = this.__events.get(name);
        if (events) {
            for (let i = 0; i < events.length; i++) {
                let event = events[i];
                // The listener may call off, so must remove it before handling
                if (event.once === true) {
                    events.splice(i--, 1);
                }
                event.listener.apply(event.scope, args);
            }
        }
    }
    removeAllListeners() {
        this.__events = new Map();
    }
}
exports.Emitter = Emitter;


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/libs/html-token.js":
/*!***********************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/libs/html-token.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.joinHTMLTokens = exports.parseToHTMLTokens = exports.HTMLTokenType = void 0;
const util_1 = __webpack_require__(/*! ./util */ "./node_modules/@pucelle/flit/out/libs/util.js");
var HTMLTokenType;
(function (HTMLTokenType) {
    HTMLTokenType[HTMLTokenType["StartTag"] = 0] = "StartTag";
    HTMLTokenType[HTMLTokenType["EndTag"] = 1] = "EndTag";
    HTMLTokenType[HTMLTokenType["Text"] = 2] = "Text";
})(HTMLTokenType = exports.HTMLTokenType || (exports.HTMLTokenType = {}));
const SELF_CLOSE_TAGS = [
    'area', 'base', 'br', 'col', 'embed', 'hr', 'img', 'input', 'link', 'meta', 'param', 'source', 'track', 'wbr'
];
/**
 * Parse html codes to tokens.
 * After parsed, all comment was removed, and `\r\n\t` in text nodes was removed too.
 * Automatically fix `<tag />` to `<tag></tag>` for not self close tags.
 * attributes are not been trimmed.
 */
function parseToHTMLTokens(string) {
    const tagRE = /<!--[\s\S]*?-->|<([\w-]+)([\s\S]*?)\/?>|<\/[\w-]+>/g;
    let lastIndex = 0;
    let tokens = [];
    let match;
    while (match = tagRE.exec(string)) {
        let piece = match[0];
        if (match.index > lastIndex) {
            let text = util_1.trim(string.slice(lastIndex, match.index));
            if (text) {
                tokens.push({
                    type: HTMLTokenType.Text,
                    text
                });
            }
        }
        lastIndex = tagRE.lastIndex;
        if (piece[1] === '!') {
            continue;
        }
        else if (piece[1] === '/') {
            let tagName = piece.slice(2, -1);
            if (!SELF_CLOSE_TAGS.includes(tagName)) {
                tokens.push({
                    type: HTMLTokenType.EndTag,
                    tagName,
                });
            }
        }
        else {
            let tagName = match[1];
            let attributes = match[2];
            let selfClose = SELF_CLOSE_TAGS.includes(tagName);
            tokens.push({
                type: HTMLTokenType.StartTag,
                tagName,
                attributes,
                selfClose,
            });
            //`<tag />` -> `<tag></tag>`
            // Benchmark: https://jsperf.com/array-includes-vs-object-in-vs-set-has
            if (piece[piece.length - 2] === '/' && !selfClose) {
                tokens.push({
                    type: HTMLTokenType.EndTag,
                    tagName,
                });
            }
        }
    }
    if (lastIndex < string.length) {
        let text = util_1.trim(string.slice(lastIndex));
        if (text) {
            tokens.push({
                type: HTMLTokenType.Text,
                text: string.slice(lastIndex)
            });
        }
    }
    return tokens;
}
exports.parseToHTMLTokens = parseToHTMLTokens;
/**
 * Join tokens that parsed from `parseToHTMLTokens` to HTML codes.
 */
function joinHTMLTokens(tokens) {
    let codes = '';
    for (let token of tokens) {
        switch (token.type) {
            case HTMLTokenType.StartTag:
                let tagName = token.tagName;
                let attributes = token.attributes;
                codes += '<' + tagName + attributes + '>';
                break;
            case HTMLTokenType.EndTag:
                codes += `</${token.tagName}>`;
                break;
            case HTMLTokenType.Text:
                codes += token.text;
                break;
        }
    }
    return codes;
}
exports.joinHTMLTokens = joinHTMLTokens;


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/libs/node-helper.js":
/*!************************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/libs/node-helper.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.NodeRange = exports.NodeAnchor = exports.NodeAnchorType = void 0;
var NodeAnchorType;
(function (NodeAnchorType) {
    NodeAnchorType[NodeAnchorType["Next"] = 0] = "Next";
    NodeAnchorType[NodeAnchorType["Root"] = 1] = "Root";
    NodeAnchorType[NodeAnchorType["Parent"] = 2] = "Parent";
})(NodeAnchorType = exports.NodeAnchorType || (exports.NodeAnchorType = {}));
/**
 * Used for `RootPart` or `NodePart` to mark end position.
 * Please never move the command type anchor node, the whole document may be removed.
 */
class NodeAnchor {
    constructor(el, type) {
        this.el = el;
        this.type = type;
    }
    insert(node) {
        if (this.type === NodeAnchorType.Next) {
            this.el.before(node);
        }
        else {
            this.el.append(node);
        }
    }
}
exports.NodeAnchor = NodeAnchor;
/**
 * Use to cache rest nodes for component, or mark the range of a template output.
 * The nodes in it may be moved or removed, or insert more.
 * We need to makesure that what ever the inner nodes change,
 * we can still get nodes from the fixed start and end node.
 */
class NodeRange {
    constructor(fragment) {
        this.fragment = null;
        this.fragment = fragment;
        // Fragment hould include at least one node, so it's position can be tracked.
        // Because startNode should always before any other nodes inside the template or as rest slot lement,
        // So if starts with a hole - comment node, which will insert nodes before it,
        // we need to prepend a comment node as `startNode`.
        let startNode = fragment.firstChild;
        if (!startNode || startNode.nodeType === 8) {
            startNode = document.createComment('');
            fragment.prepend(startNode);
        }
        this.startNode = startNode;
        // The end node will never be moved.
        // It should be a fixed element, or a comment node of a child part.
        this.endNode = fragment.lastChild;
    }
    /** Can be used to get firstly parsed fragment, or reuse template nodes as a fragment. */
    getFragment() {
        let fragment;
        if (this.fragment) {
            fragment = this.fragment;
            this.fragment = null;
        }
        else {
            fragment = document.createDocumentFragment();
            fragment.append(...this.getNodes());
        }
        return fragment;
    }
    /** Cache nodes in a fragment and use them later. */
    cacheFragment() {
        this.fragment = this.getFragment();
    }
    /** Get nodes in range. */
    getNodes() {
        let nodes = [];
        let node = this.startNode;
        while (node) {
            nodes.push(node);
            if (node === this.endNode) {
                break;
            }
            node = node.nextSibling;
        }
        return nodes;
    }
    /** Get first element in range. */
    getFirstElement() {
        let node = this.startNode;
        while (node) {
            if (node.nodeType === 1) {
                return node;
            }
            if (node === this.endNode) {
                break;
            }
            node = node.nextSibling;
        }
        return null;
    }
    /** Remove all the nodes in range from parent. */
    remove() {
        this.getNodes().forEach(node => node.remove());
    }
}
exports.NodeRange = NodeRange;


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/libs/options.js":
/*!********************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/libs/options.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Options = void 0;
/** Used to mange options updating. */
class Options {
    constructor(defaultOptions) {
        this.options = null;
        this.updated = false;
        this.default = defaultOptions;
    }
    update(options) {
        this.options = options || null;
        this.updated = true;
    }
    get(key) {
        if (this.options) {
            let value = this.options[key];
            return value === undefined ? this.default[key] : value;
        }
        else {
            return this.default[key];
        }
    }
}
exports.Options = Options;


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/libs/page-data-cacher.js":
/*!*****************************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/libs/page-data-cacher.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.PageDataCacher = void 0;
const util_1 = __webpack_require__(/*! ./util */ "./node_modules/@pucelle/flit/out/libs/util.js");
class PageDataCacher {
    constructor(pageSize) {
        this.map = {}; // Need to get keys in order, so not use `Map`.
        this.requestingMap = new Map();
        this.pageSize = pageSize;
    }
    setDataGetter(dataGetter) {
        this.dataGetter = dataGetter;
    }
    getExistingData(startIndex, endIndex) {
        let startPageIndex = Math.floor(startIndex / this.pageSize); //49 -> 0, 50 -> 1
        let endPageIndex = Math.floor((endIndex - 1) / this.pageSize); // 50 -> 0, 51 -> 1
        let data = [];
        let nullValues;
        let fresh = true;
        for (let i = startPageIndex; i <= endPageIndex; i++) {
            let cacheItem = this.map[i];
            let items = cacheItem ? cacheItem.items : nullValues || (nullValues = util_1.repeatValue(null, this.pageSize));
            if (cacheItem && !cacheItem.fresh) {
                fresh = false;
            }
            if (i === startPageIndex && i === endPageIndex) {
                data.push(...items.slice(startIndex - startPageIndex * this.pageSize, endIndex - endPageIndex * this.pageSize));
            }
            else if (i === startPageIndex) {
                data.push(...items.slice(startIndex - startPageIndex * this.pageSize));
            }
            else if (i === endPageIndex) {
                data.push(...items.slice(0, endIndex - endPageIndex * this.pageSize));
            }
            else {
                data.push(...items);
            }
        }
        if (nullValues) {
            fresh = false;
        }
        return { data, fresh };
    }
    async getFreshData(startIndex, endIndex) {
        let startPageIndex = Math.floor(startIndex / this.pageSize); //49 -> 0, 50 -> 1
        let endPageIndex = Math.floor((endIndex - 1) / this.pageSize); // 50 -> 0, 51 -> 1
        let promises = [];
        for (let i = startPageIndex; i <= endPageIndex; i++) {
            let cacheItem = this.map[i];
            if (!cacheItem || !cacheItem.fresh) {
                promises.push(this.loadPageData(i));
            }
        }
        await Promise.all(promises);
        return this.getExistingData(startIndex, endIndex).data;
    }
    // It's very often that you load one page of data, and then still load this page after scrolled.
    // So we need to cache requests for pages before it returned.
    loadPageData(pageIndex) {
        if (this.requestingMap.has(pageIndex)) {
            return this.requestingMap.get(pageIndex);
        }
        let itemsPromise = this.dataGetter(pageIndex * this.pageSize, this.pageSize);
        if (itemsPromise instanceof Promise) {
            let promise = itemsPromise.then(items => {
                this.map[pageIndex] = {
                    items: [...items],
                    fresh: true
                };
                this.requestingMap.delete(pageIndex);
            });
            this.requestingMap.set(pageIndex, promise);
            return promise;
        }
        else {
            this.map[pageIndex] = {
                items: [...itemsPromise],
                fresh: true
            };
            return Promise.resolve();
        }
    }
    // `moveRight` can be negative.
    // Not handle tatal count and slicing last page data,
    // which can be handled inside `LiveRepeat` directivve.
    moveData(index, moveRight) {
        if (moveRight === 0) {
            return;
        }
        if (moveRight > 0) {
            this.moveDataRight(index, moveRight);
        }
        else {
            this.moveDataLeft(index, -moveRight);
        }
    }
    // `count` will never be `0`
    moveDataRight(index, count) {
        let pageIndex = Math.floor(index / this.pageSize);
        let keys = Object.keys(this.map).map(Number);
        let lastGeneratedPageIndex = -1;
        let unUsedKeys = new Set();
        for (let i = keys.length - 1; i >= 0; i--) {
            let key = keys[i];
            if (key < pageIndex) {
                continue;
            }
            unUsedKeys.add(key);
            let leftPageIndex = key + Math.floor(count / this.pageSize);
            let rightPageIndex = key + Math.ceil(count / this.pageSize);
            if (rightPageIndex !== lastGeneratedPageIndex) {
                let rightPageStartIndex = rightPageIndex * this.pageSize - count;
                let generated = this.generateNewCacheItem(rightPageIndex, rightPageStartIndex, index, index);
                if (generated) {
                    unUsedKeys.delete(rightPageIndex);
                }
            }
            if (leftPageIndex !== rightPageIndex) {
                let leftPageStartIndex = leftPageIndex * this.pageSize - count;
                let generated = this.generateNewCacheItem(leftPageIndex, leftPageStartIndex, index, index);
                if (generated) {
                    unUsedKeys.delete(leftPageIndex);
                }
            }
            lastGeneratedPageIndex = leftPageIndex;
        }
        // Handle rest items in `pageIndex`
        if (lastGeneratedPageIndex > pageIndex) {
            let generated = this.generateNewCacheItem(pageIndex, pageIndex * this.pageSize - count, index, index);
            if (generated) {
                unUsedKeys.delete(pageIndex);
            }
        }
        for (let key of unUsedKeys) {
            delete this.map[key];
        }
    }
    // Will copy values whose index less than `moveStartIndex` to the generated items.
    // The value whose index less than `nullStartIndex` will be set by `null`.
    generateNewCacheItem(pageIndex, index, moveStartIndex, nullStartIndex) {
        let startPageIndex = Math.floor(moveStartIndex / this.pageSize);
        let haveItemsFromMovement = index + this.pageSize > nullStartIndex;
        let haveRestItemsInPageIndex = pageIndex === startPageIndex && this.map[pageIndex] && moveStartIndex > startPageIndex * this.pageSize;
        if (!haveItemsFromMovement && !haveRestItemsInPageIndex) {
            return false;
        }
        let newItems;
        if (index < nullStartIndex) {
            newItems = [...util_1.repeatValue(null, nullStartIndex - index), ...this.getExistingData(nullStartIndex, index + this.pageSize).data];
        }
        else {
            newItems = this.getExistingData(index, index + this.pageSize).data;
        }
        // If is the first page, move start fix items into new items.
        if (pageIndex === startPageIndex) {
            let indexToSlice = moveStartIndex - startPageIndex * this.pageSize;
            newItems = [
                ...this.getExistingData(startPageIndex * this.pageSize, moveStartIndex).data,
                ...newItems.slice(indexToSlice)
            ];
        }
        if (this.hasAnyItem(newItems)) {
            this.map[pageIndex] = {
                items: newItems,
                fresh: this.hasNoNull(newItems)
            };
            return true;
        }
        return false;
    }
    // `count` > 0
    moveDataLeft(index, count) {
        let pageIndex = Math.floor(index / this.pageSize);
        let keys = Object.keys(this.map).map(Number);
        let lastGeneratedPageIndex = -1;
        let unUsedKeys = new Set();
        for (let i = 0; i < keys.length; i++) {
            let key = keys[i];
            if (key < pageIndex) {
                continue;
            }
            unUsedKeys.add(key);
            let leftPageIndex = key - Math.ceil(count / this.pageSize);
            let rightPageIndex = key - Math.floor(count / this.pageSize);
            if (leftPageIndex >= 0 && leftPageIndex !== lastGeneratedPageIndex) {
                let leftPageStartIndex = leftPageIndex * this.pageSize + count;
                let generated = this.generateNewCacheItem(leftPageIndex, leftPageStartIndex, index, index + count);
                if (generated) {
                    unUsedKeys.delete(leftPageIndex);
                }
            }
            if (rightPageIndex >= 0 && rightPageIndex !== leftPageIndex) {
                let rightPageStartIndex = rightPageIndex * this.pageSize + count;
                let generated = this.generateNewCacheItem(rightPageIndex, rightPageStartIndex, index, index + count);
                if (generated) {
                    unUsedKeys.delete(rightPageIndex);
                }
            }
            lastGeneratedPageIndex = rightPageIndex;
        }
        for (let key of unUsedKeys) {
            delete this.map[key];
        }
    }
    hasNoNull(items) {
        return items.every(item => item !== null);
    }
    hasAnyItem(items) {
        return items.some(item => item !== null);
    }
    clear() {
        this.map = {};
    }
    // Compare to clear all the cache, here it can keep showing old results,
    // and replace them when data prepared.
    beStale() {
        for (let cacheItem of Object.values(this.map)) {
            cacheItem.fresh = false;
        }
    }
}
exports.PageDataCacher = PageDataCacher;


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/libs/transition.js":
/*!***********************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/libs/transition.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.clearTransition = exports.Transition = exports.formatShortTransitionOptions = exports.defineTransion = exports.getEasing = void 0;
const dom_event_1 = __webpack_require__(/*! ./dom-event */ "./node_modules/@pucelle/flit/out/libs/dom-event.js");
const queue_1 = __webpack_require__(/*! ../queue */ "./node_modules/@pucelle/flit/out/queue.js");
const DEFAULT_TRANSITION_OPTIONS = {
    duration: 200,
    easing: 'ease-out',
    direction: 'both'
};
// Copied from `Bourbon` source codes.
const CUBIC_BEZIER_EASINGS = {
    // BASE
    'ease': [0.250, 0.100, 0.250, 1.000],
    'ease-in': [0.420, 0.000, 1.000, 1.000],
    'ease-out': [0.000, 0.000, 0.580, 1.000],
    'ease-in-out': [0.420, 0.000, 0.580, 1.000],
    // EASE IN
    'ease-in-quad': [0.550, 0.085, 0.680, 0.530],
    'ease-in-cubic': [0.550, 0.055, 0.675, 0.190],
    'ease-in-quart': [0.895, 0.030, 0.685, 0.220],
    'ease-in-quint': [0.755, 0.050, 0.855, 0.060],
    'ease-in-sine': [0.470, 0.000, 0.745, 0.715],
    'ease-in-expo': [0.950, 0.050, 0.795, 0.035],
    'ease-in-circ': [0.600, 0.040, 0.980, 0.335],
    'ease-in-back': [0.600, -0.280, 0.735, 0.045],
    // EASE OUT
    'ease-out-quad': [0.250, 0.460, 0.450, 0.940],
    'ease-out-cubic': [0.215, 0.610, 0.355, 1.000],
    'ease-out-quart': [0.165, 0.840, 0.440, 1.000],
    'ease-out-quint': [0.230, 1.000, 0.320, 1.000],
    'ease-out-sine': [0.390, 0.575, 0.565, 1.000],
    'ease-out-expo': [0.190, 1.000, 0.220, 1.000],
    'ease-out-circ': [0.075, 0.820, 0.165, 1.000],
    'ease-out-back': [0.175, 0.885, 0.320, 1.275],
    // EASE IN OUT
    'ease-in-out-quad': [0.455, 0.030, 0.515, 0.955],
    'ease-in-out-cubic': [0.645, 0.045, 0.355, 1.000],
    'ease-in-out-quart': [0.770, 0.000, 0.175, 1.000],
    'ease-in-out-quint': [0.860, 0.000, 0.070, 1.000],
    'ease-in-out-sine': [0.445, 0.050, 0.550, 0.950],
    'ease-in-out-expo': [1.000, 0.000, 0.000, 1.000],
    'ease-in-out-circ': [0.785, 0.135, 0.150, 0.860],
    'ease-in-out-back': [0.680, -0.550, 0.265, 1.550],
};
/**
 * Get `cubic-bezier(...)` from easing name.
 * @param easing The extended easing name.
 */
/** @hidden */
function getEasing(easing) {
    return CUBIC_BEZIER_EASINGS.hasOwnProperty(easing)
        ? 'cubic-bezier(' + CUBIC_BEZIER_EASINGS[easing].join(', ') + ')'
        : 'linear';
}
exports.getEasing = getEasing;
const elementTransitionMap = new WeakMap();
const definedTransition = new Map();
/** Register a js transiton. */
function defineTransion(name, TransitionConstructor) {
    if (definedTransition.has(name)) {
        console.warn(`You are trying to overwrite transition definition "${name}"`);
    }
    if (CSS_PROPERTIES.hasOwnProperty(name)) {
        console.warn(`"${name}" is an available CSS property, you may confuse them when using short transition`);
    }
    definedTransition.set(name, TransitionConstructor);
}
exports.defineTransion = defineTransion;
const CSS_PROPERTIES = {
    width: true,
    height: true,
    opacity: true,
    margin: true,
    marginLeft: true,
    marginRght: true,
    marginTop: true,
    marginBottom: true,
    padding: true,
    paddingLeft: true,
    paddingRght: true,
    paddingTop: true,
    paddingBottom: true,
    borderWidth: true,
    borderLeftWidth: true,
    borderRightWidth: true,
    borderTopWidth: true,
    borderBottomWidth: true,
    transform: true
};
/** @hidden */
function formatShortTransitionOptions(options) {
    if (Array.isArray(options)) {
        return {
            properties: options
        };
    }
    else if (typeof options === 'string') {
        if (CSS_PROPERTIES.hasOwnProperty(options)) {
            return {
                properties: [options]
            };
        }
        else {
            return {
                name: options
            };
        }
    }
    else {
        return options;
    }
}
exports.formatShortTransitionOptions = formatShortTransitionOptions;
/**
 * Class used to play specified transition on an element.
 * Transition types includes class name, css properties, and registered js transition.
 */
class Transition {
    constructor(el, options) {
        this.cleaner = null;
        this.el = el;
        this.options = formatShortTransitionOptions(options);
        clearTransition(this.el);
        elementTransitionMap.set(this.el, this);
    }
    enter() {
        return new Promise(resolve => {
            this.clean();
            let direction = this.options.direction;
            let willPlay = direction === 'enter' || direction === 'both' || direction === undefined;
            if (!willPlay) {
                resolve(true);
                return;
            }
            let onEntered = (finish) => {
                elementTransitionMap.delete(this.el);
                resolve(finish);
            };
            if (this.options.properties) {
                this.cssEnter(onEntered);
            }
            else if (definedTransition.has(name)) {
                this.jsEnter(onEntered);
            }
            else {
                this.classEnterOrLeave('enter', onEntered);
            }
        });
    }
    leave() {
        return new Promise(resolve => {
            this.clean();
            let direction = this.options.direction;
            let willPlay = direction === 'leave' || direction === 'both' || direction === undefined;
            if (!willPlay) {
                resolve(true);
                return;
            }
            let el = this.el;
            let onLeaved = (finish) => {
                el.style.pointerEvents = '';
                elementTransitionMap.delete(this.el);
                resolve(finish);
            };
            el.style.pointerEvents = 'none';
            if (this.options.properties) {
                this.cssLeave(onLeaved);
            }
            else if (definedTransition.has(name)) {
                this.jsLeave(onLeaved);
            }
            else {
                this.classEnterOrLeave('leave', onLeaved);
            }
        });
    }
    cssEnter(onEntered) {
        let startFrame = {};
        for (let property of this.options.properties) {
            startFrame[property] = property === 'transform' ? 'none' : '0';
        }
        let { promise, cancel } = animateFrom(this.el, startFrame, this.options.duration || DEFAULT_TRANSITION_OPTIONS.duration, this.options.easing || DEFAULT_TRANSITION_OPTIONS.easing);
        promise.then(onEntered);
        this.cleaner = cancel;
    }
    cssLeave(onLeaved) {
        let endFrame = {};
        for (let property of this.options.properties) {
            endFrame[property] = property === 'transform' ? 'none' : '0';
        }
        let { promise, cancel } = animateTo(this.el, endFrame, this.options.duration || DEFAULT_TRANSITION_OPTIONS.duration, this.options.easing || DEFAULT_TRANSITION_OPTIONS.easing);
        promise.then(onLeaved);
        this.cleaner = cancel;
    }
    jsEnter(onEntered) {
        let jsTransition = this.getJSTransitionInstance();
        if (jsTransition.enter) {
            jsTransition.enter.then(onEntered);
            this.cleaner = jsTransition.clean.bind(jsTransition);
        }
        else {
            onEntered(true);
        }
    }
    jsLeave(onLeaved) {
        let jsTransition = this.getJSTransitionInstance();
        if (jsTransition.leave) {
            jsTransition.leave.then(onLeaved);
            this.cleaner = jsTransition.clean.bind(jsTransition);
        }
        else {
            onLeaved(true);
        }
    }
    getJSTransitionInstance() {
        let JsTransition = definedTransition.get(this.options.name);
        return new JsTransition(this.el, {
            duration: this.options.duration || DEFAULT_TRANSITION_OPTIONS.duration,
            easing: this.options.easing || DEFAULT_TRANSITION_OPTIONS.easing
        });
    }
    async classEnterOrLeave(type, callback) {
        let className = this.options.name + '-' + type;
        let duration = this.options.duration;
        let easing = this.options.easing;
        let canceled = false;
        let el = this.el;
        if (duration) {
            el.style.transitionDuration = String(duration / 1000) + 's';
        }
        if (easing) {
            el.style.transitionTimingFunction = getEasing(easing);
        }
        el.style.transition = 'none';
        el.classList.add(className, className + '-from');
        this.cleaner = () => {
            canceled = true;
        };
        // Here to makesure rendering complete for current frame,
        // Then the next `requestAnimationFrame` will be called for a new frame.
        queue_1.onRenderComplete(() => {
            requestAnimationFrame(() => {
                if (canceled) {
                    el.classList.remove(className, className + '-from');
                    return;
                }
                if (duration) {
                    el.style.transitionDuration = '';
                }
                if (easing) {
                    el.style.transitionTimingFunction = '';
                }
                el.style.transition = '';
                el.classList.remove(className + '-from');
                el.classList.add(className + '-to');
                this.onceTransitionEnd((finish) => {
                    el.classList.remove(className, className + '-to');
                    callback(finish);
                });
            });
        });
    }
    onceTransitionEnd(onEnd) {
        let el = this.el;
        let computedStyle = getComputedStyle(el);
        let transitionDuration = parseFloat(computedStyle.transitionDuration) || 0;
        let animationDuration = parseFloat(computedStyle.animationDuration) || 0;
        let eventName = transitionDuration > 0 ? 'transitionend' : 'animationend';
        let duration = (transitionDuration || animationDuration) * 1000;
        let onTransitionEnd = () => {
            clearTimeout(timeoutId);
            el.style.pointerEvents = '';
            onEnd(true);
        };
        let onTimeout = () => {
            dom_event_1.off(el, eventName, onTransitionEnd);
            el.style.pointerEvents = '';
            onEnd(true);
        };
        let timeoutId = setTimeout(onTimeout, duration + 50);
        dom_event_1.once(el, eventName, onTransitionEnd);
        this.cleaner = () => {
            clearTimeout(timeoutId);
            dom_event_1.off(el, eventName, onTransitionEnd);
            onEnd(false);
        };
    }
    clean() {
        if (this.cleaner) {
            this.cleaner();
            this.cleaner = null;
        }
    }
}
exports.Transition = Transition;
/** Clear the transition that is running in the element. */
function clearTransition(el) {
    if (elementTransitionMap.has(el)) {
        elementTransitionMap.get(el).clean();
    }
}
exports.clearTransition = clearTransition;
function animate(el, startFrame, endFrame, duration, easing) {
    if (!el.animate) {
        return {
            promise: Promise.resolve(false),
            cancel: () => { }
        };
    }
    let cubicEasing = getEasing(easing);
    let animation = el.animate([startFrame, endFrame], {
        easing: cubicEasing,
        duration,
    });
    let promise = new Promise((resolve) => {
        animation.addEventListener('finish', () => {
            resolve(true);
        }, false);
        animation.addEventListener('cancel', () => {
            resolve(false);
        }, false);
    });
    function cancel() {
        animation.cancel();
    }
    return {
        promise,
        cancel
    };
}
/** The default style of element, which is not 0 */
const DEFAULT_STYLE = {
    transform: 'none'
};
function animateFrom(el, startFrame, duration, easing) {
    let endFrame = {};
    let style = getComputedStyle(el);
    for (let property in startFrame) {
        endFrame[property] = style[property] || DEFAULT_STYLE[property] || '0';
    }
    return animate(el, startFrame, endFrame, duration, easing);
}
function animateTo(el, endFrame, duration, easing) {
    let startFrame = {};
    let style = getComputedStyle(el);
    for (let property in endFrame) {
        startFrame[property] = style[property] || DEFAULT_STYLE[property] || '0';
    }
    return animate(el, startFrame, endFrame, duration, easing);
    // el will hide, no need to set style to end frame.
}


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/libs/util.js":
/*!*****************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/libs/util.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.repeatValue = exports.binaryFindIndexToInsert = exports.cloneAttributes = exports.trim = void 0;
function trim(text) {
    return text.replace(/^[\r\n\t]+|[\r\n\t]+$/g, '');
}
exports.trim = trim;
function cloneAttributes(el, attributes) {
    for (let { name, value } of attributes) {
        if ((name === 'class' || name === 'style') && el.hasAttribute(name)) {
            if (name === 'style') {
                value = el.getAttribute(name) + '; ' + value;
            }
            else if (name === 'class') {
                value = el.getAttribute(name) + ' ' + value;
            }
        }
        el.setAttribute(name, value);
    }
}
exports.cloneAttributes = cloneAttributes;
/**
 * Find the closest index in a sorted array in where to insert new item.
 * Returned index betweens `0 - array.length`, and if `array[index]` exist, `fn(array[index]) >= 0`.
 * @param array The sorted array.
 * @param fn The function to accept item in array as argument and returns `-1` to move left, `1` to move right.
 */
function binaryFindIndexToInsert(array, fn) {
    if (array.length === 0) {
        return 0;
    }
    let result = fn(array[0]);
    if (result === 0 || result === -1) {
        return 0;
    }
    if (array.length === 1) {
        return 1;
    }
    result = fn(array[array.length - 1]);
    if (result === 0) {
        return array.length - 1;
    }
    if (result === 1) {
        return array.length;
    }
    let start = 0;
    let end = array.length - 1;
    while (end - start > 1) {
        let center = Math.floor((end + start) / 2);
        let result = fn(array[center]);
        if (result === 0) {
            return center;
        }
        else if (result === -1) {
            end = center;
        }
        else {
            start = center;
        }
    }
    return end;
}
exports.binaryFindIndexToInsert = binaryFindIndexToInsert;
function repeatValue(value, count) {
    let values = [];
    for (let i = 0; i < count; i++) {
        values.push(value);
    }
    return values;
}
exports.repeatValue = repeatValue;


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/libs/watched-template.js":
/*!*****************************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/libs/watched-template.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.WatchedTemplate = void 0;
const template_1 = __webpack_require__(/*! ../template */ "./node_modules/@pucelle/flit/out/template/index.js");
const watcher_1 = __webpack_require__(/*! ../watcher */ "./node_modules/@pucelle/flit/out/watcher.js");
/** Used to watch and update template result generated from `templateFn`. */
class WatchedTemplate {
    constructor(context, templateFn, item, index) {
        this.context = context;
        this.templateFn = templateFn;
        this.item = item;
        this.index = index;
        this.parseAndWatchTemplate();
    }
    parseAndWatchTemplate() {
        let { templateFn } = this;
        let watchFn = () => {
            let result = templateFn(this.item, this.index);
            return result;
        };
        let onUpdate = (result) => {
            // Note that the template update in the watcher updating queue.
            if (this.template.canMergeWith(result)) {
                this.template.merge(result);
            }
            else {
                let newTemplate = new template_1.Template(result, this.context);
                this.template.range.startNode.before(newTemplate.range.getFragment());
                this.template.remove();
                this.template = newTemplate;
            }
        };
        let watcher = new watcher_1.InnerWatcher(watchFn, onUpdate);
        this.watcher = watcher;
        this.template = new template_1.Template(watcher.value, this.context);
        if (this.context) {
            this.context.__addWatcher(watcher);
        }
        else {
            watcher_1.globalWatcherGroup.add(watcher);
        }
    }
    updateIndex(index) {
        if (index !== this.index) {
            this.index = index;
            this.watcher.__updateImmediately();
        }
    }
    update(item, index) {
        if (item !== this.item || index !== this.index) {
            this.item = item;
            this.index = index;
            this.watcher.__updateImmediately();
        }
    }
    remove() {
        this.template.remove();
        this.watcher.disconnect();
    }
}
exports.WatchedTemplate = WatchedTemplate;


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/libs/weak-2way-map.js":
/*!**************************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/libs/weak-2way-map.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Weak2WayMap = void 0;
/**
 * Implement data constructor for two way map:
 * L -> R[]
 * R -> L[]
 */
// Benchmark 1: https://jsperf.com/set-always-add-or-test-if-has-first
// Benchmark 2: https://jsperf.com/is-merge-from-small-to-large-set-be-faster
class Weak2WayMap {
    constructor() {
        this.lm = new WeakMap();
        this.rm = new WeakMap();
    }
    updateFromLeft(l, rs) {
        let oldRs = this.lm.get(l);
        if (!oldRs || oldRs.size === 0) {
            for (let r of rs) {
                this.addRightLeftMap(r, l);
            }
        }
        else {
            // Very high rate no need to add or remove.
            // So we test if should add or remove firstly.
            for (let r of rs) {
                if (!oldRs.has(r)) {
                    this.addRightLeftMap(r, l);
                }
            }
            for (let r of oldRs) {
                if (!rs.has(r)) {
                    this.removeRightLeftMap(r, l);
                }
            }
        }
        this.lm.set(l, rs);
    }
    addRightLeftMap(r, l) {
        let ls = this.rm.get(r);
        if (!ls) {
            ls = new Set();
            this.rm.set(r, ls);
        }
        ls.add(l);
    }
    removeRightLeftMap(r, l) {
        let ls = this.rm.get(r);
        if (ls) {
            ls.delete(l);
        }
    }
    getFromRight(r) {
        return this.rm.get(r);
    }
    clearFromLeft(l) {
        let rs = this.lm.get(l);
        if (rs) {
            for (let r of rs) {
                this.removeRightLeftMap(r, l);
            }
            this.lm.delete(l);
        }
    }
    clearFromRight(r) {
        let ls = this.rm.get(r);
        if (ls) {
            for (let l of ls) {
                this.removeLeftRightMap(l, r);
            }
            this.rm.delete(r);
        }
    }
    removeLeftRightMap(l, r) {
        let rs = this.lm.get(l);
        if (rs) {
            rs.delete(r);
        }
    }
}
exports.Weak2WayMap = Weak2WayMap;


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/libs/weak-2way-prop-map.js":
/*!*******************************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/libs/weak-2way-prop-map.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Weak2WayPropMap = void 0;
/**
 * Implement data constructor for two way property map:
 * L -> { R: [prop] }
 * R -> { prop: [L] }
 */
// Benchmark refere to `wrek-2way-map`.
class Weak2WayPropMap {
    constructor() {
        this.lm = new WeakMap();
        this.rm = new WeakMap();
    }
    updateFromLeft(l, rps) {
        let oldRps = this.lm.get(l);
        if (!oldRps || oldRps.size === 0) {
            for (let [r, props] of rps) {
                this.addRightLeftMap(r, props, l);
            }
        }
        else {
            for (let [r, props] of rps) {
                if (oldRps.has(r)) {
                    this.updateRightLeftMap(r, oldRps.get(r), props, l);
                }
                else {
                    this.addRightLeftMap(r, props, l);
                }
            }
            for (let [r, props] of oldRps) {
                if (!rps.has(r)) {
                    this.removeRightLeftMap(r, props, l);
                }
            }
        }
        this.lm.set(l, rps);
    }
    addRightLeftMap(r, props, l) {
        let pls = this.rm.get(r);
        if (!pls) {
            pls = new Map();
            this.rm.set(r, pls);
        }
        for (let prop of props) {
            let ls = pls.get(prop);
            if (!ls) {
                ls = new Set();
                pls.set(prop, ls);
            }
            ls.add(l);
        }
    }
    updateRightLeftMap(r, oldProps, newProps, l) {
        let pls = this.rm.get(r);
        if (pls) {
            for (let prop of newProps) {
                if (!oldProps.has(prop)) {
                    let ls = pls.get(prop);
                    if (!ls) {
                        ls = new Set();
                        pls.set(prop, ls);
                    }
                    ls.add(l);
                }
            }
            for (let prop of oldProps) {
                if (!newProps.has(prop)) {
                    let ls = pls.get(prop);
                    if (ls) {
                        ls.delete(l);
                    }
                }
            }
        }
    }
    removeRightLeftMap(r, props, l) {
        let pls = this.rm.get(r);
        if (pls) {
            for (let prop of props) {
                let ls = pls.get(prop);
                if (ls) {
                    ls.delete(l);
                }
            }
        }
    }
    getFromRight(r, prop) {
        let pls = this.rm.get(r);
        if (pls) {
            return pls.get(prop);
        }
        return undefined;
    }
    clearFromLeft(l) {
        let rps = this.lm.get(l);
        if (rps) {
            for (let [r, props] of rps) {
                this.removeRightLeftMap(r, props, l);
            }
            this.lm.delete(l);
        }
    }
    clearFromRight(r) {
        let pls = this.rm.get(r);
        if (pls) {
            for (let ls of pls.values()) {
                for (let l of ls) {
                    this.removeLeftRightMap(l, r);
                }
            }
            // Comment this line very important:
            // R may be connect again, so we can restore `L -> R -> prop` from the `R -> prop -> L`.
            // Don't worry, it doesn't prevent GC for `R`.
            //this.rm.delete(r)
        }
    }
    removeLeftRightMap(l, r) {
        let rps = this.lm.get(l);
        if (rps) {
            rps.delete(r);
        }
    }
    restoreFromRight(r) {
        let pls = this.rm.get(r);
        if (pls) {
            for (let [prop, ls] of pls.entries()) {
                for (let l of ls) {
                    this.addLeftRightMap(l, r, prop);
                }
            }
        }
    }
    addLeftRightMap(l, r, prop) {
        let rps = this.lm.get(l);
        if (!rps) {
            rps = new Map();
            this.lm.set(l, rps);
        }
        let ps = rps.get(r);
        if (!ps) {
            ps = new Set();
            rps.set(r, ps);
        }
        ps.add(prop);
    }
}
exports.Weak2WayPropMap = Weak2WayPropMap;


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/observer/dependency.js":
/*!***************************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/observer/dependency.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.notifyObjectSet = exports.notifyComPropertySet = exports.mayAddComDependency = exports.mayAddDependency = exports.restoreAsDependency = exports.clearAsDependency = exports.clearDependencies = exports.isUpdating = exports.endUpdating = exports.startUpdating = void 0;
const shared_1 = __webpack_require__(/*! ./shared */ "./node_modules/@pucelle/flit/out/observer/shared.js");
const weak_2way_map_1 = __webpack_require__(/*! ../libs/weak-2way-map */ "./node_modules/@pucelle/flit/out/libs/weak-2way-map.js");
const weak_2way_prop_map_1 = __webpack_require__(/*! ../libs/weak-2way-prop-map */ "./node_modules/@pucelle/flit/out/libs/weak-2way-prop-map.js");
/**
 * To know when rendering component, which objects we used.
 * And to know when object changed, which component or watcher should be update.
 * Otherwise we need to remove from left when component disconnected.
 *
 * If the dependent objects were removed, the component or watchers should be updated, And it will clear dependencies before.
 * So cached the objects will not prevent GC.
 */
const depMap = new weak_2way_map_1.Weak2WayMap();
/**
 * To know when rendering component, which component and what's the properties it called.
 * And to know when specified property in object changed, which component should be update.
 *
 * Why we don't observe properties for all the object but only component?
 * In fact I do so at beginning, until one day I found 1M dependencies in my app.
 * There is no memory leak, my app just may load more than 20K data records.
 * Otherwise, now we are using not 100% precise updating, and update whole component part for once.
 * no need to observe every details.
 */
const comPropMap = new weak_2way_prop_map_1.Weak2WayPropMap();
let updating = null;
// a stack is required, `watchImmediately` need to be update immediately,
// but an component may be updating recently.
const updatingStack = [];
/** Called when start rendering proxied component or running watch functions. */
function startUpdating(upt) {
    if (updating) {
        updatingStack.push(updating);
    }
    updating = {
        target: upt,
        deps: new Set(),
        depPropMap: new Map()
    };
}
exports.startUpdating = startUpdating;
/** Called when complete rendering component or complete running watch functions. */
function endUpdating(_upt) {
    if (updating) {
        depMap.updateFromLeft(updating.target, updating.deps);
        comPropMap.updateFromLeft(updating.target, updating.depPropMap);
        updating = updatingStack.pop() || null;
    }
}
exports.endUpdating = endUpdating;
/** Returns if is updating recently. */
function isUpdating() {
    return !!updating;
}
exports.isUpdating = isUpdating;
/** Called when start rendering component or running watch functions, or component and watcher disconnected. */
function clearDependencies(updating) {
    depMap.clearFromLeft(updating);
    comPropMap.clearFromLeft(updating);
}
exports.clearDependencies = clearDependencies;
/**
 * Called when don't want to obserse object or component changing.
 * In fact `dep` can only be component target.
 */
function clearAsDependency(proxiedDep) {
    let dep = shared_1.targetMap.get(proxiedDep);
    depMap.clearFromRight(dep);
    comPropMap.clearFromRight(dep);
}
exports.clearAsDependency = clearAsDependency;
// when one component or watcher was disconnected and connect again,
// it can easily restore it's dependencies by `update()`,
// But an dependency, we can't restore it's influenced components or watchers .
// So we keep the `dep -> prop -> upt` map, and restore `upt -> dep -> prop` map when `dep` connected again.
/** When one component or watcher connected again, here to restore that what it can update. */
function restoreAsDependency(proxiedDep) {
    let dep = shared_1.targetMap.get(proxiedDep);
    comPropMap.restoreFromRight(dep);
}
exports.restoreAsDependency = restoreAsDependency;
// We split adding dependencies to two steps:
//   1. Collect dependencies, cache them.
//   2. Merge them into dependency tree.
// 
// May use one object dependency for moren than 100 times in one updating,
// no need to update dependency tree for each calling.
// 
// Otherwise, a very high rate the dependencies are no need to update.
/** Called when in object's or array's proxy.get. */
function mayAddDependency(dep) {
    if (!updating) {
        return;
    }
    updating.deps.add(dep);
}
exports.mayAddDependency = mayAddDependency;
/** Called when in component's proxy.get. */
function mayAddComDependency(com, prop) {
    if (!updating) {
        return;
    }
    let propertySet = updating.depPropMap.get(com);
    if (!propertySet) {
        propertySet = new Set();
        updating.depPropMap.set(com, propertySet);
    }
    propertySet.add(prop);
}
exports.mayAddComDependency = mayAddComDependency;
/** Called when in component's proxy.set. */
function notifyComPropertySet(com, prop) {
    let upts = comPropMap.getFromRight(com, prop);
    if (upts) {
        for (let upt of upts) {
            upt.update();
        }
    }
}
exports.notifyComPropertySet = notifyComPropertySet;
/** Called when in array's or object's proxy.set. */
function notifyObjectSet(obj) {
    let upts = depMap.getFromRight(obj);
    if (upts) {
        for (let upt of upts) {
            upt.update();
        }
    }
}
exports.notifyObjectSet = notifyObjectSet;


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/observer/index.js":
/*!**********************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/observer/index.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


// Proxy benchmark: https://jsperf.com/es6-proxy/11
// Proxy getting and setting are always 50x-100x slower than plain object.
// Proxy can't apply any compile optimizing, it equals always call a dynamic function.
Object.defineProperty(exports, "__esModule", ({ value: true }));
var shared_1 = __webpack_require__(/*! ./shared */ "./node_modules/@pucelle/flit/out/observer/shared.js");
Object.defineProperty(exports, "observeTarget", ({ enumerable: true, get: function () { return shared_1.observeTarget; } }));
Object.defineProperty(exports, "getObservedTarget", ({ enumerable: true, get: function () { return shared_1.getObservedTarget; } }));
var observe_1 = __webpack_require__(/*! ./observe */ "./node_modules/@pucelle/flit/out/observer/observe.js");
Object.defineProperty(exports, "observe", ({ enumerable: true, get: function () { return observe_1.observe; } }));
var observe_com_1 = __webpack_require__(/*! ./observe-com */ "./node_modules/@pucelle/flit/out/observer/observe-com.js");
Object.defineProperty(exports, "observeComTarget", ({ enumerable: true, get: function () { return observe_com_1.observeComTarget; } }));
var dependency_1 = __webpack_require__(/*! ./dependency */ "./node_modules/@pucelle/flit/out/observer/dependency.js");
Object.defineProperty(exports, "startUpdating", ({ enumerable: true, get: function () { return dependency_1.startUpdating; } }));
Object.defineProperty(exports, "endUpdating", ({ enumerable: true, get: function () { return dependency_1.endUpdating; } }));
Object.defineProperty(exports, "clearDependencies", ({ enumerable: true, get: function () { return dependency_1.clearDependencies; } }));
Object.defineProperty(exports, "clearAsDependency", ({ enumerable: true, get: function () { return dependency_1.clearAsDependency; } }));
Object.defineProperty(exports, "restoreAsDependency", ({ enumerable: true, get: function () { return dependency_1.restoreAsDependency; } }));
var observe_getter_1 = __webpack_require__(/*! ./observe-getter */ "./node_modules/@pucelle/flit/out/observer/observe-getter.js");
Object.defineProperty(exports, "observeGetter", ({ enumerable: true, get: function () { return observe_getter_1.observeGetter; } }));


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/observer/observe-array.js":
/*!******************************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/observer/observe-array.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.observeArrayTarget = void 0;
const dependency_1 = __webpack_require__(/*! ./dependency */ "./node_modules/@pucelle/flit/out/observer/dependency.js");
const shared_1 = __webpack_require__(/*! ./shared */ "./node_modules/@pucelle/flit/out/observer/shared.js");
const ARRAY_SET_METHODS = ['push', 'pop', 'unshift', 'splice', 'shift', 'sort'];
function observeArrayTarget(arr) {
    let proxy = new Proxy(arr, proxyHandler);
    shared_1.proxyMap.set(arr, proxy);
    shared_1.proxyMap.set(proxy, proxy);
    shared_1.targetMap.set(proxy, arr);
    return proxy;
}
exports.observeArrayTarget = observeArrayTarget;
const proxyHandler = {
    get(arr, prop) {
        let value = arr[prop];
        let type = typeof value;
        if (arr.hasOwnProperty(prop)) {
            dependency_1.mayAddDependency(arr);
            if (value && type === 'object') {
                if (shared_1.proxyMap.has(value)) {
                    return shared_1.proxyMap.get(value);
                }
                else if (dependency_1.isUpdating()) {
                    return shared_1.observeTarget(value);
                }
            }
        }
        else if (type === 'function') {
            dependency_1.mayAddDependency(arr);
            if (ARRAY_SET_METHODS.includes(prop)) {
                dependency_1.notifyObjectSet(arr);
            }
        }
        return value;
    },
    set(arr, prop, value) {
        arr[prop] = value;
        dependency_1.notifyObjectSet(arr);
        return true;
    },
    has(arr, prop) {
        dependency_1.mayAddDependency(arr);
        return prop in arr;
    },
    deleteProperty(arr, prop) {
        if (arr.hasOwnProperty(prop)) {
            dependency_1.mayAddDependency(arr);
            return delete arr[prop];
        }
        else {
            return true;
        }
    }
};


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/observer/observe-com.js":
/*!****************************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/observer/observe-com.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.observeComTarget = void 0;
const dependency_1 = __webpack_require__(/*! ./dependency */ "./node_modules/@pucelle/flit/out/observer/dependency.js");
const shared_1 = __webpack_require__(/*! ./shared */ "./node_modules/@pucelle/flit/out/observer/shared.js");
function observeComTarget(com) {
    let proxy = new Proxy(com, proxyHandler);
    shared_1.proxyMap.set(com, proxy);
    shared_1.proxyMap.set(proxy, proxy);
    shared_1.targetMap.set(proxy, com);
    return proxy;
}
exports.observeComTarget = observeComTarget;
const proxyHandler = {
    get(com, prop) {
        let value = com[prop];
        // It doesn't check if own property exists here.
        // It's common that to declare `property!: Type` in Typescript,
        // Which has no initialize value but still need to be observed.
        dependency_1.mayAddComDependency(com, prop);
        if (value && typeof value === 'object') {
            if (shared_1.proxyMap.has(value)) {
                return shared_1.proxyMap.get(value);
            }
            // Here means it will only observe more data when updating.
            // If we choose to always observe every value, so many proxies will be generated.
            // Only generate new proxy only when updating still have a little problem.
            // If we cached some not proxy values, modify them will not cause rerender.
            else if (dependency_1.isUpdating()) {
                return shared_1.observeTarget(value);
            }
        }
        return value;
    },
    set(com, prop, value) {
        com[prop] = value;
        dependency_1.notifyComPropertySet(com, prop);
        return true;
    },
    has(com, prop) {
        dependency_1.mayAddComDependency(com, prop);
        return prop in com;
    },
    deleteProperty(com, prop) {
        if (com.hasOwnProperty(prop)) {
            dependency_1.mayAddComDependency(com, prop);
            return delete com[prop];
        }
        else {
            return true;
        }
    }
};


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/observer/observe-getter.js":
/*!*******************************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/observer/observe-getter.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.observeGetter = void 0;
/**
 * After think more about getter, we decided to drop supports for observing getters automatically.
 * The main reason is when we observe get callings in proxy, we can't distinguish if it's a normal property
 * or a getter calling immediately, but we must to follow prototype chains to find the getter descriptor,
 * and call the getter function manually by: `descriptor.get.call(objectProxy)`.

 * You can still check getter descriptor and call it with proxied object manually.
 */
function observeGetter(obj, getterProperty) {
    let descriptor = getPropertyDescriptor(obj, getterProperty);
    if (descriptor && descriptor.get) {
        return descriptor.get.call(obj);
    }
    else {
        return obj[getterProperty];
    }
}
exports.observeGetter = observeGetter;
function getPropertyDescriptor(obj, property) {
    let proto = obj;
    do {
        let descriptor = Object.getOwnPropertyDescriptor(proto, property);
        if (descriptor) {
            return descriptor;
        }
        else {
            proto = Object.getPrototypeOf(proto);
        }
    } while (proto);
    return null;
}


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/observer/observe-object.js":
/*!*******************************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/observer/observe-object.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.observePlainObjectTarget = void 0;
const dependency_1 = __webpack_require__(/*! ./dependency */ "./node_modules/@pucelle/flit/out/observer/dependency.js");
const shared_1 = __webpack_require__(/*! ./shared */ "./node_modules/@pucelle/flit/out/observer/shared.js");
function observePlainObjectTarget(obj) {
    let proxy = new Proxy(obj, proxyHandler);
    shared_1.proxyMap.set(obj, proxy);
    shared_1.proxyMap.set(proxy, proxy);
    shared_1.targetMap.set(proxy, obj);
    return proxy;
}
exports.observePlainObjectTarget = observePlainObjectTarget;
const proxyHandler = {
    get(obj, prop) {
        let value = obj[prop];
        dependency_1.mayAddDependency(obj);
        if (value && typeof value === 'object') {
            if (shared_1.proxyMap.has(value)) {
                return shared_1.proxyMap.get(value);
            }
            else if (dependency_1.isUpdating()) {
                return shared_1.observeTarget(value);
            }
        }
        return value;
    },
    set(obj, prop, value) {
        obj[prop] = value;
        dependency_1.notifyObjectSet(obj);
        return true;
    },
    has(obj, prop) {
        dependency_1.mayAddDependency(obj);
        return prop in obj;
    },
    deleteProperty(obj, prop) {
        if (obj.hasOwnProperty(prop)) {
            dependency_1.mayAddDependency(obj);
            return delete obj[prop];
        }
        else {
            return true;
        }
    }
};


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/observer/observe-set-or-map.js":
/*!***********************************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/observer/observe-set-or-map.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.observeMapOrSetTarget = void 0;
const dependency_1 = __webpack_require__(/*! ./dependency */ "./node_modules/@pucelle/flit/out/observer/dependency.js");
const shared_1 = __webpack_require__(/*! ./shared */ "./node_modules/@pucelle/flit/out/observer/shared.js");
const MAP_SET_METHODS = ['add', 'set', 'delete', 'clear'];
function observeMapOrSetTarget(ms) {
    let proxy = new Proxy(ms, proxyHandler);
    shared_1.proxyMap.set(ms, proxy);
    shared_1.proxyMap.set(proxy, proxy);
    shared_1.targetMap.set(proxy, ms);
    return proxy;
}
exports.observeMapOrSetTarget = observeMapOrSetTarget;
// A potential issue in map and set:
// We may add an item to a set, and then test if proxy of item in set,
// or add proxy of item and cause it has duplicate values in set.
// We will fix this when we indeed meet this.
const proxyHandler = {
    get(ms, prop) {
        let value = ms[prop];
        let type = typeof value;
        if (!ms.hasOwnProperty(prop) && type === 'function') {
            // Required, pass proxy as this to native Set or Map methods will cause error.
            value = value.bind(ms);
            dependency_1.mayAddDependency(ms);
            if (MAP_SET_METHODS.includes(prop)) {
                dependency_1.notifyObjectSet(ms);
            }
        }
        return value;
    }
};


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/observer/observe.js":
/*!************************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/observer/observe.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.observe = void 0;
const shared_1 = __webpack_require__(/*! ./shared */ "./node_modules/@pucelle/flit/out/observer/shared.js");
/**
 * Begin to track `value`'s property settings, and update components which use `value`'s properties when needed.
 * Note that if returns a proxy, it can be used like original object, but it's not it, compare with `===` will return `false`.
 * So it may cause some issue if you cached the original object and compare it with observed one.
 * Normally you don't need to call this, component's properties will be observed automatically after used when rendering.
 * Once an object was observed, it can't be revoked.
 */
function observe(value) {
    if (value && typeof value === 'object') {
        let proxy = shared_1.proxyMap.get(value);
        if (proxy) {
            return proxy;
        }
        return shared_1.observeTarget(value);
    }
    else {
        return value;
    }
}
exports.observe = observe;


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/observer/shared.js":
/*!***********************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/observer/shared.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.getObservedTarget = exports.observeTarget = exports.targetMap = exports.proxyMap = void 0;
const observe_object_1 = __webpack_require__(/*! ./observe-object */ "./node_modules/@pucelle/flit/out/observer/observe-object.js");
const observe_array_1 = __webpack_require__(/*! ./observe-array */ "./node_modules/@pucelle/flit/out/observer/observe-array.js");
const observe_set_or_map_1 = __webpack_require__(/*! ./observe-set-or-map */ "./node_modules/@pucelle/flit/out/observer/observe-set-or-map.js");
/** `target -> proxy` and `proxy -> proxy` */
exports.proxyMap = new WeakMap();
/** `proxy -> target` */
exports.targetMap = new WeakMap();
const originalToString = Object.prototype.toString;
function observeTarget(obj) {
    let str = originalToString.call(obj);
    if (str === '[object Array]') {
        return observe_array_1.observeArrayTarget(obj);
    }
    if (str === '[object Object]') {
        return observe_object_1.observePlainObjectTarget(obj);
    }
    if (str === '[object Set]' || str === '[object Map]') {
        return observe_set_or_map_1.observeMapOrSetTarget(obj);
    }
    return obj;
}
exports.observeTarget = observeTarget;
/** Returns target of observed object, or returns the argument if not been observed. */
function getObservedTarget(observed) {
    return exports.targetMap.get(observed) || observed;
}
exports.getObservedTarget = getObservedTarget;


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/queue.js":
/*!*************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/queue.js ***!
  \*************************************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.renderComplete = exports.onRenderComplete = exports.enqueueInnerWatcherToUpdate = exports.enqueueWatcherToUpdate = exports.enqueueComponentToUpdate = void 0;
let componentSet = new Set();
let watcherSet = new Set();
let innerWatcherSet = new Set();
let renderCompleteCallbacks = [];
let willUpdate = false;
let updatingComponents = false;
let watchersToUpdate = [];
let innerWatchersToUpdate = [];
let componentsToUpdate = [];
let updatedTimesMap = new Map();
/** @hidden */
function enqueueComponentToUpdate(com) {
    // If updating component trigger another watcher or component, we should update it in the same update function.
    if (!componentSet.has(com)) {
        if (updatingComponents) {
            let updatedTimes = updatedTimesMap.get(com) || 0;
            updatedTimesMap.set(com, updatedTimes + 1);
            if (updatedTimes > 3) {
                let html = com.el.outerHTML;
                let shortHTML = html.length > 100 ? html.slice(0, 100) + '...' : html;
                console.warn(`Component with element "${shortHTML}" may change values in the render function and cause infinite updating!`);
            }
        }
        componentSet.add(com);
        componentsToUpdate.push(com);
    }
    if (!willUpdate) {
        enqueueUpdate();
    }
}
exports.enqueueComponentToUpdate = enqueueComponentToUpdate;
/** @hidden */
function enqueueWatcherToUpdate(watcher) {
    if (updatingComponents) {
        watcher.__updateImmediately();
    }
    else {
        // If updating watcher trigger another watcher or component, we should update it in the same update function.
        if (!watcherSet.has(watcher)) {
            watcherSet.add(watcher);
            watchersToUpdate.push(watcher);
        }
        if (!willUpdate) {
            enqueueUpdate();
        }
    }
}
exports.enqueueWatcherToUpdate = enqueueWatcherToUpdate;
/** @hidden */
function enqueueInnerWatcherToUpdate(watcher) {
    // If updating watcher trigger another watcher or component, we should update it in the same update function.
    if (!innerWatcherSet.has(watcher)) {
        innerWatcherSet.add(watcher);
        innerWatchersToUpdate.push(watcher);
    }
    if (!willUpdate) {
        enqueueUpdate();
    }
}
exports.enqueueInnerWatcherToUpdate = enqueueInnerWatcherToUpdate;
/**
 * Call `callback` after rendered all the components in followed micro task queues.
 * Note that it was called before `renderComplete`.
 */
function onRenderComplete(callback) {
    renderCompleteCallbacks.push(callback);
    if (!willUpdate) {
        enqueueUpdate();
    }
}
exports.onRenderComplete = onRenderComplete;
/**
 * Returns a promise which will be resolved after rendered all the components in micro task queues.
 * Note that it was called after `onRenderComplete`.
 * So if you are implementing a common component, using `onRenderComplete` would be better.
 * Please don't call `await renderComplete()` for two times,
 * The second one will be called in a new `requestAnimationFrame` and browser will render before it.
 */
function renderComplete() {
    return new Promise(resolve => {
        onRenderComplete(resolve);
    });
}
exports.renderComplete = renderComplete;
function enqueueUpdate() {
    // Why not using `Promise.resolve().then` to start a micro stask:
    // When initialize a component from `connectedCallback`, it's child nodes is not ready,
    // even in the following micro task queue.
    // But we need `<slot>` elemnts to be prepared before updating.
    // Otherwise it's very frequently to trigger updating from data changing ,
    // but then more data changes in micro tasks and trigger new updating.
    requestAnimationFrame(update);
    willUpdate = true;
}
async function update() {
    do {
        // At beginning, we update watchers firstly and then components,
        // because we want to reduce the sencories that data changing in watchers cause components to updated.
        // But later we relaized the watchers were updated most possible because the components updated and applied `:prop` or `:props`,
        // And updating watchers later can ensure components which requires the watched properties are rendered.
        // So finally we decided to update watchers before components,
        // And if components are updating, we update watchers immediately.
        for (let i = 0; i < watchersToUpdate.length; i++) {
            let watcher = watchersToUpdate[i];
            // Delete it so it can be added again.
            watcherSet.delete(watcher);
            let updatedTimes = updatedTimesMap.get(watcher) || 0;
            updatedTimesMap.set(watcher, updatedTimes + 1);
            if (updatedTimes > 3) {
                console.warn(`Watcher "${watcher.toString()}" may change values in the watcher callback and cause infinite updating!`);
            }
            else {
                try {
                    watcher.__updateImmediately();
                }
                catch (err) {
                    console.error(err);
                }
            }
        }
        watchersToUpdate = [];
        updatingComponents = true;
        for (let i = 0; i < componentsToUpdate.length; i++) {
            let com = componentsToUpdate[i];
            componentSet.delete(com);
            try {
                com.__updateImmediately();
            }
            catch (err) {
                console.error(err);
            }
        }
        componentsToUpdate = [];
        updatingComponents = false;
        for (let i = 0; i < innerWatchersToUpdate.length; i++) {
            let watcher = innerWatchersToUpdate[i];
            // Delete it so it can be added again.
            innerWatcherSet.delete(watcher);
            let updatedTimes = updatedTimesMap.get(watcher) || 0;
            updatedTimesMap.set(watcher, updatedTimes + 1);
            if (updatedTimes > 3) {
                console.warn(`Watcher "${watcher.toString()}" may change values in the watcher callback and cause infinite updating!`);
            }
            else {
                try {
                    watcher.__updateImmediately();
                }
                catch (err) {
                    console.error(err);
                }
            }
        }
        innerWatchersToUpdate = [];
        // If elements were added when updating, they will be connected in micro task queue.
        // Here we must wait them to be instantiated.
        await Promise.resolve();
    } while (componentsToUpdate.length > 0 || watchersToUpdate.length > 0);
    willUpdate = false;
    updatedTimesMap = new Map();
    // Normally `onRenderComplete` should not enqueue more watchers and components.
    // But if it enqueued, run them in next updating.
    let callbacks = renderCompleteCallbacks;
    renderCompleteCallbacks = [];
    for (let callback of callbacks) {
        callback();
    }
}


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/render.js":
/*!**************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/render.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.appendTo = exports.renderComponent = exports.render = void 0;
const template_1 = __webpack_require__(/*! ./template */ "./node_modules/@pucelle/flit/out/template/index.js");
const component_1 = __webpack_require__(/*! ./component */ "./node_modules/@pucelle/flit/out/component/index.js");
const watcher_1 = __webpack_require__(/*! ./watcher */ "./node_modules/@pucelle/flit/out/watcher.js");
const directives_1 = __webpack_require__(/*! ./directives */ "./node_modules/@pucelle/flit/out/directives/index.js");
function render(codesOrRenderFn, context = null, onUpdate) {
    if (typeof codesOrRenderFn === 'function') {
        return renderAndWatch(codesOrRenderFn, context, onUpdate);
    }
    else {
        return renderCodes(codesOrRenderFn, context);
    }
}
exports.render = render;
function renderCodes(codes, context = null) {
    if (codes instanceof directives_1.DirectiveResult) {
        codes = template_1.html `${codes}`;
    }
    let template = new template_1.Template(codes, context);
    let fragment = template.range.getFragment();
    return { template, fragment };
}
function renderAndWatch(renderFn, context = null, onUpdate) {
    let template;
    let unwatch = (context || watcher_1.globalWatcherGroup).watchImmediately(renderFn, (result) => {
        if (result instanceof directives_1.DirectiveResult) {
            result = template_1.html `${result}`;
        }
        if (template) {
            template.merge(result);
            if (onUpdate) {
                onUpdate();
            }
        }
        else {
            template = new template_1.Template(result, context);
        }
    });
    return {
        fragment: template.range.getFragment(),
        unwatch,
    };
}
function renderComponent(codesOrFn, context = null, onUpdate) {
    let template;
    let fragment;
    let component = null;
    let unwatch = null;
    if (typeof codesOrFn === 'function') {
        ({ fragment, unwatch } = renderAndWatch(codesOrFn, context, onUpdate));
    }
    else {
        ({ fragment, template } = render(codesOrFn, context));
    }
    let firstElement = fragment.firstElementChild;
    if (firstElement) {
        let Com = component_1.getComponentConstructor(firstElement.localName);
        if (Com) {
            component = component_1.createComponent(firstElement, Com);
        }
    }
    if (unwatch) {
        return { component, unwatch };
    }
    else {
        return { component, template: template };
    }
}
exports.renderComponent = renderComponent;
/**
 * Append a fragment or element into target element or selector.
 * Returns the first element in the fragment.
 * It's a helper function to use like `appendTo(render(...), document.body)`.
 * @param fragment The fragment to append.
 * @param target The target element to append to.
 */
function appendTo(el, target) {
    let firstElement = el.firstElementChild;
    if (typeof target === 'string') {
        let targetEl = document.querySelector(target);
        if (targetEl && targetEl.lastElementChild !== el) {
            targetEl.append(el);
        }
    }
    else if (target && target.lastElementChild !== el) {
        target.append(el);
    }
    return firstElement;
}
exports.appendTo = appendTo;


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/template/attr-part.js":
/*!**************************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/template/attr-part.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.AttrPart = void 0;
/**
 * `<tag attr=${...}`, to set attribute value.
 */
class AttrPart {
    constructor(el, name, value) {
        this.el = el;
        this.name = name;
        this.setValue(value);
    }
    setValue(value) {
        value === null || value === undefined ? '' : String(value);
        this.el.setAttribute(this.name, value);
    }
    update(value) {
        this.setValue(value);
    }
    remove() { }
}
exports.AttrPart = AttrPart;


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/template/binding-part.js":
/*!*****************************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/template/binding-part.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.BindingPart = exports.FixedBindingPart = void 0;
const bindings_1 = __webpack_require__(/*! ../bindings */ "./node_modules/@pucelle/flit/out/bindings/index.js");
/**
 * Transfer arguments to a fixed type binding module, e.g.:
 * `:class=${...}`, `:style=${...}`, `:ref="..."`.
 */
class FixedBindingPart {
    constructor(el, name, value, context) {
        let dotIndex = name.indexOf('.');
        let bindingName = dotIndex > -1 ? name.slice(0, dotIndex) : name;
        let bindingModifiers = dotIndex > -1 ? name.slice(dotIndex + 1).split('.') : undefined;
        let result = new bindings_1.BindingResult(bindingName, value);
        this.binding = bindings_1.createBindingFromResult(el, context, result, bindingModifiers);
    }
    update(value) {
        this.binding.update(value);
    }
    remove() {
        this.binding.remove();
    }
}
exports.FixedBindingPart = FixedBindingPart;
/**
 * Transfer arguments to binding module, used in:
 * `<tag show(...)>`, `<tag hide(...)>`, `<tag cache(...)>`.
 */
class BindingPart {
    constructor(el, value, context) {
        this.binding = null;
        this.name = null;
        this.el = el;
        this.context = context;
        if (value instanceof bindings_1.BindingResult) {
            this.name = value.name;
            this.binding = bindings_1.createBindingFromResult(el, context, value);
            this.binding.update(...value.args);
        }
    }
    update(value) {
        if (value instanceof bindings_1.BindingResult) {
            if (value.name === this.name) {
                this.binding.update(...value.args);
            }
            else {
                this.removeCurrentBinding();
                this.binding = bindings_1.createBindingFromResult(this.el, this.context, value);
            }
        }
        else {
            this.removeCurrentBinding();
        }
    }
    removeCurrentBinding() {
        if (this.binding) {
            this.name = null;
            this.binding.remove();
            this.binding = null;
        }
    }
    remove() {
        if (this.binding) {
            this.binding.remove();
        }
    }
}
exports.BindingPart = BindingPart;


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/template/event-part.js":
/*!***************************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/template/event-part.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.EventPart = void 0;
const component_1 = __webpack_require__(/*! ../component */ "./node_modules/@pucelle/flit/out/component/index.js");
const dom_event_1 = __webpack_require__(/*! ../libs/dom-event */ "./node_modules/@pucelle/flit/out/libs/dom-event.js");
/**
 * `<div @click=${...}>` to register event on element.
 * `<com @event=${...}>` to register event on component.
 * `<com @@event=${...}>` to register event always on element.
 */
class EventPart {
    constructor(el, name, handler, context) {
        this.el = el;
        this.name = name[0] === '@' ? name.slice(1) : name;
        this.context = context;
        this.isComEvent = el.localName.includes('-') && name[0] !== '@';
        this.update(handler);
        this.bindListener();
    }
    update(handler) {
        if (typeof handler !== 'function') {
            throw new Error(`Failed to register listener at "<${this.el.localName} @${this.name}='${handler}'">, listener is not a function`);
        }
        // Should here compare handler `toString` result and not update if they are the same?
        // This sames required, because it's frequently to meet handlers like `() => ...`.
        // But the truth is that we must update the handler,
        // because the scoped variables that called in these handlers may changed.
        this.handler = handler;
    }
    bindListener() {
        if (this.isComEvent) {
            let com = component_1.getComponent(this.el);
            if (com) {
                this.bindComListener(com);
            }
            else {
                component_1.onComponentCreatedAt(this.el, this.bindComListener.bind(this));
            }
        }
        else {
            dom_event_1.on(this.el, this.name, this.triggerHandler, this);
        }
    }
    bindComListener(com) {
        com.on(this.name, this.triggerHandler, this);
    }
    triggerHandler(...args) {
        this.handler.call(this.context, ...args);
    }
    // If element was removed, it implies that the component was removed too.
    // No need to off listener.
    remove() { }
}
exports.EventPart = EventPart;


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/template/index.js":
/*!**********************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/template/index.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
var node_part_1 = __webpack_require__(/*! ./node-part */ "./node_modules/@pucelle/flit/out/template/node-part.js");
Object.defineProperty(exports, "NodePart", ({ enumerable: true, get: function () { return node_part_1.NodePart; } }));
var template_1 = __webpack_require__(/*! ./template */ "./node_modules/@pucelle/flit/out/template/template.js");
Object.defineProperty(exports, "Template", ({ enumerable: true, get: function () { return template_1.Template; } }));
var template_result_1 = __webpack_require__(/*! ./template-result */ "./node_modules/@pucelle/flit/out/template/template-result.js");
Object.defineProperty(exports, "TemplateResult", ({ enumerable: true, get: function () { return template_result_1.TemplateResult; } }));
Object.defineProperty(exports, "html", ({ enumerable: true, get: function () { return template_result_1.html; } }));
Object.defineProperty(exports, "css", ({ enumerable: true, get: function () { return template_result_1.css; } }));
Object.defineProperty(exports, "svg", ({ enumerable: true, get: function () { return template_result_1.svg; } }));


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/template/may-attr-part.js":
/*!******************************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/template/may-attr-part.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.MayAttrPart = void 0;
/**
 * `?checked=${...}`, remove the attribute if expression returns false.
 */
class MayAttrPart {
    constructor(el, name, value) {
        this.el = el;
        this.name = name;
        this.setValue(value);
    }
    setValue(value) {
        if (value) {
            this.el.setAttribute(this.name, '');
        }
        else {
            this.el.removeAttribute(this.name);
        }
    }
    update(value) {
        this.setValue(value);
    }
    remove() { }
}
exports.MayAttrPart = MayAttrPart;


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/template/node-part.js":
/*!**************************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/template/node-part.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.NodePart = void 0;
const template_result_1 = __webpack_require__(/*! ./template-result */ "./node_modules/@pucelle/flit/out/template/template-result.js");
const template_1 = __webpack_require__(/*! ./template */ "./node_modules/@pucelle/flit/out/template/template.js");
const directives_1 = __webpack_require__(/*! ../directives */ "./node_modules/@pucelle/flit/out/directives/index.js");
const util_1 = __webpack_require__(/*! ../libs/util */ "./node_modules/@pucelle/flit/out/libs/util.js");
var ContentType;
(function (ContentType) {
    ContentType[ContentType["Templates"] = 0] = "Templates";
    ContentType[ContentType["Directive"] = 1] = "Directive";
    ContentType[ContentType["Text"] = 2] = "Text";
})(ContentType || (ContentType = {}));
/**
 * Related to the content betweens `<tag>${...}</tag>`, may be a template result, text, template result array, or a directive.
 */
class NodePart {
    constructor(anchor, value, context) {
        this.templates = null;
        this.directive = null;
        this.textNode = null;
        this.contentType = null;
        this.anchor = anchor;
        this.context = context;
        this.update(value);
    }
    update(value) {
        let contentType = this.getContentType(value);
        if (contentType !== this.contentType) {
            this.clearContent();
            this.contentType = contentType;
        }
        switch (contentType) {
            case ContentType.Directive:
                this.updateDirective(value);
                break;
            case ContentType.Templates:
                if (Array.isArray(value)) {
                    this.updateTemplates(value.filter(v => v));
                }
                else {
                    this.updateTemplates([value]);
                }
                break;
            default:
                this.updateText(value);
        }
    }
    getContentType(value) {
        if (value instanceof directives_1.DirectiveResult) {
            return ContentType.Directive;
        }
        else if (value instanceof template_result_1.TemplateResult || Array.isArray(value)) {
            return ContentType.Templates;
        }
        else {
            return ContentType.Text;
        }
    }
    clearContent() {
        let contentType = this.contentType;
        if (contentType === null) {
            return;
        }
        if (contentType === ContentType.Directive) {
            this.directive.remove();
            this.directive = null;
        }
        else if (contentType === ContentType.Templates) {
            for (let template of this.templates) {
                template.remove();
            }
            this.templates = null;
        }
        else if (contentType === ContentType.Text) {
            if (this.textNode) {
                this.textNode.remove();
                this.textNode = null;
            }
        }
    }
    updateDirective(directiveResult) {
        if (this.directive) {
            if (this.directive.canMergeWith(...directiveResult.args)) {
                this.directive.merge(...directiveResult.args);
                return;
            }
            else {
                this.directive.remove();
            }
        }
        this.directive = directives_1.createDirectiveFromResult(this.anchor, this.context, directiveResult);
    }
    // One issue when reusing old template, image will keep old appearance until the new image loaded.
    // We fix this by implementing `:src`.
    updateTemplates(results) {
        let templates = this.templates;
        if (!templates) {
            templates = this.templates = [];
        }
        let sharedLength = Math.min(templates.length, results.length);
        if (sharedLength > 0) {
            for (let i = 0; i < sharedLength; i++) {
                let oldTemplate = templates[i];
                let result = results[i];
                if (oldTemplate.canMergeWith(result)) {
                    oldTemplate.merge(result);
                }
                else {
                    let newTemplate = new template_1.Template(result, this.context);
                    let fragment = newTemplate.range.getFragment();
                    oldTemplate.range.startNode.before(fragment);
                    oldTemplate.remove();
                    templates[i] = newTemplate;
                }
            }
        }
        if (results.length < templates.length) {
            for (let i = templates.length - 1; i >= results.length; i--) {
                templates.pop().remove();
            }
        }
        else if (templates.length < results.length) {
            for (let i = templates.length; i < results.length; i++) {
                let template = new template_1.Template(results[i], this.context);
                let fragment = template.range.getFragment();
                this.anchor.insert(fragment);
                templates.push(template);
            }
        }
    }
    updateText(value) {
        let text = value === null || value === undefined ? '' : util_1.trim(String(value));
        if (text) {
            if (this.textNode) {
                this.textNode.textContent = text;
            }
            else {
                this.textNode = document.createTextNode(text);
                this.anchor.insert(this.textNode);
            }
        }
        else {
            if (this.textNode) {
                this.textNode.textContent = '';
            }
        }
    }
    remove() {
        this.clearContent();
    }
}
exports.NodePart = NodePart;


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/template/property-part.js":
/*!******************************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/template/property-part.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.PropertyPart = void 0;
const component_1 = __webpack_require__(/*! ../component */ "./node_modules/@pucelle/flit/out/component/index.js");
/**
 * `.property=${...}` will assign value to element by `element.property = value`.
 * `.property=${...}` will assign value to component by `com.property = value` if on custom element.
 * `..property=${...}` will always assign value to element.
*/
class PropertyPart {
    constructor(el, name, value, fixed) {
        this.com = null;
        this.value = undefined;
        this.el = el;
        this.name = name[0] === '.' ? name.slice(1) : name;
        this.isComProperty = el.localName.includes('-') && name[0] !== '.';
        this.fixed = fixed;
        if (this.isComProperty) {
            this.bindCom();
            this.updateComProperty(value);
        }
        else {
            this.updateElementProperty(value);
        }
    }
    bindCom() {
        let com = component_1.getComponent(this.el);
        if (com) {
            this.com = com;
        }
        else {
            component_1.onComponentCreatedAt(this.el, this.onComCreated.bind(this));
        }
    }
    onComCreated(com) {
        this.com = com;
        this.setComProperty(this.value);
        this.value = undefined;
    }
    updateComProperty(value) {
        if (this.com) {
            this.setComProperty(value);
        }
        else {
            this.value = value;
        }
    }
    setComProperty(value) {
        if (this.fixed) {
            this.setFixedComProperty(value);
        }
        else {
            this.com[this.name] = value;
        }
    }
    setFixedComProperty(value) {
        let com = this.com;
        let type = typeof com[this.name];
        if (type === 'object' && !/^\s*(?:\{.+?\}|\[.+?\])\s*$/.test(value)) {
            type = 'string';
        }
        switch (type) {
            case 'boolean':
                com[this.name] = value === 'false' ? false : true;
                break;
            case 'number':
                com[this.name] = Number(value);
                break;
            case 'object':
                com[this.name] = JSON.parse(value);
                break;
            default:
                if (type !== 'undefined') {
                    com[this.name] = value;
                }
                else {
                    console.warn(`Please makesure value of property "${this.name}" exist on "<${com.el.localName} />" when assigning fixed property!`);
                }
        }
    }
    updateElementProperty(value) {
        // Required, set same value for `<input type="text">` may cause cursor position reset.
        if (this.el[this.name] !== value) {
            this.el[this.name] = value;
        }
    }
    update(value) {
        if (this.isComProperty) {
            this.updateComProperty(value);
        }
        else {
            this.updateElementProperty(value);
        }
    }
    remove() { }
}
exports.PropertyPart = PropertyPart;


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/template/template-extends.js":
/*!*********************************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/template/template-extends.js ***!
  \*********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.extendsTemplateResult = void 0;
const html_token_1 = __webpack_require__(/*! ../libs/html-token */ "./node_modules/@pucelle/flit/out/libs/html-token.js");
const template_result_1 = __webpack_require__(/*! ./template-result */ "./node_modules/@pucelle/flit/out/template/template-result.js");
const template_result_operate_1 = __webpack_require__(/*! ./template-result-operate */ "./node_modules/@pucelle/flit/out/template/template-result-operate.js");
const extendsTemplateCache = new Map();
/**
 * Merge root attributes and slot elements from front result to the later one.
 * This is used when one component call super template by rendering `<super-name additional-properties><tag slot="name">`.
 *
 * What happens when multiple slot element with same name exists:
 * 	 The outside most slot elements will exist, others will be removed.
 *
 * What happens when multiple rest slot anchor elements (`<slot />`) exists in different template:
 *   The outside most rest slot elements will exist too, others will be removed.
 */
function extendsTemplateResult(result, superResult) {
    let totalValues = [...result.values, ...superResult.values];
    let string = template_result_operate_1.joinWithOrderedMarkers(result.strings);
    let superString = template_result_operate_1.joinWithOrderedMarkers(superResult.strings, result.values.length);
    let stringsAndValueIndexes;
    let cacheForSuper = extendsTemplateCache.get(string);
    if (cacheForSuper) {
        stringsAndValueIndexes = cacheForSuper.get(superString);
    }
    if (!stringsAndValueIndexes) {
        stringsAndValueIndexes = parseTemplateResultForExtending(string, superString);
    }
    let { strings, valueIndexes } = stringsAndValueIndexes;
    let reOrderedValues = valueIndexes.map(index => totalValues[index]);
    return new template_result_1.TemplateResult(result.type, strings, reOrderedValues);
}
exports.extendsTemplateResult = extendsTemplateResult;
function parseTemplateResultForExtending(string, superString) {
    let tokens = html_token_1.parseToHTMLTokens(string);
    let { attributes, slots, restTokens } = parseToRootPropertiesAndSlots(tokens);
    let superTokens = parseToSuperTokens(superString);
    assignRootPropertiesAndSlotsTo(superTokens, attributes, slots, restTokens);
    let stringsAndValueIndexes = template_result_operate_1.splitByOrderedMarkers(html_token_1.joinHTMLTokens(superTokens));
    let cacheForSuper = extendsTemplateCache.get(string);
    if (!cacheForSuper) {
        cacheForSuper = new Map();
        extendsTemplateCache.set(string, cacheForSuper);
    }
    cacheForSuper.set(superString, stringsAndValueIndexes);
    return stringsAndValueIndexes;
}
function parseToRootPropertiesAndSlots(tokens) {
    let firstTagStartIndex = tokens.findIndex(token => token.type === html_token_1.HTMLTokenType.StartTag);
    let firstTagEndIndex = tokens.length - 1;
    let tabCount = 0;
    let firstTag = tokens[firstTagStartIndex];
    let attributes = firstTag.attributes;
    let slots = {};
    // Text nodes already been trimmed when parsing as tokens, no need to worry rest slot contains empty text.
    let restTokens = [];
    for (let i = 0; i < tokens.length; i++) {
        let token = tokens[i];
        switch (token.type) {
            case html_token_1.HTMLTokenType.StartTag:
                if (/slot\s*=\s*['"](\w+)/.test(token.attributes)) {
                    let name = token.attributes.match(/slot\s*=\s*['"](\w+)/)[1];
                    let wholeTokensBelows = outOuterNestingTokens(tokens, i);
                    slots[name] = slots[name] || [];
                    slots[name].push(...wholeTokensBelows);
                    i--;
                }
                else if (!token.selfClose) {
                    tabCount++;
                }
                break;
            case html_token_1.HTMLTokenType.EndTag:
                tabCount--;
                if (tabCount === 0) {
                    firstTagEndIndex = i + 1;
                }
                break;
        }
    }
    if (firstTagEndIndex - firstTagStartIndex > 2) {
        restTokens = tokens.slice(firstTagStartIndex + 1, firstTagEndIndex - 1);
    }
    return { attributes, slots, restTokens };
}
// Will add a template tag at start if don't have.
function parseToSuperTokens(string) {
    let tokens = html_token_1.parseToHTMLTokens(string);
    let firstToken = tokens[0];
    if (!firstToken || firstToken.type !== html_token_1.HTMLTokenType.StartTag || firstToken.tagName !== 'template') {
        tokens.unshift({
            type: html_token_1.HTMLTokenType.StartTag,
            tagName: 'template',
            attributes: '',
        });
        tokens.push({
            type: html_token_1.HTMLTokenType.EndTag,
            tagName: 'template',
        });
    }
    return tokens;
}
function assignRootPropertiesAndSlotsTo(tokens, attributes, slots, restTokens) {
    tokens[0].attributes += attributes;
    if (Object.keys(slots).length > 0 || restTokens.length > 0) {
        for (let i = 0; i < tokens.length; i++) {
            let token = tokens[i];
            switch (token.type) {
                case html_token_1.HTMLTokenType.StartTag:
                    if (token.tagName === 'slot') {
                        let nameMatch = token.attributes.match(/name\s*=\s*['"](\w+)/);
                        let name = nameMatch ? nameMatch[1] : null;
                        if (name) {
                            if (slots[name]) {
                                let tokenPieces = slots[name];
                                // Keep `<slot name="">` so it may be overwrited by outers.
                                outInnerNestingTokens(tokens, i);
                                tokens.splice(i + 1, 0, ...tokenPieces);
                                i += tokenPieces.length;
                            }
                        }
                        else {
                            // Removes `<slot />` so different levels of rest contents will be merged.
                            if (restTokens.length) {
                                outOuterNestingTokens(tokens, i);
                                tokens.splice(i, 0, ...restTokens);
                                i += restTokens.length;
                            }
                        }
                    }
                    break;
            }
        }
    }
}
function outOuterNestingTokens(tokens, startTagIndex) {
    return tokens.splice(startTagIndex, findEndTagIndex(tokens, startTagIndex) + 1 - startTagIndex);
}
function outInnerNestingTokens(tokens, startTagIndex) {
    return tokens.splice(startTagIndex + 1, findEndTagIndex(tokens, startTagIndex) - 1 - startTagIndex);
}
function findEndTagIndex(tokens, startTagIndex) {
    let tabCount = 1;
    for (let i = startTagIndex + 1; i < tokens.length; i++) {
        let token = tokens[i];
        switch (token.type) {
            case html_token_1.HTMLTokenType.StartTag:
                if (!token.selfClose) {
                    tabCount++;
                }
                break;
            case html_token_1.HTMLTokenType.EndTag:
                tabCount--;
                if (tabCount === 0) {
                    return i;
                }
                break;
        }
    }
    return tokens.length - 1;
}


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/template/template-parser.js":
/*!********************************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/template/template-parser.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.parse = exports.PartType = void 0;
const template_result_operate_1 = __webpack_require__(/*! ./template-result-operate */ "./node_modules/@pucelle/flit/out/template/template-result-operate.js");
const component_1 = __webpack_require__(/*! ../component */ "./node_modules/@pucelle/flit/out/component/index.js");
const util_1 = __webpack_require__(/*! ../libs/util */ "./node_modules/@pucelle/flit/out/libs/util.js");
const html_token_1 = __webpack_require__(/*! ../libs/html-token */ "./node_modules/@pucelle/flit/out/libs/html-token.js");
var PartType;
(function (PartType) {
    PartType[PartType["Node"] = 0] = "Node";
    PartType[PartType["Attr"] = 1] = "Attr";
    PartType[PartType["MayAttr"] = 2] = "MayAttr";
    PartType[PartType["Property"] = 3] = "Property";
    PartType[PartType["Event"] = 4] = "Event";
    PartType[PartType["FixedBinging"] = 5] = "FixedBinging";
    PartType[PartType["Binding"] = 6] = "Binding";
})(PartType = exports.PartType || (exports.PartType = {}));
// context name -> template string -> parse result
const parseResultCache = new Map();
/**
 * Parse template strings to an fragment and interlations and their related nodes.
 * Always prepend a comment in the front to mark current template start position.
 * @param type
 * @param strings
 */
function parse(type, strings, el) {
    let scopeName = el ? el.localName : 'global';
    if ((type === 'html' || type === 'svg')) {
        let string = template_result_operate_1.joinWithOrderedMarkers(strings);
        let sharedResultMap = parseResultCache.get(scopeName);
        let sharedResult = sharedResultMap ? sharedResultMap.get(string) : null;
        if (!sharedResult) {
            if (!sharedResultMap) {
                sharedResultMap = new Map();
                parseResultCache.set(scopeName, sharedResultMap);
            }
            sharedResult = new HTMLSVGTemplateParser(type, string, scopeName).parse();
            sharedResultMap.set(string, sharedResult);
        }
        return cloneParseResult(sharedResult, el);
    }
    else if (type === 'css') {
        let html = `<style>${strings[0]}</style>`;
        let fragment = createTemplateFromHTML(html).content;
        return {
            fragment,
            nodesInPlaces: null,
            places: null,
            hasSlots: false
        };
    }
    else {
        let text = strings[0];
        let fragment = document.createDocumentFragment();
        fragment.append(document.createTextNode(text));
        return {
            fragment,
            nodesInPlaces: null,
            places: null,
            hasSlots: false
        };
    }
}
exports.parse = parse;
function createTemplateFromHTML(html) {
    let template = document.createElement('template');
    template.innerHTML = html;
    return template;
}
class HTMLSVGTemplateParser {
    constructor(type, string, scopeName) {
        this.nodeIndex = 0;
        this.places = [];
        this.nodeIndexs = [];
        this.type = type;
        this.string = string;
        this.scopeName = scopeName;
        this.scopedClassNameSet = component_1.getScopedClassNameSet(this.scopeName);
    }
    // Benchmark: https://jsperf.com/regexp-exec-match-replace-speed
    parse() {
        let tokens = html_token_1.parseToHTMLTokens(this.string);
        let codes = '';
        let hasSlots = false;
        for (let token of tokens) {
            switch (token.type) {
                case html_token_1.HTMLTokenType.StartTag:
                    let tagName = token.tagName;
                    let attributes = token.attributes;
                    if (tagName === 'slot') {
                        hasSlots = true;
                    }
                    // ` {flit:0}` be at least 
                    if (attributes.length >= 9) {
                        attributes = this.parseAttribute(attributes);
                    }
                    codes += '<' + tagName + attributes + '>';
                    this.nodeIndex++;
                    break;
                case html_token_1.HTMLTokenType.EndTag:
                    codes += `</${token.tagName}>`;
                    break;
                case html_token_1.HTMLTokenType.Text:
                    codes += this.parseText(token.text);
                    break;
            }
        }
        let firstTag = tokens.find(token => token.type === html_token_1.HTMLTokenType.StartTag);
        let svgWrapped = false;
        if (firstTag) {
            if (this.type === 'svg' && firstTag.tagName !== 'svg') {
                codes = '<svg>' + codes + '</svg>';
                svgWrapped = true;
            }
        }
        let template = createTemplateFromHTML(codes);
        let attributes = null;
        if (svgWrapped) {
            let svg = template.content.firstElementChild;
            template.content.append(...svg.childNodes);
            svg.remove();
        }
        // We can define some classes or styles on the top element if renders `<template class="...">`.
        if (firstTag && firstTag.tagName === 'template') {
            template = template.content.firstElementChild;
            attributes = [...template.attributes].map(({ name, value }) => ({ name, value }));
        }
        return {
            template,
            places: this.places,
            hasSlots,
            attributes
        };
    }
    parseText(text) {
        // `text` has already been trimmed here when parsing as tokens.
        if (!text) {
            return text;
        }
        if (template_result_operate_1.containsOrderedMarker(text)) {
            let { strings, valueIndexes } = template_result_operate_1.splitByOrderedMarkers(text);
            // Each hole may be a string, or a `TemplateResult`, so must unique them, but can't join them to a string.
            for (let i = 1; i < strings.length; i++) {
                this.places.push({
                    type: PartType.Node,
                    name: null,
                    strings: null,
                    valueIndexes: valueIndexes.slice(i - 1, i),
                    nodeIndex: this.nodeIndex
                });
                this.nodeIndexs.push(this.nodeIndex);
                this.nodeIndex += 1;
            }
            text = strings.map(util_1.trim).join('<!--->');
        }
        return text;
    }
    parseAttribute(attr) {
        const attrRE = /([.:?@\w-]+)\s*(?:=\s*(".*?"|'.*?'|\{flit:\d+\})\s*)?|\{flit:(\d+)\}\s*/g;
        return attr.replace(attrRE, (m0, name, value = '', markerId) => {
            if (markerId) {
                this.places.push({
                    type: PartType.Binding,
                    name: null,
                    strings: null,
                    valueIndexes: [Number(markerId)],
                    nodeIndex: this.nodeIndex
                });
                this.nodeIndexs.push(this.nodeIndex);
                return '';
            }
            let type;
            let hasMarker = template_result_operate_1.containsOrderedMarker(value);
            switch (name[0]) {
                case '.':
                    type = PartType.Property;
                    break;
                case ':':
                    type = PartType.FixedBinging;
                    break;
                case '?':
                    type = PartType.MayAttr;
                    break;
                case '@':
                    type = PartType.Event;
                    break;
            }
            if (type !== undefined) {
                name = name.slice(1);
            }
            if (type === undefined && hasMarker) {
                // `class=${...}` -> `:class=${...}`, so the class value can be scoped.
                if (name === 'class') {
                    type = PartType.FixedBinging;
                }
                else {
                    type = PartType.Attr;
                }
            }
            if (type !== undefined) {
                if (value[0] === '\'' || value[0] === '"') {
                    value = value.slice(1, -1);
                }
                if (hasMarker) {
                    let { strings, valueIndexes } = template_result_operate_1.parseOrderedMarkers(value);
                    this.places.push({
                        type,
                        name,
                        strings,
                        valueIndexes,
                        nodeIndex: this.nodeIndex
                    });
                }
                else {
                    this.places.push({
                        type,
                        name,
                        strings: [value],
                        valueIndexes: null,
                        nodeIndex: this.nodeIndex
                    });
                }
                this.nodeIndexs.push(this.nodeIndex);
                if (type === PartType.Attr) {
                    return name + '="" ';
                }
                else {
                    return '';
                }
            }
            else if (name === 'class' && this.scopedClassNameSet) {
                value = value.replace(/[\w-]+/g, (m0) => {
                    if (this.scopedClassNameSet.has(m0)) {
                        return m0 + '__' + this.scopeName;
                    }
                    else {
                        return m0;
                    }
                });
                return name + '=' + value;
            }
            return m0;
        });
    }
}
/**
 * Clone the result fragment and link it with node indexes from the parsed result.
 */
// TreeWalker Benchmark: https://jsperf.com/treewalker-vs-nodeiterator
// Clone benchmark: https://jsperf.com/clonenode-vs-importnode
function cloneParseResult(sharedResult, el) {
    let { template, places, hasSlots, attributes } = sharedResult;
    let fragment = template.content.cloneNode(true);
    let nodesInPlaces = [];
    if (attributes) {
        if (!el) {
            throw new Error('A context must be provided when rendering `<template>...`');
        }
        util_1.cloneAttributes(el, attributes);
    }
    if (places.length > 0) {
        let nodeIndex = 0;
        let placeIndex = 0;
        let walker = document.createTreeWalker(fragment, NodeFilter.SHOW_ELEMENT | NodeFilter.SHOW_COMMENT, null);
        let node;
        let end = false;
        if (attributes) {
            while (placeIndex < places.length && places[placeIndex].nodeIndex === 0) {
                nodesInPlaces.push(el);
                placeIndex++;
            }
            nodeIndex = 1;
        }
        if (placeIndex < places.length) {
            while (node = walker.nextNode()) {
                while (places[placeIndex].nodeIndex === nodeIndex) {
                    nodesInPlaces.push(node);
                    placeIndex++;
                    if (placeIndex === places.length) {
                        end = true;
                        break;
                    }
                }
                if (end) {
                    break;
                }
                nodeIndex++;
            }
        }
    }
    return {
        fragment,
        nodesInPlaces,
        places,
        hasSlots,
    };
}


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/template/template-result-operate.js":
/*!****************************************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/template/template-result-operate.js ***!
  \****************************************************************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.splitByOrderedMarkers = exports.parseOrderedMarkers = exports.beOrderedMarker = exports.containsOrderedMarker = exports.joinWithOrderedMarkers = exports.getStartTagOfTemplateResult = void 0;
/** Get the start tag of a `TemplateResult`. */
function getStartTagOfTemplateResult(result) {
    let match = result.strings[0].match(/<([\w-]+)/);
    return match ? match[1] : null;
}
exports.getStartTagOfTemplateResult = getStartTagOfTemplateResult;
/**
 * Join template strings with `${flit:id}`, the id is the increased index of values.
 */
function joinWithOrderedMarkers(strings, startIndex = 0) {
    let text = strings[0];
    for (let i = 0; i < strings.length - 1; i++) {
        text += `{flit:${i + startIndex}}`;
        text += strings[i + 1];
    }
    return text;
}
exports.joinWithOrderedMarkers = joinWithOrderedMarkers;
/**
 * Test if string contains `${flit:id}`.
 */
function containsOrderedMarker(string) {
    return /\{flit:\d+\}/.test(string);
}
exports.containsOrderedMarker = containsOrderedMarker;
/**
 * Test if string is just a `${flit:id}`.
 */
function beOrderedMarker(string) {
    return /^\{flit:\d+\}$/.test(string);
}
exports.beOrderedMarker = beOrderedMarker;
/**
 * Split string contains `${flit:id}` into strings and valueIndexes.
 * But returned `strings` will be `null` if whole string be a marker.
 */
function parseOrderedMarkers(string) {
    if (beOrderedMarker(string)) {
        return {
            strings: null,
            valueIndexes: [Number(string.match(/^\{flit:(\d+)\}$/)[1])]
        };
    }
    else {
        return splitByOrderedMarkers(string);
    }
}
exports.parseOrderedMarkers = parseOrderedMarkers;
/** Split string contains `${flit:id}` into strings and valueIndexes. */
function splitByOrderedMarkers(string) {
    let re = /\{flit:(\d+)\}/g;
    let match;
    let strings = [];
    let valueIndexes = [];
    let lastIndex = 0;
    while (match = re.exec(string)) {
        strings.push(string.slice(lastIndex, match.index));
        valueIndexes.push(Number(match[1]));
        lastIndex = re.lastIndex;
    }
    strings.push(string.slice(lastIndex));
    return {
        strings,
        valueIndexes
    };
}
exports.splitByOrderedMarkers = splitByOrderedMarkers;


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/template/template-result.js":
/*!********************************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/template/template-result.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.TemplateResult = exports.css = exports.svg = exports.html = void 0;
const template_extends_1 = __webpack_require__(/*! ./template-extends */ "./node_modules/@pucelle/flit/out/template/template-extends.js");
/** HTML template literal that can be used to render or update a component. */
function html(strings, ...values) {
    return new TemplateResult('html', strings, values);
}
exports.html = html;
/** SVG template literal that can be used to render or update a component. */
function svg(strings, ...values) {
    return new TemplateResult('svg', strings, values);
}
exports.svg = svg;
/** CSS template literal that can be used as component's static style property. */
function css(strings, ...values) {
    return new TemplateResult('css', strings, values);
}
exports.css = css;
/**
 * Returned from html`...`, it represents a render result,
 * and can be used to merge with the last result.
 */
class TemplateResult {
    /**
     * Created from each html`...` or svg`...`.
     * Every time call `Component.update` will generate a new template result tree.
     * Then we will check if each result can be merged or need to be replaced recursively.
     */
    constructor(type, strings, values) {
        this.type = type;
        this.strings = strings;
        this.values = values;
    }
    /** Join strings and values to string. */
    toString() {
        let text = this.strings[0];
        for (let i = 0; i < this.strings.length - 1; i++) {
            let value = this.values[i];
            if (value !== null && value !== undefined) {
                if (Array.isArray(value)) {
                    text += value.join('');
                }
                else {
                    text += String(value);
                }
            }
            text += this.strings[i + 1];
        }
        return text;
    }
    /**
     * Used for `TemplateResult` to merge root attributes and slot elements into super.
     * Sometimes you want to reuse super rendering result and add some classes and set soem slots,
     * but normally this can only work when instantiation, not working inside a new defined component.
     * Now using `CurrentRenderingResult.extends(super.render())`, you can do this.
     *
     * At beginning, we decided to implement this by rendering `<super-com>`,
     * but every time for every rendered component to update, it need to check the name.
     * We should makesure the rendering logic simple and easy to understand,
     * so finally we implement a new API `extends` to call it manually.
     */
    extends(superResult) {
        if (this.type === 'html' || this.type === 'svg') {
            return template_extends_1.extendsTemplateResult(this, superResult);
        }
        else {
            return new TemplateResult(this.type, [...superResult.strings, ...this.strings], [...superResult.values, '', ...this.values]);
        }
    }
}
exports.TemplateResult = TemplateResult;


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/template/template.js":
/*!*************************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/template/template.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Template = void 0;
const node_helper_1 = __webpack_require__(/*! ../libs/node-helper */ "./node_modules/@pucelle/flit/out/libs/node-helper.js");
const template_parser_1 = __webpack_require__(/*! ./template-parser */ "./node_modules/@pucelle/flit/out/template/template-parser.js");
const node_part_1 = __webpack_require__(/*! ./node-part */ "./node_modules/@pucelle/flit/out/template/node-part.js");
const may_attr_part_1 = __webpack_require__(/*! ./may-attr-part */ "./node_modules/@pucelle/flit/out/template/may-attr-part.js");
const event_part_1 = __webpack_require__(/*! ./event-part */ "./node_modules/@pucelle/flit/out/template/event-part.js");
const attr_part_1 = __webpack_require__(/*! ./attr-part */ "./node_modules/@pucelle/flit/out/template/attr-part.js");
const binding_part_1 = __webpack_require__(/*! ./binding-part */ "./node_modules/@pucelle/flit/out/template/binding-part.js");
const property_part_1 = __webpack_require__(/*! ./property-part */ "./node_modules/@pucelle/flit/out/template/property-part.js");
const component_1 = __webpack_require__(/*! ../component */ "./node_modules/@pucelle/flit/out/component/index.js");
/**
 * Class to parse a template result returned from html`...` to element,
 * And can do some patches on it according to newly rendered template result.
 */
class Template {
    /**
     * Create an template from html`...` like template result and context
     * @param result The template result like html`...`.
     * @param context The context passed to event handlers.
     */
    constructor(result, context) {
        this.canUpdateParts = [];
        this.result = result;
        this.context = context;
        let { fragment, nodesInPlaces, places, hasSlots } = template_parser_1.parse(this.result.type, this.result.strings, this.context ? this.context.el : null);
        this.range = new node_helper_1.NodeRange(fragment);
        this.parseParts(nodesInPlaces, places);
        if (hasSlots && this.context) {
            this.context.__foundSlotsWhenRendering();
        }
    }
    /** Parse template result and returns a fragment. */
    parseParts(nodesInPlaces, places) {
        let resultValues = this.result.values;
        if (nodesInPlaces && places) {
            for (let nodeIndex = 0; nodeIndex < nodesInPlaces.length; nodeIndex++) {
                let node = nodesInPlaces[nodeIndex];
                let place = places[nodeIndex];
                let strings = place.strings;
                let valueIndexes = place.valueIndexes;
                let values = valueIndexes ? valueIndexes.map(index => resultValues[index]) : null;
                let value = join(strings, values);
                let part;
                switch (place.type) {
                    case template_parser_1.PartType.Node:
                        part = new node_part_1.NodePart(new node_helper_1.NodeAnchor(node, node_helper_1.NodeAnchorType.Next), value, this.context);
                        break;
                    case template_parser_1.PartType.MayAttr:
                        part = new may_attr_part_1.MayAttrPart(node, place.name, value);
                        break;
                    case template_parser_1.PartType.Event:
                        part = new event_part_1.EventPart(node, place.name, value, this.context);
                        break;
                    case template_parser_1.PartType.Attr:
                        part = new attr_part_1.AttrPart(node, place.name, value);
                        break;
                    case template_parser_1.PartType.Property:
                        part = new property_part_1.PropertyPart(node, place.name, value, !valueIndexes);
                        break;
                    case template_parser_1.PartType.FixedBinging:
                        part = new binding_part_1.FixedBindingPart(node, place.name, value, this.context);
                        break;
                    case template_parser_1.PartType.Binding:
                        part = new binding_part_1.BindingPart(node, value, this.context);
                        break;
                }
                if (part && valueIndexes) {
                    this.canUpdateParts.push({
                        part,
                        strings,
                        valueIndexes
                    });
                }
            }
        }
    }
    /** Compare if two template result can be merged. */
    canMergeWith(result) {
        if (this.result.type !== result.type) {
            return false;
        }
        if (this.result.strings.length !== result.strings.length) {
            return false;
        }
        for (let i = 0; i < this.result.strings.length; i++) {
            if (this.result.strings[i] !== result.strings[i]) {
                return false;
            }
        }
        return true;
    }
    /**
     * Merge with another template result.
     * @param result The template result to merge.
     */
    merge(result) {
        for (let { part, strings, valueIndexes } of this.canUpdateParts) {
            let changed = valueIndexes.some(index => this.result.values[index] !== result.values[index]);
            if (changed) {
                let values = valueIndexes.map(index => result.values[index]);
                let value = join(strings, values);
                part.update(value);
            }
        }
        this.result = result;
    }
    // Been called when this template will never be used any more.
    remove() {
        this.range.remove();
        for (let { part } of this.canUpdateParts) {
            part.remove();
        }
    }
    /**
     * Initialize components inside a template and update it immediately.
     * Elements are not connected but will be pre rendered.
     */
    preRender() {
        let fragment = this.range.fragment;
        if (!fragment) {
            return;
        }
        let walker = document.createTreeWalker(fragment, NodeFilter.SHOW_ELEMENT, null);
        let el;
        while (el = walker.nextNode()) {
            if (el instanceof HTMLElement && el.localName.includes('-')) {
                let Com = component_1.getComponentConstructor(el.localName);
                if (Com && !component_1.getComponent(el)) {
                    let com = component_1.createComponent(el, Com);
                    com.__updateImmediately(true);
                }
            }
        }
    }
}
exports.Template = Template;
/** Join strings and values to string, returns `values[0]` if `strings` is null. */
function join(strings, values) {
    if (!strings) {
        return values[0];
    }
    let text = strings[0];
    for (let i = 0; i < strings.length - 1; i++) {
        let value = values[i];
        text += value === null || value === undefined ? '' : String(value);
        text += strings[i + 1];
    }
    return text;
}


/***/ }),

/***/ "./node_modules/@pucelle/flit/out/watcher.js":
/*!***************************************************!*\
  !*** ./node_modules/@pucelle/flit/out/watcher.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.watchUntil = exports.watchOnce = exports.watchImmediately = exports.watch = exports.globalWatcherGroup = exports.WatcherGroup = exports.InnerWatcher = exports.Watcher = void 0;
const observer_1 = __webpack_require__(/*! ./observer */ "./node_modules/@pucelle/flit/out/observer/index.js");
const queue_1 = __webpack_require__(/*! ./queue */ "./node_modules/@pucelle/flit/out/queue.js");
/**
 * Used to watch a function returns and trigger callback if it is changed.
 * You need to know that when callback was called, it doesn't ensure the watched datas are truly changed.
 * Normally you should create watcher but using `context.watch` or `globalWatcherGroup.watch`.
 * If you use created watcher, makesure to add it to a `context` or the `globalWatcherGroup`.
 */
class Watcher {
    constructor(fn, callback) {
        this.connected = true;
        this.fn = fn;
        this.callback = callback;
        this.value = this.getValue();
    }
    getValue() {
        observer_1.startUpdating(this);
        let newValue = this.fn.call(null);
        observer_1.endUpdating(this);
        return newValue;
    }
    /** When detected dependencies changed. trigger this immediately. */
    update() {
        queue_1.enqueueWatcherToUpdate(this);
    }
    /** Keep consitant with Component */
    __updateImmediately() {
        if (!this.connected) {
            return;
        }
        let newValue = this.getValue();
        if (newValue !== this.value || typeof newValue === 'object') {
            this.callback.call(null, this.value = newValue);
        }
    }
    /**
     * We currently just check the update times, if exceed 3 then warn.
     * The better way should be analysising dependency tree:
     * Get current watcher referenced objects, then get their referenced watchers.
     * Then check if current watcher in it.
     */
    toString() {
        return this.fn.toString();
    }
    /**
     * Watcher and the Component can't be GC automatically,
     * because we added `object -> Component | Watcher` map into dependencies.
     * But if it's referred object is no longer in use any more, no need to disconnect it.
     */
    // One question: Will the update be triggered after disconnected?
    //   1. Data changed, cause watcher update been enqueued, and will be updated in micro task queue.
    //   2. later some element was removed in same stack, related watcher was disconnected in micro task queue.
    //   3. Update and then disconnect.
    //
    // So this will not happen.
    // But we still need to avoid it by adding a `connected` property,
    // because once update after disconnect, the watcher will have new dependencies and be reconnected. 
    disconnect() {
        observer_1.clearDependencies(this);
        this.connected = false;
    }
    /** If it's related commponent restore to be connected, connect and activate it's watchers. */
    connect() {
        this.connected = true;
        this.update();
    }
}
exports.Watcher = Watcher;
class InnerWatcher extends Watcher {
    /** When detected dependencies changed. trigger this immediately. */
    update() {
        queue_1.enqueueInnerWatcherToUpdate(this);
    }
}
exports.InnerWatcher = InnerWatcher;
/**
 * Used to manage several watchers that binded to a context or as global watchers.
 * By this class, you can easily connect, disconnect, update all the watchers related.
 */
/** @hidden */
class WatcherGroup {
    constructor() {
        this.watchers = new Set();
    }
    add(watcher) {
        this.watchers.add(watcher);
    }
    delete(watcher) {
        watcher.disconnect();
        this.watchers.delete(watcher);
    }
    connect() {
        for (let watcher of this.watchers) {
            watcher.connect();
        }
    }
    disconnect() {
        for (let watcher of this.watchers) {
            watcher.disconnect();
        }
    }
    update() {
        if (this.watchers) {
            for (let watcher of this.watchers) {
                watcher.update();
            }
        }
    }
    watch(fn, callback) {
        let watcher = new Watcher(fn, callback);
        this.add(watcher);
        return () => {
            this.delete(watcher);
        };
    }
    watchImmediately(fn, callback) {
        let watcher = new Watcher(fn, callback);
        callback.call(this, watcher.value);
        this.add(watcher);
        return () => {
            this.delete(watcher);
        };
    }
    watchOnce(fn, callback) {
        let wrappedCallback = (value) => {
            callback(value);
            unwatch();
        };
        let watcher = new Watcher(fn, wrappedCallback);
        this.add(watcher);
        let unwatch = () => {
            this.delete(watcher);
        };
        return unwatch;
    }
    watchUntil(fn, callback) {
        let wrappedCallback = (value) => {
            if (value) {
                callback();
                unwatch();
            }
        };
        let unwatch;
        let watcher = new Watcher(fn, wrappedCallback);
        if (watcher.value) {
            watcher.disconnect();
            callback.call(this);
            unwatch = () => { };
        }
        else {
            this.add(watcher);
            unwatch = () => {
                this.delete(watcher);
            };
        }
        return unwatch;
    }
}
exports.WatcherGroup = WatcherGroup;
/** @hidden */
exports.globalWatcherGroup = new WatcherGroup();
/** Watch return value of function and trigger callback with this value as argument. */
function watch(fn, callback) {
    return exports.globalWatcherGroup.watch(fn, callback);
}
exports.watch = watch;
/** Watch return value of function and trigger callback with this value as argument. */
function watchImmediately(fn, callback) {
    return exports.globalWatcherGroup.watchImmediately(fn, callback);
}
exports.watchImmediately = watchImmediately;
/** Watch return value of function and trigger callback with this value as argument. Run callback for only once. */
function watchOnce(fn, callback) {
    return exports.globalWatcherGroup.watchOnce(fn, callback);
}
exports.watchOnce = watchOnce;
/** Watch returned values of function and trigger callback if it becomes true. */
function watchUntil(fn, callback) {
    return exports.globalWatcherGroup.watchUntil(fn, callback);
}
exports.watchUntil = watchUntil;


/***/ }),

/***/ "./src/aegl-scene/scene-editor.ts":
/*!****************************************!*\
  !*** ./src/aegl-scene/scene-editor.ts ***!
  \****************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SceneEditor = void 0;
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
const aegl_1 = __webpack_require__(/*! ../aegl */ "./src/aegl/index.ts");
const scene_helper_1 = __webpack_require__(/*! ./scene-helper */ "./src/aegl-scene/scene-helper.ts");
const scene_1 = __webpack_require__(/*! ./scene */ "./src/aegl-scene/scene.ts");
const scene_info_1 = __webpack_require__(/*! ./scene-info */ "./src/aegl-scene/scene-info.ts");
const jpeg_orientation_1 = __webpack_require__(/*! ../libs/util/jpeg-orientation */ "./src/libs/util/jpeg-orientation.ts");
/** 用来对一个 project 进行编辑, 可以增减场景和调整时间等. */
class SceneEditor {
    project;
    /** 所有场景. */
    scenes = [];
    /** 用户编辑了音乐之后会产生的音乐素材数据. */
    userAudioData = null;
    /** 当初始化完成, 即所有场景数据准备完成后被 resolve. */
    ready;
    /** 用于保存重复的场景, 克隆自非头尾的场景. */
    loopScenes;
    /** 记录层的初始索引顺序. */
    layerRawIndex;
    constructor(project, userSceneData = null) {
        this.project = project;
        this.parseScenes();
        this.ready = this.initialize(userSceneData);
    }
    /** 初始化. */
    async initialize(userSceneData = null) {
        if (userSceneData) {
            // 加载场景数据.
            await this.loadUserSceneData(userSceneData, false, () => { });
        }
        else {
            // 生成裁剪图和缩略图.
            await this.ensureSceneMediaInfoDatas(() => { });
        }
    }
    /** 解析场景结构, 提取可重复的场景. */
    parseScenes() {
        let mediaLayers = (0, scene_helper_1.getReplacableMediaDeepLayers)(this.project);
        let textLayers = (0, scene_helper_1.getEditableTextDeepLayers)(this.project);
        let scenes = [];
        let usedTextSet = new Set();
        let usedRootLayerIdSet = new Set([...mediaLayers.map(v => v.root.id), ...textLayers.map(v => v.root.id)]);
        // 根据 media 查找对应的 text.
        for (let i = 0; i < mediaLayers.length; i++) {
            let media = mediaLayers[i];
            let textIndex = (0, scene_helper_1.getMaxCrossLayerIndex)(media, textLayers);
            let text = textIndex >= 0 ? textLayers[textIndex] : null;
            let crossed = (0, scene_helper_1.getCrossedRootLayers)(this.project, media.root, usedRootLayerIdSet);
            let scene = new scene_1.Scene(this.project, media, text, crossed);
            scenes.push(scene);
            if (text) {
                usedTextSet.add(text);
            }
        }
        // 处理遗留的 text.
        for (let text of textLayers) {
            if (!usedTextSet.has(text)) {
                let crossed = (0, scene_helper_1.getCrossedRootLayers)(this.project, text.root, usedRootLayerIdSet);
                let scene = new scene_1.Scene(this.project, null, text, crossed);
                scenes.push(scene);
            }
        }
        // 场景排序.
        (0, ff_1.orderBy)(scenes, v => v.main.root.inPoint);
        // 计算和上一个场景的距离.
        for (let i = 1; i < scenes.length; i++) {
            let scene = scenes[i];
            let prevScene = scenes[i - 1];
            scene.marginLeft = scene.main.root.inPoint - prevScene.main.root.outPoint;
        }
        // 将场景之间的距离做更加可靠的分配, 同时保证相邻的 marginLeft 和 marginRight 之和不变.
        if (scenes[1].marginLeft !== scenes[2].marginLeft) {
            let diff = scenes[2].marginLeft - scenes[1].marginLeft;
            scenes[1].marginLeft += diff;
            scenes[0].marginRight -= diff;
        }
        // 在所有场景创建之后初始化更多的细节.
        for (let scene of scenes) {
            scene.initializeAfterAllScenesCreated();
        }
        this.parseLoopScenes(scenes);
    }
    /** 生成作为模板的循环场景. */
    parseLoopScenes(scenes) {
        // 如果两个相邻场景之间有特效和它们都相交, 则目前中间循环部分会首尾相接,
        // 即第一个循环和最后一个循环样式完全相同.
        // 此时会出现最后一个场景的结束转场和最后一个场景的开始转场完全相同的情况,
        // 而不是接着上一个转场依次排号. 这个问题一般不会被留意到, 而且也很难解决.
        let loopScenes = scenes.slice(1, -1);
        let clonedLoopScenes = loopScenes.map(scene => scene.clone());
        // 这里选择将原始的场景作为循环场景模板, 这是因为这些场景关联的合成不会被删除.
        scenes.splice(1, loopScenes.length, ...clonedLoopScenes);
        for (let scene of clonedLoopScenes) {
            scene.insertToProject();
        }
        for (let scene of loopScenes) {
            scene.remove();
        }
        this.project.data.orderRootLayerData();
        this.loopScenes = loopScenes;
        this.scenes = scenes;
    }
    /** 初始化所有额外的场景信息, 生成裁剪图和缩略图, 如果场景未初始化的话. */
    async ensureSceneMediaInfoDatas(onprogress) {
        onprogress(0, this.scenes.length);
        for (let i = 0; i < this.scenes.length; i++) {
            let scene = this.scenes[i];
            await scene.ensureMediaInfoDatas();
            onprogress(i + 1, this.scenes.length);
        }
    }
    /** 在最后一个场景之前添加一个场景. */
    appendScene(scene) {
        scene.insertToProject();
        this.scenes.splice(this.scenes.length - 1, 0, scene);
        this.adjustScenesPoints();
        this.adjustDuration();
        this.project.data.orderRootLayerData();
    }
    /** 从某个场景开始, 调整其时间以让时间段能够首尾相接. */
    adjustScenesPoints() {
        for (let i = 1; i < this.scenes.length; i++) {
            let scene = this.scenes[i];
            let prevScene = this.scenes[i - 1];
            scene.moveTimeToBeAfter(prevScene);
        }
    }
    /** 编辑 duration 以及音频节点. */
    adjustDuration() {
        let duration = this.scenes[this.scenes.length - 1].main.root.outPoint;
        let lastDuration = this.project.data.duration;
        let toMove = duration - lastDuration;
        let loopLayerDatas = this.project.footages.getLoopLayerDatas();
        for (let loopLayerData of loopLayerDatas) {
            loopLayerData.outPoint = duration;
            // 对于音频移动尾部的声音渐出效果.
            if (loopLayerData.type === 'audio') {
                (0, scene_helper_1.moveLayerTimeProperties)(loopLayerData, toMove);
            }
        }
        this.project.data.duration = duration;
    }
    /** 查找指定时刻被激活的场景. */
    getActiveSceneAtTime(time) {
        return this.scenes.find(scene => {
            return scene.main.root.inPoint <= time && scene.main.root.outPoint >= time;
        }) || null;
    }
    /** 获取层的初始顺序. */
    getLayerRawIndex(layer) {
        return this.layerRawIndex.get(layer.rawId);
    }
    /** 将场景移动到指定的索引位置. 返回发生了变更的场景. */
    moveSceneTo(scene, newIndex) {
        let oldIndex = this.scenes.indexOf(scene);
        let minIndex = Math.min(oldIndex, newIndex);
        let maxIndex = Math.max(oldIndex, newIndex);
        let swapScenes = this.scenes.slice(minIndex, maxIndex + 1);
        let infos = swapScenes.map(scene => scene.info);
        let canAllSetDuration = swapScenes.every(scene => scene.canSetDuration);
        // 将数据向左或者向右拷贝, 直到倒数第二个层.
        for (let i = 0; i < swapScenes.length; i++) {
            let scene = swapScenes[i];
            let infoIndex;
            // 向右移动, 向右取值.
            if (oldIndex < newIndex) {
                infoIndex = (i + 1 + swapScenes.length) % swapScenes.length;
            }
            else {
                infoIndex = (i - 1 + swapScenes.length) % swapScenes.length;
            }
            scene.setInfo(infos[infoIndex], canAllSetDuration);
        }
        this.adjustScenesPoints();
        return swapScenes;
    }
    /** 移除指定的索引位置的场景. */
    removeScene(scene) {
        let index = this.scenes.indexOf(scene);
        let swapScenes = [];
        // 删除最后一个场景时, 交换右侧两个场景.
        if (index === this.scenes.length - 1) {
            swapScenes = this.scenes.slice(this.scenes.length - 2, this.scenes.length).reverse();
        }
        else {
            swapScenes = this.scenes.slice(index, this.scenes.length - 1);
        }
        let infos = swapScenes.map(scene => scene.info);
        // 将数据向左拷贝.
        for (let i = 0; i < swapScenes.length; i++) {
            let scene = swapScenes[i];
            let infoIndex = (i + 1) % swapScenes.length;
            scene.setInfo(infos[infoIndex]);
        }
        // 移除最后一个循环场景.
        let sceneToRemove = this.scenes[this.scenes.length - 2];
        sceneToRemove.setInfo(infos[0]);
        sceneToRemove.remove();
        this.scenes.splice(this.scenes.length - 2, 1);
        // 调整时间.
        this.adjustScenesPoints();
        this.adjustDuration();
        // 清理无关引用数据.
        this.project.data.clearUnReferencedCompItems();
    }
    /** 上传用户照片, 返回上传的数目. */
    async uploadMedias(onprogress) {
        let mediaFiles = await (0, ff_1.selectMultipleFile)(aegl_1.Footages.GraphicFileAccepts);
        if (!mediaFiles) {
            return 0;
        }
        onprogress(0, mediaFiles.length);
        // 最后一幕需要在最后设置.
        let lastScene = this.scenes[this.scenes.length - 1];
        let canReplaceLoopScenes = this.scenes.filter(scene => scene.media && !scene.info.replaced && scene !== lastScene);
        let replacedLastSceneInfo = lastScene.info.replaced ? this.scenes[this.scenes.length - 1].info : null;
        for (let i = 0; i < mediaFiles.length; i++) {
            let mediaFile = mediaFiles[i];
            mediaFile = await (0, jpeg_orientation_1.fixJPEGOrientation)(mediaFile);
            try {
                // 替换中间场景的资源.
                if (canReplaceLoopScenes.length > 0) {
                    let scene = canReplaceLoopScenes.shift();
                    await scene.setMediaFile(mediaFile);
                }
                else {
                    // 生成一个中间场景然后替换为最后一个场景的资源.
                    if (replacedLastSceneInfo) {
                        this.addSceneFromInfo(replacedLastSceneInfo);
                        replacedLastSceneInfo = null;
                        // 替换为默认以防止之后替换时被移除.
                        lastScene.info = new scene_info_1.LocalSceneInfo();
                    }
                    // 替换最后一个场景的资源, 如果可以替换的话.
                    if (i === mediaFiles.length - 1 && lastScene.media) {
                        await lastScene.setMediaFile(mediaFile);
                    }
                    // 添加场景.
                    else {
                        await this.addSceneFromMedia(mediaFile);
                    }
                }
            }
            catch (err) {
                console.error(err);
            }
            onprogress(i + 1, mediaFiles.length);
        }
        this.adjustScenesPoints();
        this.adjustDuration();
        return mediaFiles.length;
    }
    /** 在尾部场景前添加一个新的场景, 来源于循环拷贝非中间的场景. */
    async addSceneFromMedia(mediaFile) {
        let newScene = this.getNextLoopScene().clone();
        await newScene.setMediaFile(mediaFile);
        this.appendScene(newScene);
    }
    /** 在尾部场景前添加一个新的场景, 来源于循环拷贝非中间的场景. */
    async addSceneFromInfo(info) {
        let newScene = this.getNextLoopScene().clone();
        newScene.setInfo(info, false);
        this.appendScene(newScene);
    }
    /** 获得下一个重复的场景. */
    getNextLoopScene() {
        let cloneIndex = (this.scenes.length - 2) % this.loopScenes.length;
        let fromScene = this.loopScenes[cloneIndex];
        return fromScene;
    }
    /** 更改场景的图片. */
    async changeSceneMedia(scene) {
        let media = await (0, ff_1.selectFile)(aegl_1.Footages.GraphicFileAccepts);
        if (!media) {
            return;
        }
        await scene.setMediaFile(media);
        this.adjustScenesPoints();
        this.adjustDuration();
    }
    /** 修改某个场景的长度. */
    setSceneDuration(scene, duration) {
        scene.setDuration(duration);
        this.adjustScenesPoints();
        this.adjustDuration();
    }
    /** 重置某个场景的长度. */
    resetSceneDuration(scene) {
        scene.resetDuration();
        this.adjustScenesPoints();
        this.adjustDuration();
    }
    /** 是否可以调整至少一个循环幕的时长. */
    canAdjustSomeSceneDurations() {
        return this.scenes.slice(1, -1).some(scene => scene.canSetDuration && scene.info.mediaType !== 'video');
    }
    /** 由于包含背景视频素材的关系而无法调整所有幕的时长. */
    canNeverAdjustAllSceneDurations() {
        return !this.scenes.every(scene => scene.canSetDuration);
    }
    /** 是否可以调整每一幕的时长. */
    canAdjustAllSceneDurations() {
        return this.scenes.every(scene => scene.canSetDuration && scene.info.mediaType !== 'video');
    }
    /** 获得可调整的时长部分. */
    getAdjustableDuration() {
        let duration = 0;
        let count = 0;
        for (let scene of this.scenes) {
            if (scene.info.mediaType === 'image' && scene.canSetDuration) {
                count++;
                duration += scene.getDuration();
            }
        }
        let unAdjustableCount = this.scenes.length - count;
        return { count, duration, unAdjustableCount };
    }
    /** 获得循环场景的平均时长. */
    getAverageLoopSceneStartDuration() {
        return (0, ff_1.avg)(this.loopScenes.map(scene => scene.startDuration));
    }
    /** 获得循环场景的最小时长. */
    getMinimumLoopSceneStartDuration() {
        return Math.min(...this.loopScenes.map(scene => scene.startDuration));
    }
    /** 调整照片场景时长. */
    adjustScenesDuration(newDuration) {
        let oldDuration = this.project.data.duration;
        let adjustableDuration = this.getAdjustableDuration().duration;
        let freezeDuration = oldDuration - adjustableDuration;
        let scaling = (newDuration - freezeDuration) / adjustableDuration;
        for (let scene of this.scenes) {
            if (scene.info.mediaType === 'image' && scene.canSetDuration) {
                let sceneDuration = (0, ff_1.toDecimal)(scene.getDuration() * scaling, 2);
                scene.setDuration(sceneDuration);
            }
        }
        this.adjustScenesPoints();
        this.adjustDuration();
    }
    /** 重设总时长. */
    resetTotalDuration() {
        for (let scene of this.scenes) {
            scene.resetDuration();
        }
        this.adjustScenesPoints();
        this.adjustDuration();
    }
    /** 更换音乐. */
    async changeMusic() {
        let audioFile = await (0, ff_1.selectFile)(aegl_1.Footages.AudioFileAccepts);
        if (!audioFile) {
            return;
        }
        let audioLayer = this.project.footages.getReplaceableAudioLayerData();
        audioLayer.name = audioFile.name;
        audioLayer.path = URL.createObjectURL(audioFile);
        let audio = await this.project.resourceLoader.loadAudio(audioLayer);
        audioLayer.duration = audio.duration;
        this.userAudioData = {
            name: audioFile.name,
            path: URL.createObjectURL(audioFile),
            duration: audio.duration,
        };
    }
    /** 设置多个场景的时间. */
    setDurations(durations) {
        for (let i = 0; i < this.scenes.length; i++) {
            this.scenes[i].setDuration(durations[i]);
        }
        this.adjustScenesPoints();
        this.adjustDuration();
    }
    /** 恢复原始数据之后恢复场景. */
    async reset(onprogress) {
        // 因为数据被重置, 没有必要再移除层数据, 只删除场景信息即可.
        for (let scene of this.scenes) {
            scene.removeInfo();
        }
        this.userAudioData = null;
        this.parseScenes();
        // 生成裁剪图和缩略图.
        await this.ensureSceneMediaInfoDatas(onprogress);
    }
    /** 设置字体, 会同时设置相近但是未设置过的其他场景. */
    setBunchFontFamily(scene, family) {
        for (let item of this.getBunchScenes(scene)) {
            item.setFontFamily(family, item === scene);
        }
    }
    /** 设置字型类型, 会同时设置相近但是未设置过的其他场景. */
    setBunchFontStyle(scene, style) {
        for (let item of this.getBunchScenes(scene)) {
            item.setFontStyle(style, item === scene);
        }
    }
    /** 设置字号, 会同时设置相近但是未设置过的其他场景. */
    setBunchFontSize(scene, size) {
        for (let item of this.getBunchScenes(scene)) {
            item.setFontSize(size, item === scene);
        }
    }
    /** 设置填充色, 会同时设置相近但是未设置过的其他场景. */
    setBunchFillColor(scene, color) {
        for (let item of this.getBunchScenes(scene)) {
            item.setFillColor(color, item === scene);
        }
    }
    /** 获取类似的场景, 即初始字体相同并且当前字体相同的场景, 包含重复场景模板. */
    getBunchScenes(scene) {
        // 过滤出情景相似的场景.
        let similarScenes = [...this.scenes, ...this.loopScenes].filter(s => {
            return s.startFontFamily === scene.startFontFamily;
        });
        // 过滤出情景相似, 并且未被触碰过的场景.
        let bunchScenes = similarScenes.filter(s => {
            return s === scene || !s.info.touched;
        });
        // 仅当前场景以及之后的场景接受更改.
        let index = bunchScenes.indexOf(scene);
        let bunchScenesAfter = bunchScenes.slice(index);
        return bunchScenesAfter;
    }
    /** 加载用户编辑数据. replacedAspectRatio 在替换为当前模板时指定为 true. */
    async loadUserSceneData(UserSceneData, fullyReplaceAllScenes, onprogress) {
        let infos = UserSceneData.sceneInfos;
        let audioData = UserSceneData.audio;
        // 列出所有将会被替换数据的场景.
        let canReplaceScenes = this.scenes.filter(scene => fullyReplaceAllScenes || scene.media);
        let lastScene = this.scenes[this.scenes.length - 1];
        // 最后一幕需要在最后设置.
        let canReplaceLastScene = lastScene === canReplaceScenes[canReplaceScenes.length - 1];
        if (canReplaceLastScene) {
            canReplaceScenes.pop();
        }
        for (let i = 0; i < infos.length; i++) {
            let info = infos[i];
            // 替换中间场景的资源.
            if (canReplaceScenes.length > 0) {
                let scene = canReplaceScenes.shift();
                scene.setUserInfo(info, fullyReplaceAllScenes);
            }
            // 替换最后一个场景的资源.
            else if (i === infos.length - 1 && canReplaceLastScene) {
                lastScene.setUserInfo(info, fullyReplaceAllScenes);
            }
            // 在尾部添加一个场景.
            else {
                let newScene = this.getNextLoopScene().clone();
                newScene.setUserInfo(info, fullyReplaceAllScenes);
                this.appendScene(newScene);
            }
        }
        // 替换音频.
        if (audioData) {
            this.userAudioData = audioData;
            let audioLayer = this.project.footages.getReplaceableAudioLayerData();
            Object.assign(audioLayer, audioData);
        }
        // 生成裁剪图和缩略图.
        await this.ensureSceneMediaInfoDatas(onprogress);
        this.adjustScenesPoints();
        this.adjustDuration();
    }
    /** 提取用户数据. */
    extractUserSceneData() {
        let sceneInfos = [];
        for (let scene of this.scenes) {
            sceneInfos.push(scene.info.getUserSceneInfo());
        }
        return {
            sceneInfos,
            audio: this.userAudioData,
        };
    }
    /** 提取已编辑的本地数据用于在不同模板之间, 或者同一个模板的不同宽高比之间交换. */
    extractLocalSceneData() {
        let sceneInfos = [];
        for (let scene of this.scenes) {
            if (scene.info.replaced) {
                sceneInfos.push(scene.info);
            }
        }
        return {
            sceneInfos,
            audio: this.userAudioData,
        };
    }
    /** 在重设项目数据之后重新加载场景数据. */
    async reloadSceneData(onprogress) {
        let data = this.extractUserSceneData();
        this.parseScenes();
        await this.loadUserSceneData(data, true, onprogress);
    }
}
exports.SceneEditor = SceneEditor;


/***/ }),

/***/ "./src/aegl-scene/scene-helper.ts":
/*!****************************************!*\
  !*** ./src/aegl-scene/scene-helper.ts ***!
  \****************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.adjustLayerTimeProperties = exports.scaleLayerTimePoints = exports.moveLayerTimeProperties = exports.moveLayerTimePoints = exports.getMaxCrossLayerIndex = exports.getCrossedRootLayers = exports.findUnReplacableVideoLayersInside = exports.findEditableTextLayersInside = exports.getEditableTextDeepLayers = exports.findReplacableMediaLayersInside = exports.getReplacableMediaDeepLayers = void 0;
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
/** 查找所有可替换素材的层. */
function getReplacableMediaDeepLayers(project) {
    let rootLayers = project.data.layers;
    let mediaDeepLayers = rootLayers.map(root => {
        let layers = findReplacableMediaLayersInside(project, root);
        if (layers.length > 0) {
            return { root, layers };
        }
        else {
            return null;
        }
    }).filter(v => v);
    return mediaDeepLayers;
}
exports.getReplacableMediaDeepLayers = getReplacableMediaDeepLayers;
/** 查找可替换素材的层. */
function findReplacableMediaLayersInside(project, root) {
    return findLayerInside(project, root, layer => {
        return layer.replaceable === true && (layer.type === 'image' || layer.type === 'video');
    });
}
exports.findReplacableMediaLayersInside = findReplacableMediaLayersInside;
/** 查找所有可编辑的文本层. */
function getEditableTextDeepLayers(project) {
    let rootLayers = project.data.layers;
    let textDeepLayers = rootLayers.map(root => {
        let layers = findEditableTextLayersInside(project, root);
        if (layers.length > 0) {
            return { root, layers };
        }
        else {
            return null;
        }
    }).filter(v => v);
    return textDeepLayers;
}
exports.getEditableTextDeepLayers = getEditableTextDeepLayers;
/** 查找可替换素材的层. */
function findEditableTextLayersInside(project, root) {
    return findLayerInside(project, root, layer => {
        return layer.replaceable === true && layer.type === 'text';
    });
}
exports.findEditableTextLayersInside = findEditableTextLayersInside;
/** 查找不可替换的视频层. */
function findUnReplacableVideoLayersInside(project, root) {
    return findLayerInside(project, root, layer => {
        return layer.replaceable !== true && layer.type === 'video';
    });
}
exports.findUnReplacableVideoLayersInside = findUnReplacableVideoLayersInside;
/** 递归查询. */
function findLayerInside(project, layer, fn) {
    if (fn(layer)) {
        return [layer];
    }
    else if (layer.type === 'composite') {
        let childLayers = project.data.getCompLayersFromId(layer.compItemId);
        return childLayers.map(childLayer => findLayerInside(project, childLayer, fn)).flat();
    }
    return [];
}
/** 查询与多媒体或者文本层在起始位置相交, 或者在其内部的层. */
function getCrossedRootLayers(project, layer, excludeLayerIdSet) {
    let crossedLayers = [];
    for (let rootLayer of project.data.layers) {
        if (excludeLayerIdSet.has(rootLayer.id)) {
            continue;
        }
        if (layer.type === 'audio') {
            continue;
        }
        if (isLayerCrossWith(rootLayer, layer)) {
            crossedLayers.push(rootLayer);
        }
    }
    return crossedLayers;
}
exports.getCrossedRootLayers = getCrossedRootLayers;
/** 计算 layer 的结束时间是否在 compareTo 内部, 或者 layer 完全包含 compareTo. */
function isLayerCrossWith(layer, compareTo) {
    return layer.outPoint > compareTo.inPoint && layer.outPoint <= compareTo.outPoint
        || layer.inPoint <= compareTo.inPoint && layer.outPoint >= compareTo.outPoint
            && layer.type !== 'audio';
}
/** 选取相交长度最大的节点. */
function getMaxCrossLayerIndex(deepLayer, compareDeepLayers) {
    let crossSeconds = compareDeepLayers.map(compareDeepLayer => {
        return getLayerCrossSeconds(compareDeepLayer.root, deepLayer.root);
    });
    let index = (0, ff_1.maxIndex)(crossSeconds);
    return crossSeconds[index] > 0.5 ? index : -1;
}
exports.getMaxCrossLayerIndex = getMaxCrossLayerIndex;
/** 计算两个层的相交长度, 相比其中较短者的比例. */
function getLayerCrossSeconds(layer1, layer2) {
    let crossSeconds = Math.min(layer1.outPoint, layer2.outPoint) - Math.max(layer1.inPoint, layer2.inPoint);
    return crossSeconds;
}
/** 移动层的属性的时间, 包含 inPoint 和 outPoint. */
function moveLayerTimePoints(layer, toMove) {
    layer.inPoint += toMove;
    layer.outPoint += toMove;
    if (layer.startTime !== undefined) {
        layer.startTime += toMove;
    }
    for (let key of Object.keys(layer)) {
        if (key === 'layers') {
            continue;
        }
        let value = layer[key];
        if (typeof value === 'object') {
            moveLayerSubTimeProperties(value, (time) => {
                return time + toMove;
            });
        }
    }
}
exports.moveLayerTimePoints = moveLayerTimePoints;
/** 移动层的属性的时间, 不包含 inPoint 和 outPoint. */
function moveLayerTimeProperties(layer, toMove) {
    for (let key of Object.keys(layer)) {
        if (key === 'layers') {
            continue;
        }
        let value = layer[key];
        if (typeof value === 'object') {
            moveLayerSubTimeProperties(value, (time) => {
                return time + toMove;
            });
        }
    }
}
exports.moveLayerTimeProperties = moveLayerTimeProperties;
/** 缩放层的属性的时间, 包含 inPoint 和 outPoint. */
function scaleLayerTimePoints(layer, scale, startPoint) {
    layer.inPoint = (layer.inPoint - startPoint) * scale + startPoint;
    layer.outPoint = (layer.outPoint - startPoint) * scale + startPoint;
    // 视频不应当调整时间映射.
    if (layer.type === 'video' && layer.timeRemap) {
        delete layer.timeRemap;
    }
    for (let key of Object.keys(layer)) {
        if (key === 'layers') {
            continue;
        }
        let value = layer[key];
        if (typeof value === 'object') {
            moveLayerSubTimeProperties(value, (time) => {
                return (time - startPoint) * scale + startPoint;
            });
        }
    }
}
exports.scaleLayerTimePoints = scaleLayerTimePoints;
/** 调整层的属性的时间, 不包含 inPoint 和 outPoint. */
function adjustLayerTimeProperties(layer, fn) {
    for (let key of Object.keys(layer)) {
        if (key === 'layers') {
            continue;
        }
        let value = layer[key];
        if (typeof value === 'object') {
            moveLayerSubTimeProperties(value, fn);
        }
    }
}
exports.adjustLayerTimeProperties = adjustLayerTimeProperties;
/** 调整层的子属性对象的时间. */
function moveLayerSubTimeProperties(o, fn) {
    if (Array.isArray(o)) {
        for (let item of o) {
            if (item.time) {
                item.time = fn(item.time);
            }
            moveLayerSubTimeProperties(item, fn);
        }
    }
    else {
        for (let key of Object.keys(o)) {
            let value = o[key];
            if (typeof value === 'object') {
                moveLayerSubTimeProperties(value, fn);
            }
        }
    }
}


/***/ }),

/***/ "./src/aegl-scene/scene-info.ts":
/*!**************************************!*\
  !*** ./src/aegl-scene/scene-info.ts ***!
  \**************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.LocalSceneInfo = void 0;
const file_1 = __webpack_require__(/*! ../libs/util/file */ "./src/libs/util/file.ts");
/** 本地的场景信息, 包含了更多的不可上传的信息, 可以直接在本地和另一个场景交换. */
class LocalSceneInfo {
    name = '';
    mediaType = null;
    mediaPath = '';
    mediaWidth = 0;
    mediaHeight = 0;
    mediaPosition = [0.5, 0.5];
    mediaFrameRate;
    mediaDuration;
    duration = 0;
    text = null;
    fontFamily = null;
    fontStyle = null;
    fontSize = null;
    fillColor = null;
    /** 被裁减的资源地址. 如果存在的话, 则总是和 `mediaPath 的内容保持一致. */
    croppedPath = '';
    /** 被裁减的资源宽度. */
    croppedWidth = 0;
    /** 被裁减的资源高度. */
    croppedHeight = 0;
    /** 缩略图路径. 如果存在的话, 则总是和 `mediaPath 的内容保持一致. */
    thumbnailPath = '';
    /** 是否已执行了素材替换. */
    replaced = false;
    /** 是否有手动设置过某个属性, 主要是文字属性. */
    touched = false;
    constructor(userInfo) {
        if (userInfo) {
            Object.assign(this, userInfo);
        }
    }
    /** 导出为可用于保存在服务端的 JSON 数据. */
    getUserSceneInfo() {
        let userInfo = {
            name: this.name,
            mediaType: this.mediaType,
            mediaPath: this.mediaPath,
            mediaWidth: this.mediaWidth,
            mediaHeight: this.mediaHeight,
            mediaPosition: this.mediaPosition,
            duration: this.duration,
            text: this.text,
            fontFamily: this.fontFamily,
            fontStyle: this.fontStyle,
            fontSize: this.fontSize,
            fillColor: this.fillColor,
        };
        if (this.mediaType === 'video') {
            userInfo.mediaFrameRate = this.mediaFrameRate;
            userInfo.mediaDuration = this.mediaDuration;
        }
        return userInfo;
    }
    /** 更新资源路径, 同时会让缩略图属性过期. */
    updateMediaPath(mediaPath) {
        this.deleteMedia();
        this.mediaPath = mediaPath;
    }
    /** 更新裁剪资源地址. */
    updateCroppedPath(croppedPath) {
        if ((0, file_1.isBlobURL)(this.croppedPath) && this.croppedPath !== this.mediaPath) {
            URL.revokeObjectURL(this.croppedPath);
        }
        this.croppedPath = croppedPath;
    }
    /** 更新缩略图地址. */
    updateThumbnailPath(thumbnailPath) {
        if ((0, file_1.isBlobURL)(this.thumbnailPath)) {
            URL.revokeObjectURL(this.thumbnailPath);
        }
        this.thumbnailPath = thumbnailPath;
    }
    /**
     * 手动设置了某个属性之后通知其被触碰过.
     * 之后它会被一些 "群组设置" 之类的功能所影响.
     */
    toTouch() {
        this.touched = true;
    }
    /** 移除此场景信息, 注销所有 URL 资源. */
    delete() {
        this.deleteMedia();
    }
    /** 移除当前的场景信息以及其中的 Blob URL. */
    deleteMedia() {
        if ((0, file_1.isBlobURL)(this.mediaPath)) {
            URL.revokeObjectURL(this.mediaPath);
        }
        this.mediaPath = '';
        if ((0, file_1.isBlobURL)(this.croppedPath)) {
            URL.revokeObjectURL(this.croppedPath);
        }
        this.croppedPath = '';
        if ((0, file_1.isBlobURL)(this.thumbnailPath)) {
            URL.revokeObjectURL(this.thumbnailPath);
        }
        this.thumbnailPath = '';
    }
}
exports.LocalSceneInfo = LocalSceneInfo;


/***/ }),

/***/ "./src/aegl-scene/scene.ts":
/*!*********************************!*\
  !*** ./src/aegl-scene/scene.ts ***!
  \*********************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Scene = void 0;
const scene_helper_1 = __webpack_require__(/*! ./scene-helper */ "./src/aegl-scene/scene-helper.ts");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
const media_1 = __webpack_require__(/*! ../aegl/helpers/media */ "./src/aegl/helpers/media.ts");
const preload_1 = __webpack_require__(/*! ../libs/util/preload */ "./src/libs/util/preload.ts");
const file_1 = __webpack_require__(/*! ../libs/util/file */ "./src/libs/util/file.ts");
const ffmpeg_1 = __webpack_require__(/*! ../libs/ffmpeg/ffmpeg */ "./src/libs/ffmpeg/ffmpeg.ts");
const scene_info_1 = __webpack_require__(/*! ./scene-info */ "./src/aegl-scene/scene-info.ts");
const pico_face_1 = __webpack_require__(/*! ../libs/pico-face */ "./src/libs/pico-face.ts");
/** 单个场景. */
class Scene {
    /** 当前项目 */
    project;
    /** 主要的层, 为图片或者视频, 如果没有的话则为文本. */
    main;
    /** 图片或者视频层. */
    media;
    /** 场景信息. */
    info = new scene_info_1.LocalSceneInfo();
    /** 文本层. */
    text;
    /** 开始时间和上一个场景结束时间之间的距离. */
    marginLeft = 0;
    /** 结束时间和下一个场景开始时间之间的距离. */
    marginRight = 0;
    /** 是否包含了转场, 即溢出其时间段的相交层用于连接上一个或者下一个场景. */
    includedTransitions = false;
    /** 是否可以设置 duration. */
    canSetDuration = false;
    /** 起始的该幕时长. */
    startDuration;
    /** 起始的该幕文字. */
    startText;
    /** 起始字体. */
    startFontFamily;
    /** 起始字体. */
    startFontStyle;
    /** 起始字号. */
    startFontSize;
    /** 起始字号. */
    startFillColor;
    /** 同一时间段的其他层, 跟随层数据一起重复. */
    crossed;
    constructor(project, media, text, crossed) {
        this.project = project;
        this.main = (media || text);
        this.media = media;
        this.text = text;
        this.crossed = crossed;
        this.startDuration = this.main.root.outPoint - this.main.root.inPoint;
        this.startText = text ? text.layers[0].text : '';
        this.startFontSize = text ? text.layers[0].fontSize : null;
        this.startFontFamily = text ? text.layers[0].fontFamily : null;
        this.startFontStyle = text ? text.layers[0].fauxBold ? 'Bold' : text.layers[0].fontStyle : null;
        this.startFillColor = text ? text.layers[0].fillColor : null;
        this.info.duration = this.getDuration();
        if (this.media) {
            this.initializeInfoFromMediaLayer();
        }
        else {
            this.initializeCoverAsThumbnail();
        }
        // 在初始化完成后需要外部调用生成缩略图和裁剪图.
    }
    /** 此场景是否可被移除. */
    get canBeRemoved() {
        return !!this.media;
    }
    /** 此场景是否可被移动. */
    get canBeMoved() {
        return !!this.media;
    }
    /**
     * 对于很长的背景视频素材, 或者任意其他类型的素材, 我们将其裁剪为片段,
     * 同时保持原 id. 因此它既可以使用原先的层, 又可以对于重复的场景,
     * 经过时间映射到原先的时间.
     */
    initializeAfterAllScenesCreated() {
        // 进行层切片.
        this.initializeSegmentClippingForLongCrossed();
        // 检查是否包含所有的相交层, 如果是的话, 当前的层可以随意重复, 否则必须考虑首尾对接.
        this.includedTransitions = this.crossed.some(layer => {
            return (layer.inPoint + 0.1 < this.main.root.inPoint || layer.outPoint > this.main.root.outPoint + 0.1)
                && layer.outPoint - layer.inPoint < (this.main.root.outPoint - this.main.root.inPoint) * 0.8;
        });
        // 检查是否有覆盖其的视频层, 如果是的话, 那么不能调整时长.
        // 可重复的视频不算在内.
        let hasLongCrossedVideo = [...this.getRootLayers(), ...this.crossed].some(layer => {
            let videoLayers = (0, scene_helper_1.findUnReplacableVideoLayersInside)(this.project, layer);
            return videoLayers.some(video => {
                return video.outPoint - video.inPoint > this.startDuration * 0.99
                    && !(video.loop && video.loop > 1);
            });
        });
        this.canSetDuration = !hasLongCrossedVideo;
    }
    /** 辅助函数, 获得 media 和 text 的 root. */
    getRootLayers() {
        let rootLayers = [this.main.root];
        if (this.media && this.media.root.id !== this.main.root.id) {
            rootLayers.push(this.media.root);
        }
        if (this.text && this.text.root.id !== this.main.root.id) {
            rootLayers.push(this.text.root);
        }
        return rootLayers;
    }
    /** 进行长层的切片. */
    initializeSegmentClippingForLongCrossed() {
        for (let i = 0; i < this.crossed.length; i++) {
            let oldLayer = this.crossed[i];
            let duration = oldLayer.outPoint - oldLayer.inPoint;
            let loop = oldLayer.loop || 1;
            // 至少达到当前场景的时长 * 2, 并且不是循环视频.
            if (duration < this.startDuration * 2 || loop > 1) {
                continue;
            }
            let newLayer = this.project.data.cloneLayerData(oldLayer);
            // 如果没有视频的时间映射参数, 为其设置.
            this.project.data.ensureTimeRemap(newLayer);
            // 这些层应当覆盖当前层, 这样可以被 link.
            // 此外还应当和前面以及后面的相接.
            // 有一种情况比较特殊, 既被 link 又需要相接绘制.
            // 这个时候我们优先保证 link, 绘制有可能会被绘制两次, 不过关系不大.
            // 因此时间轴仅向外扩张, 不向内伸缩.
            newLayer.inPoint = this.main.root.inPoint;
            newLayer.outPoint = this.main.root.outPoint;
            if (this.marginLeft > 0) {
                newLayer.inPoint -= this.marginLeft;
            }
            if (this.marginRight > 0) {
                newLayer.outPoint += this.marginRight;
            }
            // 重新进行时间映射.
            if ((newLayer.type === 'video' || newLayer.type === 'composite')) {
                let timeRemap = newLayer.timeRemap;
                let timeMove = newLayer.inPoint - oldLayer.inPoint;
                // 移动时间映射.
                if (Array.isArray(timeRemap)) {
                    for (let map of timeRemap) {
                        map.time += timeMove;
                        map.value += timeMove;
                    }
                    // 对时间映射范围做线性裁剪, 这样不至于出现非常长的时间映射.
                    if (timeRemap.length === 2 && timeRemap[1].time > newLayer.outPoint) {
                        let timeMove = newLayer.outPoint - timeRemap[1].time;
                        timeRemap[1].time += timeMove;
                        timeRemap[1].value += timeMove;
                    }
                }
                else {
                    newLayer.timeRemap += timeMove;
                }
            }
            this.crossed[i] = newLayer;
            // 必须插入到上面, 这样在进行查找时, 相同 id 会优先保留上面的.
            this.project.data.insertRootLayerData(newLayer);
        }
    }
    /** 从层提取场景信息. */
    initializeInfoFromMediaLayer() {
        let layer = this.media.layers[0];
        this.info.mediaType = layer.type;
        this.info.mediaPath = this.project.resourceLoader.getLayerPath(layer);
        this.info.mediaWidth = layer.mediaWidth;
        this.info.mediaHeight = layer.mediaHeight;
        this.info.mediaPosition = layer.mediaPosition;
        if (layer.type === 'video') {
            this.info.mediaFrameRate = layer.frameRate;
            this.info.mediaDuration = layer.duration;
        }
    }
    /** 设置封面和封底作为缩略图. */
    initializeCoverAsThumbnail() {
        if (this.main.root.inPoint < 1) {
            this.info.thumbnailPath = this.project.footages.getCoverPath() || '';
        }
        else {
            this.info.thumbnailPath = this.project.footages.getBackCoverPath() || '';
        }
    }
    /** 设置图片或视频资源路径, 会同时设置相关的裁剪资源和缩略图. 原先的资源作废. */
    async setMediaFile(file) {
        let extension = (0, file_1.getPathExtension)(file.name);
        this.info.mediaType = extension === 'mp4' ? 'video' : 'image';
        this.info.updateMediaPath(URL.createObjectURL(file));
        let element = await this.getCurrentMediaElement();
        // 从文件获取信息.
        await this.fetchInfoFromFile(file, element);
        // 更新裁剪图和缩略图.
        await this.ensureMediaInfoDatas(element);
        // 重新设置最佳的场景长度.
        if (this.canSetDuration) {
            this.resetDuration();
        }
    }
    /** 获得文件相关的多媒体信息. */
    async fetchInfoFromFile(file, element) {
        let size = this.getElementSize(element);
        let info = this.info;
        info.name = file.name;
        info.mediaWidth = size.width;
        info.mediaHeight = size.height;
        info.replaced = true;
        if (info.mediaType === 'video') {
            let fffile = await ffmpeg_1.ffmpeg.getFFFileFromFile(file);
            let mediaInfo = await ffmpeg_1.ffmpeg.getMediaInfo(fffile);
            info.mediaFrameRate = mediaInfo.video.frameRate;
            info.mediaDuration = mediaInfo.duration;
        }
        // 使用的阈值为 0, 即一旦有一点像脸就获得. 之后还会根据相似度加权.
        let faceResults = await pico_face_1.PicoFace.getFaces(element, 25);
        let facePosition = pico_face_1.PicoFace.getTotalFaceAlignPosition(faceResults);
        if (facePosition) {
            info.mediaPosition = [
                facePosition.x,
                facePosition.y,
            ];
        }
        return info;
    }
    /** 获得图片或者视频元素的尺寸. */
    getElementSize(element) {
        let width;
        let height;
        if (element instanceof HTMLVideoElement) {
            width = element.videoWidth;
            height = element.videoHeight;
        }
        else {
            width = element.naturalWidth;
            height = element.naturalHeight;
        }
        return { width, height };
    }
    /** 更新扩展的图片以及视频的裁剪和缩略图信息, 如果他们尚不存在或者已过期的话. */
    async ensureMediaInfoDatas(element) {
        if (this.media && (!this.info.croppedPath || !this.info.thumbnailPath)) {
            element = element || await this.getCurrentMediaElement();
            // 如果裁剪资源不存在, 或者分辨率变更.
            let isCroppedInCurrentAspectRatio = Math.round(this.info.croppedHeight * this.project.data.aspectRatio) === this.info.croppedWidth;
            if (!this.info.croppedPath || !isCroppedInCurrentAspectRatio) {
                await this.updateCroppedMedia(element);
            }
            if (!this.info.thumbnailPath) {
                await this.updateThumbnail(element);
            }
        }
    }
    /** 更新资源元素以及其尺寸. */
    async getCurrentMediaElement() {
        return await this.getMediaElement(this.info.mediaPath, this.info.mediaType);
    }
    /** 获得当前多媒体元素. */
    async getMediaElement(path, mediaType) {
        let element;
        if (mediaType === 'video') {
            element = await (0, preload_1.preloadVideo)(path);
        }
        else {
            element = await (0, preload_1.preloadImage)(path);
        }
        return element;
    }
    /** 更新裁剪的多媒体资源, 当更换原图或者更换对齐位置时需要调用. */
    async updateCroppedMedia(element) {
        if (this.shouldCropMedia()) {
            element = element || await this.getCurrentMediaElement();
            let canvas = await (0, media_1.cropImageToMaximumSize)(element, this.project.data.width, this.project.data.height, this.info.mediaPosition);
            let imageBlob = await (0, media_1.readCanvasAsJPEG)(canvas);
            this.info.updateCroppedPath(URL.createObjectURL(imageBlob));
            this.info.croppedWidth = canvas.width;
            this.info.croppedHeight = canvas.height;
        }
        else {
            this.info.updateCroppedPath(this.info.mediaPath);
            this.info.croppedWidth = this.info.mediaWidth;
            this.info.croppedHeight = this.info.mediaHeight;
        }
        // 将信息应用于层数据.
        this.applyMediaInfo();
    }
    /** 是否需要进行裁剪. */
    shouldCropMedia() {
        if (this.info.mediaType !== 'image') {
            return false;
        }
        let width = this.info.mediaWidth;
        let height = this.info.mediaHeight;
        return width > this.project.data.width
            || height > this.project.data.height
            || Math.round(height * this.project.data.aspectRatio) !== width;
    }
    /** 更新缩略图. */
    async updateThumbnail(element) {
        element = element || await this.getCurrentMediaElement();
        // 用于创建缩略图的原图, 来自于原图或者一个视频帧.
        let image;
        if (element instanceof HTMLVideoElement) {
            let video = element;
            let canvas = await (0, media_1.extractVideoFrame)(video);
            let blob = await (0, media_1.readCanvasAsJPEG)(canvas);
            image = await (0, preload_1.preloadImage)(URL.createObjectURL(blob));
        }
        else {
            image = element;
        }
        // 缩略图显示的高度为 180.
        let minPixelHeight = 180;
        let minPixelWidth = this.project.data.aspectRatio * minPixelHeight;
        let minThumbnailWidth = minPixelWidth * devicePixelRatio;
        let minThumbnailHeight = minPixelHeight * devicePixelRatio;
        let canvas = await (0, media_1.createSameAspectRatioImageThumbnail)(image, minThumbnailWidth, minThumbnailHeight);
        let blob = await (0, media_1.readCanvasAsJPEG)(canvas);
        this.info.updateThumbnailPath(URL.createObjectURL(blob));
    }
    /** 重新设置场景信息, 包括扩展场景信息. */
    setUserInfo(info, toSetDuration = true) {
        if (info instanceof scene_info_1.LocalSceneInfo) {
            this.setInfo(info, toSetDuration);
        }
        else {
            this.setInfo(new scene_info_1.LocalSceneInfo(info), toSetDuration);
        }
    }
    /** 重新设置场景信息, 包括扩展场景信息. */
    setInfo(info, toSetDuration = true) {
        this.info = info;
        this.applyMediaInfo();
        this.applyTextInfo();
        // 如果可以的话, 设置时长信息.
        if (toSetDuration && this.canSetDuration) {
            this.setDuration(info.duration);
        }
        else {
            info.duration = this.getDuration();
        }
    }
    /** 设置层上的 media 数据. */
    applyMediaInfo() {
        let info = this.info;
        if (this.media) {
            this.media.layers.forEach(layer => {
                layer.name = info.name;
                layer.path = info.croppedPath;
                layer.mediaWidth = info.croppedWidth;
                layer.mediaHeight = info.croppedHeight;
                layer.mediaPosition = info.mediaPosition;
                if (info.mediaType === 'video') {
                    layer.type = 'video';
                    layer.frameRate = info.mediaFrameRate;
                    layer.duration = info.mediaDuration;
                }
                else {
                    layer.type = 'image';
                    delete layer.frameRate;
                    delete layer.duration;
                }
            });
        }
    }
    /** 设置层上的 media 数据. */
    applyTextInfo() {
        let info = this.info;
        if (this.text) {
            this.text.layers.forEach(layer => {
                layer.text = info.text === null ? this.startText : info.text;
                layer.fontFamily = info.fontFamily === null ? this.startFontFamily : info.fontFamily;
                layer.fontStyle = info.fontStyle === null ? this.startFontStyle : info.fontStyle;
                layer.fontSize = info.fontSize === null ? this.startFontSize : info.fontSize;
                layer.fillColor = info.fillColor === null ? this.startFillColor : info.fillColor;
            });
        }
        else {
            info.text = null;
        }
    }
    /** 设置文本内容. */
    setText(text) {
        if (this.text) {
            this.text.layers.forEach(layer => {
                layer.text = text;
            });
            this.info.text = text;
            this.info.toTouch();
        }
    }
    /** 设置字体. */
    setFontFamily(family, manually = false) {
        if (this.text) {
            this.text.layers.forEach(layer => {
                layer.fontFamily = family;
            });
            this.info.fontFamily = family;
            if (manually) {
                this.info.toTouch();
            }
        }
    }
    /** 设置字型类型. */
    setFontStyle(style, manually = false) {
        if (this.text) {
            this.text.layers.forEach(layer => {
                layer.fontStyle = style;
                if (layer.fauxBold) {
                    delete layer.fauxBold;
                }
            });
            this.info.fontStyle = style;
            if (manually) {
                this.info.toTouch();
            }
        }
    }
    /** 设置字号. */
    setFontSize(size, manually = false) {
        if (this.text) {
            this.text.layers.forEach(layer => {
                layer.fontSize = size;
            });
            this.info.fontSize = size;
            if (manually) {
                this.info.toTouch();
            }
        }
    }
    /** 设置填充色. */
    setFillColor(color, manually = false) {
        if (this.text) {
            this.text.layers.forEach(layer => {
                layer.fillColor = color;
            });
            this.info.fillColor = color;
            if (manually) {
                this.info.toTouch();
            }
        }
    }
    /** 设置文本内容. */
    notifyMediaChanged() {
        if (this.media) {
            this.media.layers.forEach(layer => {
                this.project.notifyLayerUpdated(layer);
            });
        }
    }
    /** 设置 mediaPosition. */
    setMediaPosition(position) {
        this.info.mediaPosition = position;
        this.media.layers.forEach(layer => {
            layer.mediaPosition = position;
        });
    }
    /** 获得当前场景的时长. */
    getDuration() {
        return this.main.root.outPoint - this.main.root.inPoint;
    }
    /** 调整场景时长. */
    setDuration(duration) {
        let inPoint = this.main.root.inPoint;
        let outPoint = this.main.root.outPoint;
        let oldDuration = outPoint - inPoint;
        let scale = duration / oldDuration;
        if (scale === 1) {
            return;
        }
        for (let rootLayer of this.getRootLayers()) {
            this.scaleLayerTimePoints(rootLayer, scale, inPoint);
        }
        for (let layer of this.crossed) {
            let layerDuration = layer.outPoint - layer.inPoint;
            // 未铺满整个场景, 并且在开始位置有交点, 则认为是开始位置的转场.
            if (layerDuration < oldDuration * 0.8 && layer.inPoint <= inPoint) {
                // 不作处理
            }
            // 跟随整个场景做缩放.
            else {
                this.scaleLayerTimePoints(layer, scale, inPoint);
            }
        }
        this.info.duration = duration;
    }
    /** 缩放层的时长. */
    scaleLayerTimePoints(layerData, scale, startPoint) {
        if (layerData.type !== 'video' && layerData.type !== 'audio' && !layerData.timeRemap) {
            this.project.data.ensureTimeRemap(layerData);
        }
        (0, scene_helper_1.scaleLayerTimePoints)(layerData, scale, startPoint);
    }
    /** 恢复 duration. 对于视频, 恢复到视频长; 对于图片, 恢复到初始的长. */
    resetDuration() {
        if (this.info.mediaType === 'video') {
            let duration = this.media.layers[0].duration;
            this.setDuration(duration);
        }
        else {
            this.setDuration(this.startDuration);
        }
    }
    /** 是否会裁剪多媒体资源. */
    willCropMedia() {
        let ratio = this.project.data.width / this.project.data.height;
        return Math.round(this.info.mediaHeight * ratio) !== this.info.mediaWidth;
    }
    /** 克隆一个可重复的场景. */
    clone() {
        let layerIdMap = new Map();
        let media = null;
        let text = null;
        // 克隆 media 和 text.
        if (this.media && this.text && this.media.root === this.text.root) {
            [media, text] = this.cloneBothDeepLayers(layerIdMap);
        }
        else {
            if (this.media) {
                media = this.cloneDeepLayer(this.media, layerIdMap);
            }
            if (this.text) {
                text = this.cloneDeepLayer(this.text, layerIdMap);
            }
        }
        // 克隆相交层, 共享 id, 这样这类层不会在同一时刻出现两个.
        let crossed = [];
        for (let layer of this.crossed) {
            let cloned = this.project.data.cloneLayerData(layer, layerIdMap);
            crossed.push(cloned);
        }
        let rootLayers = [];
        if (media) {
            rootLayers.push(media.root);
        }
        if (text && (!media || text.root.id !== media.root.id)) {
            rootLayers.push(text.root);
        }
        for (let layer of [...rootLayers, ...crossed]) {
            if (layer.parentId) {
                layer.parentId = layerIdMap.get(layer.parentId) || layer.parentId;
            }
        }
        let cloned = new Scene(this.project, media, text, crossed);
        cloned.marginLeft = this.marginLeft;
        cloned.marginRight = this.marginRight;
        cloned.canSetDuration = this.canSetDuration;
        return cloned;
    }
    /** 当 media 和 text 被包含在一个层中时克隆其对应的深度层. */
    cloneBothDeepLayers(layerIdMap) {
        let textAndMediaLayerIds = [...this.media.layers.map(layer => layer.id), ...this.text.layers.map(layer => layer.id)];
        let newRoot = this.project.data.deepCloneLayerData(this.media.root, textAndMediaLayerIds, layerIdMap);
        let newMediaLayers = (0, scene_helper_1.findReplacableMediaLayersInside)(this.project, newRoot);
        let newTextLayers = (0, scene_helper_1.findEditableTextLayersInside)(this.project, newRoot);
        return [
            {
                root: newRoot,
                layers: newMediaLayers,
            },
            {
                root: newRoot,
                layers: newTextLayers,
            },
        ];
    }
    /** 克隆一个深度层. */
    cloneDeepLayer(deepLayer, layerIdMap) {
        let layerIds = deepLayer.layers.map(layer => layer.id);
        let newRoot = this.project.data.deepCloneLayerData(deepLayer.root, layerIds, layerIdMap);
        let newLayers = deepLayer.layers[0].type === 'text'
            ? (0, scene_helper_1.findEditableTextLayersInside)(this.project, newRoot)
            : (0, scene_helper_1.findReplacableMediaLayersInside)(this.project, newRoot);
        return {
            root: newRoot,
            layers: newLayers,
        };
    }
    /** 添加到指定的两个场景中间. */
    insertToProject() {
        // 插入图片或视频资源.
        if (this.media) {
            this.project.data.insertRootLayerData(this.media.root);
        }
        // 插入其他相交资源.
        if (this.crossed.length > 0) {
            for (let i = 0; i < this.crossed.length; i++) {
                this.project.data.insertRootLayerData(this.crossed[i]);
            }
        }
        // 插入文字.
        if (this.text) {
            this.project.data.insertRootLayerData(this.text.root);
        }
    }
    /** 将场景移动到指定场景之后. */
    moveTimeToBeAfter(prevScene) {
        let toMove = prevScene.main.root.outPoint + prevScene.marginRight + this.marginLeft - this.main.root.inPoint;
        if (toMove !== 0) {
            this.moveSceneWithTime(toMove);
        }
    }
    /** 将层的时间轴进行移动. */
    moveSceneWithTime(toMove) {
        for (let rootLayer of this.getRootLayers()) {
            (0, scene_helper_1.moveLayerTimePoints)(rootLayer, toMove);
        }
        this.crossed.forEach(crossed => {
            (0, scene_helper_1.moveLayerTimePoints)(crossed, toMove);
        });
    }
    /** 移除场景. */
    remove() {
        this.removeInfo();
        this.removeLayers();
    }
    /** 移除场景信息. */
    removeInfo() {
        this.info.delete();
    }
    /** 移除所有层. */
    removeLayers() {
        if (this.media) {
            this.removeLayer(this.media.root);
        }
        if (this.text) {
            this.removeLayer(this.text.root);
        }
        this.crossed.forEach(crossed => {
            this.removeLayer(crossed);
        });
    }
    /** 移除层. */
    removeLayer(layer) {
        (0, ff_1.removeWhere)(this.project.data.layers, l => l.id === layer.id);
    }
}
exports.Scene = Scene;


/***/ }),

/***/ "./src/aegl-ui/aegl-encoding-config.ts":
/*!*********************************************!*\
  !*** ./src/aegl-ui/aegl-encoding-config.ts ***!
  \*********************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.AEGLEncodingConfig = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
const video_encoder_1 = __webpack_require__(/*! ../aegl/project/video-encoder */ "./src/aegl/project/video-encoder.ts");
const flit_ui_1 = __webpack_require__(/*! @pucelle/flit-ui */ "./node_modules/@pucelle/flit-ui/out/index.js");
const debug_1 = __webpack_require__(/*! ../libs/util/debug */ "./src/libs/util/debug.ts");
let AEGLEncodingConfig = class AEGLEncodingConfig extends flit_ui_1.Modal {
    title = 'Export Video';
    project;
    config;
    heightData;
    frameRateData;
    crfData;
    encoder = null;
    encodingAnalyser;
    progress = 0;
    canceled = false;
    onCreated() {
        this.initializeConfig();
        this.initializeFrameRates();
        this.initializeResolution();
        this.encodingAnalyser = new video_encoder_1.VideoEncodingAnalyser(this.project);
        this.crfData = [
            { value: 'very-low', text: 'Very Low' }, //1080P 下 12M
            { value: 'low', text: 'Low' }, //1080P 下 8M
            { value: 'medium', text: 'Medium' }, //1080P 下 crf 24 6M, 和 AE 默认输出一致.
            { value: 'high', text: 'High' },
            { value: 'very-high', text: 'Very High' },
        ];
    }
    /** 初始化配置信息. */
    initializeConfig() {
        this.config = ff_1.storage.get('aegl_encoding_config', {
            name: '',
            frameRate: 30,
            height: 720,
            quality: 'medium',
        });
        this.config.name = this.project.data.name;
    }
    /** 初始化帧率. */
    initializeFrameRates() {
        let frameRates = [25, 30, 60];
        let templateFrameRate = Math.round(this.project.footages.getTemplateVideoFrameRate());
        let userFrameRate = Math.round(this.project.footages.getUserVideoFrameRate());
        // 如果模板素材或者用户素材有其他帧率设置, 将他们推送入选项.
        if (templateFrameRate && !frameRates.includes(templateFrameRate)) {
            frameRates.push(templateFrameRate);
        }
        if (userFrameRate && !frameRates.includes(userFrameRate)) {
            frameRates.push(userFrameRate);
        }
        frameRates.sort();
        // 选择默认帧率.
        if (templateFrameRate && userFrameRate) {
            this.config.frameRate = Math.min(templateFrameRate, userFrameRate);
        }
        else if (templateFrameRate) {
            this.config.frameRate = templateFrameRate;
        }
        else if (userFrameRate) {
            this.config.frameRate = userFrameRate;
        }
        this.frameRateData = frameRates.map(frameRateOption => {
            let text = frameRateOption + ' fps';
            let tip = undefined;
            if (templateFrameRate === frameRateOption && templateFrameRate && userFrameRate && templateFrameRate === userFrameRate) {
                tip = `Framerate of template assets and your videos is all ${templateFrameRate} fps, suggest you to choose ${frameRateOption} fps`;
            }
            else if (frameRateOption === userFrameRate) {
                tip = `Framerate of your videos is  ${userFrameRate} fps, suggest you to choose ${frameRateOption} fps`;
            }
            else if (frameRateOption === templateFrameRate) {
                tip = `Framerate of template assets is ${templateFrameRate} fps, suggest you to choose ${frameRateOption} fps`;
            }
            else if (userFrameRate) {
                text = (0, flit_1.html) `<span class="secondary-choice">${text}<span>`;
                if (frameRateOption >= userFrameRate * 2) {
                    tip = `Framerate of your videos is  ${userFrameRate} fps, choose ${frameRateOption} fps would not provide the expected boost`;
                }
                else {
                    tip = `Framerate of your videos is  ${userFrameRate} fps, choose ${frameRateOption} fps may result in framerate mismatch artifacts.`;
                }
            }
            else if (templateFrameRate) {
                text = (0, flit_1.html) `<span class="secondary-choice">${text}<span>`;
                // 使用 60 帧渲染 25 或者 30 不会有啥明显质量损失, 但是 25 和 30 帧混合就会很糟糕.
                if (frameRateOption >= templateFrameRate * 2) {
                    tip = `Framerate of template assets is ${templateFrameRate} fps, choose ${frameRateOption} fps would not provide the expected boost`;
                }
                else {
                    tip = `Framerate of template assets is ${templateFrameRate} fps, choose ${frameRateOption} fps may result in framerate mismatch artifacts.`;
                }
            }
            return {
                value: frameRateOption,
                text,
                tip,
            };
        });
    }
    /** 初始化分辨率选择. */
    initializeResolution() {
        let heights = [
            360,
            480,
            720,
            1080,
            1440,
            2160,
        ];
        let aspectRatio = this.project.data.width / this.project.data.height;
        if (aspectRatio === 1) {
            heights.push(1000);
            heights.sort((a, b) => a - b);
        }
        if (aspectRatio < 1) {
            heights = heights.map(height => Math.round(height / aspectRatio / 2) * 2);
        }
        let heightData = heights.map(height => {
            let width = Math.round(aspectRatio * height / 2) * 2;
            return {
                value: height,
                text: `${height}P`,
                tip: `${width}x${height}`,
            };
        });
        // 例如推荐使用 1080P 渲染 940P 以及其以上的照片.
        const AllowedScalingDown = 1.15;
        let templateFootageHeight = Math.round(this.project.footages.getTemplateFootageHeight());
        let userFootageHeight = Math.round(this.project.footages.getUserFootageHeight());
        let matchItem = heightData.filter(v => v.value <= userFootageHeight * AllowedScalingDown).pop();
        this.config.height = matchItem ? matchItem.value : this.project.data.height;
        this.heightData = heightData.map(({ value, text, tip }) => {
            if (value >= userFootageHeight * AllowedScalingDown) {
                text = (0, flit_1.html) `<span class="secondary-choice">${text}<span>`;
                tip += `. Average resolution of your resources is ${userFootageHeight}P, choose ${value}P would not provide the expected boost`;
            }
            else if (templateFootageHeight && value > templateFootageHeight) {
                tip += `. Average resolution of template assets is ${templateFootageHeight}P, choose ${value}P would not provide the expected boost`;
            }
            return {
                value,
                text,
                tip,
            };
        });
    }
    render() {
        return (0, flit_1.html) `<template class="aegl-encoding-config">
		<f-row>
			<f-col .span="12">
				Video Name:
			</f-col>
			<f-col .span="12">
				<f-input :model="config.name" />
			</f-col>
		</f-row>

		<f-row>
			<f-col .span="12">
				Resolution:
			</f-col>
			<f-col .span="12">
				<f-select :model="config.height"
					.data=${this.heightData}
				/>
			</f-col>
		</f-row>

		<f-row>
			<f-col .span="12">
				Framerate:
			</f-col>
			<f-col .span="12">
				<f-select :model="config.frameRate"
					.data=${this.frameRateData}
				/>
			</f-col>
		</f-row>

		<f-row>
			<f-col .span="12">
				Video Quality:
			</f-col>
			<f-col .span="12">
				<f-select :model="config.quality"
					.data=${this.crfData}
				/>
			</f-col>
		</f-row>

		<div :show=${!this.encoder} class="encoding-tips">
			Video export will take about ${this.getExportTimeInMinutes()} mins, file size is about ${this.getExportFileSizeInM()} MB.
		</div>

		<button :show=${!this.encoder} primary @click=${this.export}>Export</button>

		<div :show=${this.encoder} class="encoding-progress">
			<f-progress .value=${this.progress} />
		</div>
		<button :show=${this.encoder} @click=${this.cancelExport}>Cancel</button>

		</template>`.extends(super.render());
    }
    /** 获得大致的导出时间. */
    getExportTimeInMinutes() {
        return this.encodingAnalyser.guessEncodingTimeInMinutes(this.config.height, this.config.frameRate, this.config.quality);
    }
    /** 获得视频的大致文件大小. */
    getExportFileSizeInM() {
        return this.encodingAnalyser.guessExportFileSizeInM(this.config.height, this.config.quality);
    }
    async export() {
        onbeforeunload = () => {
            return `Encoding video, current progress is ${this.progress * 100}%, are you sure you want to quit?`;
        };
        let options = {
            name: this.config.name,
            frameRate: this.config.frameRate,
            height: this.config.height,
            quality: this.config.quality,
        };
        let timeEnd = debug_1.debug.timeStart('Video Encoding');
        this.emit('beginexport');
        this.encoder = new video_encoder_1.FFVideoEncoder(this.project, options);
        this.progress = 0;
        this.encoder.on('progress', (loaded, total) => {
            this.progress = (0, ff_1.toDecimal)(loaded / total, 3);
        });
        try {
            if (window.VideoEncoder) {
                await this.encoder.encodeByWeb();
            }
            else {
                await this.encoder.encodeByFF();
                flit_ui_1.notification.warn('You are encoding videos by wasm version of ffmpeg, which is 10x slower. try switch to modern browsers supports WebCodecs like Chrome or Edge.', { hideDelay: 10000 });
            }
            timeEnd();
            this.saveEncodingResults();
        }
        catch (err) {
            if (!this.canceled) {
                console.warn(err);
                flit_ui_1.notification.error('Failed to export video!', { hideDelay: 10000 });
            }
        }
        this.encoder = null;
        onbeforeunload = null;
        this.emit('endexport');
    }
    /** 保存视频的大致编码时间比率. */
    saveEncodingResults() {
        ff_1.storage.set('aegl_encoding_config', this.config);
        this.encodingAnalyser.saveEncodingSpeed(this.encoder);
    }
    cancelExport() {
        this.encoder.terminate();
        this.canceled = true;
        this.encoder = null;
    }
};
exports.AEGLEncodingConfig = AEGLEncodingConfig;
exports.AEGLEncodingConfig = AEGLEncodingConfig = __decorate([
    (0, flit_1.define)('aegl-encoding-config')
], AEGLEncodingConfig);


/***/ }),

/***/ "./src/aegl-ui/aegl-preview.ts":
/*!*************************************!*\
  !*** ./src/aegl-ui/aegl-preview.ts ***!
  \*************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.AEGLPreview = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const project_1 = __webpack_require__(/*! ../aegl/project/project */ "./src/aegl/project/project.ts");
const json_manager_1 = __webpack_require__(/*! ../aegl/project/json-manager */ "./src/aegl/project/json-manager.ts");
__webpack_require__(/*! ./aegl-encoding-config */ "./src/aegl-ui/aegl-encoding-config.ts");
__webpack_require__(/*! ./aegl-scene-editor */ "./src/aegl-ui/aegl-scene-editor.ts");
const flit_ui_1 = __webpack_require__(/*! @pucelle/flit-ui */ "./node_modules/@pucelle/flit-ui/out/index.js");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
let AEGLPreview = class AEGLPreview extends flit_1.Component {
    id = 0;
    jsonManager;
    project;
    renderer;
    encoding = false;
    editorUI;
    prepared = false;
    currentAspectRatio = ff_1.storage.get('aegl_prefered_aspect_ratio', '16x9');
    render() {
        return (0, flit_1.html) `
		<template class="preview aegl-preview">
			${this.renderCanvas()}
			${this.renderToolbar()}
			${this.renderProgress()}
			${this.renderEditor()}
		</template>
		`;
    }
    renderCanvas() {
        return (0, flit_1.html) `
			<div class="preview-canvas" :ref="canvasContainer">
				<canvas :ref="canvas" />
			</div>
		`;
    }
    renderToolbar() {
        let ended = this.renderer ? this.renderer.ended : false;
        let paused = this.renderer ? this.renderer.paused : false;
        let musicDuration = this.project ? Math.round(this.project.footages.getReplaceableAudioLayerData().duration) : null;
        // let qrCode = popup(() => html`
        // 	<f-popup>
        // 		<div style="font-size: 14px; line-height: 22px; max-width: 240px; padding: 8px 16px;">
        // 			<div>这里会放置一个二维码, 手机扫描之后会打开一个网页, 在网页中可以上传照片, 上传完成后会添加到这里.</div>
        // 			<div style="margin-top: 8px;">由于我们有能力自己编译 ffmpeg 的 wasm 版本, 所以苹果设备上的 heif 图片和 hevc 视频都不再是问题.</div>
        // 		</div>
        // 	</f-popup>`,
        // 	{
        // 		alignPosition: 't',
        // 	}
        // )
        let popDuration = (0, flit_ui_1.popup)(() => {
            //let canNeverAdjust = this.editorUI && this.editorUI.editor.canNeverAdjustAllSceneDurations()
            return (0, flit_1.html) `<f-menu>
				<f-list .data=${[
                // {text: html`<div @click=${() => this.adjustTotalDuration()}>Adjust Total Duration</div>`},
                { text: (0, flit_1.html) `
						<div @click=${() => this.adjustToAudioDuration()}
							:tooltip="${musicDuration} Sec"
						>
							Stretch to Audio Duration
						</div>
					`
                },
                // {text: html`
                // 	<div @click=${() => this.alignToAudioRaisePoints()}
                // 		:style.opacity=${canNeverAdjust ? '0.4' : ''}
                // 		:tooltip=${canNeverAdjust ? '由于此模板包含了背景视频素材而无法调整场景长度, 你可以尝试更换其他模板.' : ''}
                // 	>
                // 		同步场景和音乐节奏
                // 	</div>`
                // },
                { text: (0, flit_1.html) `<div @click=${() => this.resetTotalDuration()}>Reset Duration of All Scenes</div>` },
            ]} />
			</f-menu>
			`;
        });
        let popResolution = (0, flit_ui_1.popup)(() => (0, flit_1.html) `<f-menu>
			<f-list
				.selectable
				.selected=${[this.currentAspectRatio]}
				@select=${(value) => this.adjustAspectRatio(value[0])}
				.data=${Object.keys(this.jsonManager.currentAspectRatios).map(value => ({
            value,
            text: value,
        }))}
			/>
		</f-menu>
		`);
        return (0, flit_1.html) `
		<div class="preview-additional-toolbar" :enable=${this.prepared}>
			<f-buttongroup>
				<button @click=${this.togglePaused}>${ended ? 'Play' : paused ? 'Play' : 'Pause'}</button>

				<button @click=${this.toFullscreen}>
					Fullscreen
				</button>
			</f-buttongroup>

			<f-buttongroup>
				<button @click=${this.useMyPhotos}>
					Replace Photos
				</button>

				<!-- <button>
					扫描二维码传照片
				</button> -->

				<button @click=${this.changeMusic}>
					Replace Audio
				</button>

				<button @click=${this.reset}>
					Reset
				</button>
			</f-buttongroup>

			<button ${popDuration} :enable=${this.editorUI && this.editorUI.editor.canAdjustSomeSceneDurations()}>
				Adjust Duration
				<f-icon .type="down" />
			</button>

			<button ${popResolution}>
				Adjust Resolution
				<f-icon .type="down" />
			</button>

			<button @click=${this.encodeVideo} style="margin-left: auto">
				Export
			</button>
		</div>
		`;
    }
    renderProgress() {
        let time = this.renderer ? this.renderer.time : 0;
        return (0, flit_1.html) `
		<f-slider class="preview-progress" :ref="slider"
			.min="0"
			.max=${this.project ? this.project.data.duration : 0}
			.step="0.02"
			.value=${time}
			.decimalCount="2"
			@dragstart=${this.startChangingTime}
			@dragend=${this.endChangingTime}
			@change=${this.changeTime}
		/>
		`;
    }
    renderEditor() {
        if (!this.project) {
            return null;
        }
        return (0, flit_1.html) `
			<aegl-scene-editor :ref=${this.refEditor} .project=${this.project} />
		`;
    }
    /** 开始拖动时间轴时触发. */
    startChangingTime() {
        this.renderer.pause();
    }
    /** 结束拖动时间轴时触发. */
    endChangingTime() {
        if (!this.renderer.paused) {
            this.renderer.play();
        }
    }
    /** 更新渲染器的时间. */
    changeTime(value) {
        this.renderer.setTime(value);
    }
    async refEditor(el) {
        this.editorUI = await (0, flit_1.getComponentAsync)(el);
    }
    async onReady() {
        // 初始化 webgl 环境, 加载项目.
        await this.loadProject();
        // 更新尺寸信息, 但不实际绘制.
        await this.adjustCanvasSize();
        // 等待渲染完成并且生成 this.editorUI.
        await (0, flit_1.renderComplete)();
        // 加载资源然后开始播放.
        let noti = flit_ui_1.notification.unique();
        noti.info(`Loading assets of template ${this.id} ...`);
        await this.editorUI.ready;
        await this.renderer.play();
        this.prepared = true;
        noti.success(`Loaded assets of template ${this.id}.`, { hideDelay: 3000 });
        this.on('disconnected', () => {
            noti.hide();
        });
    }
    onConnected() {
        (0, flit_1.on)(window, 'resize', this.onResize, this);
        (0, flit_1.on)(document, 'keydown.space.prevent', this.togglePaused, this);
    }
    onDisconnected() {
        this.project.delete();
        (0, flit_1.off)(window, 'resize', this.onResize, this);
        (0, flit_1.off)(document, 'keydown', this.togglePaused, this);
    }
    /** 加载项目. */
    async loadProject() {
        let canvas = this.refs.canvas;
        this.jsonManager = new json_manager_1.JSONManager(this.id);
        await this.jsonManager.ready;
        if (!this.jsonManager.currentAspectRatios[this.currentAspectRatio]) {
            this.currentAspectRatio = Object.keys(this.jsonManager.currentAspectRatios)[0];
        }
        this.project = new project_1.Project(canvas, this.jsonManager.rootDirectory, this.jsonManager.requestProjectData(this.currentAspectRatio));
        // 初始化渲染器.
        // renderer 不是一个被 observed 的对象, 所以内部状态的切换需要通过事件 end 来通知.
        this.renderer = this.project.renderer;
        this.renderer.on('updatetime', () => this.update());
        this.renderer.on('end', () => this.update());
        // 根据参数降低预览分辨率.
        let pixelRatio = devicePixelRatio;
        let downSampling = (0, ff_1.firstMatch)(location.href, /downsampling=([\d\.]+)/);
        if (downSampling) {
            pixelRatio /= Number(downSampling);
            this.renderer.setPixelRatio(pixelRatio);
        }
    }
    /** 当页面缩放后触发. */
    async onResize() {
        if (this.project && !this.encoding) {
            await this.adjustCanvasSize();
        }
    }
    /** 调整 Canvas 元素的尺寸. */
    async adjustCanvasSize() {
        let maxWidth = this.refs.canvasContainer.offsetWidth;
        let maxHeight = Infinity;
        if (document.fullscreen) {
            maxHeight = this.refs.canvasContainer.offsetHeight;
        }
        else {
            maxHeight = 640;
        }
        let [w, h] = this.getCanvasSizeInContainMode(maxWidth, maxHeight);
        await this.renderer.setCanvasSize(w, h);
    }
    /** 获得最合适的 canvas 尺寸. */
    getCanvasSizeInContainMode(maxWidth, maxHeight) {
        let vw = this.project.data.width;
        let vh = this.project.data.height;
        let w = maxWidth;
        let h = vh / vw * w;
        if (h > maxHeight) {
            w *= maxHeight / h;
            h = maxHeight;
        }
        w = Math.round(w / 2) * 2;
        h = Math.round(h / 2) * 2;
        return [w, h];
    }
    /** 切换暂停状态. */
    togglePaused() {
        if (!this.prepared) {
            return;
        }
        else if (this.renderer.ended) {
            this.renderer.playFrom(0);
        }
        else if (this.renderer.paused) {
            this.renderer.play();
        }
        else {
            this.renderer.pause();
        }
    }
    /** 进入全屏. */
    async toFullscreen() {
        this.refs.canvasContainer.requestFullscreen();
        await this.adjustCanvasSize();
    }
    /** 上传用户照片. */
    async useMyPhotos() {
        await this.editorUI.useMyPhotos();
    }
    /** 更换音乐. */
    async changeMusic() {
        // 音乐也被归类为场景数据.
        await this.editorUI.changeMusic();
    }
    /** 调整总时长. */
    // private async adjustTotalDuration() {
    // 	await this.editorUI.adjustTotalDuration()
    // }
    /** 调整为音乐时长. */
    async adjustToAudioDuration() {
        await this.editorUI.adjustToAudioDuration();
    }
    /** 让场景和音乐的升高点进行卡点. */
    // private async alignToAudioRaisePoints() {
    // 	await this.editorUI.alignToAudioRaisePoints()
    // }
    /** 重设总时长. */
    resetTotalDuration() {
        this.editorUI.resetTotalDuration();
    }
    /** 调整分辨率. */
    async adjustAspectRatio(aspectRatio) {
        if (aspectRatio === this.currentAspectRatio) {
            return;
        }
        // 更新当前宽高比.
        this.currentAspectRatio = aspectRatio;
        // 更新当前数据.
        let newData = this.jsonManager.requestProjectData(aspectRatio);
        this.project.data.setData(newData);
        // 重置场景数据.
        await this.editorUI.reloadSceneData();
        // 调整和重绘.
        await this.adjustCanvasSize();
        ff_1.storage.set('aegl_prefered_aspect_ratio', aspectRatio);
    }
    /** 重置所有数据. */
    async reset() {
        let newData = this.jsonManager.requestProjectData(this.currentAspectRatio);
        this.project.data.setData(newData);
        await this.editorUI.reset();
    }
    /** 编码视频. */
    async encodeVideo() {
        (0, flit_1.off)(document, 'keydown.space.prevent', this.togglePaused, this);
        this.renderer.pause();
        let encodingConfig = (0, flit_1.renderComponent)((0, flit_1.html) `<aegl-encoding-config .project=${this.project}/>`).component;
        encodingConfig.show();
        encodingConfig.on('beginexport', () => {
            this.project.clearResoures();
            this.encoding = true;
        });
        encodingConfig.on('disconnected', () => {
            (0, flit_1.on)(document, 'keydown.space.prevent', this.togglePaused, this);
            this.encoding = false;
            this.onResize();
        });
    }
};
exports.AEGLPreview = AEGLPreview;
exports.AEGLPreview = AEGLPreview = __decorate([
    (0, flit_1.define)('aegl-preview')
], AEGLPreview);


/***/ }),

/***/ "./src/aegl-ui/aegl-scene-editor.ts":
/*!******************************************!*\
  !*** ./src/aegl-ui/aegl-scene-editor.ts ***!
  \******************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.AEGLFontWeightSelect = exports.AEGLFontFamilySelect = exports.AEGLSceneEditor = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const flit_ui_1 = __webpack_require__(/*! @pucelle/flit-ui */ "./node_modules/@pucelle/flit-ui/out/index.js");
const scene_editor_1 = __webpack_require__(/*! ../aegl-scene/scene-editor */ "./src/aegl-scene/scene-editor.ts");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
const color_1 = __webpack_require__(/*! ../aegl/helpers/color */ "./src/aegl/helpers/color.ts");
const fonts_list_1 = __webpack_require__(/*! ../aegl/helpers/fonts-list */ "./src/aegl/helpers/fonts-list.ts");
let globalUserSceneData = null;
/** 负责进行场景数据编辑. */
let AEGLSceneEditor = class AEGLSceneEditor extends flit_1.Component {
    project;
    editor;
    ready;
    currentScene = null;
    includedFontNames = [];
    adjustingDuration = false;
    render() {
        let showSceneEditor = this.currentScene && this.project.renderer.paused;
        let editorResult = showSceneEditor ? this.renderCurrentSceneEditor() : null;
        return (0, flit_1.html) `
		<div class="aegl-editor">
			${this.renderScenes()}
			${(0, flit_1.cache)(editorResult, { transition: 'fade' })}
		</div>
		`;
    }
    renderScenes() {
        let drop = (0, flit_ui_1.droppable)((scene, index) => this.onDropScene(scene, index));
        return (0, flit_1.html) `
			<div class="editor-scenes" ${drop}>
				<div class="editor-scenes-slider">
					${
        // 这里使用 info 作为数据进行枚举是因为场景总是位置不变, 只是交换数据,
        // 我们想让数据交换的顺序和元素交换顺序保持一致, 因此对 info 进行枚举.
        (0, flit_1.repeat)(this.editor.scenes.map(scene => scene.info), (_info, index) => this.renderScene(this.editor.scenes[index], index))}
				</div>
			</div>
		`;
    }
    renderScene(scene, index) {
        let path = scene.info.thumbnailPath;
        let left = scene.main.root.inPoint / this.project.data.duration;
        let width = (scene.main.root.outPoint - scene.main.root.inPoint) / this.project.data.duration;
        let mediaPosition = scene.info.mediaPosition;
        // 只要有多媒体资源就可以拖动.
        let drag = scene.canBeMoved ? (0, flit_ui_1.draggable)(scene, index) : null;
        let menu = scene.canBeRemoved && this.editor.scenes.length >= 2 ? (0, flit_ui_1.contextmenu)(this.renderSceneContextMenu(scene)) : null;
        return (0, flit_1.html) `
			<div class="editor-scene"
				:style.left=${`calc(${left * 100}% - 2px)`}
				:style.width=${`calc(${width * 100}% + 4px)`}
				:class.active=${this.currentScene === scene}
				:class.covered=${!scene.media}
				@click=${() => this.viewScene(scene)}
				${drag}
				${menu}
			>
				<img :src=${path} :style.object-position="${mediaPosition[0] * 100}% ${mediaPosition[1] * 100}%" />
			</div>
		`;
    }
    renderSceneContextMenu(scene) {
        return () => (0, flit_1.html) `
		<f-contextmenu>
			<f-list .data=${[
            { text: (0, flit_1.html) `<div @click=${() => this.removeScene(scene)}>Remove Scene</div>` },
        ]}/>
		</f-contextmenu>
		`;
    }
    renderCurrentSceneEditor() {
        return (0, flit_1.html) `
		<div class="current-scene">
			<header class="scene-title">
				Edit Scene
			</header>

			<div class="scene-content">
				${this.renderPhotoAdjustment()}
				${this.renderRightEditing()}
			</div>
		</div>`;
    }
    renderPhotoAdjustment() {
        let currentScene = this.currentScene;
        let src = currentScene.info.thumbnailPath;
        let { imageRect, containerSize } = this.generatePhotoStyle();
        return (0, flit_1.html) `
		<div class="scene-photo" :style.width.px=${containerSize.width + 8}>
			<div class="photo-area">
				<div class="photo-clip" :style.width.px=${containerSize.width}>
					<img :src=${src} :style=${imageRect}/>
				</div>
				<div class="photo-full">
					<img :src=${src} :style=${imageRect} @mousedown=${this.startDraggingPhoto} />
				</div>
			</div>

			<button :show=${src} flat @click=${() => this.changeSceneMedia(currentScene)}>Replace Photo</button>
		</div>
		`;
    }
    renderRightEditing() {
        let scene = this.currentScene;
        return (0, flit_1.html) `
		<div class="scene-text">
			<f-row :show=${scene.canSetDuration}>
				<f-col .span="2" class="text-label" style="min-width: 100px;">
					Duration:
				</f-col>
				<f-col .span="10" style="display: flex;">
					<f-slider .value=${scene.getDuration()} .min="1" .max="20" .step="0.1" .decimalCount="1"
						@change=${(duration) => this.changeDuration(scene, duration)}
						@dragstart=${() => this.adjustingDuration = true}
						@dragend=${() => { this.adjustingDuration = false; this.checkCurrentScene(); }}
					/>
				</f-col>
				<f-col .span="4">
					<button style="margin-left: 8px; font-size: 12px;" @click=${() => this.resetDuration(scene)}>Reset</button>
				</f-col>
			</f-row>

			${(0, flit_1.cache)(scene.text ? this.renderTextEdit() : '', { transition: 'fade' })}
		</div>`;
    }
    renderTextEdit() {
        let scene = this.currentScene;
        let textLayer = scene.text.layers[0];
        return (0, flit_1.html) `
		<div>
			<f-row>
				<f-col .span="2" class="text-label" style="padding-top: 3px; min-width: 100px;">
					Text:
				</f-col>

				<f-col .span="22" style="max-width: calc(100% - 100px);">
					<f-textarea type="text"
						.value=${textLayer.text}
						.placeholder="Add Text Here"
						:style='font-family: "${textLayer.fontFamily}"'
						:ref="textarea"
						@@keydown.stop=${() => { }}
						@input=${(value) => this.changeText(scene, value)}
					/>
				</f-col>
			</f-row>

			<f-row>
				<f-col .span="2" class="text-label" style="min-width: 100px;">
					Font Family:
				</f-col>
				<f-col .span="10">
					<aegl-font-family-select
						.additionalFontNames=${this.includedFontNames}
						.value=${textLayer.fontFamily}
						@change=${(value) => this.changeFontFamily(scene, value)}
					/>
				</f-col>
				<f-col .span="4">
					<button style="margin-left: 8px; font-size: 12px;" @click=${() => this.resetFontFamily(scene)}>Reset</button>
				</f-col>
			</f-row>
			
			<f-row>
				<f-col .span="2" class="text-label" style="min-width: 100px;">
					Font Weight:
				</f-col>
				<f-col .span="10">
					<aegl-font-weight-select
						.family=${textLayer.fontFamily}
						.value=${textLayer.fauxBold ? 'Bold' : fonts_list_1.FontList.getFontWeight(textLayer.fontStyle || '')}
						@change=${(fontWeight) => this.changeFontStyle(scene, fontWeight)}
					/>
				</f-col>
				<f-col .span="4">
					<button style="margin-left: 8px; font-size: 12px;" @click=${() => this.resetFontStyle(scene)}>Reset</button>
				</f-col>
			</f-row>

			<f-row>
				<f-col .span="2" class="text-label" style="min-width: 100px;">
					Font Size:
				</f-col>
				<f-col .span="10">
					<f-slider .value=${textLayer.fontSize} .min="1" .max="400" .step="1" .decimalCount="0"
						@change=${(fontSize) => this.changeFontSize(scene, fontSize)}
					/>
				</f-col>
				<f-col .span="4">
					<button style="margin-left: 8px; font-size: 12px;" @click=${() => this.resetFontSize(scene)}>Reset</button>
				</f-col>
			</f-row>

			<f-row>
				<f-col .span="2" class="text-label" style="min-width: 100px;">
					Text Color:
				</f-col>
				<f-col .span="10">
					<input type="color" .value=${(0, color_1.colorArrayToString)(textLayer.fillColor || [0, 0, 0])}
						@input=${(e) => this.changeTextColor(scene, e.target.value)}
					/>
				</f-col>
				<f-col .span="4">
					<button style="margin-left: 8px; font-size: 12px;" @click=${() => this.resetTextColor(scene)}>Reset</button>
				</f-col>
			</f-row>
		</div>
		`;
    }
    onCreated() {
        // 初始化编辑器.
        this.editor = new scene_editor_1.SceneEditor(this.project, globalUserSceneData);
        // 渲染树更新后更新 UI.
        this.project.renderer.on('updatetree', this.onUpdateTree, this);
        this.ready = this.editor.ready.then();
    }
    async onReady() {
        await fonts_list_1.FontList.ensure();
        // 查找包含的字体.
        this.includedFontNames = this.project.footages.getIncludedFontFamilies().sort();
    }
    onDisconnected() {
        globalUserSceneData = this.editor.extractLocalSceneData();
    }
    /** 当渲染树更新时触发. */
    onUpdateTree(time) {
        if (!this.adjustingDuration) {
            this.checkSceneAtTime(time);
        }
    }
    /** 查找当前激活的场景. */
    checkCurrentScene() {
        this.checkSceneAtTime(this.project.renderer.time);
    }
    /** 查找当前激活的场景. */
    checkSceneAtTime(time) {
        this.currentScene = this.editor.getActiveSceneAtTime(time);
    }
    /** 上传用户照片. 返回一个建议的宽高比. */
    async useMyPhotos() {
        let noti = flit_ui_1.notification.unique();
        let count = await this.editor.uploadMedias((loaded, total) => {
            noti.info(`Appending scenes (${loaded} / ${total})...`);
        });
        if (count > 0) {
            noti.success(`Appended ${count} scenes.`);
        }
        this.project.notifyProjectUpdated();
    }
    /** 更换音乐. */
    async changeMusic() {
        await this.editor.changeMusic();
        let audioLayer = this.project.footages.getReplaceableAudioLayerData();
        this.project.notifyLayerUpdated(audioLayer);
        flit_ui_1.notification.success(`Replaces audio.`);
    }
    /** 将时间轴拉倒场景的中央. */
    viewScene(scene) {
        this.project.renderer.pause();
        let time = (scene.main.root.inPoint + scene.main.root.outPoint) / 2;
        this.project.renderer.setTime(time);
    }
    /** 拖动以交换场景. */
    onDropScene(scene, index) {
        let changedScenes = this.editor.moveSceneTo(scene, index);
        for (let scene of changedScenes) {
            scene.notifyMediaChanged();
        }
    }
    /** 移除场景. */
    removeScene(scene) {
        this.editor.removeScene(scene);
        this.project.notifyProjectUpdated();
    }
    /** 生成图片的位置信息. */
    generatePhotoStyle() {
        let aspectRatio = this.project.data.width / this.project.data.height;
        let h = 180;
        let w = h * aspectRatio;
        let currentScene = this.currentScene;
        if (!currentScene.media) {
            return {
                imageRect: {
                    left: 0,
                    top: 0,
                    width: w,
                    height: h,
                },
                containerSize: {
                    width: w,
                    height: h,
                }
            };
        }
        let { mediaWidth, mediaHeight, mediaPosition } = currentScene.info;
        let scaling = w / mediaWidth;
        if (mediaHeight * scaling < h) {
            scaling = h / mediaHeight;
        }
        let width = mediaWidth * scaling;
        let height = mediaHeight * scaling;
        let left = (w - width) * mediaPosition[0];
        let top = (h - height) * mediaPosition[1];
        return {
            imageRect: {
                left,
                top,
                width,
                height,
            },
            containerSize: {
                width: w,
                height: h,
            }
        };
    }
    /** 拖动图片并且动态更改其位置. */
    startDraggingPhoto(e) {
        let currentScene = this.currentScene;
        if (!currentScene.media || !currentScene.willCropMedia()) {
            return;
        }
        let { mediaWidth, mediaHeight, mediaPosition } = currentScene.info;
        let aspectRatio = this.project.data.width / this.project.data.height;
        let h = 180;
        let w = h * aspectRatio;
        let startPositionX = mediaPosition[0];
        let startPositionY = mediaPosition[1];
        let startX = e.clientX;
        let startY = e.clientY;
        let scaling = w / mediaWidth;
        if (mediaHeight * scaling < h) {
            scaling = h / mediaHeight;
        }
        let width = mediaWidth * scaling;
        let height = mediaHeight * scaling;
        let moved = false;
        let onMouseMove = (e) => {
            e.preventDefault();
            let moveX = e.clientX - startX;
            let moveY = e.clientY - startY;
            let newPositionX = moveX / (w - width) + startPositionX;
            let newPositionY = moveY / (h - height) + startPositionY;
            moved = moveX !== 0 || moveY !== 0;
            newPositionX = (0, ff_1.constrain)(newPositionX || 0, 0, 1);
            newPositionY = (0, ff_1.constrain)(newPositionY || 0, 0, 1);
            currentScene.setMediaPosition([newPositionX, newPositionY]);
        };
        let onMouseUp = async () => {
            (0, flit_1.off)(document, 'mousemove', onMouseMove);
            if (moved) {
                await currentScene.updateCroppedMedia();
                currentScene.notifyMediaChanged();
                //this.saveMediaPositionToJSON(currentScene)
            }
        };
        e.preventDefault();
        (0, flit_1.on)(document, 'mousemove', onMouseMove);
        (0, flit_1.once)(document, 'mouseup', onMouseUp);
    }
    /** 保存原始模板图片的位置. */
    // private async saveMediaPositionToJSON(scene: Scene) {
    // 	if (!scene.info.replaced && scene.media && location.hostname === 'localhost') {
    // 		let params = {
    // 			template_id: this.project.data.id,
    // 			file_name: getPathName(scene.media.layers[0].path as string),
    // 			aspect_ratio: this.project.data.width / this.project.data.height,
    // 		} as any
    // 		let query = new URLSearchParams(params).toString()
    // 		try {
    // 			await fetch('http://localhost:8081/media-position/update?' + query, {
    // 				method: 'PATCH',
    // 				headers: {
    // 					"Content-Type": "application/json",
    // 				},
    // 				body: JSON.stringify(scene.info.mediaPosition),
    // 			})
    // 		}
    // 		catch (err) {
    // 			notification.warn(`请运行 "npm run start-dev" 来开启 Web 服务以保存模板默认图片的位置调整!`)
    // 		}
    // 	}
    // }
    /** 修改图片. */
    async changeSceneMedia(scene) {
        await this.editor.changeSceneMedia(scene);
        scene.notifyMediaChanged();
    }
    /** 修改文本. */
    changeText(scene, text) {
        scene.setText(text);
        this.project.notifyUpdated();
        this.refs.textarea.style.height = this.refs.textarea.querySelector('textarea').scrollHeight + 'px';
    }
    /** 修改字体. */
    changeFontFamily(scene, fontFamily) {
        this.editor.setBunchFontFamily(scene, fontFamily);
        let fontWeights = fonts_list_1.FontList.getFontWeightList(fontFamily) || ['Regular', 'Bold'];
        let keepOldFontStyle = scene.info.fontStyle && fontWeights.includes(scene.info.fontStyle);
        if (!keepOldFontStyle) {
            this.editor.setBunchFontStyle(scene, fontWeights.includes('Regular') ? 'Regular' : fontWeights[0]);
        }
        this.project.notifyUpdated();
    }
    /** 修改字号. */
    changeFontSize(scene, fontSize) {
        this.editor.setBunchFontSize(scene, fontSize);
        this.project.notifyUpdated();
    }
    /** 修改颜色. */
    changeTextColor(scene, color) {
        this.editor.setBunchFillColor(scene, new flit_ui_1.Color(color).getRGB());
        this.project.notifyUpdated();
    }
    /** 修改是否为粗体 */
    changeFontStyle(scene, fontStyle) {
        this.editor.setBunchFontStyle(scene, fontStyle);
        this.project.notifyUpdated();
    }
    /** 重置字体. */
    resetFontFamily(scene) {
        this.changeFontFamily(scene, scene.startFontFamily);
    }
    /** 重置字号. */
    resetFontSize(scene) {
        this.changeFontSize(scene, scene.startFontSize);
    }
    /** 重置字粗. */
    resetFontStyle(scene) {
        this.changeFontStyle(scene, scene.startFontStyle);
    }
    /** 重置文字颜色. */
    resetTextColor(scene) {
        this.changeTextColor(scene, scene.startFillColor);
    }
    /** 修改场景长度. */
    changeDuration(scene, duration) {
        this.editor.setSceneDuration(scene, duration);
        this.project.notifyTimelineUpdated();
    }
    /** 重置场景长度. */
    resetDuration(scene) {
        this.editor.resetSceneDuration(scene);
        this.project.notifyTimelineUpdated();
    }
    /** 调整总时长. */
    // async adjustTotalDuration() {
    // 	let newDurationText = await dialog.prompt(`请输入你所期望的总时长, 单位为秒, 当前时长为 ${toDecimal(this.project.data.duration, 1)} 秒:`)
    // 	if (!newDurationText && !Number(newDurationText)) {
    // 		return
    // 	}
    // 	let newDuration = Number(newDurationText)
    // 	await this.adjustWithTotalDuration(newDuration)
    // }
    /** 调整总时长. */
    async adjustWithTotalDuration(newDuration) {
        newDuration = (0, ff_1.toDecimal)(newDuration, 1);
        let oldDuration = this.project.data.duration;
        let adjustable = this.editor.getAdjustableDuration();
        let freezeDuration = oldDuration - adjustable.duration;
        //let averageLoopSceneDuration = this.editor.getAverageLoopSceneStartDuration()
        // 全部为视频素材或者都不可以调整.
        if (adjustable.duration === 0) {
            flit_ui_1.notification.error(`Can't adjust duration since scenes contain video assets.`);
            return;
        }
        else {
            let scaling = (0, ff_1.toDecimal)((newDuration - freezeDuration) / adjustable.duration, 2);
            if (scaling === 1) {
                flit_ui_1.notification.success(`Adjusted total duration to ${newDuration} seconds.`);
                return;
            }
            // let sceneIncreaseCountToBalance = Math.round((newDuration - oldDuration) / averageLoopSceneDuration)
            // let sceneIncreaseText = sceneIncreaseCountToBalance !== 0
            // 	? `此外你还可以通过 ${sceneIncreaseCountToBalance > 0 ? '增加' : '减少'} <b>${Math.abs(sceneIncreaseCountToBalance)}</b> 个场景来保持当前几乎的场景几乎不缩放.`
            // 	: ''
            // let adjustText = adjustable.unAdjustableCount > 0
            // 	? adjustable.count + ' / ' + (adjustable.unAdjustableCount + adjustable.count)
            // 	: adjustable.count
            // let btn = await dialog.confirm(
            // 	html`
            // 		<div><b>${adjustText}</b> 个场景的时长将会${scaling > 1 ? '拉长' : '缩放'}为原先的 <b>${scaling}</b> 倍,
            // 		这可能会导致场景中的动画偏${scaling > 1 ? '慢' : '快'}. ${sceneIncreaseText}</div>
            // 		<div style="margin-top: 12px;">你确定要应用此调整吗?</div>
            // 		<div style="margin-top: 12px;">你可以稍后通过 "重置所有场景时长" 来恢复此调整.<div>`,
            // 	{
            // 		actions: [
            // 			{value: 'cancel', text: '取消'},
            // 			{value: 'ok', text: '应用', primary: true},
            // 		]
            // 	}
            // )
            // if (btn !== 'ok') {
            // 	return
            // }
            this.editor.adjustScenesDuration(newDuration);
        }
        this.project.notifyTimelineUpdated();
        flit_ui_1.notification.success(`Adjusted total duration to ${(0, ff_1.toDecimal)(this.project.data.duration, 1)} seconds.`);
    }
    /** 调整为音乐时长. */
    async adjustToAudioDuration() {
        let audioLauer = this.project.footages.getReplaceableAudioLayerData();
        let audioDuration = audioLauer.duration;
        await this.adjustWithTotalDuration(audioDuration);
    }
    /** 让场景和音乐的升高点进行卡点. */
    // async alignToAudioRaisePoints() {
    // 	// 只要有一个场景不能调节时长, 卡点失败.
    // 	if (!this.editor.canAdjustAllSceneDurations()) {
    // 		notification.error(`此模板的部分场景因为包含视频素材而无法调节时长.`)
    // 		return
    // 	}
    // 	let audioLayer = this.project.footages.getReplaceableAudioLayerData()
    // 	let audioPath = this.project.resourceLoader.getLayerPath(audioLayer)
    // 	let analyser = new AudioPointsAnalyser(audioPath)
    // 	await analyser.ready
    // 	let minLoopDuration = this.editor.getMinimumLoopSceneStartDuration()
    // 	let raisePoints = analyser.analysisAmplitudeRaisePoints(minLoopDuration)
    // 	let durations: number[] = []
    // 	for (let i = 1; i < raisePoints.length; i++) {
    // 		durations.push(raisePoints[i] - raisePoints[i - 1])
    // 	}
    // 	if (durations.length < this.editor.scenes.length) {
    // 		while (durations.length < this.editor.scenes.length) {
    // 			durations = [...durations, ...durations]
    // 		}
    // 	}
    // 	durations = durations.slice(0, this.editor.scenes.length)
    // 	this.editor.setDurations(durations)
    // 	this.project.notifyTimelineUpdated()
    // 	let sceneCountDiff = raisePoints.length - this.editor.scenes.length
    // 	let sceneCountText = sceneCountDiff !== 0
    // 		? html`此外你还可以通过 ${sceneCountDiff > 0 ? '增加' : '减少'} <b>${Math.abs(sceneCountDiff)}</b> 个场景来刚好和音乐时长保持一致.`
    // 		: ''
    // 	if (raisePoints.length > this.editor.scenes.length) {
    // 		notification.success(html`已将场景和音乐同步. ${sceneCountText}`)
    // 	}
    // }
    /** 重设总时长. */
    resetTotalDuration() {
        this.editor.resetTotalDuration();
        this.project.notifyTimelineUpdated();
        flit_ui_1.notification.success(`Reset total duration back to ${(0, ff_1.toDecimal)(this.project.data.duration, 1)} seconds.`);
    }
    /** 在重设项目数据之后重设所有场景. */
    async reset() {
        let noti = flit_ui_1.notification.unique();
        await this.editor.reset((loaded, total) => {
            noti.info(`Resetting scenes (${loaded} / ${total})...`);
        });
        noti.success(`All scenes reset.`, { hideDelay: 3000 });
        this.project.notifyProjectUpdated();
        this.checkCurrentScene();
    }
    /** 在重设项目数据之后重新加载场景数据. */
    async reloadSceneData() {
        let noti = flit_ui_1.notification.unique();
        await this.editor.reloadSceneData((loaded, total) => {
            noti.info(`Reloading scenes (${loaded} / ${total})...`);
        });
        noti.success(`All scenes reloaded.`, { hideDelay: 3000 });
        this.project.notifyProjectUpdated();
    }
};
exports.AEGLSceneEditor = AEGLSceneEditor;
exports.AEGLSceneEditor = AEGLSceneEditor = __decorate([
    (0, flit_1.define)('aegl-scene-editor')
], AEGLSceneEditor);
let AEGLFontFamilySelect = class AEGLFontFamilySelect extends flit_ui_1.Select {
    additionalFontNames = [];
    async onCreated() {
        let enFonts = [
            ...fonts_list_1.FontList.getWebSafeFonts('en-US').map(v => [v, v]),
            ...(await fonts_list_1.FontList.getFamilyListByLanguage('en-US')).map(v => [v.fontFamily, v.localizedName])
        ]
            .sort((a, b) => a[0].localeCompare(b[0], undefined, { numeric: true }));
        let zhFonts = [
            ...fonts_list_1.FontList.getWebSafeFonts('zh-CN').map(v => [v, v]),
            ...(await fonts_list_1.FontList.getFamilyListByLanguage('zh-CN')).map(v => [v.fontFamily, v.localizedName])
        ]
            .sort((a, b) => a[0].localeCompare(b[0], undefined, { numeric: true }));
        // 获得支持的字体以及系统安全字体.
        this.data = [
            ...enFonts,
            ...zhFonts,
        ]
            .map(([fontFamily, localizedName]) => {
            return { value: fontFamily, text: (0, flit_1.html) `<div style='font-family: "${fontFamily}"'>${localizedName}</div>` };
        });
    }
};
exports.AEGLFontFamilySelect = AEGLFontFamilySelect;
exports.AEGLFontFamilySelect = AEGLFontFamilySelect = __decorate([
    (0, flit_1.define)('aegl-font-family-select')
], AEGLFontFamilySelect);
let AEGLFontWeightSelect = class AEGLFontWeightSelect extends flit_ui_1.Select {
    family = '';
    onCreated() {
        this.watchImmediately(() => this.family, () => {
            let weights = fonts_list_1.FontList.getFontWeightList(this.family) || ['Regular', 'Bold'];
            if (!weights.includes('Bold')) {
                weights.push('Bold');
            }
            this.data = weights.map(weight => {
                return {
                    value: weight,
                    text: weight
                };
            });
        });
    }
};
exports.AEGLFontWeightSelect = AEGLFontWeightSelect;
exports.AEGLFontWeightSelect = AEGLFontWeightSelect = __decorate([
    (0, flit_1.define)('aegl-font-weight-select')
], AEGLFontWeightSelect);


/***/ }),

/***/ "./src/aegl/aegl-default-values.ts":
/*!*****************************************!*\
  !*** ./src/aegl/aegl-default-values.ts ***!
  \*****************************************/
/***/ ((__unused_webpack_module, exports) => {


/* 警告: 此文件拷贝自 adobe-scripts, 请勿在此修改.*/
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.MaskDefaultValues = exports.LayerStyleDropShadowDefaultValues = exports.LayerStyleBlendingOptionDefaultValues = exports.ShapeDefaultValues = exports.ShapePathVertexDefaultValues = exports.ShapeGroupDefaultValues = exports.ShapeEllipseDefaultValues = exports.ShapeRectDefaultValues = exports.ShapeStrokeDefaultValues = exports.ShapeFillDefaultValues = exports.ShapeTrimDefaultValues = exports.TextAnimatorPropertiesDefaultValues = exports.TextAnimaterSelecterDefaultValues = exports.TextLayerDefaultValues = exports.AllEffectsDefaultValues = exports.EffectRampDefaultValues = exports.EffectEasyLevelsDefaultValues = exports.EffectColorGradient4DefaultValues = exports.EffectFractalNoiseDefaultValues = exports.EffectRoughenEdgesDefaultValues = exports.EffectDisplacementMapDefaultValues = exports.EffectTintDefaultValues = exports.EffectGammaDefaultValues = exports.EffectMaskDefaultValues = exports.EffectFillDefaultValues = exports.EffectAnimateCharacterDefaultValues = exports.EffectTileDefaultValues = exports.EffectTransformDefaultValues = exports.EffectBulgeDefaultValues = exports.EffectBoxBlurDefaultValues = exports.EffectFastBlurDefaultValues = exports.EffectGaussianBlurDefaultValues = exports.EffectDropShadowDefaultValues = exports.EffectDefaultValues = exports.CameraTransformDefaultValues = exports.CameraDefaultValues = exports.TransformDefaultValues = void 0;
exports.TransformDefaultValues = {
    anchorPoint: [0, 0, 0],
    skew: 0,
    skewAxis: 0,
    orientation: [0, 0, 0],
    opacity: 100,
};
exports.CameraDefaultValues = {
    zoom: 0,
    depthOfField: 0,
    focusDistance: 0,
    aperture: 0,
    blurLevel: 100,
    irisShape: 1,
    irisRotation: 0,
    irisRoundness: 0,
    irisAspectRatio: 1,
    irisDiffractionFringe: 0,
    highlightGain: 0,
    highlightThreshold: 1,
    highlightSaturation: 0
};
exports.CameraTransformDefaultValues = {
    pointOfInterest: [0, 0, 0],
    position: [0, 0, 0],
    orientation: [0, 0, 0],
};
exports.EffectDefaultValues = {
    effectOpacity: 100
};
exports.EffectDropShadowDefaultValues = {
    shadowColor: [0, 0, 0, 0],
    opacity: 100,
    direction: 0,
    distance: 0,
    softness: 0,
    shadowOnly: 0,
};
exports.EffectGaussianBlurDefaultValues = {
    blurriness: 0,
    blurDimensions: 1,
    repeatEdgePixels: 0,
};
exports.EffectFastBlurDefaultValues = exports.EffectGaussianBlurDefaultValues;
exports.EffectBoxBlurDefaultValues = exports.EffectGaussianBlurDefaultValues;
exports.EffectBulgeDefaultValues = {
    horizontalRadius: 0,
    verticalRadius: 0,
    bulgeCenter: [0, 0],
    bulgeHeight: 0,
    taperRadius: 0,
    antialiasing: 2,
    pinning: 0,
};
exports.EffectTransformDefaultValues = {
    anchorPoint: [0, 0],
    position: [0, 0],
    skew: 0,
    skewAxis: 0,
    rotation: 0,
    xRotation: 0,
    yRotation: 0,
    zRotation: 0,
    opacity: 100,
    shutterAngle: 0,
};
exports.EffectTileDefaultValues = {
    tileCenter: [0, 0],
    tileWidth: 100,
    tileHeight: 100,
    outputWidth: 100,
    outputHeight: 100,
    mirrorEdges: 1,
    phase: 0,
    horizontalPhaseShift: 0,
};
exports.EffectAnimateCharacterDefaultValues = {
    position: [0, 0],
    rotation: 0,
    scale: [100, 100],
    opacity: 100,
    delay: 0,
    elasticity: 0,
    maxBounces: 0,
    reversedOrder: 0,
    randomizedOrder: 0,
    randomStartValueMin: 0,
    randomStartValueMax: 0,
    randomSeed: 0
};
exports.EffectFillDefaultValues = {
    color: [0, 0, 0, 0],
    opacity: 100,
};
exports.EffectMaskDefaultValues = {
    trackMatteType: 'ALPHA',
};
exports.EffectGammaDefaultValues = {
    redGamma: 1,
    redPedestal: 0,
    redGain: 1,
    greenGamma: 1,
    greenPedestal: 0,
    greenGain: 1,
    blueGamma: 1,
    bluePedestal: 0,
    blueGain: 1
};
exports.EffectTintDefaultValues = {
    mapBlackTo: [0, 0, 0, 1],
    mapWhiteTo: [1, 1, 1, 1],
    amountToTint: 100,
};
exports.EffectDisplacementMapDefaultValues = {
    useForHorizontalDisplacement: 5,
    maxHorizontalDisplacement: 0,
    useForVerticalDisplacement: 5,
    maxVerticalDisplacement: 0,
    displacementMapBehavior: 1,
    edgeBehavior: 1,
    expandOutput: 1,
};
exports.EffectRoughenEdgesDefaultValues = {
    edgeColor: [0.6, 0.2, 0, 1],
    border: 0,
    edgeSharpness: 0,
    fractalInfluence: 1,
    scale: 100,
    stretchWidthOrHeight: 0,
    offset: [0, 0],
    complexity: 0,
    evolution: 0,
    cycleEvolution: 0,
    cycle: 0,
    randomSeed: 0,
};
exports.EffectFractalNoiseDefaultValues = {
    invert: 0,
    contrast: 100,
    brightness: 0,
    overflow: 4,
    rotation: 0,
    offsetTurbulence: [0, 0],
    perspectiveOffset: 0,
    complexity: 0,
    subInfluence: 0,
    subScaling: 0,
    subRotation: 0,
    subOffset: [0, 0],
    centerSubscale: 0,
    evolution: 0,
    cycleEvolution: 0,
    cycle: 1,
    randomSeed: 0,
    opacity: 100,
    blendingMode: 1,
};
exports.EffectColorGradient4DefaultValues = {
    color1: [0, 0, 0, 0],
    color2: [0, 0, 0, 0],
    color3: [0, 0, 0, 0],
    color4: [0, 0, 0, 0],
    point1: [0, 0],
    point2: [0, 0],
    point3: [0, 0],
    point4: [0, 0],
    blend: 0,
    jitter: 0,
    opacity: 100,
    blendingMode: 1,
};
exports.EffectEasyLevelsDefaultValues = {
    channel: 1,
    inputBlack: 0,
    inputWhite: 1,
    gamma: 1,
    outputBlack: 0,
    outputWhite: 1,
};
exports.EffectRampDefaultValues = {
    startOfRamp: [0, 0],
    startColor: [0, 0, 0, 0],
    endOfRamp: [0, 0],
    endColor: [0, 0, 0, 0],
    rampShape: 0,
    rampScatter: 0,
    blendWithOriginal: 0,
};
exports.AllEffectsDefaultValues = {
    dropShadow: exports.EffectDropShadowDefaultValues,
    bulge: exports.EffectBulgeDefaultValues,
    transform: exports.EffectTransformDefaultValues,
    tile: exports.EffectTileDefaultValues,
    fill: exports.EffectFillDefaultValues,
    gamma: exports.EffectGammaDefaultValues,
    tint: exports.EffectTintDefaultValues,
    displacementMap: exports.EffectDisplacementMapDefaultValues,
    roughenEdges: exports.EffectRoughenEdgesDefaultValues,
    fractalNoise: exports.EffectFractalNoiseDefaultValues,
    colorGradient4: exports.EffectColorGradient4DefaultValues,
    eastLevels: exports.EffectEasyLevelsDefaultValues,
    ramp: exports.EffectRampDefaultValues,
    gaussianBlur: exports.EffectGaussianBlurDefaultValues,
    fastBlur: exports.EffectFastBlurDefaultValues,
};
exports.TextLayerDefaultValues = {
    anchorPointGrouping: 1,
    groupingAlignment: [0, 0],
    tracking: 0,
    justification: 1,
    fauxBold: false,
    fauxItalic: false,
};
exports.TextAnimaterSelecterDefaultValues = {
    start: 0,
    end: 100,
    offset: 0,
    units: 1,
    basedOn: 1,
    mode: 1,
    amount: 100,
    shape: 0,
    smoothness: 0,
    easeHigh: 0,
    easeLow: 0,
    randomizeOrder: 0,
    randomSeed: 0,
};
exports.TextAnimatorPropertiesDefaultValues = {
    anchorPoint: [0, 0, 0],
    position: [0, 0, 0],
    scale: [100, 100, 100],
    skew: 0,
    skewAxis: 0,
    rotation: 0,
    xRotation: 0,
    yRotation: 0,
    zRotation: 0,
    opacity: 100,
    trackingAmount: 0,
    blur: [0, 0],
};
exports.ShapeTrimDefaultValues = {
    start: 0,
    end: 100,
    offset: 0,
    trimMultipleShapes: 1,
};
exports.ShapeFillDefaultValues = {
    fillRule: 1,
    color: [0, 0, 0, 0],
    opacity: 100,
};
exports.ShapeStrokeDefaultValues = {
    color: [0, 0, 0, 0],
    opacity: 100,
    strokeWidth: 0,
    lineCap: 1,
    lineJoin: 1,
    miterLimit: 4,
    dashes: [],
    dashOffset: 0,
};
exports.ShapeRectDefaultValues = {
    shapeDirection: 1,
    size: [0, 0],
    position: [0, 0],
    roundness: 0,
};
exports.ShapeEllipseDefaultValues = {
    shapeDirection: 1,
    size: [0, 0],
    position: [0, 0],
};
exports.ShapeGroupDefaultValues = {
    shapeDirection: 1,
};
exports.ShapePathVertexDefaultValues = {
    closed: false,
    featherInterps: [],
    featherRadii: [],
    featherRelCornerAngles: [],
    featherRelSegLocs: [],
    featherSegLocs: [],
    featherTensions: [],
    featherTypes: [],
};
exports.ShapeDefaultValues = {
    rect: exports.ShapeRectDefaultValues,
    ellipse: exports.ShapeEllipseDefaultValues,
    group: exports.ShapeGroupDefaultValues,
};
exports.LayerStyleBlendingOptionDefaultValues = {
    fillOpacity: 100,
};
exports.LayerStyleDropShadowDefaultValues = {
    color: [0, 0, 0, 0],
    opacity: 100,
    angle: 0,
    distance: 0,
    spread: 0,
    size: 0,
};
exports.MaskDefaultValues = {
    maskMode: 1,
    inverted: false,
    maskPath: [],
    maskFeather: [0, 0],
    maskOpacity: 100,
    maskExpansion: 0,
};


/***/ }),

/***/ "./src/aegl/aegl-enums.ts":
/*!********************************!*\
  !*** ./src/aegl/aegl-enums.ts ***!
  \********************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.AETextAnimaterSelecterShape = exports.AETextAnimaterSelecterMode = exports.AETextAnimaterSelecterBasedOn = exports.AETextAnimaterSelecterUnit = exports.AERampShape = exports.AEChannels = exports.AEEffectBlendingMode = exports.AEFractalNoiseOverflow = exports.AENoiseType = exports.AEFractalType = exports.AEDisplacementMapBehavior = exports.AEUseForHorizontalDisplacement = exports.AEEffectAntialiasing = exports.AEEffectGaussianBlurDimension = exports.AEMaskMode = exports.AEShapeTrimMultipleShapes = exports.AEShapeFillRule = exports.AEShapeStrokeLineJoin = exports.AEShapeStrokeLineCap = exports.AECameraIrisShape = exports.AETextParagraphJustification = exports.AETextAnchorPoint = exports.AESamplingQuality = void 0;
/* 警告: 此文件拷贝自 adobe-scripts, 请勿在此修改.*/ /** 层渲染时的采样方式. */
var AESamplingQuality;
(function (AESamplingQuality) {
    /** 临近采样. */
    AESamplingQuality[AESamplingQuality["Nearest"] = 1] = "Nearest";
    /** 双线性采样. */
    AESamplingQuality[AESamplingQuality["BiLinear"] = 2] = "BiLinear";
    /** 双立方采样, 由于绘制所需的资源过多, 所以暂不进行绘制. */
    AESamplingQuality[AESamplingQuality["BiCubic"] = 3] = "BiCubic";
})(AESamplingQuality || (exports.AESamplingQuality = AESamplingQuality = {}));
/** 文字的锚点设置, 影响到文字动画. */
var AETextAnchorPoint;
(function (AETextAnchorPoint) {
    AETextAnchorPoint[AETextAnchorPoint["Character"] = 1] = "Character";
    AETextAnchorPoint[AETextAnchorPoint["Word"] = 2] = "Word";
    AETextAnchorPoint[AETextAnchorPoint["Line"] = 3] = "Line";
    AETextAnchorPoint[AETextAnchorPoint["All"] = 4] = "All";
})(AETextAnchorPoint || (exports.AETextAnchorPoint = AETextAnchorPoint = {}));
/** 文字的对齐方式. */
var AETextParagraphJustification;
(function (AETextParagraphJustification) {
    AETextParagraphJustification[AETextParagraphJustification["LeftJustify"] = 0] = "LeftJustify";
    AETextParagraphJustification[AETextParagraphJustification["CenterJustify"] = 1] = "CenterJustify";
    AETextParagraphJustification[AETextParagraphJustification["RightJustify"] = 2] = "RightJustify";
    AETextParagraphJustification[AETextParagraphJustification["FullJustifyLastLineLeft"] = 3] = "FullJustifyLastLineLeft";
    AETextParagraphJustification[AETextParagraphJustification["FullJustifyLastLineRight"] = 4] = "FullJustifyLastLineRight";
    AETextParagraphJustification[AETextParagraphJustification["FullJustifyLastLineCenter"] = 5] = "FullJustifyLastLineCenter";
    AETextParagraphJustification[AETextParagraphJustification["FullJustifyLastLineFull"] = 6] = "FullJustifyLastLineFull";
    AETextParagraphJustification[AETextParagraphJustification["MultipleJustifications"] = 7] = "MultipleJustifications";
})(AETextParagraphJustification || (exports.AETextParagraphJustification = AETextParagraphJustification = {}));
/**
 * 借此在预览时加载不同分辨率的素材.
 * 需要注意, 这里的 540p 并不表示素材是 540p, 而是表示在 540p 渲染模式下使用的素材.
 * 另外具体生成多大的低分辨率素材由业务需求决定.
 */ /** 镜头进光孔的类型. */
var AECameraIrisShape;
(function (AECameraIrisShape) {
    AECameraIrisShape[AECameraIrisShape["FastRectangle"] = 0] = "FastRectangle";
    AECameraIrisShape[AECameraIrisShape["Triangle"] = 1] = "Triangle";
    AECameraIrisShape[AECameraIrisShape["Square"] = 2] = "Square";
    AECameraIrisShape[AECameraIrisShape["Pentagon"] = 3] = "Pentagon";
    AECameraIrisShape[AECameraIrisShape["Hexagon"] = 4] = "Hexagon";
    AECameraIrisShape[AECameraIrisShape["Heptagon"] = 5] = "Heptagon";
    AECameraIrisShape[AECameraIrisShape["Octagon"] = 6] = "Octagon";
    AECameraIrisShape[AECameraIrisShape["Nonagon"] = 7] = "Nonagon";
    AECameraIrisShape[AECameraIrisShape["Decagon"] = 8] = "Decagon";
})(AECameraIrisShape || (exports.AECameraIrisShape = AECameraIrisShape = {}));
/** 线段首尾处的线帽类型. */
var AEShapeStrokeLineCap;
(function (AEShapeStrokeLineCap) {
    // 两侧和边界相接.
    AEShapeStrokeLineCap[AEShapeStrokeLineCap["Butt"] = 1] = "Butt";
    // 两侧为圆形.
    AEShapeStrokeLineCap[AEShapeStrokeLineCap["Round"] = 2] = "Round";
    // 两侧向外延伸并且为方形. 和 Canvas 或者 SVG 中的 Square 等同.
    AEShapeStrokeLineCap[AEShapeStrokeLineCap["Projecting"] = 3] = "Projecting";
})(AEShapeStrokeLineCap || (exports.AEShapeStrokeLineCap = AEShapeStrokeLineCap = {}));
/** 线段相接处的连接类型. */
var AEShapeStrokeLineJoin;
(function (AEShapeStrokeLineJoin) {
    // 尖角.
    AEShapeStrokeLineJoin[AEShapeStrokeLineJoin["Miter"] = 1] = "Miter";
    // 圆角.
    AEShapeStrokeLineJoin[AEShapeStrokeLineJoin["Round"] = 2] = "Round";
    // 平角.
    AEShapeStrokeLineJoin[AEShapeStrokeLineJoin["Bevel"] = 3] = "Bevel";
})(AEShapeStrokeLineJoin || (exports.AEShapeStrokeLineJoin = AEShapeStrokeLineJoin = {}));
/** 填充 */
var AEShapeFillRule;
(function (AEShapeFillRule) {
    /** 非零填充. */
    AEShapeFillRule[AEShapeFillRule["NonZero"] = 1] = "NonZero";
    /** 奇偶填充. */
    AEShapeFillRule[AEShapeFillRule["EvenOdd"] = 2] = "EvenOdd";
})(AEShapeFillRule || (exports.AEShapeFillRule = AEShapeFillRule = {}));
/** 裁剪路径类别. */
var AEShapeTrimMultipleShapes;
(function (AEShapeTrimMultipleShapes) {
    /** 所有路径连起来进行裁剪. */
    AEShapeTrimMultipleShapes[AEShapeTrimMultipleShapes["Simultaneously"] = 1] = "Simultaneously";
    /** 分别裁剪所有路径. */
    AEShapeTrimMultipleShapes[AEShapeTrimMultipleShapes["Individually"] = 2] = "Individually";
})(AEShapeTrimMultipleShapes || (exports.AEShapeTrimMultipleShapes = AEShapeTrimMultipleShapes = {}));
/** 蒙版的叠加模式. */
var AEMaskMode;
(function (AEMaskMode) {
    AEMaskMode[AEMaskMode["None"] = 1] = "None";
    AEMaskMode[AEMaskMode["Add"] = 2] = "Add";
    AEMaskMode[AEMaskMode["Subtract"] = 3] = "Subtract";
    AEMaskMode[AEMaskMode["Intersect"] = 4] = "Intersect";
    AEMaskMode[AEMaskMode["Lighten"] = 5] = "Lighten";
    AEMaskMode[AEMaskMode["Darken"] = 6] = "Darken";
    AEMaskMode[AEMaskMode["Difference"] = 7] = "Difference";
})(AEMaskMode || (exports.AEMaskMode = AEMaskMode = {}));
/** 高斯模糊的方向. */
var AEEffectGaussianBlurDimension;
(function (AEEffectGaussianBlurDimension) {
    AEEffectGaussianBlurDimension[AEEffectGaussianBlurDimension["Both"] = 1] = "Both";
    AEEffectGaussianBlurDimension[AEEffectGaussianBlurDimension["Herizontal"] = 2] = "Herizontal";
    AEEffectGaussianBlurDimension[AEEffectGaussianBlurDimension["Vertical"] = 3] = "Vertical";
})(AEEffectGaussianBlurDimension || (exports.AEEffectGaussianBlurDimension = AEEffectGaussianBlurDimension = {}));
/** 抗锯齿方式. */
var AEEffectAntialiasing;
(function (AEEffectAntialiasing) {
    AEEffectAntialiasing[AEEffectAntialiasing["Low"] = 1] = "Low";
    AEEffectAntialiasing[AEEffectAntialiasing["High"] = 2] = "High";
})(AEEffectAntialiasing || (exports.AEEffectAntialiasing = AEEffectAntialiasing = {}));
/**
 * Gamma 颜色调整特效.
 * 转换关系为 c' = (gain * c + pedestal)^(1 / gamma).
 */ /** 指定层的哪个通道决定偏移. */
var AEUseForHorizontalDisplacement;
(function (AEUseForHorizontalDisplacement) {
    AEUseForHorizontalDisplacement[AEUseForHorizontalDisplacement["Red"] = 1] = "Red";
    AEUseForHorizontalDisplacement[AEUseForHorizontalDisplacement["Green"] = 2] = "Green";
    AEUseForHorizontalDisplacement[AEUseForHorizontalDisplacement["Blue"] = 3] = "Blue";
    AEUseForHorizontalDisplacement[AEUseForHorizontalDisplacement["Alpha"] = 4] = "Alpha";
    AEUseForHorizontalDisplacement[AEUseForHorizontalDisplacement["Luminance"] = 5] = "Luminance";
    AEUseForHorizontalDisplacement[AEUseForHorizontalDisplacement["Hue"] = 6] = "Hue";
    AEUseForHorizontalDisplacement[AEUseForHorizontalDisplacement["Lightness"] = 7] = "Lightness";
    AEUseForHorizontalDisplacement[AEUseForHorizontalDisplacement["Saturation"] = 8] = "Saturation";
    AEUseForHorizontalDisplacement[AEUseForHorizontalDisplacement["Full"] = 9] = "Full";
    AEUseForHorizontalDisplacement[AEUseForHorizontalDisplacement["Half"] = 10] = "Half";
    AEUseForHorizontalDisplacement[AEUseForHorizontalDisplacement["Off"] = 11] = "Off";
})(AEUseForHorizontalDisplacement || (exports.AEUseForHorizontalDisplacement = AEUseForHorizontalDisplacement = {}));
/** 指定拉伸覆盖的方式. */
var AEDisplacementMapBehavior;
(function (AEDisplacementMapBehavior) {
    AEDisplacementMapBehavior[AEDisplacementMapBehavior["CenterMap"] = 1] = "CenterMap";
    AEDisplacementMapBehavior[AEDisplacementMapBehavior["StretchMapToFit"] = 2] = "StretchMapToFit";
    AEDisplacementMapBehavior[AEDisplacementMapBehavior["TileMap"] = 3] = "TileMap";
})(AEDisplacementMapBehavior || (exports.AEDisplacementMapBehavior = AEDisplacementMapBehavior = {}));
/** 分形类型. */
var AEFractalType;
(function (AEFractalType) {
    AEFractalType[AEFractalType["Basic"] = 1] = "Basic";
    AEFractalType[AEFractalType["TurbelentSmooth"] = 2] = "TurbelentSmooth";
    AEFractalType[AEFractalType["TurbelentBasic"] = 3] = "TurbelentBasic";
    AEFractalType[AEFractalType["TurbelentSharp"] = 4] = "TurbelentSharp";
    AEFractalType[AEFractalType["Dynamic"] = 5] = "Dynamic";
    AEFractalType[AEFractalType["DynamicProgressive"] = 6] = "DynamicProgressive";
    AEFractalType[AEFractalType["DynamicTwist"] = 7] = "DynamicTwist";
    AEFractalType[AEFractalType["Max"] = 8] = "Max";
    AEFractalType[AEFractalType["Smeary"] = 9] = "Smeary";
    AEFractalType[AEFractalType["Swirly"] = 10] = "Swirly";
    AEFractalType[AEFractalType["Rocky"] = 11] = "Rocky";
    AEFractalType[AEFractalType["Cloudy"] = 12] = "Cloudy";
    AEFractalType[AEFractalType["Terrain"] = 13] = "Terrain";
    AEFractalType[AEFractalType["Subscale"] = 14] = "Subscale";
    AEFractalType[AEFractalType["SmallBumps"] = 15] = "SmallBumps";
    AEFractalType[AEFractalType["Strings"] = 16] = "Strings";
    AEFractalType[AEFractalType["Threads"] = 17] = "Threads";
})(AEFractalType || (exports.AEFractalType = AEFractalType = {}));
/** 噪声类型. */
var AENoiseType;
(function (AENoiseType) {
    AENoiseType[AENoiseType["Block"] = 1] = "Block";
    AENoiseType[AENoiseType["Linear"] = 2] = "Linear";
    AENoiseType[AENoiseType["SoftLinear"] = 3] = "SoftLinear";
    AENoiseType[AENoiseType["Spline"] = 4] = "Spline";
})(AENoiseType || (exports.AENoiseType = AENoiseType = {}));
/** 对于颜色值溢出的处理. */
var AEFractalNoiseOverflow;
(function (AEFractalNoiseOverflow) {
    AEFractalNoiseOverflow[AEFractalNoiseOverflow["Clip"] = 1] = "Clip";
    AEFractalNoiseOverflow[AEFractalNoiseOverflow["SoftClamp"] = 2] = "SoftClamp";
    AEFractalNoiseOverflow[AEFractalNoiseOverflow["WrapBack"] = 3] = "WrapBack";
    AEFractalNoiseOverflow[AEFractalNoiseOverflow["AllowHDRResults"] = 4] = "AllowHDRResults";
})(AEFractalNoiseOverflow || (exports.AEFractalNoiseOverflow = AEFractalNoiseOverflow = {}));
/** 特效中的颜色混合模式. */
var AEEffectBlendingMode;
(function (AEEffectBlendingMode) {
    AEEffectBlendingMode[AEEffectBlendingMode["None"] = 1] = "None";
    AEEffectBlendingMode[AEEffectBlendingMode["Normal"] = 2] = "Normal";
    AEEffectBlendingMode[AEEffectBlendingMode["Add"] = 3] = "Add";
    AEEffectBlendingMode[AEEffectBlendingMode["Multiply"] = 4] = "Multiply";
    AEEffectBlendingMode[AEEffectBlendingMode["Screen"] = 5] = "Screen";
    AEEffectBlendingMode[AEEffectBlendingMode["Overlay"] = 6] = "Overlay";
    AEEffectBlendingMode[AEEffectBlendingMode["SoftLight"] = 7] = "SoftLight";
    AEEffectBlendingMode[AEEffectBlendingMode["HardLight"] = 8] = "HardLight";
    AEEffectBlendingMode[AEEffectBlendingMode["ColorDodge"] = 9] = "ColorDodge";
    AEEffectBlendingMode[AEEffectBlendingMode["ColorBurn"] = 10] = "ColorBurn";
    AEEffectBlendingMode[AEEffectBlendingMode["Draken"] = 11] = "Draken";
    AEEffectBlendingMode[AEEffectBlendingMode["Lighten"] = 12] = "Lighten";
    AEEffectBlendingMode[AEEffectBlendingMode["Difference"] = 13] = "Difference";
    AEEffectBlendingMode[AEEffectBlendingMode["Exclusion"] = 14] = "Exclusion";
    AEEffectBlendingMode[AEEffectBlendingMode["Hue"] = 15] = "Hue";
    AEEffectBlendingMode[AEEffectBlendingMode["Saturation"] = 16] = "Saturation";
    AEEffectBlendingMode[AEEffectBlendingMode["Luminosity"] = 17] = "Luminosity";
})(AEEffectBlendingMode || (exports.AEEffectBlendingMode = AEEffectBlendingMode = {}));
/** 调色等作用于的通道. */
var AEChannels;
(function (AEChannels) {
    AEChannels[AEChannels["RGB"] = 1] = "RGB";
    AEChannels[AEChannels["Red"] = 2] = "Red";
    AEChannels[AEChannels["Blue"] = 3] = "Blue";
    AEChannels[AEChannels["Green"] = 4] = "Green";
    AEChannels[AEChannels["Alpha"] = 5] = "Alpha";
})(AEChannels || (exports.AEChannels = AEChannels = {})); /** Ramp 的形状. */
var AERampShape;
(function (AERampShape) {
    AERampShape[AERampShape["LinearRamp"] = 1] = "LinearRamp";
    AERampShape[AERampShape["RadialRamp"] = 2] = "RadialRamp";
})(AERampShape || (exports.AERampShape = AERampShape = {}));
/** 逐文字特效的选择器的单位. */
var AETextAnimaterSelecterUnit;
(function (AETextAnimaterSelecterUnit) {
    AETextAnimaterSelecterUnit[AETextAnimaterSelecterUnit["Percentage"] = 1] = "Percentage";
    AETextAnimaterSelecterUnit[AETextAnimaterSelecterUnit["Index"] = 2] = "Index";
})(AETextAnimaterSelecterUnit || (exports.AETextAnimaterSelecterUnit = AETextAnimaterSelecterUnit = {}));
/** 文字动画作用于字母还是单词. */
var AETextAnimaterSelecterBasedOn;
(function (AETextAnimaterSelecterBasedOn) {
    AETextAnimaterSelecterBasedOn[AETextAnimaterSelecterBasedOn["Characters"] = 1] = "Characters";
    AETextAnimaterSelecterBasedOn[AETextAnimaterSelecterBasedOn["CharactersExcludingSpaces"] = 2] = "CharactersExcludingSpaces";
    AETextAnimaterSelecterBasedOn[AETextAnimaterSelecterBasedOn["Words"] = 3] = "Words";
    AETextAnimaterSelecterBasedOn[AETextAnimaterSelecterBasedOn["Lines"] = 4] = "Lines";
})(AETextAnimaterSelecterBasedOn || (exports.AETextAnimaterSelecterBasedOn = AETextAnimaterSelecterBasedOn = {}));
/** 文字动画的执行模式. */
var AETextAnimaterSelecterMode;
(function (AETextAnimaterSelecterMode) {
    AETextAnimaterSelecterMode[AETextAnimaterSelecterMode["Add"] = 1] = "Add";
    AETextAnimaterSelecterMode[AETextAnimaterSelecterMode["Subtract"] = 2] = "Subtract";
    AETextAnimaterSelecterMode[AETextAnimaterSelecterMode["Intersect"] = 3] = "Intersect";
    AETextAnimaterSelecterMode[AETextAnimaterSelecterMode["Min"] = 4] = "Min";
    AETextAnimaterSelecterMode[AETextAnimaterSelecterMode["Max"] = 5] = "Max";
    AETextAnimaterSelecterMode[AETextAnimaterSelecterMode["Difference"] = 6] = "Difference";
})(AETextAnimaterSelecterMode || (exports.AETextAnimaterSelecterMode = AETextAnimaterSelecterMode = {}));
/** 文字动画的结构类型. */
var AETextAnimaterSelecterShape;
(function (AETextAnimaterSelecterShape) {
    AETextAnimaterSelecterShape[AETextAnimaterSelecterShape["Square"] = 1] = "Square";
    AETextAnimaterSelecterShape[AETextAnimaterSelecterShape["RampUp"] = 2] = "RampUp";
    AETextAnimaterSelecterShape[AETextAnimaterSelecterShape["RampDown"] = 3] = "RampDown";
    AETextAnimaterSelecterShape[AETextAnimaterSelecterShape["Triangle"] = 4] = "Triangle";
    AETextAnimaterSelecterShape[AETextAnimaterSelecterShape["Round"] = 5] = "Round";
    AETextAnimaterSelecterShape[AETextAnimaterSelecterShape["Smooth"] = 6] = "Smooth";
})(AETextAnimaterSelecterShape || (exports.AETextAnimaterSelecterShape = AETextAnimaterSelecterShape = {}));
/**
 * 文字动画的属性设置.
 * 不包含 xyzPosition 属性.
 */ 


/***/ }),

/***/ "./src/aegl/helpers/browser.ts":
/*!*************************************!*\
  !*** ./src/aegl/helpers/browser.ts ***!
  \*************************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.isWindowsSystem = exports.isMacSystem = void 0;
/** 是否为 Mac 系统. */
function isMacSystem() {
    return /Macintosh|Mac OS X/.test(navigator.userAgent);
}
exports.isMacSystem = isMacSystem;
/** 是否为 Windows 系统. */
function isWindowsSystem() {
    return /Windows NT|Win32|Win64/.test(navigator.userAgent);
}
exports.isWindowsSystem = isWindowsSystem;


/***/ }),

/***/ "./src/aegl/helpers/color.ts":
/*!***********************************!*\
  !*** ./src/aegl/helpers/color.ts ***!
  \***********************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.premultiplyColorArray = exports.colorArrayToString = void 0;
const color_1 = __webpack_require__(/*! ../../libs/util/color */ "./src/libs/util/color.ts");
/** 从颜色数组获得字符串形式. 如果未定义, 则返回 transparent */
function colorArrayToString(color) {
    if (color) {
        if (color.length === 4) {
            return color_1.Color.fromRGBA(...color).toString();
        }
        else {
            return color_1.Color.fromRGB(...color).toString();
        }
    }
    else {
        return 'transparent';
    }
}
exports.colorArrayToString = colorArrayToString;
/** 对颜色进行预乘. */
function premultiplyColorArray(color) {
    let [r, g, b, a] = color;
    return [r * a, g * a, b * a, a];
}
exports.premultiplyColorArray = premultiplyColorArray;


/***/ }),

/***/ "./src/aegl/helpers/fonts-list.ts":
/*!****************************************!*\
  !*** ./src/aegl/helpers/fonts-list.ts ***!
  \****************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.FontList = void 0;
const preload_1 = __webpack_require__(/*! ../../libs/util/preload */ "./src/libs/util/preload.ts");
const web_safe_fonts_1 = __webpack_require__(/*! ./web-safe-fonts */ "./src/aegl/helpers/web-safe-fonts.ts");
const timestamp_1 = __webpack_require__(/*! ../../libs/util/timestamp */ "./src/libs/util/timestamp.ts");
const browser_1 = __webpack_require__(/*! ./browser */ "./src/aegl/helpers/browser.ts");
/** 字体加重程度映射表. */
const WeightMap = {
    Thin: 250,
    ExtraLight: 275,
    UltraLight: 275,
    Light: 300,
    SemiLight: 350,
    DemiLight: 350,
    Regular: 400,
    Normal: 400,
    Book: 400,
    Roman: 400,
    Medium: 500,
    SemiBold: 600,
    DemiBold: 600,
    Bold: 700,
    ExtraBold: 800,
    UltraBold: 800,
    Black: 900,
    Heavy: 900,
};
/** 用于管理全局的字体. */
var FontList;
(function (FontList) {
    /** 缓存的所有字体数据. */
    let dataMap = new Map();
    /** 偏平排列的所有字体. */
    let allFonts = [];
    /** 偏平排列的所有字体. */
    let fontGroup = new Map();
    /** 当资源加载后被 resolve. */
    let loadingPromises = new Map();
    /** 字体目录. */
    let fontDirectory = 'aegl/fonts';
    /** 加载了英文字体之后被 resolve. */
    let ensurePromise;
    /** 配置存储目录地址. */
    function configDirectory(directory) {
        fontDirectory = directory;
    }
    FontList.configDirectory = configDirectory;
    /** 准备必要的数据, 可以反复调用. */
    async function ensure() {
        if (!ensurePromise) {
            ensurePromise = ensureDataOfLanguage('en-US');
        }
        await ensurePromise;
    }
    FontList.ensure = ensure;
    /** 确保加载指定语言的字体. */
    async function ensureDataOfLanguage(language) {
        if (dataMap.has(language)) {
            return;
        }
        if (loadingPromises.has(language)) {
            await loadingPromises.get(language);
        }
        loadingPromises.set(language, loadDataOfLanguage(language));
        await loadingPromises.get(language);
        loadingPromises.delete(language);
    }
    /** 初始化和加载资源. */
    async function loadDataOfLanguage(language) {
        let cssPath = (0, timestamp_1.addTimestamp)(`${fontDirectory}/${language.toLowerCase()}/fonts.css`);
        let dataPath = (0, timestamp_1.addTimestamp)(`${fontDirectory}/${language.toLowerCase()}/fonts.json`);
        (0, preload_1.loadStyle)(cssPath);
        let fonts = await (await fetch(dataPath)).json();
        dataMap.set(language, fonts);
        allFonts = [...dataMap.values()].flat();
        for (let font of fonts) {
            let group = fontGroup.get(font.fontFamily);
            if (!group) {
                group = [];
                fontGroup.set(font.fontFamily, group);
            }
            group.push(font);
        }
    }
    /** 检查是否存在字体数据. */
    function has(name) {
        return allFonts.some(font => font.fontFamily === name);
    }
    FontList.has = has;
    /** 获取一个字体数据. */
    function get(name, style) {
        let matched;
        if (style) {
            matched = allFonts.find(font => font.fontFamily === name && font.fontSubFamily === style);
        }
        if (!matched) {
            matched = allFonts.find(font => font.fontFamily === name);
        }
        return matched;
    }
    FontList.get = get;
    /** 获取所有的字体名称列表. */
    async function getFamilyListByLanguage(language) {
        await ensureDataOfLanguage(language);
        let processed = new Set();
        let list = [];
        for (let font of dataMap.get(language)) {
            if (processed.has(font.fontFamily)) {
                continue;
            }
            list.push({ fontFamily: font.fontFamily, localizedName: font.localizedName });
            processed.add(font.fontFamily);
        }
        return list;
    }
    FontList.getFamilyListByLanguage = getFamilyListByLanguage;
    /** 获取所有的字体名称列表. */
    function getFontWeightList(family) {
        let fonts = fontGroup.get(family) || [];
        let weights = fonts.filter(font => !/ ?Italic/.test(font.fontSubFamily))
            .map(font => font.fontSubFamily);
        weights.sort((w1, w2) => WeightMap[w1] - WeightMap[w2]);
        if (weights.length === 0) {
            return null;
        }
        return weights;
    }
    FontList.getFontWeightList = getFontWeightList;
    /** 获得字体的加重程度. */
    function getFontWeight(subFamily) {
        let weight = subFamily.replace(/ ?Italic/, '') || 'Regular';
        return Object.keys(WeightMap).includes(weight) ? weight : 'Regular';
    }
    FontList.getFontWeight = getFontWeight;
    /** 获得 CSS 加重程度. */
    function getCSSFontWeight(subFamily) {
        let weight = WeightMap[getFontWeight(subFamily)] || 400;
        if (weight === 400) {
            return 'normal';
        }
        else if (weight === 700) {
            return 'bold';
        }
        else {
            return weight.toString();
        }
    }
    FontList.getCSSFontWeight = getCSSFontWeight;
    /** 获得 CSS 斜体样式. */
    function getCSSFontStyle(subFamily) {
        if (subFamily.includes('Italic')) {
            return 'italic';
        }
        else {
            return 'normal';
        }
    }
    FontList.getCSSFontStyle = getCSSFontStyle;
    /** 检查文字是否只有斜体可用, 而没有非斜体可用. */
    function canOnlyBeItalic(family) {
        let fonts = fontGroup.get(family) || [];
        let isEveryBeItalic = fonts.length > 0 && fonts.every(font => font.fontSubFamily.includes('Italic'));
        return isEveryBeItalic;
    }
    FontList.canOnlyBeItalic = canOnlyBeItalic;
    /** 获得 Web 安全字体. */
    function getWebSafeFonts(language) {
        let isMac = (0, browser_1.isMacSystem)();
        let isWin = (0, browser_1.isWindowsSystem)();
        let property = isWin ? 'win' : isMac ? 'mac' : 'others';
        let fontsObject = web_safe_fonts_1.WebSafeFonts[language];
        let fontNames = [];
        if (fontsObject.common) {
            fontNames.push(...fontsObject.common);
        }
        if (fontsObject[property]) {
            fontNames.push(...fontsObject[property]);
        }
        return fontNames;
    }
    FontList.getWebSafeFonts = getWebSafeFonts;
})(FontList || (exports.FontList = FontList = {}));


/***/ }),

/***/ "./src/aegl/helpers/framerate-calculator.ts":
/*!**************************************************!*\
  !*** ./src/aegl/helpers/framerate-calculator.ts ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.FrameRateCalculator = void 0;
const stat_1 = __webpack_require__(/*! ../../libs/math/stat */ "./src/libs/math/stat.ts");
/** 用于计算浏览器的刷新帧率. */
class FrameRateCalculator {
    /** 上一个时间戳. */
    lastTimestamp = -1;
    /** 时间戳的数目. */
    timestampCount = 0;
    /** 当前帧率. */
    frameRate = 0;
    /** 当前帧率. */
    cachedFrameRates = [];
    /** 重新开始进行帧率检测. */
    restart() {
        this.lastTimestamp = -1;
        this.timestampCount = 0;
    }
    /** 在浏览器刷新时触发此函数. timestamp 单位为毫秒. */
    trigger(timestamp) {
        if (this.timestampCount > 0) {
            let duration = timestamp - this.lastTimestamp;
            let frameRate = 1000 / duration;
            // 保留最近的 30 个值.
            this.cachedFrameRates.push(frameRate);
            if (this.cachedFrameRates.length > 30) {
                this.cachedFrameRates.shift();
            }
            this.analysisFrameRate();
        }
        this.lastTimestamp = timestamp;
        this.timestampCount++;
    }
    analysisFrameRate() {
        // 计算中心均值, 要求误差在标准差的 1.5 倍范围内.
        let coreAverage = stat_1.Stat.getCoreAverageValues(this.cachedFrameRates, 1.5);
        this.frameRate = coreAverage;
    }
    /** 获取当前帧率. */
    getFrameRate() {
        return Math.ceil(this.frameRate / 3) * 3;
    }
    /** 获取当前一帧的时长. */
    getFrameDuration() {
        return 1 / this.getFrameRate();
    }
}
exports.FrameRateCalculator = FrameRateCalculator;


/***/ }),

/***/ "./src/aegl/helpers/media.ts":
/*!***********************************!*\
  !*** ./src/aegl/helpers/media.ts ***!
  \***********************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.waitForVideoDecoded = exports.VideoFrameExtractor = exports.extractVideoFrame = exports.cropImageToMaximumSize = exports.cropImageToAspectRatio = exports.getCoverCropImageRect = exports.createSameAspectRatioImageThumbnail = exports.createImageThumbnail = exports.readCanvasAsImage = exports.readCanvasAsJPEG = exports.isSameFrameTimes = void 0;
/** 返回两个采样时刻是否共享同一帧. */
function isSameFrameTimes(time1, time2, frameRate = 30) {
    return Math.round(time1 * frameRate) === Math.round(time2 * frameRate);
}
exports.isSameFrameTimes = isSameFrameTimes;
/**
 * 读取 Canvas 元素为 JPEG Blob.
 * quality 范围为 0~1, 对于 JPEG 默认为 0.92.
 */
async function readCanvasAsJPEG(canvas, quality) {
    return await readCanvasAsImage(canvas, 'jpeg', quality);
}
exports.readCanvasAsJPEG = readCanvasAsJPEG;
/**
 * 读取 Canvas 元素为图片 Blob.
 * quality 范围为 0~1, 对于 JPEG 默认为 0.92.
 */
function readCanvasAsImage(canvas, type, quality) {
    return new Promise((resolve) => {
        canvas.toBlob((blob) => {
            resolve(blob);
        }, `image/${type}`, quality);
    });
}
exports.readCanvasAsImage = readCanvasAsImage;
/** 使用 cover 模式创建指定尺寸的缩略图, width 和 height 指定其在宽高上的尺寸. */
async function createImageThumbnail(image, width, height, position) {
    let aspectRatio = width / height;
    let [x, y, w, h] = getCoverCropImageRect(image.naturalWidth, image.naturalHeight, aspectRatio, position);
    let canvas = document.createElement('canvas');
    canvas.width = width;
    canvas.height = height;
    canvas.getContext('2d').imageSmoothingQuality = 'high';
    canvas.getContext('2d').drawImage(image, x, y, w, h, 0, 0, width, height);
    return canvas;
}
exports.createImageThumbnail = createImageThumbnail;
/** 创建原始宽高比例的缩略图, 并且指定最小的宽高尺寸. */
async function createSameAspectRatioImageThumbnail(image, minWidth, minHeight) {
    // 缩略图显示的高度为 180.
    let imageAspectRatio = image.naturalWidth / image.naturalHeight;
    let height = minHeight;
    let width = Math.round(imageAspectRatio * height);
    if (width < minWidth) {
        width = minWidth;
        height = Math.round(width / imageAspectRatio);
    }
    let canvas = document.createElement('canvas');
    canvas.width = width;
    canvas.height = height;
    canvas.getContext('2d').imageSmoothingQuality = 'high';
    canvas.getContext('2d').drawImage(image, 0, 0, width, height);
    return canvas;
}
exports.createSameAspectRatioImageThumbnail = createSameAspectRatioImageThumbnail;
/** 获得 cover 模式裁剪的坐标范围. */
function getCoverCropImageRect(imageWidth, imageHeight, aspectRatio, position) {
    let w = imageWidth;
    let h = imageHeight;
    if (w / h > aspectRatio) {
        w = h * aspectRatio;
    }
    else {
        h = w / aspectRatio;
    }
    w = Math.round(w);
    h = Math.round(h);
    let x = position[0] * (imageWidth - w);
    let y = position[1] * (imageHeight - h);
    return [x, y, w, h];
}
exports.getCoverCropImageRect = getCoverCropImageRect;
/** 使用 cover 模式裁剪图片, 裁剪结果会使用指定的 aspectRatio, 同时尽量大. */
async function cropImageToAspectRatio(image, aspectRatio, position) {
    let canvas = document.createElement('canvas');
    let [x, y, w, h] = getCoverCropImageRect(image.naturalWidth, image.naturalHeight, aspectRatio, position);
    canvas.width = w;
    canvas.height = h;
    canvas.getContext('2d').drawImage(image, x, y, w, h, 0, 0, w, h);
    return canvas;
}
exports.cropImageToAspectRatio = cropImageToAspectRatio;
/** 使用 cover 模式裁剪图片. 裁剪结果会使用指定宽高对应的 aspectRatio, 尽量大, 但是不会超过指定的宽高. */
async function cropImageToMaximumSize(image, maxWidth, maxHeight, position) {
    let canvas = document.createElement('canvas');
    let aspectRatio = maxWidth / maxHeight;
    let [x, y, w, h] = getCoverCropImageRect(image.naturalWidth, image.naturalHeight, aspectRatio, position);
    let toWidth = Math.min(maxWidth, w);
    let toHeight = Math.min(maxHeight, h);
    canvas.width = toWidth;
    canvas.height = toHeight;
    canvas.getContext('2d').drawImage(image, x, y, w, h, 0, 0, toWidth, toHeight);
    return canvas;
}
exports.cropImageToMaximumSize = cropImageToMaximumSize;
/** 导出指定时刻的视频帧. */
async function extractVideoFrame(video) {
    let canvas = document.createElement('canvas');
    let w = video.videoWidth;
    let h = video.videoHeight;
    canvas.width = w;
    canvas.height = h;
    // 如果未完成帧的解码, 则等待.
    if (video.readyState < video.HAVE_CURRENT_DATA) {
        await waitForVideoDecoded(video);
    }
    canvas.getContext('2d').drawImage(video, 0, 0, w, h);
    return canvas;
}
exports.extractVideoFrame = extractVideoFrame;
/** 共用一个 canvas 导出某个视频的多个时刻的视频帧. */
class VideoFrameExtractor {
    canvas;
    context;
    /** 初始化 Canvas 元素. */
    initializeCanvas(video) {
        let canvas = document.createElement('canvas');
        let w = video.videoWidth;
        let h = video.videoHeight;
        canvas.width = w;
        canvas.height = h;
        this.canvas = canvas;
        this.context = canvas.getContext('2d');
    }
    /** 清空 Canvas 元素的绘制内容. */
    clearCanvas() {
        let w = this.canvas.width;
        let h = this.canvas.height;
        this.context.clearRect(0, 0, w, h);
    }
    /** 导出帧. */
    async extract(video) {
        if (this.canvas) {
            this.clearCanvas();
        }
        else {
            this.initializeCanvas(video);
        }
        // 如果未完成帧的解码, 则等待.
        if (video.readyState < video.HAVE_CURRENT_DATA) {
            await waitForVideoDecoded(video);
        }
        let w = video.videoWidth;
        let h = video.videoHeight;
        this.context.drawImage(video, 0, 0, w, h);
        return this.canvas;
    }
}
exports.VideoFrameExtractor = VideoFrameExtractor;
/** 等待视频解码完成. */
async function waitForVideoDecoded(video, timeLimit = 3000) {
    return new Promise((resolve) => {
        let intervalId = setInterval(() => {
            if (video.readyState >= video.HAVE_CURRENT_DATA) {
                clearInterval(intervalId);
                clearTimeout(timeoutId);
                resolve(true);
                video.ontimeupdate = null;
            }
        }, 10);
        // 如果 1000ms 仍未解码完成, 仍然使用之前的纹理进行一次绘制.
        // 这样可以防止解码失败或者卡住, 并且不至于出现过大的卡顿.
        // 但是仍可能会出现视频帧错误而渲染错误的问题, 例如本应该盖住某个地方.
        let timeoutId = setTimeout(() => {
            clearInterval(intervalId);
            resolve(false);
        }, timeLimit);
    });
}
exports.waitForVideoDecoded = waitForVideoDecoded;


/***/ }),

/***/ "./src/aegl/helpers/promise.ts":
/*!*************************************!*\
  !*** ./src/aegl/helpers/promise.ts ***!
  \*************************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.promiseWithResolves = void 0;
/** Returns a promise, with it's resolve and reject. */
function promiseWithResolves() {
    let resolve;
    let reject;
    let promise = new Promise((res, rej) => {
        resolve = res;
        reject = rej;
    });
    return {
        promise,
        resolve: resolve,
        reject: reject,
    };
}
exports.promiseWithResolves = promiseWithResolves;


/***/ }),

/***/ "./src/aegl/helpers/resolution.ts":
/*!****************************************!*\
  !*** ./src/aegl/helpers/resolution.ts ***!
  \****************************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.getAspectRatioFromResolution = void 0;
/** 检查分辨率所对应的宽高比. */
function getAspectRatioFromResolution(resolution) {
    if (resolution === 1000) {
        return '1x1';
    }
    else if (resolution === 1920) {
        return '9x16';
    }
    else if (resolution === 1080) {
        return '16x9';
    }
    else {
        throw new Error(`未预定义的分辨率 "${resolution}p"!`);
    }
}
exports.getAspectRatioFromResolution = getAspectRatioFromResolution;


/***/ }),

/***/ "./src/aegl/helpers/shared-resources.ts":
/*!**********************************************!*\
  !*** ./src/aegl/helpers/shared-resources.ts ***!
  \**********************************************/
/***/ ((__unused_webpack_module, exports) => {


/**
 * 用于在多个对象之间共享资源和状态.
 * 例如多个对象在生命周期内, 只有第一个对象需要创建一份资源,
 * 其他对象跳过创建而直接共享它.
 * 多个对象发出的更新请求, 在同一时刻只有一个真正被执行.
 * 当所有对象对资源的引用全部移除后才会移除资源.
 */
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SharedResource = void 0;
/** 存储创建的唯一资源. */
const SharedResourceUniqueMap = new Map();
/** 存储正在进行同步的资源. */
const SharedResourceSyncOnceMap = new Map();
/** 存储正在进行同步的资源. */
const SharedResourceSyncAllMap = new Map();
/** 存储正在进行同步的资源. */
const SharedResourceSyncSomeMap = new Map();
class SharedResource {
    /** 共享的凭证. */
    id;
    constructor(id) {
        if (!id) {
            throw new Error(`Please privide a valid id!`);
        }
        this.id = id;
    }
    /**
     * 创建共享资源, 一旦创建则始终保持.
     * 如果只需要同步更新则不需要调用此方法.
     */
    async unique(name, createFn, deleteFn) {
        if (SharedResourceUniqueMap.has(this.id) && SharedResourceUniqueMap.get(this.id).has(name)) {
            let existedResource = SharedResourceUniqueMap.get(this.id).get(name);
            existedResource.usedBy.add(this);
            return await existedResource.promise;
        }
        else {
            let map = SharedResourceUniqueMap.get(this.id);
            if (!map) {
                map = new Map();
                SharedResourceUniqueMap.set(this.id, map);
            }
            let promise = createFn();
            let usedBy = new Set;
            map.set(name, {
                promise,
                deleteFn,
                usedBy,
            });
            return await promise;
        }
    }
    /** 移除当前对象, 当使用共享一个资源的对象全部移除后会触发 deleteFn. */
    async deleteUnique(name) {
        let map = SharedResourceUniqueMap.get(this.id);
        if (map) {
            let existedResource = map.get(name);
            if (existedResource) {
                existedResource.usedBy.delete(this);
                if (existedResource.usedBy.size === 0) {
                    // 可能仍处于创建状态, 所以需要等待它.
                    let resource = await existedResource.promise;
                    // 由于进行了等待, 此时需要再度判断其是否有引用.
                    if (existedResource.usedBy.size > 0) {
                        return;
                    }
                    existedResource.deleteFn(resource);
                    map.delete(name);
                }
            }
        }
    }
    /** 同步共享资源, 相交的多次更新只有第一个生效. 返回更新的结果. */
    async syncOnce(name, syncFn) {
        if (SharedResourceSyncOnceMap.has(this.id) && SharedResourceSyncOnceMap.get(this.id).has(name)) {
            let existedSyncPromise = SharedResourceSyncOnceMap.get(this.id).get(name);
            return await existedSyncPromise;
        }
        else {
            let map = SharedResourceSyncOnceMap.get(this.id);
            if (!map) {
                map = new Map();
                SharedResourceSyncOnceMap.set(this.id, map);
            }
            let promise = syncFn();
            map.set(name, promise);
            let result = await promise;
            map.delete(name);
            return result;
        }
    }
    /** 更新共享资源, 返回相交的多次更新的结果组成的数组. */
    async syncAll(name, syncFn) {
        let map = SharedResourceSyncAllMap.get(this.id);
        if (!map) {
            map = new Map();
            SharedResourceSyncAllMap.set(this.id, map);
        }
        let syncObject = map.get(name);
        if (!syncObject) {
            syncObject = {
                results: [],
                pendingCount: 0,
            };
            syncObject.promise = new Promise((resolve) => {
                syncObject.resolve = resolve;
            });
            map.set(name, syncObject);
        }
        syncObject.pendingCount++;
        syncFn().then(result => {
            syncObject.results.push(result);
            syncObject.pendingCount--;
            if (syncObject.pendingCount === 0) {
                syncObject.resolve();
                map.delete(name);
            }
        });
        await syncObject.promise;
        return syncObject.results;
    }
    /** 更新共享资源, 有一个结果为 true 则返回 true. */
    async syncSome(name, syncFn) {
        let map = SharedResourceSyncSomeMap.get(this.id);
        if (!map) {
            map = new Map();
            SharedResourceSyncSomeMap.set(this.id, map);
        }
        let syncObject = map.get(name);
        if (!syncObject) {
            syncObject = {
                result: false,
                pendingCount: 0,
            };
            syncObject.promise = new Promise((resolve) => {
                syncObject.resolve = resolve;
            });
            map.set(name, syncObject);
        }
        syncObject.pendingCount++;
        syncFn().then(result => {
            syncObject.result = syncObject.result || result;
            syncObject.pendingCount--;
            // 只要出现了一个 true 就 resolve.
            if (syncObject.result) {
                syncObject.resolve();
            }
            // 全部的任务运行完成再关闭同步.
            if (syncObject.pendingCount === 0) {
                syncObject.resolve();
                map.delete(name);
            }
        });
        await syncObject.promise;
        return syncObject.result;
    }
    /** 更新共享资源, 所有结果为 true 才返回 true. */
    async syncEvery(name, syncFn) {
        return !(await this.syncSome(name, async () => !(await syncFn())));
    }
    /** 移除当前对象, 当使用共享一个资源的对象全部移除后会触发 deleteFn. */
    async delete() {
        let map = SharedResourceUniqueMap.get(this.id);
        if (map) {
            for (let name of [...map.keys()]) {
                let existedResource = map.get(name);
                existedResource.usedBy.delete(this);
                if (existedResource.usedBy.size === 0) {
                    // 可能仍处于创建状态, 所以需要等待它.
                    let resource = await existedResource.promise;
                    existedResource.deleteFn(resource);
                    map.delete(name);
                }
            }
            if (map.size === 0) {
                SharedResourceUniqueMap.delete(this.id);
            }
        }
    }
}
exports.SharedResource = SharedResource;


/***/ }),

/***/ "./src/aegl/helpers/text.ts":
/*!**********************************!*\
  !*** ./src/aegl/helpers/text.ts ***!
  \**********************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.isWhiteSpaceChar = exports.reverseFindWordStartIndex = void 0;
/** 查找上一个单词的结束边界, 返回其索引. */
function reverseFindWordStartIndex(text, fromIndex) {
    // 不构成单词时, 返回当前索引.
    if (!/\w/i.test(text[fromIndex])) {
        return fromIndex;
    }
    // 构成单词时, 逆向查找直到遇到非单词字幕.
    for (let i = fromIndex; i >= 0; i--) {
        if (!/\w/.test(text[i])) {
            return i + 1;
        }
    }
    return 0;
}
exports.reverseFindWordStartIndex = reverseFindWordStartIndex;
/** 查找是否是空字符. */
function isWhiteSpaceChar(char) {
    return ' \r\n\t'.includes(char);
}
exports.isWhiteSpaceChar = isWhiteSpaceChar;


/***/ }),

/***/ "./src/aegl/helpers/video-frames-extractor.ts":
/*!****************************************************!*\
  !*** ./src/aegl/helpers/video-frames-extractor.ts ***!
  \****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.VideoFramesExtractor = void 0;
const ffmpeg_1 = __webpack_require__(/*! ../../libs/ffmpeg/ffmpeg */ "./src/libs/ffmpeg/ffmpeg.ts");
const preload_1 = __webpack_require__(/*! ../../libs/util/preload */ "./src/libs/util/preload.ts");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
const debug_1 = __webpack_require__(/*! ../../libs/util/debug */ "./src/libs/util/debug.ts");
const mediabunny_1 = __webpack_require__(/*! mediabunny */ "../../../AppData/Roaming/npm/node_modules/mediabunny/dist/bundles/mediabunny.cjs");
const promise_1 = __webpack_require__(/*! ./promise */ "./src/aegl/helpers/promise.ts");
/**
 * 用于存储申请视频数据的指定帧.
 * 请注意此类同一时刻仅能供一个对象使用,
 * 而且对于帧的请求应该总体上连续.
 */
class VideoFramesExtractor extends ff_1.Emitter {
    /** 通过 ffmpeg 获取的多媒体信息. */
    mediaInfo;
    /** 是否导出 Alpha 通道. */
    extractAlphaChannel;
    /** 导出的图像格式. */
    imageFormat;
    /** 总的帧数目, 可能会被更新. */
    totalFrameCount;
    /** 增加一个时间偏移, 这样 js 的运算结果出现了 0.999999997 之类的情况也不会取帧出错. */
    timeOffset = 0.00000001;
    /** 已加载的视频帧数量. */
    loadedFrameCount = 0;
    /** 解析出的视频文件. */
    videoFile;
    /** 解析出的视频文件的蒙版. */
    alphaFile;
    /** 最近访问位置以及向后的图像缓存. */
    imageCache = new Map();
    /** 每组数据的状态信息. */
    groupState = [];
    /** 请求到的数据. */
    blobDatas = [];
    /**
     * 每个片段的长度, 单位为秒.
     * 1080P 下每张图约为 300KB, Alpha 图片很小, 一般不到 50KB.
     * 所以每秒最多 30 * 340KB = 10M.
     */
    segmentDuration = 1;
    /** 当前帧时刻. */
    time = 0;
    /** 初始化时刻, 单位为秒. */
    initializeTime = performance.now() / 1000;
    /** 是否在导出帧是发生错误, 例如手动取消了帧的导出. */
    errorHappens = null;
    /** To read each frame in order. */
    frameReader = null;
    alphaReader = null;
    /** 初始化完成时被 resolve. */
    ready;
    constructor(videoPath, imageFormat = 'jpeg', mayExtractAlphaChannel = false) {
        super();
        // 编码速度: BMP: 0.4x, JPEG: 0.33x, PNG: 0.08x, WEBP: 0.03x.
        // 大小: BMP: 50x, JPEG: 1x, PNG: 15x, WEBM: 0.7x.
        // 实测 bmp 不支持 alpha.
        this.extractAlphaChannel = mayExtractAlphaChannel;
        this.imageFormat = imageFormat;
        // 等待初始化.
        this.ready = this.initialize(videoPath);
    }
    /** 初始化. */
    async initialize(videoPath) {
        await this.initializeFF(videoPath);
        if (window.VideoDecoder) {
            this.frameReader = new PerFrameReader(this.videoFile.data, this.mediaInfo.video.frameRate);
            await this.frameReader.ready;
            if (this.extractAlphaChannel) {
                let alphaPath = videoPath.replace(/\.\w+$/, '-alpha$&');
                try {
                    this.alphaFile = await ffmpeg_1.ffmpeg.getFFFileFromPath(alphaPath);
                    this.alphaReader = new PerFrameReader(this.alphaFile.data, this.mediaInfo.video.frameRate);
                    await this.alphaReader.ready;
                }
                catch (err) { }
            }
        }
        else {
            this.initializeIdleTask();
        }
    }
    /** 初始化. */
    async initializeFF(videoPath) {
        let loadedOriginal = false;
        if (this.extractAlphaChannel && window.VideoDecoder) {
            let yuvPath = videoPath.replace(/\.\w+$/, '-yuv$&');
            try {
                this.videoFile = await ffmpeg_1.ffmpeg.getFFFileFromPath(yuvPath);
            }
            catch (err) {
                this.videoFile = await ffmpeg_1.ffmpeg.getFFFileFromPath(videoPath);
                loadedOriginal = true;
            }
        }
        else {
            this.videoFile = await ffmpeg_1.ffmpeg.getFFFileFromPath(videoPath);
            loadedOriginal = true;
        }
        this.mediaInfo = await ffmpeg_1.ffmpeg.getMediaInfo(this.videoFile);
        this.totalFrameCount = Math.ceil(this.mediaInfo.video.frameRate * this.mediaInfo.duration);
        // 根据多媒体信息检查图像是否包含 alpha 通道.
        if (this.extractAlphaChannel && loadedOriginal) {
            let colorSpace = this.mediaInfo.video.pixelFormat.replace(/\d+p/, '').toLowerCase();
            if (['yuv', 'rgb'].includes(colorSpace)) {
                this.extractAlphaChannel = false;
            }
        }
    }
    /** 初始化用于处理闲置任务的对象. */
    initializeIdleTask() {
        globalFrameExtractingTaskQueue = globalFrameExtractingTaskQueue || new FrameExtractingTaskQueue();
        let duration = this.mediaInfo.duration;
        let groupCount = Math.ceil(duration / this.segmentDuration);
        for (let index = 0; index < groupCount; index += 1) {
            // 计算此片段大致需要被加载的时间.
            let startTime = this.initializeTime + index * this.segmentDuration;
            this.groupState[index] = { promise: null, done: false };
            globalFrameExtractingTaskQueue.add(this, startTime, index);
        }
    }
    /** 获得当前时刻的帧. */
    async getCurrentFrame() {
        return await this.getFrameAtTime(this.time);
    }
    /** 获得视频某个时刻的帧数据构成的图片. */
    async getFrameAtTime(time) {
        time += this.timeOffset;
        time = (0, ff_1.constrain)(time, 0, this.mediaInfo.duration);
        if (this.frameReader) {
            let canvas = await this.frameReader.getFrameAt(time);
            let alpha = await this.alphaReader?.getFrameAt(time);
            this.loadedFrameCount += 1;
            this.emit('progress', this.loadedFrameCount);
            if (canvas) {
                return {
                    image: canvas.canvas,
                    alpha: alpha ? alpha.canvas : null,
                };
            }
        }
        let groupIndex = Math.min(Math.floor(time / this.segmentDuration), this.groupState.length - 1);
        await this.ensureFrameGroupData(groupIndex);
        let frameIndex = this.getFrameIndexFromTime(time);
        let frame = await this.getExistedFrame(frameIndex);
        // 清理过期的图片.
        this.clearStaleImages(frameIndex);
        // 加载完当前的图片之后预加载下一张图, 不等待.
        if (frameIndex + 1 < this.totalFrameCount) {
            this.preloadFrame(frameIndex + 1);
        }
        return frame;
    }
    /** 获得视频某个索引的帧数据构成的图片. */
    async getFrameAtIndex(index) {
        let time = index / this.mediaInfo.video.frameRate;
        return await this.getFrameAtTime(time);
    }
    /** 获得视频某个时刻的帧数据构成的图片. */
    async getBlobsAtTime(time) {
        time += this.timeOffset;
        time = (0, ff_1.constrain)(time, 0, this.mediaInfo.duration);
        let groupIndex = Math.min(Math.floor(time / this.segmentDuration), this.groupState.length - 1);
        await this.ensureFrameGroupData(groupIndex);
        let frameIndex = this.getFrameIndexFromTime(time);
        // 防止溢出右侧边界.
        frameIndex = this.limitExistedFrameIndex(frameIndex);
        return this.blobDatas[frameIndex];
    }
    /** 获得视频某个索引的帧数据构成的图片. */
    async getBlobsAtIndex(index) {
        let time = index / this.mediaInfo.video.frameRate;
        return await this.getBlobsAtTime(time);
    }
    /** 确保视频帧被加载. */
    async ensureFrameGroupData(groupIndex) {
        let state = this.groupState[groupIndex];
        if (state.promise) {
            await state.promise;
        }
        if (state.done) {
            return;
        }
        state.promise = this.extractGroupFrameDatas(groupIndex);
        await state.promise;
        state.done = true;
        state.promise = null;
    }
    /** 请求指定的组的帧数据. */
    async extractGroupFrameDatas(groupIndex) {
        debug_1.debug.verbose(`Extractor "${this.videoFile.name}" is extracting group ${groupIndex}...`);
        let startTime = groupIndex * this.segmentDuration;
        let endTime = Math.min(groupIndex + 1, this.mediaInfo.duration) * this.segmentDuration;
        let startIndex = this.getFrameIndexFromTime(startTime);
        let files = [this.videoFile];
        let lastLoaded = 0;
        // 对于 VP9 编码的透明视频, 必须手动指定输入编码才能导出透明图片.
        // codec 必须指定为 libvpx-vp9, Google 的 VP9 解码器不支持透明度.
        let codec = this.mediaInfo.video.codec;
        let inputCodecArgs = codec === 'vp9' ? ['-c:v', 'libvpx-vp9'] : [];
        // 质量 3 比质量 0 大约快 30%, 文件小 30%, 差别几乎难以察觉.
        let qualityArgs = this.imageFormat === 'jpeg' ? ['-q:v', 0] : [];
        // 输入参数.
        let inputArgs = [
            '-ss', startTime,
            '-to', endTime,
            ...inputCodecArgs,
            '-i', this.videoFile.name,
        ];
        // 图像输出.
        let imageOutputArgs = [
            ...qualityArgs,
            `%05d.${this.imageFormat}`,
        ];
        // Alpha 通道输出.
        let alphaOutputArgs = this.extractAlphaChannel ? [
            '-vf', 'alphaextract,format=yuv420p',
            ...qualityArgs,
            `%05d-alpha.${this.imageFormat}`,
        ] : [];
        let onProgress = (loaded) => {
            this.loadedFrameCount += loaded - lastLoaded;
            this.emit('progress', this.loadedFrameCount);
            lastLoaded = loaded;
        };
        let worker = await ffmpeg_1.ffmpeg.defaultWorkerGroup.request();
        let frameFiles = await worker.execWithProgress(files, [
            ...inputArgs,
            ...imageOutputArgs,
            ...alphaOutputArgs
        ], onProgress);
        let frameFilesBundleCount = this.extractAlphaChannel ? frameFiles.length / 2 : frameFiles.length;
        if (this.extractAlphaChannel) {
            for (let i = 0; i < frameFilesBundleCount; i++) {
                let imageBlob = new Blob([frameFiles[2 * i].data], { type: `image/${this.imageFormat}` });
                let alphaBlob = new Blob([frameFiles[2 * i + 1].data], { type: `image/${this.imageFormat}` });
                this.blobDatas[startIndex + i] = [imageBlob, alphaBlob];
            }
        }
        else {
            for (let i = 0; i < frameFilesBundleCount; i++) {
                let imageBlob = new Blob([frameFiles[i].data], { type: `image/${this.imageFormat}` });
                this.blobDatas[startIndex + i] = [imageBlob, null];
            }
        }
        debug_1.debug.verbose(`Extractor ${this.videoFile.name}" extracted group ${groupIndex}`);
    }
    /** 根据时间返回帧索引. */
    getFrameIndexFromTime(time) {
        let frameRate = this.mediaInfo.video.frameRate;
        return Math.floor(time * frameRate);
    }
    /** 尝试根据索引访问已加载的视频帧. */
    async getExistedFrame(frameIndex) {
        // 防止溢出右侧边界.
        frameIndex = this.limitExistedFrameIndex(frameIndex);
        if (this.imageCache.has(frameIndex)) {
            return await this.imageCache.get(frameIndex);
        }
        else if (this.blobDatas[frameIndex]) {
            return await this.parseFrameData(frameIndex);
        }
        else {
            return null;
        }
    }
    /** 限制 frameIndex 来防止溢出边界. */
    limitExistedFrameIndex(frameIndex) {
        return Math.min(frameIndex, this.blobDatas.length - 1);
    }
    /** 解析帧数据为图片. */
    async parseFrameData(frameIndex) {
        let [imageBlob, alphaBlob] = this.blobDatas[frameIndex];
        let imagePromise = (0, preload_1.preloadImage)(URL.createObjectURL(imageBlob));
        let alphaPromise = alphaBlob ? (0, preload_1.preloadImage)(URL.createObjectURL(alphaBlob)) : Promise.resolve(null);
        let promise = Promise.all([imagePromise, alphaPromise]).then(([image, alpha]) => {
            return { image, alpha };
        });
        this.imageCache.set(frameIndex, promise);
        return await promise;
    }
    /** 清理过期的图片资源. */
    async clearStaleImages(currentFrameIndex) {
        for (let index of [...this.imageCache.keys()]) {
            if (index < currentFrameIndex) {
                let { image, alpha } = await this.imageCache.get(index);
                if (image instanceof HTMLImageElement) {
                    URL.revokeObjectURL(image.src);
                }
                if (alpha && alpha instanceof HTMLImageElement) {
                    URL.revokeObjectURL(alpha.src);
                }
                this.imageCache.delete(index);
            }
        }
    }
    /** 预加载指定的索引位置的帧图片. */
    async preloadFrame(frameIndex) {
        await this.getExistedFrame(frameIndex);
    }
    /** 在闲置时运行任务, 并且等待其进入到 worker 序列. */
    async runIdleTask(index) {
        // 如果发生了导出帧错误, 那么之后不会再导出了.
        // 例如中止导出视频时触发的错误.
        if (this.errorHappens) {
            throw this.errorHappens;
        }
        // 捕获帧导出时的错误.
        this.ensureFrameGroupData(index).catch((err) => {
            if (!this.errorHappens) {
                this.errorHappens = err;
                this.delete();
            }
        });
        // 略微等待以便运行 micro task 并且让任务进入到 worker 序列中.
        await (0, ff_1.sleep)(0);
    }
    delete() {
        this.clearStaleImages(Infinity);
        globalFrameExtractingTaskQueue?.removeAllOf(this);
    }
}
exports.VideoFramesExtractor = VideoFramesExtractor;
/** 全局闲置视频帧导出对象. */
let globalFrameExtractingTaskQueue;
/** 由于导出视频帧非常耗时, 所以为了将 CPU 尽量填满, 在闲置时应当做帧导出. */
class FrameExtractingTaskQueue {
    /** 所有的任务. */
    tasks = [];
    /** 是否正在运行. */
    running = false;
    /** 添加一个任务. */
    add(extrator, startTime, groupIndex) {
        this.tasks.push({
            extrator,
            startTime,
            groupIndex,
        });
        // 由于任务已排序, 这里使用二分插入最合适, 不过由于任务数有限, 关系不大.
        this.tasks.sort((a, b) => a.startTime - b.startTime);
        if (!this.running) {
            this.run();
        }
    }
    /** 运行任务. */
    async run() {
        while (this.tasks.length > 0) {
            let task = this.tasks.shift();
            // 等到彻底闲置, 如果刚闲置就被其他线程占用就不抢占.
            while (!ffmpeg_1.ffmpeg.defaultWorkerGroup.isIdle()) {
                await ffmpeg_1.ffmpeg.defaultWorkerGroup.untilIdle();
                await (0, ff_1.sleep)(10);
            }
            await task.extrator.runIdleTask(task.groupIndex);
        }
        this.running = false;
    }
    /** 是否包含任务. */
    has(extrator, groupIndex) {
        return this.tasks.some(task => {
            return extrator === task.extrator && groupIndex === task.groupIndex;
        });
    }
    /** 移除一个任务. */
    remove(extrator, groupIndex) {
        (0, ff_1.removeWhere)(this.tasks, task => {
            return extrator === task.extrator && groupIndex === task.groupIndex;
        });
    }
    /** 移除一个 VideoFramesExtractor 的所有任务. */
    removeAllOf(extrator) {
        this.tasks = this.tasks.filter(task => {
            return extrator !== task.extrator;
        });
    }
    /** 从头部获得当前的任务. */
    shift() {
        return this.tasks.shift();
    }
}
class PerFrameReader {
    buffer;
    frameRate;
    ready;
    videoTrack;
    videoSink;
    videoSinkReader = null;
    currentCanvas = null;
    firstTimestamp = 0;
    gettingPromise = null;
    inLastFrame = false;
    constructor(buffer, frameRate) {
        this.buffer = buffer;
        this.frameRate = frameRate;
        this.ready = this.init();
    }
    async init() {
        let input = new mediabunny_1.Input({
            formats: [mediabunny_1.WEBM, mediabunny_1.MP4],
            source: new mediabunny_1.BufferSource(this.buffer)
        });
        this.videoTrack = (await input.getPrimaryVideoTrack());
        this.videoSink = new mediabunny_1.CanvasSink(this.videoTrack, { poolSize: 1 });
        this.firstTimestamp = await this.videoTrack.getFirstTimestamp();
    }
    async getFrameAt(time) {
        time = Math.max(time, this.firstTimestamp);
        await this.ready;
        // 如果两个相同时间的请求同时进入, 那么在第一个产生 seek, 但是未生成缓存的情况下,
        // 第二个将会缓存命中失败.
        if (this.gettingPromise) {
            await this.gettingPromise;
        }
        let pr = (0, promise_1.promiseWithResolves)();
        this.gettingPromise = pr.promise;
        let canvas = await this.gettingFrameAt(time);
        this.currentCanvas = canvas;
        this.gettingPromise = null;
        pr.resolve();
        return canvas;
    }
    async gettingFrameAt(time) {
        let currentCanvas = this.currentCanvas;
        if (currentCanvas && this.isCanvasOK(currentCanvas, time)) {
            return currentCanvas;
        }
        if (this.inLastFrame && currentCanvas && time >= currentCanvas.timestamp) {
            return currentCanvas;
        }
        if (this.videoSinkReader) {
            let canvas = await this.readFromVideoSinkReader(time);
            if (canvas) {
                return canvas;
            }
        }
        // Re-create reader.
        this.videoSinkReader = this.videoSink.canvases(time);
        this.inLastFrame = false;
        let canvas = await this.readFromVideoSinkReader(time);
        if (canvas) {
            return canvas;
        }
        // Reset reader.
        this.videoSinkReader = null;
        this.inLastFrame = false;
        canvas = await this.videoSink.getCanvas(time);
        return canvas;
    }
    async readFromVideoSinkReader(time) {
        let canvasInOrder = await this.videoSinkReader.next();
        if (!canvasInOrder.done) {
            let canvas = canvasInOrder.value;
            if (this.isCanvasOK(canvas, time)) {
                return canvas;
            }
            // Assume are generating 12fps video, and video asset are 60fps.
            if (time - canvas.timestamp > 0 && time - canvas.timestamp < 5 / this.frameRate) {
                while (!canvasInOrder.done && canvasInOrder.value.timestamp < time + 0.5 / this.frameRate) {
                    canvasInOrder = await this.videoSinkReader.next();
                    // Last frame.
                    if (canvasInOrder.done) {
                        this.inLastFrame = true;
                        return canvas;
                    }
                    canvas = canvasInOrder.value;
                    if (this.isCanvasOK(canvas, time)) {
                        return canvas;
                    }
                }
            }
        }
        return null;
    }
    isCanvasOK(canvas, time) {
        return Math.abs(canvas.timestamp - time) <= 0.5 / this.frameRate;
    }
}


/***/ }),

/***/ "./src/aegl/helpers/web-safe-fonts.ts":
/*!********************************************!*\
  !*** ./src/aegl/helpers/web-safe-fonts.ts ***!
  \********************************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.WebSafeFonts = void 0;
/** Web 安全字体. */
exports.WebSafeFonts = {
    // https://web.mit.edu/jmorzins/www/fonts.html
    'en-US': {
        common: [
            'Arial',
            'Arial Black',
            'Book Antiqua',
            'Charcoal',
            'Comic Sans MS',
            'Consolas',
            'Courier',
            'Courier New',
            'cursive',
            'Gadget',
            'Geneva',
            'Georgia',
            'Helvetica',
            'Impact',
            'Lucida Grande',
            'Lucida Sans Unicode',
            'Monaco',
            'Palatino',
            'Palatino Linotype',
            'sans-serif',
            'Tahoma',
            'Times',
            'Times New Roman',
            'Trebuchet MS',
            'Verdana',
        ]
    },
    // https://www.hellomagento2.com/web-fonts-chinese/
    'zh-CN': {
        win: [
            '黑体',
            '宋体',
            '新宋体',
            '仿宋',
            '楷体',
            '微软雅黑',
        ],
        mac: [
            '冬青黑体',
            '华文细黑',
            '华文黑体',
            '华文楷体',
            '华文宋体',
            '华文仿宋',
        ]
    }
};


/***/ }),

/***/ "./src/aegl/index.ts":
/*!***************************!*\
  !*** ./src/aegl/index.ts ***!
  \***************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.TemplateList = exports.ResourceLoader = exports.Footages = exports.ProjectData = exports.FontList = exports.VideoEncodingAnalyser = exports.VideoEncoder = exports.VideoEncoderOptions = exports.ProjectAspectRatio = exports.JSONManager = exports.ProjectRenderOptions = exports.ProjectEvents = exports.Project = exports.Renderer = void 0;
var renderer_1 = __webpack_require__(/*! ./renderer/renderer */ "./src/aegl/renderer/renderer.ts");
Object.defineProperty(exports, "Renderer", ({ enumerable: true, get: function () { return renderer_1.Renderer; } }));
var project_1 = __webpack_require__(/*! ./project/project */ "./src/aegl/project/project.ts");
Object.defineProperty(exports, "Project", ({ enumerable: true, get: function () { return project_1.Project; } }));
Object.defineProperty(exports, "ProjectEvents", ({ enumerable: true, get: function () { return project_1.ProjectEvents; } }));
Object.defineProperty(exports, "ProjectRenderOptions", ({ enumerable: true, get: function () { return project_1.ProjectRenderOptions; } }));
var json_manager_1 = __webpack_require__(/*! ./project/json-manager */ "./src/aegl/project/json-manager.ts");
Object.defineProperty(exports, "JSONManager", ({ enumerable: true, get: function () { return json_manager_1.JSONManager; } }));
Object.defineProperty(exports, "ProjectAspectRatio", ({ enumerable: true, get: function () { return json_manager_1.ProjectAspectRatio; } }));
var video_encoder_1 = __webpack_require__(/*! ./project/video-encoder */ "./src/aegl/project/video-encoder.ts");
Object.defineProperty(exports, "VideoEncoderOptions", ({ enumerable: true, get: function () { return video_encoder_1.VideoEncoderOptions; } }));
Object.defineProperty(exports, "VideoEncoder", ({ enumerable: true, get: function () { return video_encoder_1.FFVideoEncoder; } }));
Object.defineProperty(exports, "VideoEncodingAnalyser", ({ enumerable: true, get: function () { return video_encoder_1.VideoEncodingAnalyser; } }));
var fonts_list_1 = __webpack_require__(/*! ./helpers/fonts-list */ "./src/aegl/helpers/fonts-list.ts");
Object.defineProperty(exports, "FontList", ({ enumerable: true, get: function () { return fonts_list_1.FontList; } }));
var project_data_1 = __webpack_require__(/*! ./project/project-data */ "./src/aegl/project/project-data.ts");
Object.defineProperty(exports, "ProjectData", ({ enumerable: true, get: function () { return project_data_1.ProjectData; } }));
var footages_1 = __webpack_require__(/*! ./project/footages */ "./src/aegl/project/footages.ts");
Object.defineProperty(exports, "Footages", ({ enumerable: true, get: function () { return footages_1.Footages; } }));
var resource_loader_1 = __webpack_require__(/*! ./project/resource-loader */ "./src/aegl/project/resource-loader.ts");
Object.defineProperty(exports, "ResourceLoader", ({ enumerable: true, get: function () { return resource_loader_1.ResourceLoader; } }));
var template_list_1 = __webpack_require__(/*! ./project/template-list */ "./src/aegl/project/template-list.ts");
Object.defineProperty(exports, "TemplateList", ({ enumerable: true, get: function () { return template_list_1.TemplateList; } }));


/***/ }),

/***/ "./src/aegl/plugins/text-animaters/ac-8pr-overshoot.ts":
/*!*************************************************************!*\
  !*** ./src/aegl/plugins/text-animaters/ac-8pr-overshoot.ts ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
const base_1 = __webpack_require__(/*! ./base */ "./src/aegl/plugins/text-animaters/base.ts");
const ac_base_1 = __webpack_require__(/*! ./ac-base */ "./src/aegl/plugins/text-animaters/ac-base.ts");
class OvershootIn1106 extends ac_base_1.TextACBase {
    isIn = true;
    effectName = 'AC IN [8PR] Controls';
    initialize() {
        super.initialize();
    }
    /** 计算衰减弹簧运动的强度. */
    calcAmount(x) {
        // frequency 用于指定运动的周期数, 为 1 时运行一个正弦周期.
        let frequency = (this.effect.frequency || 100) / 100;
        // decay 指定振幅指数衰减的速度.
        let decay = (this.effect.decay || 40) / 10;
        // 获得正弦波振幅.
        let y = Math.cos(x * frequency * Math.PI * 2);
        // 最后衰减到的值.
        let lastRate = 1 / Math.exp(decay);
        // 当前衰减到的值.
        let rate = 1 / Math.exp(x * decay);
        // 将当前的衰减进行一个线性映射, 以确保最终值为 0.
        rate = (rate - lastRate) / (1 - lastRate);
        return y * rate;
    }
    rotation() {
        return this.effect.rotation || 0;
    }
    position() {
        return this.effect.position || [0, 0, 0];
    }
    scale() {
        return this.effect.scale || [0, 0, 0];
    }
    opacity() {
        return this.effect.opacity || 100;
    }
    trackingAmount() {
        return this.effect.tracking || -80;
    }
}
class OvershootOut1106 extends OvershootIn1106 {
    isIn = false;
    effectName = 'AC OUT [8PR] 2 Controls';
}
(0, base_1.registerTextAnimaterPlugin)('AC IN [8PR] Overshoot', OvershootIn1106);
(0, base_1.registerTextAnimaterPlugin)('AC OUT [8PR] Overshoot', OvershootOut1106);


/***/ }),

/***/ "./src/aegl/plugins/text-animaters/ac-base.ts":
/*!****************************************************!*\
  !*** ./src/aegl/plugins/text-animaters/ac-base.ts ***!
  \****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.TextACBase = void 0;
const base_1 = __webpack_require__(/*! ./base */ "./src/aegl/plugins/text-animaters/base.ts");
const random_1 = __webpack_require__(/*! ../../../libs/math/random */ "./src/libs/math/random.ts");
/** AC 系列插件文字动画的基类. */
class TextACBase extends base_1.TextAnimationPlugin {
    inTime = 0;
    outTime = 0;
    effect;
    /** 是否忽略随机的起始值. */
    ignoreRandomStartVal;
    initialize() {
        if (this.isIn) {
            this.inTime = this.getMarkerFromName('TR In').time;
        }
        else {
            this.outTime = this.getMarkerFromName('TR Out').time;
        }
        this.effect = this.getEffectFromName(this.effectName);
    }
    amount(textIndex, textTotal) {
        let timeRate;
        if (this.isIn) {
            timeRate = (this.time - this.data.inPoint) / (this.inTime - this.data.inPoint);
        }
        else {
            // 使用 1 减去是因为动画为逆向播放.
            timeRate = 1 - (this.time - this.outTime) / (this.data.outPoint - this.outTime);
        }
        return this.getAmountFromTimeRate(timeRate, textIndex, textTotal);
    }
    /** 从时刻百分比获得对应的值. */
    getAmountFromTimeRate(timeRate, textIndex, textTotal) {
        let seed = textIndex + (this.effect.randomSeed || 1);
        let effect = this.effect;
        // 重新调整当前文字顺序.
        let index = effect.reversedOrder ? textTotal - textIndex : textIndex;
        // 文字动画的延时时间百分比.
        let delayFactor = (effect.delay || 50) / 100 / textTotal;
        // 动画的播放时间.
        let playTimeRate = 1 - delayFactor * (textTotal - 1);
        // 如果设置了随机顺序, 则当前的文字顺序转为随机并且可能会相同.
        if (effect.randomizedOrder) {
            index = (0, random_1.seedRandom)(0, textTotal, seed);
        }
        // 当前文字动画的延时时间.
        let delayTimeRate = index * delayFactor;
        let x = (timeRate - delayTimeRate) / playTimeRate;
        let amount = 0;
        if (x > 1) {
            amount = 0;
        }
        else if (x < 0) {
            amount = 1;
        }
        else {
            amount = this.calcAmount(x);
        }
        let minStartValue = effect.randomStartValueMin || 100;
        let maxStartValue = effect.randomStartValueMax || 100;
        let startValue = this.ignoreRandomStartVal ? 100 : (0, random_1.seedRandom)(minStartValue, maxStartValue, seed);
        return startValue * amount;
    }
}
exports.TextACBase = TextACBase;


/***/ }),

/***/ "./src/aegl/plugins/text-animaters/ac-kpo-bounce.ts":
/*!**********************************************************!*\
  !*** ./src/aegl/plugins/text-animaters/ac-kpo-bounce.ts ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
const base_1 = __webpack_require__(/*! ./base */ "./src/aegl/plugins/text-animaters/base.ts");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
const ac_base_1 = __webpack_require__(/*! ./ac-base */ "./src/aegl/plugins/text-animaters/ac-base.ts");
class TextBounceIn1100 extends ac_base_1.TextACBase {
    isIn = true;
    effectName = 'AC IN [KPO] Controls';
    initialize() {
        super.initialize();
        let forRotation = this.animater.properties.hasOwnProperty('rotation');
        this.ignoreRandomStartVal = !forRotation;
    }
    /** 计算弹性产生的运动强度. */
    calcAmount(x) {
        // elasticity 用于指定弹过之后速度相比之前速度的比例.
        let elasticity = (this.effect.elasticity || 70) / 100;
        // maxBounces 指定最大的弹跳次数.
        let maxBounces = this.effect.maxBounces || 10;
        // 计算总共的弹起时间相比于第一次弹起的比例.
        // 第一次只有下落半个周期.
        let timeCosts = [0.5];
        for (let i = 1; i < maxBounces; i++) {
            // 每次弹起的时间为 2v/g, 与速度成正比.
            let timeOfRound = Math.pow(elasticity, i);
            timeCosts.push(timeOfRound);
            // 很小的时间没有实际意义.
            if (timeOfRound < 0.01) {
                break;
            }
        }
        // 将每一轮的时间消耗转换为比例.
        let totalTimeCost = (0, ff_1.sum)(timeCosts);
        timeCosts = timeCosts.map(v => v / totalTimeCost);
        // 累积弹跳时间以及归属第几轮弹跳.
        let timeCosted = 0;
        let roundIndex = 0;
        let xOfRound = 0;
        for (let i = 0; i < maxBounces; i++) {
            let timeOfRound = timeCosts[i];
            if (timeCosted + timeOfRound >= x) {
                roundIndex = i;
                xOfRound = (x - timeCosted) / timeOfRound;
                break;
            }
            else {
                timeCosted += timeOfRound;
            }
        }
        // 将下落的后半个周期的比例映射到整个周期.
        if (roundIndex === 0) {
            xOfRound = 0.5 * xOfRound + 0.5;
        }
        // 每一次弹跳的高度按照 elasticity^2 衰减.
        let maxHeightOfRound = Math.pow(elasticity, 2 * roundIndex);
        // 穿过 (0, 0), (0.5, 1), (1, 0) 的函数.
        return maxHeightOfRound * (1 - 4 * Math.pow(xOfRound - 0.5, 2));
    }
    rotation() {
        return this.effect.rotation || 121;
    }
    position() {
        return this.effect.position || [0, -300, 0];
    }
    scale() {
        return this.effect.scale || [0, 0, 0];
    }
    opacity() {
        return this.effect.opacity || 0;
    }
}
class BounceOut1100 extends TextBounceIn1100 {
    isIn = false;
    effectName = 'AC OUT [KPO] 2 Controls';
}
(0, base_1.registerTextAnimaterPlugin)('AC IN [KPO] Bounce', TextBounceIn1100);
(0, base_1.registerTextAnimaterPlugin)('AC OUT [KPO] Bounce', BounceOut1100);


/***/ }),

/***/ "./src/aegl/plugins/text-animaters/all.ts":
/*!************************************************!*\
  !*** ./src/aegl/plugins/text-animaters/all.ts ***!
  \************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
__webpack_require__(/*! ./ac-kpo-bounce */ "./src/aegl/plugins/text-animaters/ac-kpo-bounce.ts");
__webpack_require__(/*! ./ac-8pr-overshoot */ "./src/aegl/plugins/text-animaters/ac-8pr-overshoot.ts");


/***/ }),

/***/ "./src/aegl/plugins/text-animaters/base.ts":
/*!*************************************************!*\
  !*** ./src/aegl/plugins/text-animaters/base.ts ***!
  \*************************************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.getTextAnimaterPlugin = exports.registerTextAnimaterPlugin = exports.TextAnimationPlugin = void 0;
class TextAnimationPlugin {
    /** 对应的 Animater. */
    animater;
    /** 当前层的数据. */
    data;
    /** 设置当前的时刻. */
    time = 0;
    constructor(textLayerData, animater) {
        this.data = textLayerData;
        this.animater = animater;
    }
    /** 从名称获得对应的特效数据. */
    getEffectFromName(name) {
        return this.data.effects.find(effect => effect.name === name);
    }
    /** 从名称获得对应的特效数据. */
    getMarkerFromName(name) {
        return this.data.markers.find(marker => marker.comment === name);
    }
    /** 更新当前的时刻. */
    updateTime(time) {
        this.time = time;
    }
    amount(_textIndex, _textTotal) {
        return 0;
    }
    anchorPoint(_textIndex, _textTotal) {
        return [0, 0, 0];
    }
    position(_textIndex, _textTotal) {
        return [0, 0, 0];
    }
    scale(_textIndex, _textTotal) {
        return [0, 0, 0];
    }
    skew(_textIndex, _textTotal) {
        return 0;
    }
    skewAxis(_textIndex, _textTotal) {
        return 0;
    }
    rotation(_textIndex, _textTotal) {
        return 0;
    }
    xRotation(_textIndex, _textTotal) {
        return 0;
    }
    yRotation(_textIndex, _textTotal) {
        return 0;
    }
    zRotation(_textIndex, _textTotal) {
        return 0;
    }
    opacity(_textIndex, _textTotal) {
        return 0;
    }
    trackingAmount(_textIndex, _textTotal) {
        return 0;
    }
}
exports.TextAnimationPlugin = TextAnimationPlugin;
/** 存储所有的文字动画插件. */
const TextAnimaterPlugins = new Map();
/** 注册用于运行文字动画表达式的插件. */
function registerTextAnimaterPlugin(name, Plugin) {
    TextAnimaterPlugins.set(name, Plugin);
}
exports.registerTextAnimaterPlugin = registerTextAnimaterPlugin;
/** 根据名称获得插件. */
function getTextAnimaterPlugin(name) {
    // 名称经常会以 `name 1`, `name 2` 的形式出现, 所以这里去除了其中的数字.
    name = name.replace(/\s+\d\s*/g, ' ').trim();
    let Plugin = TextAnimaterPlugins.get(name);
    if (!Plugin) {
        throw new Error(`No plugin with name ${name} exist!`);
    }
    return Plugin;
}
exports.getTextAnimaterPlugin = getTextAnimaterPlugin;


/***/ }),

/***/ "./src/aegl/project/footages.ts":
/*!**************************************!*\
  !*** ./src/aegl/project/footages.ts ***!
  \**************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Footages = void 0;
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
/** 用于检查, 搜寻和统计素材的信息, 包括用户素材和模板素材. */
class Footages {
    static GraphicFileAccepts = [
        '.mp4',
        '.jpeg',
        '.jpg',
        '.png',
        '.bmp',
        '.webp',
    ].join(',');
    static AudioFileAccepts = [
        '.mp3',
        '.ogg',
    ].join(',');
    /** 当前项目. */
    project;
    constructor(project) {
        this.project = project;
    }
    /**
     * 获得总的视频素材的帧数目.
     * 请注意它只是一个粗略的估计, 没有考虑一个视频被包含于合成层然后再度经过场景裁剪的情况.
     */
    getTotalVideoFrames() {
        let videoFootages = this.filterFootageLayers(l => l.type === 'video' && !l.hidden);
        let count = 0;
        for (let layerData of videoFootages) {
            let { frameRate, inPoint, outPoint } = layerData;
            let duration = outPoint - inPoint;
            count += duration * (frameRate || 30);
        }
        return count;
    }
    /** 过滤素材层, 并且对于同样的 path 的层只会返回一个. */
    filterFootageLayers(fn) {
        let pathSet = new Set();
        return this.project.data.getAllPlainLayerDatas().filter(layer => {
            if (!fn(layer)) {
                return false;
            }
            let path = layer.path;
            if (path && !pathSet.has(path)) {
                pathSet.add(path);
                return true;
            }
            return false;
        });
    }
    /** 检查不可替换的图片或者视频素材的最大高度, 没有的话返回 0. 如果包含此类素材并且比较小, 那么渲染 4K 的视频可能不太合适. */
    getTemplateFootageHeight() {
        let allLayers = this.project.data.getAllPlainLayerDatas();
        let hasTemplateFootage = allLayers.some(l => {
            return l.replaceable !== true && (l.type === 'video' || l.type === 'image');
        });
        return hasTemplateFootage ? this.project.data.height : 0;
    }
    /** 检查可替换的图片或者视频素材的平均高度, 如果高度为 1080, 那么渲染 4K 的视频将会不太合适. */
    getUserFootageHeight() {
        let userFootages = this.filterFootageLayers(l => {
            return l.replaceable === true && (l.type === 'video' || l.type === 'image');
        });
        let mediaHeights = userFootages.map(l => l.mediaHeight);
        return (0, ff_1.avg)(mediaHeights);
    }
    /** 检查不可替换的素材的最小帧率, 如果不包含此类素材, 则返回 0. */
    getTemplateVideoFrameRate() {
        let videoFootages = this.filterFootageLayers(l => {
            return l.replaceable !== true && l.type === 'video';
        });
        let frameRates = videoFootages.map(l => l.frameRate);
        return videoFootages.length > 0 ? Math.min(...frameRates) : 0;
    }
    /** 检查用户素材的平均帧率, 如果不包含此类素材, 则返回 0. */
    getUserVideoFrameRate() {
        let videoFootages = this.filterFootageLayers(l => {
            return l.replaceable === true && l.type === 'video';
        });
        let frameRates = videoFootages.map(l => l.frameRate);
        return (0, ff_1.avg)(frameRates);
    }
    /** 查找可替换的音频数据. */
    getReplaceableAudioLayerData() {
        return this.project.data.getAllPlainLayerDatas()
            .find(l => l.type === 'audio' && l.replaceable);
    }
    /** 查找可循环的层, 这些层不会被场景剪切. */
    getLoopLayerDatas() {
        return this.project.data.getAllPlainLayerDatas().filter(l => {
            return l.type === 'audio' && l.replaceable
                || l.type === 'video' && l.loop;
        });
    }
    /** 获得当前模板中包含的所有字体. */
    getIncludedFontFamilies() {
        let allTextLayers = this.project.data.getAllPlainLayerDatas()
            .filter(l => l.type === 'text');
        return (0, ff_1.unique)(allTextLayers.map(l => l.fontFamily));
    }
    /** 获得素材的平均宽高比. */
    getAverageAspectRatio() {
        let allMediaLayers = this.filterFootageLayers(l => {
            return l.type === 'image' || l.type === 'video';
        });
        let aspectRatios = allMediaLayers
            .map(l => l.mediaWidth / l.mediaHeight);
        // 取对数做平均, 以防止一个 1x5 的图片把其他 4 个图片掩盖了.
        return Math.pow(Math.E, (0, ff_1.avg)(aspectRatios.map(v => Math.log(v))));
    }
    /** 获取封面图片路径. */
    getCoverPath() {
        if (this.project.data.cover) {
            return this.project.resourceLoader.getAbsolutePath(this.project.data.cover);
        }
        else {
            return null;
        }
    }
    /** 获取封底图片路径. */
    getBackCoverPath() {
        if (this.project.data.backCover) {
            return this.project.resourceLoader.getAbsolutePath(this.project.data.backCover);
        }
        else {
            return null;
        }
    }
}
exports.Footages = Footages;


/***/ }),

/***/ "./src/aegl/project/json-manager.ts":
/*!******************************************!*\
  !*** ./src/aegl/project/json-manager.ts ***!
  \******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.JSONManager = void 0;
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
const property_1 = __webpack_require__(/*! ../property/property */ "./src/aegl/property/property.ts");
const timestamp_1 = __webpack_require__(/*! ../../libs/util/timestamp */ "./src/libs/util/timestamp.ts");
const resolution_1 = __webpack_require__(/*! ../helpers/resolution */ "./src/aegl/helpers/resolution.ts");
/**
 * 用于加载某个工程的不同分辨率的 JSON 文件, 以及管理这些数据.
 * 它不负责和具体的某个 Project 连接.
 * 此外还负责响应对于不同的分辨率的数据的请求.
 */
class JSONManager {
    /** 所支持的宽高比以及对应的分辨率. */
    static AllAspectRatios = {
        '16x9': [1920, 1080],
        '1x1': [1000, 1000],
        '9x16': [1080, 1920],
    };
    /** 当前所所支持的宽高比以及对应的分辨率. */
    currentAspectRatios = {};
    /** 当前渲染项目的 id. */
    id;
    /** 根目录, 包含 templates 和 fonts 等文件夹. */
    rootDirectory;
    /** 总的 JSON 数据, 可能包含多种分辨率. */
    json;
    /** 当资源加载后被 resolve. */
    ready;
    constructor(id, directory = 'aegl') {
        this.id = id;
        this.rootDirectory = directory;
        this.ready = this.load();
    }
    /** 加载数据. */
    async load() {
        let jsonPath = (0, timestamp_1.addTimestamp)(`${this.rootDirectory}/templates/${this.id}/${this.id}.json`);
        this.json = await (await fetch(jsonPath)).json();
        this.initializeCurrentAspectRatios();
    }
    /** 初始化所支持的宽高比. */
    initializeCurrentAspectRatios() {
        if (this.json.supportsSyntheticAspectRatios || this.json.supportsSyntheticAspectRatios === undefined) {
            this.currentAspectRatios = JSONManager.AllAspectRatios;
        }
        else {
            let currentAspectRatios = [];
            for (let project of this.json.projects) {
                let aspectRatio = (0, resolution_1.getAspectRatioFromResolution)(project.height);
                currentAspectRatios.push(aspectRatio);
            }
            for (let aspectRatio of Object.keys(JSONManager.AllAspectRatios)) {
                if (currentAspectRatios.includes(aspectRatio)) {
                    this.currentAspectRatios[aspectRatio] = JSONManager.AllAspectRatios[aspectRatio];
                }
            }
        }
    }
    /** 请求一个指定的分辨率的数据. */
    requestProjectData(aspectRatio) {
        let [width, height] = JSONManager.AllAspectRatios[aspectRatio];
        let data;
        // 查询刚好尺寸相等或者宽高比相等的.
        let rawData = this.json.projects.find(data => data.width === width && data.height === height);
        // 查询到了对应的分辨率的项目数据. 拷贝以防污染源数据.
        if (rawData) {
            data = (0, ff_1.deepClone)(rawData);
        }
        else {
            // 获得最接近的宽高比的数据. 拷贝以防污染源数据.
            let closestData = (0, ff_1.deepClone)(this.getClosestRatioProjectData(width / height));
            data = this.adjustViewportSize(closestData, width, height);
        }
        // 拷贝数据节点.
        data.id = this.json.id;
        data.name = this.json.name;
        data.cover = this.json.cover;
        data.coverAtSecond = this.json.coverAtSecond;
        data.backCover = this.json.backCover;
        return data;
    }
    /** 获得和指定的宽高比最接近的数据. */
    getClosestRatioProjectData(aspectRatio) {
        // 计算宽高比例和 aspectRatio 参数的比值的差.
        let ratioDiffs = this.json.projects.map(data => {
            let r = data.width / data.height / aspectRatio;
            if (r >= 1) {
                return r - 1;
            }
            else {
                return 1 / r - 1;
            }
        });
        let minDiffIndex = (0, ff_1.minIndex)(ratioDiffs);
        return this.json.projects[minDiffIndex];
    }
    /** 将当前的渲染数据调整为另一个尺寸, 宽高以及位置信息将会等比例缩放. */
    adjustViewportSize(data, width, height) {
        let scaleX = width / data.width;
        let scaleY = height / data.height;
        data.width = Math.round(data.width * scaleX);
        data.height = Math.round(data.height * scaleY);
        let allLayerDatas = [
            ...data.layers,
            ...data.compItems.map(c => c.layers).flat()
        ];
        for (let layerData of allLayerDatas) {
            this.scaleLayer(layerData, scaleX, scaleY);
        }
        return data;
    }
    /** 缩放单个层. */
    scaleLayer(layerData, scaleX, scaleY) {
        // 调整层的属性.
        // 这里设置 mediaWidth 和 mediaHeight 的原因是项目初始化时会从 width 和 height 初始化他们,
        // 所以如果使用缩放后的 width 和 height, 会造成这些数据错误.
        if (layerData.width) {
            layerData.mediaWidth = layerData.mediaWidth || layerData.width;
            layerData.width = this.scaleProperty(layerData.width, scaleX, scaleX);
        }
        if (layerData.height) {
            layerData.mediaHeight = layerData.mediaHeight || layerData.height;
            layerData.height = this.scaleProperty(layerData.height, scaleY, scaleY);
        }
        switch (layerData.type) {
            // 调整摄影机层.
            case 'camera':
                this.scaleCameraLayer(layerData, scaleX, scaleY);
                break;
            // 调整形状的变换, 他们的大小属性不变.
            case 'text':
                this.scaleTextLayer(layerData, scaleX, scaleY);
                break;
            // 调整形状的变换, 他们的大小属性不变.
            case 'shape':
                this.scaleShapeLayer(layerData, scaleX, scaleY);
                break;
        }
        // 调整变换.
        if (layerData.transform) {
            this.scaleTransform(layerData.transform, scaleX, scaleY);
        }
        // 调整效果.
        let effects = layerData.effects;
        if (effects) {
            this.scaleEffects(effects, scaleX, scaleY);
        }
    }
    /** 调整摄影机层. */
    scaleCameraLayer(layerData, scaleX, scaleY) {
        // 等比例调整.
        for (let key of ['zoom', 'focusDistance']) {
            if (layerData[key]) {
                layerData[key] = this.scaleProperty(layerData[key], scaleX, scaleY);
            }
        }
    }
    /** 调整形状层. */
    scaleTextLayer(layerData, scaleX, scaleY) {
        // 非拉伸调整.
        for (let key of ['fontSize', 'tracking', 'strokeWidth']) {
            if (layerData[key]) {
                layerData[key] = this.scaleProperty(layerData[key], Math.sqrt(scaleX * scaleY));
            }
        }
        // 等比例调整.
        for (let key of ['boxTextSize']) {
            if (layerData[key]) {
                layerData[key] = this.scaleProperty(layerData[key], scaleX, scaleY);
            }
        }
        // 稍微调整文本层的 y 坐标, 以将重新映射的 y 坐标的中点进行对齐, 而不是默认情况下的基线.
        if (layerData.transform && layerData.transform.position) {
            if (layerData.transform.position && typeof layerData.fontSize === 'number') {
                // 实测这个移动比率在 0.1 左右.
                this.moveProperty(layerData.transform.position, 0, (1 - scaleY) * layerData.fontSize * 0.08);
            }
        }
        if (layerData.animaters) {
            for (let animater of layerData.animaters) {
                if (animater.properties) {
                    this.scaleTransform(animater.properties, Math.sqrt(scaleX * scaleY));
                }
            }
        }
    }
    /** 调整形状层. */
    scaleShapeLayer(layerData, scaleX, scaleY) {
        for (let content of layerData.contents) {
            if (content.transform) {
                this.scaleTransform(content.transform, scaleX, scaleY);
            }
            // 调整矩形, 相比之下圆形不作调整.
            if (content.type === 'rect') {
                content.size = this.scaleProperty(content.size, scaleX, scaleY);
            }
        }
    }
    /** 调整 transform 属性. */
    scaleTransform(transform, scaleX, scaleY = scaleX) {
        if (transform) {
            for (let key of ['anchorPoint', 'position', 'pointOfInterest']) {
                if (transform[key]) {
                    transform[key] = this.scaleProperty(transform[key], scaleX, scaleY);
                }
            }
        }
    }
    /** 缩放特效. */
    scaleEffects(effects, scaleX, scaleY = scaleX) {
        for (let effect of effects) {
            for (let key of ['horizontalRadius']) {
                if (effect[key]) {
                    effect[key] = this.scaleProperty(effect[key], scaleX);
                }
            }
            for (let key of ['verticalRadius']) {
                if (effect[key]) {
                    effect[key] = this.scaleProperty(effect[key], scaleY);
                }
            }
            for (let key of ['anchorPoint', 'position', 'tileCenter', 'bulgeCenter']) {
                if (effect[key]) {
                    effect[key] = this.scaleProperty(effect[key], scaleX, scaleY);
                }
            }
            // 更换分辨率之后, 很可能出现 tile 不够大无法遮住画面的问题.
            if (effect.type === 'tile') {
                effect.outputWidth = effect.outputHeight = Math.max(effect.outputWidth || 100, effect.outputHeight || 100);
            }
        }
    }
    /** 缩放属性. */
    scaleProperty(propertyValue, scaleX, scaleY = scaleX) {
        if ((0, property_1.isPropertyValueBeKeyFrames)(propertyValue)) {
            for (let i = 0; i < propertyValue.length; i++) {
                let o = propertyValue[i];
                o.value = this.scaleValue(o.value, scaleX, scaleY);
            }
        }
        else {
            propertyValue = this.scaleValue(propertyValue, scaleX, scaleY);
        }
        return propertyValue;
    }
    /** 缩放值. */
    scaleValue(value, scaleX, scaleY) {
        if (Array.isArray(value)) {
            if (value.length > 0) {
                value[0] *= scaleX;
            }
            if (value.length > 1) {
                value[1] *= scaleY;
            }
            if (value.length > 2) {
                value[2] *= Math.max(scaleX, scaleY);
            }
        }
        else {
            // 缩放 XY 的较大值, 其相当于进行 cover 布局然后裁剪.
            value *= Math.max(scaleX, scaleY);
        }
        return value;
    }
    /** 移动属性. */
    moveProperty(propertyValue, moveX, moveY) {
        if ((0, property_1.isPropertyValueBeKeyFrames)(propertyValue)) {
            for (let i = 0; i < propertyValue.length; i++) {
                let o = propertyValue[i];
                o.value = this.moveValue(o.value, moveX, moveY);
            }
        }
        else {
            propertyValue = this.moveValue(propertyValue, moveX, moveY);
        }
        return propertyValue;
    }
    /** 移动值. */
    moveValue(value, moveX, moveY) {
        if (Array.isArray(value)) {
            if (value.length > 0) {
                value[0] += moveX;
            }
            if (value.length > 1) {
                value[1] += moveY;
            }
        }
        else {
            throw new Error(`Can't move not array type of value ${value}!`);
        }
        return value;
    }
}
exports.JSONManager = JSONManager;


/***/ }),

/***/ "./src/aegl/project/project-data.ts":
/*!******************************************!*\
  !*** ./src/aegl/project/project-data.ts ***!
  \******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ProjectData = void 0;
const util_1 = __webpack_require__(/*! ../../libs/webgl/util */ "./src/libs/webgl/util.ts");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
/** 用于管理项目数据. */
class ProjectData {
    /** 项目 id. */
    id;
    /** 项目名称, 和 AE 中的顶层名称保持一致. */
    name;
    /** 封面. */
    cover;
    /** 封面在整个模板时长的第几秒. */
    coverAtSecond;
    /** 封底. */
    backCover;
    /** 是否支持合成为多分辨率数据. */
    supportsSyntheticAspectRatios;
    /** 分辨率宽. */
    width;
    /** 分辨率高. */
    height;
    /** 项目的长度, 单位秒. */
    duration;
    /** 包含的所有的顶层. */
    layers;
    /** 项目的包含的所有子合成层. */
    compItems;
    /** 包含了所有的合成层, 便于通过 id 访问. */
    compItemMap;
    /** 包含了初始的时候的所有的合成层 id, 其对应层不可被删除. */
    startCompItemIds;
    /** 记录层排列的初始顺序. */
    layerRawOrder;
    constructor(json) {
        this.setData(json);
    }
    /** 获取当前宽高比. */
    get aspectRatio() {
        return this.width / this.height;
    }
    /** 设置或者重设置数据. */
    setData(jsonData) {
        Object.assign(this, jsonData);
        this.initializeIds();
        this.initializeMediaProperties();
        this.initializeCompItemMap();
        this.initializeLayerRawOrder();
    }
    /** 拷贝 JSON 数据, 用于进行数据备份. */
    cloneData() {
        let keys = [
            'id',
            'name',
            'width',
            'height',
            'duration',
            'layers',
            'compItems',
        ];
        return (0, ff_1.deepClone)((0, ff_1.assign)({}, this, keys));
    }
    /** 为每个层和特效添加唯一的 id. */
    initializeIds() {
        for (let layer of this.getAllPlainLayerDatas()) {
            if (!layer.id) {
                layer.id = (0, util_1.generateUniqueID)();
            }
            // 添加原始 id.
            layer.rawId = layer.id;
            // 为渲染特效增加一个唯一 id. 因为这些特效会使用 Effect 类进行渲染, 并且会加载资源.
            if (layer.effects) {
                for (let effectData of layer.effects) {
                    effectData.id = (0, util_1.generateUniqueID)();
                }
            }
            // 为形状层的一些特效添加 id.
            if (layer.type === 'shape') {
                let layerStyle = layer.layerStyle;
                if (layerStyle && layerStyle.dropShadow) {
                    layerStyle.dropShadow.id = (0, util_1.generateUniqueID)();
                }
            }
        }
    }
    /** 为多媒体层生成需要的 mediaWidth 和 mediaHeight 节点. */
    initializeMediaProperties() {
        for (let layer of this.getAllPlainLayerDatas()) {
            if (layer.type === 'video' || layer.type === 'image') {
                if (!layer.mediaWidth) {
                    layer.mediaWidth = layer.width;
                }
                if (!layer.mediaHeight) {
                    layer.mediaHeight = layer.height;
                }
                if (!layer.mediaPosition) {
                    layer.mediaPosition = [0.5, 0.5];
                }
            }
        }
    }
    /** 创建 compItems 的 id 映射. */
    initializeCompItemMap() {
        this.compItemMap = new Map();
        this.startCompItemIds = new Set();
        for (let item of this.compItems) {
            this.compItemMap.set(item.id, item);
            this.startCompItemIds.add(item.id);
        }
    }
    /** 记录层排列的初始顺序. */
    initializeLayerRawOrder() {
        this.layerRawOrder = new Map();
        for (let i = 0; i < this.layers.length; i++) {
            let layer = this.layers[i];
            this.layerRawOrder.set(layer.rawId, i);
        }
    }
    /** 获得项目的扁平化的所有层. */
    getAllPlainLayerDatas() {
        let compItems = this.compItems;
        let compLayers = compItems.map(item => item.layers).flat();
        return [...this.layers, ...compLayers];
    }
    /** 从 id 获得对应的合成. */
    getCompItemFromId(compId) {
        return this.compItemMap.get(compId);
    }
    /** 从合成层获得其子层. */
    getCompLayersFromId(compId) {
        return this.compItemMap.get(compId).layers;
    }
    /** 深度克隆层数据, 允许链接相同的合成层, 但是必须保持 diffLayers 中的层数据相异. */
    deepCloneLayerData(layerData, diffLayerIds, layerIdMap) {
        return this.deepCloneLayerDataRecursively(layerData, diffLayerIds, layerIdMap);
    }
    /** 递归克隆. */
    deepCloneLayerDataRecursively(layerData, diffLayerIds, layerIdMap) {
        if (layerData.type === 'composite' && this.isLayerIncludeLayers(layerData, diffLayerIds)) {
            return this.deepCloneCompLayerDatas(layerData, diffLayerIds, layerIdMap);
        }
        else {
            return this.cloneLayerData(layerData, layerIdMap);
        }
    }
    /** 检查层的树结构数据内部是否包含有指定的层数据. */
    isLayerIncludeLayers(layerData, childLayerIds) {
        if (layerData.type === 'composite') {
            let childLayerDatas = this.getCompItemFromId(layerData.compItemId).layers;
            return childLayerDatas.some(layerData => this.isLayerIncludeLayers(layerData, childLayerIds));
        }
        else {
            return childLayerIds.includes(layerData.id);
        }
    }
    /** 克隆合成层包含其子层的数据, 其 id 和 compItemId 会被重设. */
    deepCloneCompLayerDatas(compLayerData, diffLayerIds, layerIdMap) {
        let compItem = this.getCompItemFromId(compLayerData.compItemId);
        let cloned = this.cloneLayerData(compLayerData, layerIdMap);
        // 如果已被克隆过.
        if (layerIdMap.has(compItem.id)) {
            cloned.compItemId = layerIdMap.get(compItem.id);
            return cloned;
        }
        let clonedCompItem = Object.assign({}, compItem);
        clonedCompItem.id = (0, util_1.generateUniqueID)();
        cloned.compItemId = clonedCompItem.id;
        layerIdMap.set(compItem.id, clonedCompItem.id);
        clonedCompItem.layers = compItem.layers.map(layer => {
            let newLayer = this.deepCloneLayerDataRecursively(layer, diffLayerIds, layerIdMap);
            layerIdMap.set(layer.id, newLayer.id);
            if (newLayer.type === 'composite') {
                layerIdMap.set(layer.compItemId, newLayer.compItemId);
            }
            return newLayer;
        });
        // 替换掉父层 id.
        for (let layer of clonedCompItem.layers) {
            if (layer.parentId) {
                layer.parentId = layerIdMap.get(layer.parentId);
            }
        }
        // 添加合成层.
        this.compItemMap.set(clonedCompItem.id, clonedCompItem);
        this.compItems.push(clonedCompItem);
        return cloned;
    }
    /** 克隆层数据, 其 id 会被重设. */
    cloneLayerData(layerData, layerIdMap) {
        let cloned = (0, ff_1.deepClone)(layerData);
        cloned.id = (0, util_1.generateUniqueID)();
        cloned.rawId = layerData.rawId;
        if (layerIdMap) {
            layerIdMap.set(layerData.id, cloned.id);
        }
        return cloned;
    }
    /** 将层插入到最外层的 layers 数组中. */
    insertRootLayerData(layerData) {
        this.layers.push(layerData);
    }
    /** 排序最外层的 layers 数组. */
    orderRootLayerData() {
        this.layers.sort((l1, l2) => {
            let l1Order = this.layerRawOrder.get(l1.rawId);
            let l2Order = this.layerRawOrder.get(l2.rawId);
            if (l1Order === l2Order) {
                return l1.inPoint - l2.inPoint;
            }
            else {
                return l1Order - l2Order;
            }
        });
    }
    /** 如果层应当有 timeRemap, 则为其设置. */
    ensureTimeRemap(layerData) {
        if ((layerData.type === 'video' || layerData.type === 'composite') && !layerData.timeRemap) {
            let { inPoint, outPoint } = layerData;
            layerData.timeRemap = [
                { time: inPoint, value: 0 },
                { time: outPoint, value: outPoint - inPoint },
            ];
        }
    }
    /** 清除无引用的合成层. */
    clearUnReferencedCompItems() {
        let allCompLayers = this.getAllPlainLayerDatas().filter(l => l.type === 'composite');
        let referencedCompItemIds = new Set(allCompLayers.map(l => l.compItemId));
        let notReferencedCompItemIds = new Set();
        for (let compItemId of this.compItemMap.keys()) {
            if (!referencedCompItemIds.has(compItemId) && !this.startCompItemIds.has(compItemId)) {
                this.compItemMap.delete(compItemId);
                notReferencedCompItemIds.add(compItemId);
            }
        }
        this.compItems = this.compItems.filter(compItem => {
            return !notReferencedCompItemIds.has(compItem.id);
        });
    }
}
exports.ProjectData = ProjectData;


/***/ }),

/***/ "./src/aegl/project/project.ts":
/*!*************************************!*\
  !*** ./src/aegl/project/project.ts ***!
  \*************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Project = void 0;
const renderer_1 = __webpack_require__(/*! ../renderer/renderer */ "./src/aegl/renderer/renderer.ts");
const resource_loader_1 = __webpack_require__(/*! ./resource-loader */ "./src/aegl/project/resource-loader.ts");
const timeline_1 = __webpack_require__(/*! ./timeline */ "./src/aegl/project/timeline.ts");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
const simple_webgl_1 = __webpack_require__(/*! ../../libs/webgl/simple-webgl */ "./src/libs/webgl/simple-webgl.ts");
const keyframe_1 = __webpack_require__(/*! ../property/keyframe */ "./src/aegl/property/keyframe.ts");
const property_1 = __webpack_require__(/*! ../property/property */ "./src/aegl/property/property.ts");
const footages_1 = __webpack_require__(/*! ./footages */ "./src/aegl/project/footages.ts");
const project_data_1 = __webpack_require__(/*! ./project-data */ "./src/aegl/project/project-data.ts");
const text_1 = __webpack_require__(/*! ../property/text */ "./src/aegl/property/text.ts");
/**
 * 默认预览配置, 代表着难以察觉视觉效果差异时的最低配置.
 * Video-Encoder 中放置有另一个用于编码的默认配置.
 */
const DefaultPreviewProjectRenderOptions = {
    textPlaceholder: 'Add Text Here',
    preloadSeconds: 10.5,
    preserveSeconds: 5.5,
    frameRate: 60,
    motionBlurSamplingCount: 32,
    fastBlurSamplingCount: 32,
    fastBlurRenderingIterateCount: 2,
    maxDropShadowSamplingCount: 32,
    dropShadowRenderingIterateCount: 1,
    clearResourcesAfterNoInteractionForSeconds: 60,
    textSuperSamplingRate: 2,
};
/** 默认在编码时的项目配置, 一些涉及到渲染质量的参数会有提升. */
const DefaultEncodingProjectRenderOptions = {
    textPlaceholder: '',
    preloadSeconds: 30,
    preserveSeconds: 0,
    frameRate: 30,
    motionBlurSamplingCount: 64,
    fastBlurSamplingCount: 64,
    fastBlurRenderingIterateCount: 3,
    maxDropShadowSamplingCount: 64,
    dropShadowRenderingIterateCount: 3,
    clearResourcesAfterNoInteractionForSeconds: 0,
    textSuperSamplingRate: 2,
};
/** 用于管理工程项目以及所有数据, 以及以及作为桥梁通知项目的更改. */
class Project extends ff_1.Emitter {
    /** 画布元素. */
    canvas;
    /**
     * AEGL 资源的根目录, 默认为当前网址下的 aegl 目录.
     * 其中会包含 fonts 和 templates 等子文件夹.
     */
    rootDirectory;
    /** 项目配置信息. */
    options;
    /** 当前所选分辨率下的项目数据, 可写, 但是必须写入后调用 notify 系列接口. */
    data;
    /** 资源加载器. */
    resourceLoader;
    /** 渲染器. */
    renderer;
    /** 时间轴管理器. */
    timeline;
    /** 编码器, 仅在编码时存在. */
    encoder = null;
    /** 素材查询器. */
    footages;
    /** 运行模式. */
    mode;
    constructor(canvas, rootDirectory, jsonData, options = {}, encoder = null) {
        super();
        let sw = new simple_webgl_1.SimpleWebGL(canvas);
        this.canvas = canvas;
        this.rootDirectory = rootDirectory;
        this.options = (0, ff_1.assignIf)(options, encoder ? DefaultEncodingProjectRenderOptions : DefaultPreviewProjectRenderOptions);
        this.encoder = encoder;
        this.mode = encoder ? 'encoding' : 'previewing';
        // 用于管理数据.
        this.data = new project_data_1.ProjectData(jsonData);
        // 用于加载资源.
        this.resourceLoader = new resource_loader_1.ResourceLoader(this, sw);
        // 用于时间轴控制, 根据时刻获得当前的层.
        this.timeline = new timeline_1.Timeline(this);
        // 生成渲染器用于进行渲染.
        this.renderer = new renderer_1.Renderer(this, sw);
        // 用于查询素材的统计状态.
        this.footages = new footages_1.Footages(this);
    }
    /** 清理所有的纹理内存以及网络资源的内存占用. */
    clearResoures() {
        this.clearPropertyCaches();
        this.timeline.resetAllTimeRanges();
        this.renderer.clear();
        this.resourceLoader.clear();
        // 有一些共享资源有延迟清除设置.
        requestAnimationFrame(() => {
            this.renderer.sw.warnIfNotClean();
        });
    }
    /** 清理系列缓存. */
    clearPropertyCaches() {
        (0, keyframe_1.clearKeyframeCache)();
        (0, property_1.resetStaticPropertyValuesCache)();
        (0, text_1.clearTextAnimaterPlugins)();
    }
    /**
     * 重设通用的项目数据之后通知其发生了变更.
     * 例如数据被重置, 层增减, 以及一些影响到全局但是不会实时更新的的关键属性.
     */
    notifyProjectUpdated() {
        this.clearPropertyCaches();
        this.emit('updateproject');
    }
    /**
     * 重设通用的项目数据之后通知其发生了变更.
     * 例如层的时间进行了调整.
     */
    notifyTimelineUpdated() {
        this.clearPropertyCaches();
        this.emit('updatetimeline');
    }
    /**
     * 重设层的重要数据之后通知其发生了变更, 这些数据应该是时间轴无关, 并且初始化之后就不会再更改的.
     * 例如图片层的地址属性.
     * 不包含文字层, 文字层的所有属性都可以实时响应.
     */
    notifyLayerUpdated(layerData) {
        this.clearPropertyCaches();
        this.emit('updatelayer', layerData);
    }
    /** 重设特效数据之后通知其发生了变更. */
    notifyEffectUpdated(effectData) {
        this.clearPropertyCaches();
        this.emit('updateeffect', effectData);
    }
    /**
     * 重设层的一些可实时变更的属性之后通知其发生了变更.
     * 此时不会重建层, 只会触发渲染.
     * 例如文字的所有属性等等会在层的 update 部分响应变更的属性.
     */
    notifyUpdated() {
        this.clearPropertyCaches();
        this.emit('update');
    }
    /** 移除项目以及其包含的所有资源. */
    delete() {
        this.clearPropertyCaches();
        this.resourceLoader.delete();
        this.renderer.delete();
    }
}
exports.Project = Project;


/***/ }),

/***/ "./src/aegl/project/resource-loader.ts":
/*!*********************************************!*\
  !*** ./src/aegl/project/resource-loader.ts ***!
  \*********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ResourceLoader = void 0;
const preload_1 = __webpack_require__(/*! ../../libs/util/preload */ "./src/libs/util/preload.ts");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
const file_1 = __webpack_require__(/*! ../../libs/util/file */ "./src/libs/util/file.ts");
const debug_1 = __webpack_require__(/*! ../../libs/util/debug */ "./src/libs/util/debug.ts");
const timestamp_1 = __webpack_require__(/*! ../../libs/util/timestamp */ "./src/libs/util/timestamp.ts");
const image_worker_decoder_1 = __webpack_require__(/*! ../../libs/util/image-worker-decoder */ "./src/libs/util/image-worker-decoder.ts");
/** 这个类用于缓存已加载的资源和释放不需要的资源. */
// 在此我们采取了逐步加载的策略来保证内存和显存占用的稳定.
// 另一端的渲染器应当进行预加载接下来一段时间内的资源来保证实时渲染时的流畅.
// 稍后此类还应当支持项目资源更改时重验证和加载新的资源.
// 另一方面这里的图片等资源只是请求完成, 未经解码, 其是否占用 CPU 内存也是由浏览器自动管理的.
// 如果实现的系统不需要实施绘制, 可以不实现资源缓存系统, 只在需要时加载图片并解码;
// 如果需要实施绘制, 但是 CPU 内存资源比较紧张, 可以实现一个先进先出的固定大小的缓冲区.
// 默认所有资源都是共享的, 即, 如果两个层引用了同一个地址的资源, 那么他们总是共享该资源所产生的对象.
// 这对于时间相关的资源会产生问题, 例如两个层时间轴不同, 但是引用了同一个视频.
// 这时我们应该生成一个引用资源的时间轴签名, 通过时间轴和资源地址共同获得资源.
class ResourceLoader {
    /** 项目对象. */
    project;
    /** 记录路径 - 资源文件标签. */
    resources = new Map();
    /** 记录层 id - 层路径, 它不和项目同步, 用于当层的路径发生改变时来移除不需要的资源. */
    layerIdToPath = new Map();
    // 用于解决请求资源过程中发来了新的同样的请求.
    resourcePromises = new Map();
    /** 用来在删除时拒绝已有的请求. */
    resourceRejects = new Set();
    // 这里传递一个 sw 作为参数而不是直接取 project.sw 是为了防止初始化时的顺序混乱.
    constructor(project, sw) {
        this.project = project;
        project.on('updatelayer', this.onUpdateLayer, this);
        project.on('updateproject', this.onUpdateProject, this);
        // 由于图片解码数据会被释放掉源数据, 所以当其释放掉纹理对象时, 这里的缓存也要释放.
        sw.samplerManager.on('deletedata', data => {
            if (!(data instanceof Element)) {
                this.resourcePromises.delete(data);
            }
        });
    }
    onUpdateLayer(layerData) {
        let id = layerData.id;
        let path = layerData.path;
        if (path) {
            let oldPath = this.layerIdToPath.get(id);
            // 不能直接删除旧资源, 因为可能被其他层引用.
            if (path !== oldPath) {
                this.layerIdToPath.delete(id);
                this.validateResources();
            }
        }
    }
    /** 当项目发生了比较大的变更时重新加载另一个 project, 它会自动重用之前的资源. */
    async onUpdateProject() {
        this.validateResources();
    }
    /**
     * 检查缓存的资源文件, 并且释放掉不再使用的资源.
     * 着色器代码因为本身就很小, 而且是通用的, 所以不对其做检查.
     */
    async validateResources() {
        if (this.resources.size === 0) {
            return;
        }
        let layerDatas = this.project.data.getAllPlainLayerDatas();
        let paths = new Set();
        for (let layerData of layerDatas) {
            if (layerData.path) {
                paths.add(this.getLayerPath(layerData));
            }
        }
        for (let path of this.resources.keys()) {
            if (!paths.has(path)) {
                this.resources.delete(path);
                debug_1.debug.verbose(`Released resource ${(0, file_1.getPathName)(path)}`);
            }
        }
    }
    /** 获取最合适尺寸的素材. */
    getLayerPath(layerData) {
        let path = layerData.path;
        if (typeof path === 'object') {
            let videoHeight = this.project.data.height;
            let preferFootageHeight = videoHeight * this.project.renderer.scaleRatio;
            // 在预览模式下始终只使用半分辨率的素材.
            // 由于 1000p 会升级到 1440p 渲染, 所以使用比例 1/3.
            if (this.project.mode === 'previewing') {
                preferFootageHeight = videoHeight / 3;
            }
            let keys = Object.keys(path);
            let heights = keys.map(key => Number(key.slice(0, -1)));
            // 计算比例中最接近的.
            // 渲染 720p 时, 1080p 素材相比 540p 获胜.
            let rateDiffs = heights.map(height => {
                let rate = height / preferFootageHeight;
                // 1.1 -> 0.1
                if (rate >= 1) {
                    return rate - 1;
                }
                // 0.9 -> 0.2, 即偏好较大的素材.
                else {
                    return (1 / rate - 1) * 2;
                }
            });
            let matchIndex = (0, ff_1.minIndex)(rateDiffs);
            let matchKey = keys[matchIndex];
            path = path[matchKey];
        }
        path = (0, file_1.isAbsolutePath)(path)
            ? path
            : this.getAbsolutePath(path);
        this.layerIdToPath.set(layerData.id, path);
        return (0, timestamp_1.addTimestamp)(path);
    }
    /** 获得 json 文件中的相对路径生成的绝对路径. */
    getAbsolutePath(relativePath) {
        return new URL(this.project.rootDirectory + `/templates/${this.project.data.id}/${relativePath}`, location.href).href;
    }
    /** 根据层数据加载图片. */
    async loadImage(layerData) {
        return this.loadResource(layerData, preload_1.preloadImage);
    }
    /** 根据路径加载图片. */
    async loadDecodedImage(layerData) {
        return this.loadResource(layerData, image_worker_decoder_1.decodeImageInWorker);
    }
    /**
     * 根据层数据加载视频.
     * 需要注意的是, 如果有所处时间不同的视频存在, 应该在加载时传入一个能够表达时间的 hash.
     * 这样能够让不同时间的视频获得不同的视频元素.
     */
    async loadVideo(layerData) {
        return this.loadResource(layerData, preload_1.preloadVideo);
    }
    /** 根据层数据加载音频. */
    async loadAudio(layerData) {
        return this.loadResource(layerData, preload_1.preloadAudio);
    }
    /** 据层数据加载资源, 它会收集 reject 函数, 如果加载过程里中断则使用其抛出异常. */
    loadResource(layerData, preloadFn) {
        return new Promise(async (resolve, reject) => {
            let path = this.getLayerPath(layerData);
            if (this.resources.has(path)) {
                resolve(this.resources.get(path));
                return;
            }
            if (this.resourcePromises.has(path)) {
                resolve(this.resourcePromises.get(path));
                return;
            }
            let promise = preloadFn(path);
            this.resourcePromises.set(path, promise);
            this.resourceRejects.add(reject);
            let element = await promise;
            this.resources.set(path, element);
            this.resourcePromises.delete(path);
            this.resourceRejects.delete(reject);
            debug_1.debug.verbose(`Loaded resource ${(0, file_1.getPathName)(path)}`);
            resolve(element);
        });
    }
    /** 清理资源的内存占用. */
    clear() {
        this.resources.clear();
        this.resourcePromises.clear();
        this.resourceRejects.clear();
    }
    /** 移除所有的资源, 如果有资源正在请求中, 则 reject. */
    delete() {
        for (let reject of this.resourceRejects) {
            reject('Deleted');
        }
        this.clear();
    }
}
exports.ResourceLoader = ResourceLoader;


/***/ }),

/***/ "./src/aegl/project/template-list.ts":
/*!*******************************************!*\
  !*** ./src/aegl/project/template-list.ts ***!
  \*******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.TemplateList = void 0;
const timestamp_1 = __webpack_require__(/*! ../../libs/util/timestamp */ "./src/libs/util/timestamp.ts");
/** 用于加载模板列表. */
var TemplateList;
(function (TemplateList) {
    /** 根目录, 包含 templates 和 fonts 等文件夹. */
    let rootDirectory = 'aegl';
    /** 列表数据. */
    let listData;
    /** 当资源加载后被 resolve. */
    let ready;
    /** 配置资源根目录. */
    function configDirectory(directory) {
        rootDirectory = directory;
    }
    TemplateList.configDirectory = configDirectory;
    /** 返回数据数据. */
    async function get() {
        if (!ready) {
            ready = load();
        }
        await ready;
        return listData;
    }
    TemplateList.get = get;
    /** 加载数据. */
    async function load() {
        let listDataPath = (0, timestamp_1.addTimestamp)(`${rootDirectory}/templates/list.json`);
        listData = await (await fetch(listDataPath)).json();
    }
})(TemplateList || (exports.TemplateList = TemplateList = {}));


/***/ }),

/***/ "./src/aegl/project/timeline.ts":
/*!**************************************!*\
  !*** ./src/aegl/project/timeline.ts ***!
  \**************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Timeline = void 0;
const time_map_1 = __webpack_require__(/*! ../property/time-map */ "./src/aegl/property/time-map.ts");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
/**
 * 用于根据当前时间获得当前的所有层,
 * 以及根据一个时间段准备需要加载资源的所有层.
 */
class Timeline {
    /** 所属渲染项目. */
    project;
    /**
     * 微小的时间偏移, 用来解决当前时刻正好是某个偏整的时刻产生的前后两层都选中的问题.
     * 例如我们根据时刻获得层时, 左右都可以等于, 如果一个当前时刻刚好和某两个层的切换时刻相等,
     * 那么此帧两个层会同时绘制, 这会带来一些不必要的性能问题, 有时还会产生错误.
     * 此外, 此时间偏移还解决了准点时刻采样, 例如采样 30 帧的视频采样出 31 帧的问题.
     * 注意它并不影响到结束时刻.
     */
    timeOffset = 0.00000001;
    /** 自从上次检查之后, 此范围不会造成当前的所有层的结果的变化. */
    mutatedTimeRange = [-1, -1];
    /** 自从上次检查之后, 此范围不会造成当前的需要预加载的资源层的结果的变化. */
    mutatedTimeRangeForPreloading = [-1, -1];
    /** 上一次已经预加载的时间范围.. */
    preloadedTimeRange = null;
    constructor(project) {
        this.project = project;
        project.on('updateproject', this.resetAllTimeRanges, this);
        project.on('updatetimeline', this.resetTimeRange, this);
        project.on('updatelayer', this.resetTimeRange, this);
        project.on('updateeffect', this.resetTimeRange, this);
    }
    /** 清除安全时间段缓存, 下一次申请时会更新结果. */
    resetTimeRange() {
        this.mutatedTimeRange = [-1, -1];
    }
    /** 清除所有的安全时间段缓存, 下一次申请时会更新结果. */
    resetAllTimeRanges() {
        this.mutatedTimeRange = [-1, -1];
        this.mutatedTimeRangeForPreloading = [-1, -1];
        this.preloadedTimeRange = null;
    }
    /** 获得安全时间段的开始时刻. */
    getStartSafeTime() {
        return this.mutatedTimeRange[0];
    }
    /**
     * 如果当前应该被激活的层发生了变更, 则返回当前时刻应该被激活的层.
     * 如果结果没有变化则返回 null.
     */
    getMutatedLayerDatas(time) {
        time = (0, ff_1.constrain)(time + this.timeOffset, 0, this.project.data.duration);
        if (time >= this.mutatedTimeRange[0] && time <= this.mutatedTimeRange[1]) {
            return null;
        }
        return this.getShouldActivateLayerDatas(time);
    }
    getShouldActivateLayerDatas(time) {
        let { datas, timeMoves } = this.filterRootLayerDatasFromTimeBounds(time, time);
        let timeRange = timeMoves.map(m => m + time);
        // 在经过场景编辑之后, 背景贯通层可能在两个场景, 在同一时刻出现.
        // 因此需要对首层进行过滤, 防止重复 rawId 的层出现.
        let rawIdSet = new Set();
        datas = datas.filter(({ rawId }) => {
            if (rawIdSet.has(rawId)) {
                return false;
            }
            else {
                rawIdSet.add(rawId);
                return true;
            }
        });
        this.mutatedTimeRange = timeRange;
        return datas;
    }
    /**
     * 如果当前时刻应该被加载资源的层发生了变换, 则返回当前时刻应该被加载资源的层.
     * 如果结果没有变化则返回 null.
     */
    getMutatedPreloadLayerDatas(time, preserveSeconds = this.project.options.preserveSeconds, preloadSeconds = this.project.options.preloadSeconds) {
        if (time >= this.mutatedTimeRangeForPreloading[0] && time <= this.mutatedTimeRangeForPreloading[1]) {
            return null;
        }
        return this.getShouldPreloadLayerDatas(time, preserveSeconds, preloadSeconds);
    }
    getShouldPreloadLayerDatas(time, preserveSeconds, preloadSeconds) {
        // 如果有已经预加载的时间段, 那么会尽量保留靠后的时间段.
        // 因此如果我们之前预加载了一个很长的时间段, 并且新的时刻和其相交,
        // 那么再次预加载短的时间段会不释放后面的部分.
        if (this.preloadedTimeRange) {
            if (time >= this.preloadedTimeRange[0]) {
                preloadSeconds = Math.max(preloadSeconds, this.preloadedTimeRange[1] - time);
            }
        }
        let { datas, timeMoves } = this.filterRootLayerDatasFromTimeBounds(time - preserveSeconds, time + preloadSeconds);
        let timeRange = timeMoves.map(m => m + time);
        this.mutatedTimeRangeForPreloading = timeRange;
        // 更新已经预加载资源的时间段.
        this.preloadedTimeRange = [
            Math.max(0, time - preserveSeconds),
            Math.min(time + preloadSeconds, this.project.data.duration),
        ];
        return datas;
    }
    /** 检查这个时间竖条范围会碰到哪些层, 以及往左和往右分别移动到什么位置会碰到新的层. */
    filterRootLayerDatasFromTimeBounds(minTimeBound, maxTimeBound) {
        let duration = this.project.data.duration;
        return this.filterLayerDatasFromTimeBounds(this.project.data.layers, duration, minTimeBound, maxTimeBound);
    }
    /** 检查这个时间竖条范围会碰到哪些层, 以及往左和往右分别移动到什么位置会碰到新的层. */
    // 如果两个参数相等, 这段代码可以简化, 不过由于调用频率不高, 所以不做处理.
    filterLayerDatasFromTimeBounds(layerDatas, duration, minTimeBound, maxTimeBound) {
        let minMove = -duration;
        let maxMove = duration;
        let filteredLayerDatas = [];
        for (let layerData of layerDatas) {
            let { inPoint, outPoint, hidden } = layerData;
            // 跳过隐藏层.
            if (hidden) {
                continue;
            }
            // 代表着移动哪些距离可以让边界对齐.
            let moveValues = [
                inPoint - minTimeBound,
                outPoint - minTimeBound,
                inPoint - maxTimeBound,
                outPoint - maxTimeBound,
            ];
            // 分别检查向左移动和向右移动的最小距离.
            // 另一个常见的算法是分类为左外, 左侧相交, 包含, 右侧相交, 右外. 但是很明显其更加复杂.
            for (let value of moveValues) {
                if (value < 0) {
                    minMove = Math.max(minMove, value);
                }
                else if (value > 0) {
                    maxMove = Math.min(maxMove, value);
                }
            }
            let match = outPoint >= minTimeBound && inPoint <= maxTimeBound;
            // 如果相交, 则选择该层. 它其实等价于 moveValues 中既有正值也有负值.
            if (match) {
                filteredLayerDatas.push(layerData);
                // 如果是合成层, 则继续过滤其子层.
                if (layerData.type === 'composite') {
                    let { datas, timeMoves } = this.filterCompLayerDatasFromTimeBounds(layerData, minTimeBound, maxTimeBound);
                    layerData.layers = datas;
                    minMove = Math.max(minMove, timeMoves[0]);
                    maxMove = Math.min(maxMove, timeMoves[1]);
                }
            }
        }
        let timeMoves = [minMove, maxMove];
        return {
            datas: filteredLayerDatas,
            timeMoves,
        };
    }
    /** 检查这个时间竖条范围在合成层内部会碰到哪些层, 以及往左和往右分别移动到什么位置会碰到新的层. */
    filterCompLayerDatasFromTimeBounds(layerData, minTimeBound, maxTimeBound) {
        let compItem = this.project.data.getCompItemFromId(layerData.compItemId);
        // 将当前的时间映射到合成内部.
        let timeMap = time_map_1.TimeMap.fromLayer(layerData);
        let minTimeBoundInside = timeMap.map(minTimeBound);
        let maxTimeBoundInside = timeMap.map(maxTimeBound);
        // minTimeBound 和 maxTimeBound 相等时, 运行于基于时刻查找的模式下, 此时 scaling 为 1.
        let timeScaling = (maxTimeBoundInside - minTimeBoundInside) / (maxTimeBound - minTimeBound) || 1;
        // 将合成层内部的时间偏移做一个线性映射, 以和外部的时间对应.
        let { datas, timeMoves: innerTimeMoves } = this.filterLayerDatasFromTimeBounds(compItem.layers, compItem.duration, minTimeBoundInside, maxTimeBoundInside);
        let timeMoves = innerTimeMoves.map(m => m / timeScaling);
        return { datas, timeMoves };
    }
}
exports.Timeline = Timeline;


/***/ }),

/***/ "./src/aegl/project/video-encoder.ts":
/*!*******************************************!*\
  !*** ./src/aegl/project/video-encoder.ts ***!
  \*******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.VideoEncodingAnalyser = exports.FFVideoEncoder = void 0;
const project_1 = __webpack_require__(/*! ./project */ "./src/aegl/project/project.ts");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
const ffmpeg_1 = __webpack_require__(/*! ../../libs/ffmpeg/ffmpeg */ "./src/libs/ffmpeg/ffmpeg.ts");
const file_1 = __webpack_require__(/*! ../../libs/util/file */ "./src/libs/util/file.ts");
const work_queue_1 = __webpack_require__(/*! ../../libs/ffmpeg/work-queue */ "./src/libs/ffmpeg/work-queue.ts");
const media_1 = __webpack_require__(/*! ../helpers/media */ "./src/aegl/helpers/media.ts");
const mediabunny_1 = __webpack_require__(/*! mediabunny */ "../../../AppData/Roaming/npm/node_modules/mediabunny/dist/bundles/mediabunny.cjs");
const QualityCRFMap = {
    'very-low': 30,
    'low': 27,
    'medium': 24,
    'high': 21,
    'very-high': 18,
};
const QualityBunnyMap = {
    'very-low': mediabunny_1.QUALITY_VERY_LOW,
    'low': mediabunny_1.QUALITY_LOW,
    'medium': mediabunny_1.QUALITY_MEDIUM,
    'high': mediabunny_1.QUALITY_HIGH,
    'very-high': mediabunny_1.QUALITY_VERY_HIGH,
};
/** 默认编码配置. */
const DefaultVideoEncoderOptions = {
    name: '',
    format: 'mp4',
    frameRate: 30,
    height: 540,
    quality: 'medium',
    fragmentSeconds: 2,
    ffmpegWorkerPath: '',
};
/** 用于进行视频编码. */
class FFVideoEncoder extends ff_1.Emitter {
    options;
    width;
    height;
    project;
    /** 记录花费的时间. */
    costSeconds = {
        encoding: 0,
        concat: 0,
    };
    /** 是否已取消导出. */
    terminated = false;
    /** 进行帧计数. */
    frameCounter;
    constructor(fromProject, partialOptions) {
        super();
        this.options = (0, ff_1.assignIf)(partialOptions, DefaultVideoEncoderOptions);
        if (this.options.ffmpegWorkerPath) {
            ffmpeg_1.ffmpeg.configWorkerPath(this.options.ffmpegWorkerPath);
        }
        // 宽高需要是 2 的倍数.
        this.height = Math.round(this.options.height / 2) * 2;
        this.width = Math.round(fromProject.data.width / fromProject.data.height * this.height / 2) * 2;
        this.cloneProject(fromProject);
        this.initializeFrameCounter();
        // 预热, 可以略微减少其后再次加载的时间大约 300ms.
        // ffmpeg.info(['-encoders'])
    }
    /** 克隆项目. */
    async cloneProject(fromProject) {
        let canvas = document.createElement('canvas');
        let rootDirectory = fromProject.rootDirectory;
        let data = fromProject.data.cloneData();
        let projectOptions = this.getProjectOptions();
        this.project = new project_1.Project(canvas, rootDirectory, data, projectOptions, this);
        this.project.renderer.setCanvasSize(this.width, this.height);
    }
    /** 获得项目的配置信息. */
    getProjectOptions() {
        let frameRate = this.options.frameRate;
        return {
            frameRate,
        };
    }
    /** 初始化帧计数器. */
    initializeFrameCounter() {
        this.frameCounter = new FrameCounter();
        this.frameCounter.totalFramesExtracting = this.project.footages.getTotalVideoFrames();
    }
    /** 进行逐帧编码. */
    async encodeByFF() {
        let frameRate = this.options.frameRate;
        let frameTime = 1 / frameRate;
        let duration = this.project.data.duration;
        let totalFrameCount = this.frameCounter.total = Math.round(duration / frameTime) + 1;
        let frames = [];
        let promises = [];
        let startMS = performance.now();
        // 将片段进行一个大概的长度进行均分.
        let videoSegmentIndex = 0;
        let segmentCount = Math.round(totalFrameCount / this.options.fragmentSeconds / frameRate);
        let fragmentFrames = Math.ceil(totalFrameCount / segmentCount);
        // 3 个编码, 2 个等待, 这样可以均衡编码速度以及内存占用.
        let maxSegmentEncodingThreadCount = Math.ceil(ffmpeg_1.ffmpeg.defaultWorkerGroup.threadCount * 1.5);
        let segmentEncodingQueue = new SegmentEncodingQueue(maxSegmentEncodingThreadCount);
        // 只要队列没有达到一个片段的帧数目就会一直生成帧.
        // 达到数目之后则等待编码器闲置.
        // 相比 ffmpeg 原生支持的多线程并行编码, 此方法效率更高,
        // 但是生成的视频片段再组合, 其编码质量和文件大小都稍逊于一次编码.
        // 另外其内存占用将会明显增大.
        for (let frameIndex = 0; frameIndex < totalFrameCount; frameIndex++) {
            if (this.terminated) {
                promises.push(Promise.reject(new Error('Terminated')));
                break;
            }
            try {
                let frame = await this.drawImageAsBuffer(frameIndex * frameTime);
                frames.push(frame);
            }
            catch (err) {
                // 如果我们中止导出, 那么这里必定会出现错误, 此时这个错误应当被拦截.
                if (!this.terminated) {
                    throw err;
                }
            }
            this.frameCounter.drawn = frameIndex + 1;
            this.updateProgress();
            // 这里的编码并不完全阻塞帧的生成, 只要帧被消耗完, 就会补充到一个片段准备下一次编码.
            // 如果希望速度更快, 可以补充帧到多个片段的长度.
            if (frames.length >= fragmentFrames || frameIndex === totalFrameCount - 1) {
                let frameSegment = frames.slice(0, fragmentFrames);
                frames = frames.slice(fragmentFrames);
                let encodingPromise = this.encodeSegmentByFF(frameSegment, videoSegmentIndex++);
                promises.push(encodingPromise);
                // 错误已经在 promises 中被处理.
                segmentEncodingQueue.addPromise(encodingPromise).catch(() => { });
                await segmentEncodingQueue.untilIdle();
            }
        }
        let videoSegments = await Promise.all(promises);
        // 记录绘制和编码时间.
        let endMS = performance.now();
        this.costSeconds.encoding += (endMS - startMS) / 1000;
        await this.joinVideoSegmentsByFF(videoSegments);
        this.project.delete();
    }
    /** 编码多帧构成的片段. */
    async encodeSegmentByFF(frames, segmentIndex) {
        let worker = await ffmpeg_1.ffmpeg.defaultWorkerGroup.request();
        return this.encodeFramesByFF(worker, frames, segmentIndex);
    }
    /** 触发进度事件. */
    updateProgress() {
        let { loaded, total } = this.frameCounter.getProgress();
        this.emit('progress', loaded, total);
    }
    /** 编码图片帧序列. */
    async encodeFramesByFF(worker, frames, segmentIndex) {
        let { frameRate, quality } = this.options;
        let crf = QualityCRFMap[quality];
        let files = frames.map((data, index) => {
            return {
                name: String(index).padStart(4, '0') + '.jpeg',
                data,
            };
        });
        let args = [
            '-hide_banner',
            '-framerate', frameRate,
            '-i', '%04d.jpeg',
            '-an',
            '-c:v', 'libx264',
            '-crf', crf,
            // yuv420p 是在大小和质量之间比较均衡的格式.
            // 必须转为 bt709, 否则颜色会偏淡.
            '-pix_fmt', 'yuv420p',
            '-vf', 'scale=out_color_matrix=bt709',
            // 设置 meta 数据.
            '-color_primaries', 'bt709',
            '-color_trc', 'bt709',
            '-colorspace', 'bt709',
            // 经过测试, ultrafast 快 50%, 但是文件大一倍, 并且质量非常差.
            // veryfast 慢 50%, 文件略小, 质量上并没有太大区别. 为 AE 的默认选项.
            '-preset', 'superfast',
            `${String(segmentIndex).padStart(4, '0')}.mp4`
        ];
        let outFiles = await worker.execWithProgress(files, args, this.getProgressFn('encoded'));
        return outFiles[0];
    }
    /** 根据 key 获得一个可以进度函数. */
    getProgressFn(key) {
        // 编码是并发的, 所以计数必须相互不干扰.
        let lastLoaded = 0;
        let onProgress = (loaded) => {
            this.frameCounter[key] += loaded - lastLoaded;
            lastLoaded = loaded;
            this.updateProgress();
        };
        return onProgress;
    }
    /** 获取用于通知帧导出进度的函数. */
    getFramesExtractProgressFn() {
        return this.getProgressFn('framesExtracting');
    }
    /** 合并所有的视频片段. */
    async joinVideoSegmentsByFF(videoSegments) {
        let files = ffmpeg_1.ffmpeg.listInputFiles(videoSegments);
        let audioLayerData = this.project.footages.getReplaceableAudioLayerData();
        let audioPath = this.project.resourceLoader.getLayerPath(audioLayerData);
        let audioFile = await ffmpeg_1.ffmpeg.getFFFileFromPath(audioPath);
        let duration = this.project.data.duration;
        let audioDuration = audioLayerData.duration;
        let startMS = performance.now();
        files.push(audioFile);
        let args = [
            '-hide_banner',
            '-f', 'concat',
            '-i', 'list.txt',
            // 循环音频.
            '-stream_loop', '-1',
            '-i', audioFile.name,
            '-shortest',
            '-map', '0:v:0',
            '-map', '1:a:0',
            '-c:v', 'copy',
        ];
        // 如果音乐时长和总时长相差不大, 直接拷贝.
        if (Math.abs(audioDuration - duration) <= 1) {
            args.push('-c:a', `copy`);
        }
        // 否则在末尾处降低音量.
        else {
            args.push('-af', `afade=t=out:st=${duration - 2}:d=2`);
        }
        args.push(`${this.options.name}.mp4`);
        let onProgress = (loaded) => {
            this.frameCounter.concat = loaded;
            this.updateProgress();
        };
        let outFiles = await ffmpeg_1.ffmpeg.execWithProgress(files, args, onProgress);
        // 记录编码时间.
        let endMS = performance.now();
        this.costSeconds.concat += (endMS - startMS) / 1000;
        ffmpeg_1.ffmpeg.downloadFile(outFiles[0]);
    }
    /** 进行逐帧编码. */
    async encodeByWeb() {
        let frameRate = this.options.frameRate;
        let frameTime = 1 / frameRate;
        let duration = this.project.data.duration;
        let totalFrameCount = this.frameCounter.total = Math.round(duration / frameTime) + 1;
        let startMS = performance.now();
        // let encoder = new VideoEncoder({
        // 	output: handleChunk,
        // 	error: (e) => console.error(e),
        // })
        // let analyzer = new VideoEncodingAnalyser(this.project)
        // let bitrate = analyzer.getVideoBitrateInM(this.height, this.options.crf)
        // let config: VideoEncoderConfig = {
        // 	codec: 'avc1.420028', // Baseline profile, Level 4.0
        // 	width: this.width,
        // 	height: this.height,
        // 	bitrate: bitrate * 1000000,
        // 	framerate: this.options.frameRate,
        // 	avc: { format: 'avc' }, // Could also use 'annexb'
        // }
        // encoder.configure(config)
        // let chunks: EncodedVideoChunk[] = []
        // function handleChunk(chunk: EncodedVideoChunk, _metadata: EncodedVideoChunkMetadata | undefined) {
        // 	chunks.push(chunk)
        // }
        // for (let frameIndex = 0; frameIndex < totalFrameCount; frameIndex++) {
        // 	if (this.terminated) {
        // 		return Promise.reject(new Error('Terminated'))
        // 	}
        // 	try {
        // 		let canvas = await this.drawImageAsCanvas(frameIndex * frameTime)
        // 		let frame = new VideoFrame(canvas, {timestamp: frameIndex * frameTime})
        // 		encoder.encode(frame, {keyFrame: frameIndex % (5 * frameRate) === 0})
        // 		frame.close()
        // 	}
        // 	catch (err) {
        // 		if (!this.terminated) {
        // 			throw err
        // 		}
        // 	}
        // 	while (encoder.encodeQueueSize > 2) {
        // 		await sleep(5)
        // 	}
        // 	this.frameCounter.drawn = frameIndex + 1
        // 	this.frameCounter.encoded = frameIndex + 1
        // 	this.updateProgress()
        // }
        // await encoder.flush()
        // // 记录绘制和编码时间.
        // let endMS = performance.now()
        // this.costSeconds.encoding += (endMS - startMS) / 1000
        // Mux with MP4Box.js.
        // let file = new (window as any).MP4Box.createFile()
        // let trackId = file.addTrack({
        // 	timescale: 1000000,
        // 	width: this.width,
        // 	height: this.height,
        // 	nb_samples: totalFrameCount,
        // 	codec: 'avc1.420028',
        // 	avcDecoderConfigRecord,
        // })
        // let sampleOptions: any = {
        //	 duration: frameTime * 1000
        // }
        // for (let chunk of chunks) {
        // 	let buffer = new ArrayBuffer(chunk.byteLength)
        //	 chunk.copyTo(buffer)
        // 	sampleOptions.dts = chunk.timestamp * 1000
        //	 sampleOptions.cts = chunk.timestamp * 1000
        // 	sampleOptions.is_sync = chunk.type === 'key'
        // 	file.addSample(trackId, buffer, sampleOptions)
        // }
        // encoder.close()
        // file.save(`${this.options.name}.mp4`)
        // Create a new output file
        let output = new mediabunny_1.Output({
            target: new mediabunny_1.BufferTarget(), // Stored in memory
            format: new mediabunny_1.Mp4OutputFormat(),
        });
        let videoCodec = await (0, mediabunny_1.getFirstEncodableVideoCodec)(output.format.getSupportedVideoCodecs(), {
            width: this.width,
            height: this.height,
        });
        if (!videoCodec) {
            throw new Error('Your browser doesn\'t support video encoding.');
        }
        // For video, we use a CanvasSource for convenience, as we're rendering to a canvas
        const canvasSource = new mediabunny_1.CanvasSource(this.project.canvas, {
            codec: videoCodec,
            bitrate: QualityBunnyMap[this.options.quality],
        });
        output.addVideoTrack(canvasSource, { frameRate });
        // Retrieve the first audio codec supported by this browser that can be contained in the output format
        const audioCodec = await (0, mediabunny_1.getFirstEncodableAudioCodec)(output.format.getSupportedAudioCodecs(), {
            numberOfChannels: 2,
            sampleRate: 48000,
        });
        if (!audioCodec) {
            throw new Error('Your browser doesn\'t support audio encoding, so we won\'t include audio in the output file.');
        }
        let audioBufferSource = new mediabunny_1.AudioBufferSource({
            codec: audioCodec,
            bitrate: mediabunny_1.QUALITY_VERY_HIGH,
        });
        output.addAudioTrack(audioBufferSource);
        await output.start();
        for (let currentFrame = 0; currentFrame < totalFrameCount; currentFrame++) {
            if (this.terminated) {
                return Promise.reject(new Error('Terminated'));
            }
            let currentTime = currentFrame * frameTime;
            try {
                await this.drawImageAsCanvas(currentFrame * frameTime);
                // Add the current state of the canvas as a frame to the video. Using `await` here is crucial to
                // automatically slow down the rendering loop when the encoder can't keep up.
                await canvasSource.add(currentTime, frameTime);
            }
            catch (err) {
                if (!this.terminated) {
                    throw err;
                }
            }
            this.frameCounter.drawn = currentFrame + 1;
            this.frameCounter.encoded = currentFrame + 1;
            this.updateProgress();
        }
        canvasSource.close();
        let audioLayerData = this.project.footages.getReplaceableAudioLayerData();
        let audioPath = this.project.resourceLoader.getLayerPath(audioLayerData);
        let audioArrayBuffer = await (await fetch(audioPath)).arrayBuffer();
        let audioBuffer = await new AudioContext().decodeAudioData(audioArrayBuffer);
        let audioContext = new OfflineAudioContext({ length: 48000 * duration, sampleRate: 48000, numberOfChannels: 2 });
        let audioSource = audioContext.createBufferSource();
        audioSource.buffer = audioBuffer;
        audioSource.loop = true; // Enable looping
        audioSource.loopStart = 0; // Start loop at 0s (default)
        audioSource.loopEnd = audioBuffer.duration; // Loop until the end
        audioSource.connect(audioContext.destination);
        audioSource.start();
        //let audioDuration = audioLayerData.duration
        //let audioRounds = Math.ceil(duration / audioDuration)
        // for (let i = 0; i < audioRounds; i++) {
        // 	const source = context.createBufferSource();
        // 	source.buffer = buffer;
        // 	source.connect(context.destination);
        // 	source.start(clip.timelineStart, clip.mediaStart, clip.duration);
        // }
        audioBufferSource.add(await audioContext.startRendering());
        await output.finalize();
        // 记录绘制和编码时间.
        let endMS = performance.now();
        this.costSeconds.encoding += (endMS - startMS) / 1000;
        let videoBlob = new Blob([output.target.buffer], { type: output.format.mimeType });
        let a = document.createElement('a');
        let url = URL.createObjectURL(videoBlob);
        a.textContent = `${this.options.name}.mp4`;
        a.setAttribute('href', url);
        a.setAttribute('download', `${this.options.name}.mp4`);
        a.click();
    }
    /**
     * 克隆项目以用于进行编码.
     * 被克隆的项目完全不干扰之前进行预览的项目, 因此在编码时原先的项目能够正常运行.
     */
    async drawImageAsBuffer(time) {
        let canvas = await this.drawImageAsCanvas(time);
        // 当页面失去焦点后, 此步骤耗时将会变为 1s 起.
        let jpegBlob = await (0, media_1.readCanvasAsJPEG)(canvas, 1);
        let arrayBuffer = await (0, file_1.readBlobAsArrayBuffer)(jpegBlob);
        return arrayBuffer;
    }
    async drawImageAsCanvas(time) {
        await this.project.renderer.setTime(time);
        this.project.renderer.sw.waitDrawingCompleted();
        return this.project.canvas;
    }
    /** 取消编码. */
    terminate() {
        ffmpeg_1.ffmpeg.defaultWorkerGroup.abort();
        this.project.delete();
        this.terminated = true;
    }
}
exports.FFVideoEncoder = FFVideoEncoder;
/**
 * 在队列编码时, 应当提前准备资源, 例如 3 线程下,
 * 可以准备 5 个资源, 3 个在编码, 2 个在排队,
 * 这样如果有两个同时结束, 后续的 2 个可以立刻补上.
 * 3 个同时结束的概率实在太低, 不予考虑.
 */
class SegmentEncodingQueue extends work_queue_1.WorkQueue {
    /** 创建, 仅作为 key 来和其他的区分. */
    create() {
        return {};
    }
    /** 添加一个 promise 来填充当前正在运行的任务的计数. */
    async addPromise(promise) {
        let value = await this.request();
        await promise;
        this.delete(value);
    }
}
/** 用于统计进度信息. */
class FrameCounter {
    /** 要渲染的帧的总数. */
    total = 0;
    /** 已渲染的帧的总数. */
    drawn = 0;
    /** 已编码到视频片段的帧的总数. */
    encoded = 0;
    /** 已解码的视频素材的帧的总数. */
    framesExtracting = 0;
    /** 视频素材的帧的总数. */
    totalFramesExtracting = 0;
    /** 已从视频片段合并到最终视频的帧的总数. */
    concat = 0;
    /** 各种方式处理一帧的时间比例. */
    rates = {
        drawing: 10,
        encoding: 10,
        framesExtracting: 10,
        concat: 1,
    };
    /** 获得进度信息. */
    getProgress() {
        let { total, drawn, encoded, framesExtracting, totalFramesExtracting, concat } = this;
        console.log({ total, drawn, encoded, framesExtracting, totalFramesExtracting, concat });
        // 将帧导出所占用的比重逐渐降低, 以缓解获取的视频帧数目不正确时所产生的误差.
        let framesExtractingRate = this.rates.framesExtracting;
        framesExtractingRate *= (1 - drawn / total);
        let all = total * this.rates.drawing
            + total * this.rates.encoding
            + totalFramesExtracting * framesExtractingRate
            + total * this.rates.concat;
        let loaded = drawn * this.rates.drawing
            + encoded * this.rates.encoding
            + framesExtracting * framesExtractingRate
            + concat * this.rates.concat;
        return { loaded, total: all };
    }
}
/** 用于分析编码时间和文件大小, 以及记录. */
class VideoEncodingAnalyser {
    /** 存储于 localStorage 的前缀. */
    storagePrefix = 'aegl_time_speed_of_';
    /** 所关联项目. */
    project;
    constructor(project) {
        this.project = project;
    }
    /** 预测编码时间, 会参考之前的编码时间. */
    guessEncodingTimeInMinutes(encodeHeight, frameRate, quality) {
        return (0, ff_1.toPrecision)(this.guessEncodingTimeInSeconds(encodeHeight, frameRate, quality) / 60, 2);
    }
    /** 预测编码时间, 会参考之前的编码时间. */
    guessEncodingTimeInSeconds(encodeHeight, frameRate, quality) {
        let { drawingAndEncodingTime, extractingFrameTime } = this.guessBaseEncodingTimeInSeconds(encodeHeight, frameRate, quality);
        let timeSpeedOfTemplate = ff_1.storage.get(this.storagePrefix + this.project.data.id);
        let costSeconds = timeSpeedOfTemplate
            ? timeSpeedOfTemplate * drawingAndEncodingTime
            : drawingAndEncodingTime + extractingFrameTime;
        return (0, ff_1.toPrecision)(costSeconds, 2);
    }
    /** 猜测一个编码时间参考值. */
    guessBaseEncodingTimeInSeconds(encodeHeight, frameRate, quality) {
        let crf = QualityCRFMap[quality];
        // 在极低配置的 双核 4 线程电脑上, 32s 视频编码为 30 帧时, 360p: 50s, 720p: 100s, 1080p: 220s.
        let x = this.getEncodingPixelCountInM(encodeHeight);
        let costSecondsPer1SDuration = (-1.5 * x - 1) / (0.14 * x - 0.9);
        let duration = this.project.data.duration;
        let crfTimeSpeed = 2 - crf / 21;
        let drawingAndEncodingTime = costSecondsPer1SDuration * duration * frameRate / 30 * crfTimeSpeed;
        // 素材的导出时间只和素材分辨率有关, 实测 1080P 的导出比 540P 快 100%.
        let videoFrameCount = this.project.footages.getTotalVideoFrames();
        let extractingFrameTime = videoFrameCount * 2 / 30;
        // 因核心数而提升编码速度.
        let speedRate = Math.pow(Math.max(navigator.hardwareConcurrency - 2, 1) / 2, 0.5);
        drawingAndEncodingTime /= speedRate;
        extractingFrameTime /= speedRate;
        // By Web Video Encoder.
        if (window.VideoEncoder) {
            drawingAndEncodingTime /= 10;
            extractingFrameTime /= 10;
        }
        return { drawingAndEncodingTime, extractingFrameTime };
    }
    /** 获得编码的像素值, 单位为 M. */
    getEncodingPixelCountInM(encodeHeight) {
        let width = this.project.data.width / this.project.data.height * encodeHeight;
        return width * encodeHeight / 1000000;
    }
    /** 获得视频的大致文件大小的一个参考值, 单位为 M. */
    guessExportFileSizeInM(encodeHeight, quality) {
        let videoBitrateInM = this.getVideoBitrateInM(encodeHeight, quality);
        let duration = this.project.data.duration;
        let fileSize = videoBitrateInM * duration / 8;
        return (0, ff_1.toDecimal)((0, ff_1.toPrecision)(fileSize, 2), 0);
    }
    /** 获得视频的近似比特率. */
    getVideoBitrateInM(encodeHeight, quality) {
        let crf = QualityCRFMap[quality];
        // Type		Standard	High
        // 2160p	35-45 Mbps	53-68 Mbps
        // 1440p	16 Mbps		24 Mbps
        // 1080p	8 Mbps		12 Mbps
        // 720P		5 Mbps		7.5 Mbps
        // 480p		2.5 Mbps	4 Mbps
        // 360p		1 Mbps		1.5 Mbps
        // 实测 360P 需要 1.279M.
        // 720P 需要 3.083M.
        // 1080P 需要 6.734M.
        let x = this.getEncodingPixelCountInM(encodeHeight);
        let standardVideoBitrateAt30FPS = 0.3 * x * x + 2.26 * x + 0.74;
        let crfRate = Math.pow(2, (21 - crf) / 6);
        // 最终的比特率由预设比特率乘以当前质量参数, 再乘以帧率产生的倍数.
        let videoBitrate = standardVideoBitrateAt30FPS * crfRate;
        // 保留一位小数.
        return (0, ff_1.toDecimal)(videoBitrate, 1);
    }
    /** 用于保存特定模板的编码速度. */
    saveEncodingSpeed(encoder) {
        let { drawingAndEncodingTime } = this.guessBaseEncodingTimeInSeconds(encoder.options.height, encoder.options.frameRate, encoder.options.quality);
        let timeSpeedOfTemplate = (encoder.costSeconds.encoding + encoder.costSeconds.concat) / drawingAndEncodingTime;
        ff_1.storage.set(this.storagePrefix + this.project.data.id, timeSpeedOfTemplate);
    }
}
exports.VideoEncodingAnalyser = VideoEncodingAnalyser;


/***/ }),

/***/ "./src/aegl/property/camera.ts":
/*!*************************************!*\
  !*** ./src/aegl/property/camera.ts ***!
  \*************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.getDefaultCameraProjectionMatrix = exports.getCameraLayerProjectionMatrix = exports.getDefaultCameraLookAtMatrix = exports.getCameraLookAtMatrix = exports.getCameraLayerLookAtMatrix = void 0;
const property_1 = __webpack_require__(/*! ./property */ "./src/aegl/property/property.ts");
const aegl_default_values_1 = __webpack_require__(/*! ../aegl-default-values */ "./src/aegl/aegl-default-values.ts");
const vector4_1 = __webpack_require__(/*! ../../libs/math/vector4 */ "./src/libs/math/vector4.ts");
const matrix4_1 = __webpack_require__(/*! ../../libs/math/matrix4 */ "./src/libs/math/matrix4.ts");
/** 根据的摄影机层的 transform 变换特效计算其观察矩阵. */
function getCameraLayerLookAtMatrix(cameraData, time, outerTransform) {
    let { pointOfInterest, position, orientation } = (0, property_1.getPropertyValues)(cameraData.transform, time, aegl_default_values_1.CameraTransformDefaultValues);
    return getCameraLookAtMatrix(pointOfInterest, position, orientation, outerTransform);
}
exports.getCameraLayerLookAtMatrix = getCameraLayerLookAtMatrix;
/** 根据具体的属性计算其对应的投影矩阵. */
function getCameraLookAtMatrix(pointOfInterest, position, orientation, outerTransform) {
    const toRadians = Math.PI / 180;
    // 观察的坐标.
    let watchCoord = outerTransform.transfer3(new vector4_1.Vector3(...pointOfInterest));
    // 摄影极坐标.
    let cameraCoord = outerTransform.transfer3(new vector4_1.Vector3(...position));
    // 向上的向量.
    let upVector = new vector4_1.Vector3(0, -1, 0);
    // 用于进行三维观察.
    let lookAtMatrix = matrix4_1.Matrix4.lookAt(cameraCoord, watchCoord, upVector);
    // 用于处理坐标轴旋转.
    // 由于 orientation 作用于坐标轴, 所以坐标的旋转应是其逆, 即转置.
    let orientationMatrix = new matrix4_1.Matrix4().rotate3D(...orientation.map(degree => -toRadians * degree));
    // 摄影机变换矩阵.
    let cameraTransformMatrix = orientationMatrix.multiply(lookAtMatrix);
    return cameraTransformMatrix;
}
exports.getCameraLookAtMatrix = getCameraLookAtMatrix;
/** 获取一个默认的摄影机投影设置. */
function getDefaultCameraLookAtMatrix(videoWidth, videoHeight) {
    let zoom = Math.max(videoWidth, videoHeight) * Math.sqrt(2);
    let pointOfInterest = [videoWidth / 2, videoHeight / 2, 0];
    let position = [videoWidth / 2, videoHeight / 2, -zoom];
    let orientation = [0, 0, 0];
    return getCameraLookAtMatrix(pointOfInterest, position, orientation, matrix4_1.Matrix4.I);
}
exports.getDefaultCameraLookAtMatrix = getDefaultCameraLookAtMatrix;
/** 根据的摄影机层的 transform 变换特效计算其投影矩阵. */
function getCameraLayerProjectionMatrix(cameraData, time, videoWidth, videoHeight) {
    let zoom = (0, property_1.getPropertyValue)(cameraData.zoom, time, 0);
    let projectionMatrix = matrix4_1.Matrix4.perspective(videoWidth, videoHeight, zoom, 10, 100000);
    return projectionMatrix;
}
exports.getCameraLayerProjectionMatrix = getCameraLayerProjectionMatrix;
/** 获取一个默认的摄影机投影设置. */
function getDefaultCameraProjectionMatrix(videoWidth, videoHeight) {
    let zoom = Math.max(videoWidth, videoHeight) * Math.sqrt(2);
    let projectionMatrix = matrix4_1.Matrix4.perspective(videoWidth, videoHeight, zoom, 10, 100000);
    return projectionMatrix;
}
exports.getDefaultCameraProjectionMatrix = getDefaultCameraProjectionMatrix;


/***/ }),

/***/ "./src/aegl/property/keyframe.ts":
/*!***************************************!*\
  !*** ./src/aegl/property/keyframe.ts ***!
  \***************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ComplexKeyframesPacker = exports.PropertyKeyframes = exports.clearKeyframeCache = exports.ensureComplexKeyframeClass = exports.ensureKeyframeClass = void 0;
const bezier_1 = __webpack_require__(/*! ../../libs/math/bezier */ "./src/libs/math/bezier.ts");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
/**
 * 由于 proeprty 结构的存储比较零散, 基于所属 layer 或者其他属性初始化 PropertyKeyFrames 以及存储它都会是一件麻烦事.
 * 所以这里我们将具体的 json keyframe 数据作为键以持久化关联的对象.
 *
 * 如果在移植时遇到了对象不能作为键的问题, 可以为所有的 keyframe 预先标注一个 id, 然后使用其作为键.
 *
 * 如果系统的渲染工程和层属性切换比较少, 或者不太在乎内存的占用, 也可以不释放这些类, 他们一般不会造成内存溢出.
 * 如果对于实时绘制要求不高, 也可以不持久化此类, 每次调用时都新建它.
 */
let KeyframeCache = new Map();
/** 为关键帧数据创建对象. */
function ensureKeyframeClass(keyframes) {
    let keyframeClass = KeyframeCache.get(keyframes); // 命中率很高
    if (!keyframeClass) {
        keyframeClass = new PropertyKeyframes(keyframes);
        KeyframeCache.set(keyframes, keyframeClass);
    }
    return keyframeClass;
}
exports.ensureKeyframeClass = ensureKeyframeClass;
/** 缓存复杂关键帧对象. */
let ComplexKeyframeCache = new Map();
/** 为复杂关键帧数据创建对象. */
function ensureComplexKeyframeClass(keyframes) {
    let keyframeClass = ComplexKeyframeCache.get(keyframes); // 命中率很高
    if (!keyframeClass) {
        keyframeClass = new ComplexKeyframesPacker(keyframes);
        ComplexKeyframeCache.set(keyframes, keyframeClass);
    }
    return keyframeClass;
}
exports.ensureComplexKeyframeClass = ensureComplexKeyframeClass;
/** 当关键帧数据发生更改时, 重置缓存的关键帧预设函数. */
function clearKeyframeCache() {
    KeyframeCache = new Map();
    ComplexKeyframeCache = new Map();
}
exports.clearKeyframeCache = clearKeyframeCache;
/** 由于我们要频繁地基于关键帧查询当前值, 而上次计算的结果绝大部分可以用于下一次查询, 所以使用此类来控制. */
class PropertyKeyframes {
    keyframes;
    timeRange = [-1, -1];
    /** 根据时刻返回值. */
    valueFn;
    constructor(keyframes) {
        this.keyframes = keyframes;
    }
    /** 对指定的所有的关键帧数据进行自动贝塞尔平滑处理, 其方法是使用左右两帧的数据做均衡. */
    getAutoBezierEase(index) {
        let leftIndex = Math.max(index - 1, 0);
        let rightIndex = Math.min(index + 1, this.keyframes.length - 1);
        let leftFrame = this.keyframes[leftIndex];
        let rightFrame = this.keyframes[rightIndex];
        let speeds = this.geKeyframeSpeeds(leftFrame.value, rightFrame.value, rightFrame.time - leftFrame.time);
        return speeds.map(speed => ({ speed, influence: 33.3 }));
    }
    /** 获得值的变化速度. */
    geKeyframeSpeeds(value1, value2, timeDiff) {
        if (Array.isArray(value1)) {
            return value2.map((v2, index) => {
                let v1 = value1[index];
                return (v2 - v1) / timeDiff;
            });
        }
        else {
            return [(value2 - value1) / timeDiff];
        }
    }
    /** 获得指定时刻的值. */
    get(time) {
        if (time < this.timeRange[0] || time > this.timeRange[1]) {
            this.updateLeftRight(time);
        }
        return this.valueFn(time);
    }
    /** 更新左右两侧的关键帧. */
    updateLeftRight(time) {
        // 储存上一次的索引位置, 下一次先尝试将其 +1 可以带来一定的效率提升.
        // 使用二分法也是一个不错的建议, 不过一般的关键帧数据都不会太多, 平均不到 10 条.
        // 而且平均几百帧才会更新一次, 数组查询速度又足够快, 一般每一帧时间内可以运行百万次.
        let index = this.keyframes.findIndex(frame => frame.time >= time);
        // 计算时刻左右两侧的帧, 两者必然有一个存在.
        let right = index >= 0 && index < this.keyframes.length ? this.keyframes[index] : null;
        let left = index > 0 ? this.keyframes[index - 1] : index === 0 ? null : this.keyframes[this.keyframes.length - 1];
        // 左右都有匹配, 进行线性插值或者贝塞尔曲线插值.
        if (left && right) {
            this.timeRange = [left.time, right.time];
            // 如果是贝塞尔类型缓动.
            if (left.outEase || right.inEase || left.autoBezier || right.autoBezier) {
                let leftOutEase = left.outEase || (left.autoBezier ? this.getAutoBezierEase(index - 1) : undefined);
                let rightInEase = right.inEase || (right.autoBezier ? this.getAutoBezierEase(index) : undefined);
                this.valueFn = this.createCubicBezierValueFn(left, right, leftOutEase, rightInEase);
            }
            // 如果是线性类型缓动.
            else {
                this.valueFn = this.createLinearValueFn(left, right);
            }
        }
        // 右侧为第一个帧数据.
        else if (right) {
            this.timeRange = [-Infinity, right.time];
            this.valueFn = () => right.value;
        }
        // 左侧为最后一个帧数据.
        else {
            this.timeRange = [left.time, Infinity];
            this.valueFn = () => left.value;
        }
    }
    /**
     * 创建贝塞尔缓动函数.
     * 这里根据参数的类型将稍后每一帧都会使用到的函数做预生成.
     * 看起来代码有点多, 不过由于根据情况预先创建返回函数, 所以不用反复创建函数, 也不会在调用的函数时遇到多态问题.
     */
    createCubicBezierValueFn(left, right, leftEase, rightEase) {
        let timeRange = right.time - left.time;
        let leftTime = left.time;
        if (Array.isArray(left.value)) {
            let leftValues = left.value;
            let rightValues = right.value;
            let fns = left.value.map((leftValue, index) => {
                let rightValue = rightValues[index];
                let valueRange = rightValue - leftValue;
                // 由于 ease 数据可能只有一条, 所以如果指定的索引的 ease 数据不存在, 改访问第一条.
                let lEase = leftEase ? leftEase[index] || leftEase[0] : undefined;
                let rEase = rightEase ? rightEase[index] || rightEase[0] : undefined;
                return this.createSingleCubicBezierEasing(lEase, rEase, timeRange, valueRange);
            });
            return ((time) => {
                let timeRate = (time - leftTime) / timeRange;
                let valueRates = fns.map(fn => fn(timeRate));
                return valueRates.map((valueRate, index) => {
                    return leftValues[index] * (1 - valueRate) + rightValues[index] * valueRate;
                });
            });
        }
        else {
            let leftValue = left.value;
            let rightValue = right.value;
            let valueRange = rightValue - leftValue;
            let lEase = leftEase ? leftEase[0] : undefined;
            let rEase = rightEase ? rightEase[0] : undefined;
            let fn = this.createSingleCubicBezierEasing(lEase, rEase, timeRange, valueRange);
            return ((time) => {
                let timeRate = (time - leftTime) / timeRange;
                let valueRate = fn(timeRate);
                return leftValue * (1 - valueRate) + rightValue * valueRate;
            });
        }
    }
    /** 进行贝塞尔曲线关键帧插值. */
    createSingleCubicBezierEasing(leftEase, rightEase, timeRange, valueRange) {
        let valueChangesRate = valueRange / timeRange;
        let [x1, y1] = this.getBezierControlPoint(leftEase, valueChangesRate, true);
        let [x2, y2] = this.getBezierControlPoint(rightEase, valueChangesRate, false);
        return (0, bezier_1.getCubicBezierEasingFunction)(x1, y1, x2, y2);
    }
    /**
     * 获得贝塞尔曲线的基于 0~1 的控制点.
     * 需要注意的是由于我们将范围映射到 0~1 做处理, 如果左右两个端点的 y 值相同, 那么此处理会失败.
     * 不过由于一般不会遇到此类问题, 所以等到遇到时再做一般的贝塞尔插值.
     */
    getBezierControlPoint(ease, valueChangesRate, isIn) {
        let x = ease ? ease.influence / 100 : 0;
        let y = ease && valueChangesRate !== 0 ? x * ease.speed / valueChangesRate : 0;
        return isIn ? [x, y] : [1 - x, 1 - y];
    }
    /** 创建线性缓动函数. */
    createLinearValueFn(left, right) {
        let timeRange = right.time - left.time;
        let leftTime = left.time;
        if (Array.isArray(left.value)) {
            let leftValues = left.value;
            let rightValues = right.value;
            return ((time) => {
                let valueRate = (time - leftTime) / timeRange;
                return leftValues.map((leftValue, index) => {
                    return leftValue * (1 - valueRate) + rightValues[index] * valueRate;
                });
            });
        }
        else {
            let leftValue = left.value;
            let rightValue = right.value;
            return ((time) => {
                let valueRate = (time - leftTime) / timeRange;
                return leftValue * (1 - valueRate) + rightValue * valueRate;
            });
        }
    }
}
exports.PropertyKeyframes = PropertyKeyframes;
/** 封装自 PropertyKeyFrames, 用于打包处理路径等包含多个子项的关键帧数据. */
class ComplexKeyframesPacker {
    /** 打包时生成的解包模板. */
    template;
    /** 经过打包的帧处理器. */
    propertyKeyframes;
    constructor(keyframes) {
        this.template = (0, ff_1.deepClone)(keyframes[0].value);
        this.propertyKeyframes = new PropertyKeyframes(this.packKeyFrames(keyframes));
    }
    /** 打包属性. */
    packKeyFrames(keyframes) {
        let packedKeyframes = [];
        for (let keyframe of keyframes) {
            let numbers = this.getAllNumbers(keyframe.value);
            let packedFrame = {
                time: keyframe.time,
                value: numbers,
            };
            for (let key of Object.keys(keyframe)) {
                if (key !== 'time' && key !== 'value') {
                    packedFrame[key] = keyframe[key];
                }
            }
            packedKeyframes.push(packedFrame);
        }
        return packedKeyframes;
    }
    /** 获取对象中的所有数字属性. */
    getAllNumbers(value) {
        let numbers = [];
        this.walkObjectToFindNumbers(value, (_object, _key, value) => {
            numbers.push(value);
        });
        return numbers;
    }
    /** 设置对象中的所有数字属性. */
    setAllNumbers(value, numbers) {
        let index = 0;
        this.walkObjectToFindNumbers(value, (object, key, _value) => {
            object[key] = numbers[index++];
        });
        return value;
    }
    /** 便利对象查询数字属性. */
    walkObjectToFindNumbers(object, fn) {
        if (Array.isArray(object)) {
            for (let i = 0; i < object.length; i++) {
                let value = object[i];
                if (typeof value === 'number') {
                    fn(object, i, value);
                }
                if (typeof value === 'object') {
                    this.walkObjectToFindNumbers(value, fn);
                }
            }
        }
        else if (object && typeof object === 'object') {
            for (let [key, value] of Object.entries(object)) {
                if (typeof value === 'number') {
                    fn(object, key, value);
                }
                if (typeof value === 'object') {
                    this.walkObjectToFindNumbers(value, fn);
                }
            }
        }
    }
    /**
     * 获得指定时刻的值.
     * 注意其返回的对象会在下一时刻被重用, 所以请不要持久化它.
     */
    get(time) {
        let numbers = this.propertyKeyframes.get(time);
        return this.setAllNumbers(this.template, numbers);
    }
}
exports.ComplexKeyframesPacker = ComplexKeyframesPacker;


/***/ }),

/***/ "./src/aegl/property/motion.ts":
/*!*************************************!*\
  !*** ./src/aegl/property/motion.ts ***!
  \*************************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.getExposureTime = void 0;
/** 计算运动模糊的曝光时间. shutterAngle 默认为 180. */
function getExposureTime(shutterAngle, frameRate) {
    return shutterAngle / (360 * frameRate);
}
exports.getExposureTime = getExposureTime;


/***/ }),

/***/ "./src/aegl/property/projection.ts":
/*!*****************************************!*\
  !*** ./src/aegl/property/projection.ts ***!
  \*****************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.getFlatProjectionMatrix = exports.getPixelReflectionMatrix = exports.getFinalProjectedCoords = exports.get2DProjectionMatrix = exports.is3DProjectionMatrix = void 0;
const matrix4_1 = __webpack_require__(/*! ../../libs/math/matrix4 */ "./src/libs/math/matrix4.ts");
const vector4_1 = __webpack_require__(/*! ../../libs/math/vector4 */ "./src/libs/math/vector4.ts");
/** 检查投影矩阵是否为 3D 投影. */
function is3DProjectionMatrix(projectionMatrix) {
    // 大致为检查最后一行是否为 [0, 0, 0, 1], 尤其是倒数第二个元素.
    return projectionMatrix.data[11] !== 0;
}
exports.is3DProjectionMatrix = is3DProjectionMatrix;
/** 默认投影变换矩阵, 用于将左上角开始的像素坐标投影到 opengl 坐标. */
function get2DProjectionMatrix(videoWidth, videoHeight) {
    let sx = 2 / videoWidth;
    let sy = 2 / videoHeight;
    return new matrix4_1.Matrix4(sx, 0, 0, -1, 0, -sy, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1);
}
exports.get2DProjectionMatrix = get2DProjectionMatrix;
/** 根据坐标和变换矩阵以及投影矩阵计算最终的绘制像素坐标. */
function getFinalProjectedCoords(numCoords, transformMatrix, projectionMatrix, videoWidth, videoHeight) {
    // 如果是一个 3D 投影, 我们不再准确计算其投影范围, 而直接返回全屏绘制范围.
    if (is3DProjectionMatrix(projectionMatrix)) {
        return getFinal3DProjectedCoords(numCoords, transformMatrix, projectionMatrix, videoWidth, videoHeight);
    }
    // 注意这里跳过了投影矩阵, 因为使用的是默认的 2D 投影.
    let coords = numCoords.map(coord => {
        return transformMatrix.transfer2(new vector4_1.Vector2(...coord));
    });
    return coords;
}
exports.getFinalProjectedCoords = getFinalProjectedCoords;
/** 3D 投影需要先计算投影, 然后再通过投影恢复到像素坐标. */
function getFinal3DProjectedCoords(numCoords, transformMatrix, projectionMatrix, videoWidth, videoHeight) {
    // 用于计算最终 OpenGL 投影坐标.
    let toProjectMatrix = projectionMatrix.multiply(transformMatrix);
    // 用于将 OpenGL 投影坐标还原到像素坐标.
    let reflectionMatrix = getPixelReflectionMatrix(videoWidth, videoHeight);
    let coords = numCoords.map(coord => {
        let projectedCoord = toProjectMatrix.transfer3(new vector4_1.Vector3(...coord));
        let x = projectedCoord.x / projectedCoord.z;
        let y = projectedCoord.y / projectedCoord.z;
        return reflectionMatrix.transfer2(new vector4_1.Vector2(x, y));
    });
    return coords;
}
/** 获得一个用于将投影后 OpenGL 坐标还原为像素坐标的矩阵. */
function getPixelReflectionMatrix(videoWidth, videoHeight) {
    let w = videoWidth / 2;
    let h = videoHeight / 2;
    // 保留 z 轴为 1, 这样这个矩阵可以求逆.
    return new matrix4_1.Matrix4(w, 0, 0, w, 0, -h, 0, h, 0, 0, 1, 0, 0, 0, 0, 1);
}
exports.getPixelReflectionMatrix = getPixelReflectionMatrix;
/**
 * 根据变换矩阵以及投影矩阵计算其几乎等价的平面变换.
 * 可以用于衡量原始 z 分量为 0 位置的坐标所经历的变换.
 */
function getFlatProjectionMatrix(transformMatrix, projectionMatrix, videoWidth, videoHeight) {
    // 用于计算最终 OpenGL 投影坐标.
    let toProjectMatrix = projectionMatrix.multiply(transformMatrix);
    let homogeneous = toProjectMatrix.data[15]; // 齐次坐标值.
    let n11 = toProjectMatrix.data[0] / homogeneous;
    let n12 = toProjectMatrix.data[4] / homogeneous;
    let n14 = toProjectMatrix.data[12] / homogeneous;
    let n21 = toProjectMatrix.data[1] / homogeneous;
    let n22 = toProjectMatrix.data[5] / homogeneous;
    let n24 = toProjectMatrix.data[13] / homogeneous;
    // 保留 z 轴为 1, 这样这个矩阵可以求逆.
    let projection2DMatrix = new matrix4_1.Matrix4(n11, n12, 0, n14, n21, n22, 0, n24, 0, 0, 1, 0, 0, 0, 0, 1);
    // 用于将 OpenGL 投影坐标还原到像素坐标.
    let reflectionMatrix = getPixelReflectionMatrix(videoWidth, videoHeight);
    return reflectionMatrix.multiply(projection2DMatrix);
}
exports.getFlatProjectionMatrix = getFlatProjectionMatrix;


/***/ }),

/***/ "./src/aegl/property/property.ts":
/*!***************************************!*\
  !*** ./src/aegl/property/property.ts ***!
  \***************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.resetStaticPropertyValuesCache = exports.StaticPropertyValuesCacher = exports.getMaxPropertyValue = exports.isPropertyValueBeKeyFrames = exports.doesDataHaveKeyframes = exports.getComplexPropertyValues = exports.getPropertyValue = exports.getPropertyValues = void 0;
const keyframe_1 = __webpack_require__(/*! ./keyframe */ "./src/aegl/property/keyframe.ts");
/** 从可能为值或者关键帧的属性值中获得当前值组成的对象. */
function getPropertyValues(o, time, defaultValues) {
    let values = {};
    if (!o) {
        return defaultValues;
    }
    // 处理关键帧数据.
    for (let key of Object.keys(o)) {
        let value = o[key];
        values[key] = getPropertyValue(value, time);
    }
    // 增加默认值.
    if (defaultValues) {
        for (let key of Object.keys(defaultValues)) {
            if (values[key] === undefined) {
                values[key] = defaultValues[key];
            }
        }
    }
    return values;
}
exports.getPropertyValues = getPropertyValues;
/** 从可能为值或者关键帧的值获得当前值. */
function getPropertyValue(value, time, defaultValue) {
    if (isPropertyValueBeKeyFrames(value)) {
        let keyframeClass = (0, keyframe_1.ensureKeyframeClass)(value);
        return keyframeClass.get(time);
    }
    else if (value === undefined) {
        return defaultValue;
    }
    else {
        return value;
    }
}
exports.getPropertyValue = getPropertyValue;
/**
 * 从可能为值或者关键帧的值获得当前值.
 * 仅在有必要的时候再使用此方法, 因为其会进行拆包和封包, 开销比较大.
 */
function getComplexPropertyValues(value, time) {
    if (isPropertyValueBeKeyFrames(value)) {
        let keyframeClass = (0, keyframe_1.ensureComplexKeyframeClass)(value);
        return keyframeClass.get(time);
    }
    else {
        return value;
    }
}
exports.getComplexPropertyValues = getComplexPropertyValues;
/** 检查特效包含的数据是否有关键帧. */
function doesDataHaveKeyframes(values) {
    for (let value of Object.values(values)) {
        if (isPropertyValueBeKeyFrames(value)) {
            return true;
        }
    }
    return false;
}
exports.doesDataHaveKeyframes = doesDataHaveKeyframes;
/** 检查值是否含有关键帧的值. */
function isPropertyValueBeKeyFrames(value) {
    return Array.isArray(value) && typeof value[0] === 'object' && typeof value[0].time === 'number';
}
exports.isPropertyValueBeKeyFrames = isPropertyValueBeKeyFrames;
/** 获得值的关键帧中的最大的值. 如果值为数组, 则会将其扁平化. */
function getMaxPropertyValue(value, defaultValue) {
    if (isPropertyValueBeKeyFrames(value)) {
        let allFrameValues = value.map(frame => frame.value).flat();
        return Math.max(...allFrameValues);
    }
    else if (value === undefined) {
        return defaultValue;
    }
    else {
        return value;
    }
}
exports.getMaxPropertyValue = getMaxPropertyValue;
/**
 * 如果属性不包含关键帧, 那么其返回数据应当保持不变, 和时间无关.
 * 这个类供外部初始化, 还不是作用于 getCurrentPropertyValues 上,
 * 是因为 getCurrentPropertyValues 的返回值还会经过继续包装生成其他类型的数据,
 * 我们应当在可以保证数据不变的最顶层进行缓存.
 * 实测大约可以提升平均 100% 的获取属性时的运行效率.
 */
const AllCachers = [];
class StaticPropertyValuesCacher {
    map = new Map();
    constructor() {
        AllCachers.push(this);
    }
    /** 是否已缓存. */
    has(k) {
        return !!this.map.get(k);
    }
    /** 获取当前值. */
    get(k) {
        return this.map.get(k);
    }
    /** 获取当前值. */
    set(k, v) {
        if (!this.map.has(k)) {
            if (doesDataHaveKeyframes(k)) {
                // 设置为 null 值以防止下一次继续做此检查.
                this.map.set(k, null);
            }
            else {
                this.map.set(k, v);
            }
        }
    }
    /** 重设缓存. */
    reset() {
        this.map = new Map();
    }
}
exports.StaticPropertyValuesCacher = StaticPropertyValuesCacher;
/** 重设所有的属性值缓存. */
function resetStaticPropertyValuesCache() {
    for (let cacher of AllCachers) {
        cacher.reset();
    }
}
exports.resetStaticPropertyValuesCache = resetStaticPropertyValuesCache;


/***/ }),

/***/ "./src/aegl/property/text.ts":
/*!***********************************!*\
  !*** ./src/aegl/property/text.ts ***!
  \***********************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.getAlignRateFromLeft = exports.getLetterSpacingFronTrackingAmount = exports.getLetterSpacingFronTracking = exports.clearTextAnimaterPlugins = exports.getTextAnimaterProperties = void 0;
const property_1 = __webpack_require__(/*! ./property */ "./src/aegl/property/property.ts");
const aegl_default_values_1 = __webpack_require__(/*! ../aegl-default-values */ "./src/aegl/aegl-default-values.ts");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
const bezier_1 = __webpack_require__(/*! ../../libs/math/bezier */ "./src/libs/math/bezier.ts");
const aegl_enums_1 = __webpack_require__(/*! ../aegl-enums */ "./src/aegl/aegl-enums.ts");
const base_1 = __webpack_require__(/*! ../plugins/text-animaters/base */ "./src/aegl/plugins/text-animaters/base.ts");
const random_1 = __webpack_require__(/*! ../../libs/math/random */ "./src/libs/math/random.ts");
const aegl_enums_2 = __webpack_require__(/*! ../aegl-enums */ "./src/aegl/aegl-enums.ts");
/**
 * 用于获取某时刻的文字动画附加属性, 应确保 animaters 属性存在.
 * @param total 总的文字数目或者单词数或者行数, 跟 AETextAnimaterSelecterBasedOn 有关.
 */
function getTextAnimaterProperties(textLayerData, time, charIndices) {
    let generator = new TextAnimaterGenerator(textLayerData, time, charIndices);
    return generator.generateProperties();
}
exports.getTextAnimaterProperties = getTextAnimaterProperties;
/** 用于生成文字动画. */
class TextAnimaterGenerator {
    layerData;
    time;
    charIndices;
    animaterPropertieValuesArray = [];
    animaterSelectorValuesArray = [];
    constructor(textLayerData, time, charIndices) {
        this.layerData = textLayerData;
        this.charIndices = charIndices;
        this.time = time;
        this.initializeCharFreeSelectorValues();
    }
    /** 生成字符无关的动画属性. */
    initializeCharFreeSelectorValues() {
        for (let animater of this.layerData.animaters) {
            let { selectors, properties } = animater;
            let propertyValues = (0, property_1.getPropertyValues)(properties, this.time);
            if (selectors) {
                let selectValueArray = selectors.map(selector => {
                    return (0, property_1.getPropertyValues)(selector, this.time, aegl_default_values_1.TextAnimaterSelecterDefaultValues);
                });
                this.animaterSelectorValuesArray.push(selectValueArray);
            }
            else {
                this.animaterSelectorValuesArray.push(null);
            }
            this.animaterPropertieValuesArray.push(propertyValues);
        }
    }
    /** 生成逐文字动画属性. */
    generateProperties() {
        let propertiesArray = [];
        for (let i = 0; i < this.charIndices.length; i++) {
            let finalProperties = null;
            for (let animaterIndex = 0; animaterIndex < this.layerData.animaters.length; animaterIndex++) {
                let currentProperties = this.getSingleTextAnimaterProperties(animaterIndex, i);
                if (finalProperties) {
                    finalProperties = this.mergeAnimaterProperties(finalProperties, currentProperties);
                }
                else {
                    finalProperties = currentProperties;
                }
            }
            (0, ff_1.assignIf)(finalProperties, aegl_default_values_1.TextAnimatorPropertiesDefaultValues);
            propertiesArray.push(finalProperties);
        }
        return propertiesArray;
    }
    /** 获取单个 animater 的当前属性. */
    getSingleTextAnimaterProperties(animaterIndex, index) {
        let animater = this.layerData.animaters[animaterIndex];
        let selectorValuesArray = this.animaterSelectorValuesArray[animaterIndex];
        let propertyValues = this.animaterPropertieValuesArray[animaterIndex];
        let finalAmount = 1;
        let plugin = null;
        // 没有指定选择器, 直接返回当前属性.
        if (!selectorValuesArray) {
            return propertyValues;
        }
        for (let i = 0; i < selectorValuesArray.length; i++) {
            let selectorValues = selectorValuesArray[i];
            let [charIndex, charTotal] = this.getCharIndex(index, selectorValues.basedOn);
            let amount;
            // 将索引随机调整为另一个索引.
            if (selectorValues.randomizeOrder === 1) {
                charIndex = (0, random_1.seedRandom)(0, charTotal, (selectorValues.randomSeed || 0) + charIndex);
            }
            // 对于表达式, 获得对应的插件, 然后从其 amount 方法生成.
            if (selectorValues.amount === 'EXPRESSION') {
                plugin = getAnimaterPlugin(this.layerData, animater, this.time);
                amount = plugin.amount(charIndex, charTotal) / 100;
                // 将属性通过插件重新做计算.
                for (let key of Object.keys(propertyValues)) {
                    propertyValues[key] = plugin[key](index, this.charIndices.length);
                }
            }
            else {
                // 获得初始值.
                amount = this.getSelectorInitialAmount(selectorValues, charIndex, charTotal);
                // 如果是第一个并且是相减模式, 则取 1 - x, 否则取 x.
                if (i === 0 && selectorValues.mode === aegl_enums_1.AETextAnimaterSelecterMode.Subtract) {
                    amount = 1 - amount;
                }
                // 处理高点和低点的缓动.
                if (selectorValues.easeHigh || selectorValues.easeLow) {
                    amount = mapEaseHighLow(amount, selectorValues.easeHigh, selectorValues.easeLow);
                }
                // 乘以当前的权重.
                amount *= selectorValues.amount / 100;
            }
            if (i === 0) {
                finalAmount = amount;
            }
            // 从上到下合并.
            else {
                finalAmount = this.mergeSelectorAmounts(finalAmount, amount, selectorValues.mode);
            }
            // 约束到 -1~1. 经过对 AE 的测试确定其为每步约束, 而不是最后约束.
            finalAmount = (0, ff_1.constrain)(finalAmount, -1, 1);
        }
        // 将属性值乘以 amount 返回.
        let o = {};
        // 将当前时刻的值和原始值按照 finalAmount 指定的百分比混合.
        for (let key of Object.keys(propertyValues)) {
            o[key] = this.mixPropertyValue(propertyValues[key], aegl_default_values_1.TextAnimatorPropertiesDefaultValues[key], finalAmount);
        }
        return o;
    }
    /** 获得指定索引位置字符在某个索引结构下的索引值. */
    getCharIndex(index, basedOn) {
        let indices = this.charIndices[index];
        if (basedOn === aegl_enums_2.AETextAnimaterSelecterBasedOn.CharactersExcludingSpaces) {
            return [
                indices.charIndexExcludeSpace,
                this.charIndices[this.charIndices.length - 1].charIndexExcludeSpace + 1
            ];
        }
        else if (basedOn === aegl_enums_2.AETextAnimaterSelecterBasedOn.Words) {
            return [
                indices.wordIndex,
                this.charIndices[this.charIndices.length - 1].wordIndex + 1
            ];
        }
        else if (basedOn === aegl_enums_2.AETextAnimaterSelecterBasedOn.Lines) {
            return [
                indices.lineIndex,
                this.charIndices[this.charIndices.length - 1].lineIndex + 1
            ];
        }
        else {
            return [
                indices.charIndex,
                this.charIndices[this.charIndices.length - 1].charIndex + 1
            ];
        }
    }
    /** 获取选择器的初始计算值, 仅跟位置以及形状有关. */
    getSelectorInitialAmount(selectorValues, index, total) {
        // 计算当前在动画周期中的百分比, 以及形状下的对应值.
        // 这里没有考虑 units, 因为不同的 units 下的计算方式相同.
        let range = selectorValues.end - selectorValues.start;
        let x = (index / total * range - selectorValues.offset - selectorValues.start) / range;
        if (selectorValues.shape == aegl_enums_1.AETextAnimaterSelecterShape.Square) {
            return this.getSquareShapeAmount(x, total, range, selectorValues.smoothness);
        }
        else {
            return this.getNotSquareShapeAmount(x, selectorValues.shape);
        }
    }
    /** 获得在 Square Shape 下的 Y 值. */
    getSquareShapeAmount(x, total, range, smoothness) {
        // 理论值为 1, 但是实测略大于 1 效果会更加平滑.
        let smoothRange = 1.1 / total * smoothness / range;
        if (x < 0) {
            return linearStep(-smoothRange, 0, x);
        }
        else if (x > 1) {
            return linearStep(1, 1 + smoothRange, x);
        }
        else {
            return 1;
        }
    }
    /** 根据形状设置以及 x 值返回 y 值. */
    getNotSquareShapeAmount(x, shape) {
        x = (0, ff_1.constrain)(x, 0, 1);
        let y;
        switch (shape) {
            case aegl_enums_1.AETextAnimaterSelecterShape.RampUp:
                y = x;
                break;
            case aegl_enums_1.AETextAnimaterSelecterShape.RampDown:
                y = 1 - x;
                break;
            case aegl_enums_1.AETextAnimaterSelecterShape.Triangle:
                y = Math.max(1 - 2 * Math.abs(x - 0.5), 0);
                break;
            case aegl_enums_1.AETextAnimaterSelecterShape.Round:
                y = Math.sqrt(1 - Math.pow(2 * x - 1, 2));
                break;
            case aegl_enums_1.AETextAnimaterSelecterShape.Smooth:
                x = Math.max(1 - 2 * Math.abs(x - 0.5), 0);
                y = 3 * Math.pow(x, 2) - 2 * Math.pow(x, 3);
                break;
        }
        return y;
    }
    /** 根据模式合并两个选择器的值. */
    mergeSelectorAmounts(top, bot, mode) {
        switch (mode) {
            case aegl_enums_1.AETextAnimaterSelecterMode.Add:
                return top + bot;
            case aegl_enums_1.AETextAnimaterSelecterMode.Subtract:
                return top * (1 - bot);
            case aegl_enums_1.AETextAnimaterSelecterMode.Intersect:
                return top * bot;
            case aegl_enums_1.AETextAnimaterSelecterMode.Min:
                return Math.min(top, bot);
            case aegl_enums_1.AETextAnimaterSelecterMode.Max:
                return Math.max(top, bot);
            case aegl_enums_1.AETextAnimaterSelecterMode.Difference:
                return bot - top;
        }
    }
    /** 如果是数字或者数字数组, 将其乘以一个权重. */
    mixPropertyValue(value, defaultValue, amount) {
        if (typeof value === 'number') {
            return value * amount + (defaultValue || 0) * (1 - amount);
        }
        else if (Array.isArray(value) && typeof value[0] === 'number') {
            if (defaultValue === undefined) {
                return value.map(v => v * amount);
            }
            else {
                return value.map((v, index) => v * amount + defaultValue[index] * (1 - amount));
            }
        }
        else {
            return value;
        }
    }
    /** 从上到下合并动画属性. */
    mergeAnimaterProperties(top, bot) {
        for (let key of Object.keys(bot)) {
            if (top.hasOwnProperty(key)) {
                top[key] = this.mergePropertyValues(key, top[key], bot[key]);
            }
            else {
                top[key] = bot[key];
            }
        }
        return top;
    }
    /** 合并数字或者数字数组的属性值. */
    mergePropertyValues(key, top, bot) {
        if (key === 'opacity' || key === 'scale') {
            if (typeof top === 'number') {
                return top * bot / 100;
            }
            else if (Array.isArray(top) && typeof top[0] === 'number') {
                return top.map((tv, index) => tv * bot[index] / 100);
            }
            else {
                return bot;
            }
        }
        else {
            if (typeof top === 'number') {
                return top + bot;
            }
            else if (Array.isArray(top) && typeof top[0] === 'number') {
                return top.map((tv, index) => tv + bot[index]);
            }
            else {
                return bot;
            }
        }
    }
}
/** 用于存储 Animater 到已实例化的 Plugin 的映射, 由于表达式 Animater 的数据是不应当被更改的, 所以不用清除缓存. */
let AnimaterPluginMap = new Map();
/** 获得插件实例化的插件. */
function getAnimaterPlugin(textLayerData, animater, time) {
    let plugin = AnimaterPluginMap.get(animater);
    if (!plugin) {
        let Plugin = (0, base_1.getTextAnimaterPlugin)(animater.name);
        plugin = new Plugin(textLayerData, animater);
        plugin.initialize();
        AnimaterPluginMap.set(animater, plugin);
    }
    plugin.updateTime(time);
    return plugin;
}
/** 清空所有已注册的文字动画插件, 需要在文字动画属性更改之后调用. */
function clearTextAnimaterPlugins() {
    AnimaterPluginMap = new Map();
}
exports.clearTextAnimaterPlugins = clearTextAnimaterPlugins;
/** 在范围内进行平滑插值. */
function linearStep(start, end, value) {
    if (value <= start) {
        return 0;
    }
    else if (value >= end) {
        return 1;
    }
    else {
        let x = (value - start) / (end - start);
        return x;
    }
}
/** 因为高低点缓动函数的总数有限, 而且一般只会用到几个, 所以这里增加一层缓存. */
const EaseHighLowFnCache = new Map();
/**
 * 处理高点和低点的缓动映射.
 * easeHigh 和 easeLow 介于 -100~100, 当为正时对应的控制点在 x 轴, 为负时在 y 轴.
 */
function mapEaseHighLow(x, easeHigh, easeLow) {
    // 16 字节的数字, easeHigh 放到前 8 位, easeLow 放到后 8 位.
    let id = (easeHigh + 100) * 256 + (easeLow + 100);
    let fn = EaseHighLowFnCache.get(id);
    if (!fn) {
        let x1 = easeLow >= 0 ? easeLow / 100 : 0;
        let y1 = easeLow >= 0 ? 0 : -easeLow / 100;
        let x2 = easeHigh >= 0 ? 1 - easeHigh / 100 : 1;
        let y2 = easeHigh >= 0 ? 1 : 1 + easeHigh / 100;
        fn = (0, bezier_1.getCubicBezierEasingFunction)(x1, y1, x2, y2);
        EaseHighLowFnCache.set(id, fn);
    }
    return fn(x);
}
/** 根据文字的尺寸和 tracking 获得文字的字母像素间距. */
function getLetterSpacingFronTracking(fontSize, tracking) {
    return fontSize * tracking / 1100; // 这只是一个猜测.
}
exports.getLetterSpacingFronTracking = getLetterSpacingFronTracking;
/**
 * 根据文字的尺寸和 tracking amount 获得文字的字母像素间距.
 * trackingAmount 用于文字动画, 它和 tracking 的解析不同.
 */
function getLetterSpacingFronTrackingAmount(fontSize, trackingAmount) {
    return fontSize * trackingAmount / 100;
}
exports.getLetterSpacingFronTrackingAmount = getLetterSpacingFronTrackingAmount;
/** 获得对齐方式所对应的比例: 左 - 0; 中 - 0.5, 右 - 1. */
function getAlignRateFromLeft(justification) {
    return justification === aegl_enums_2.AETextParagraphJustification.LeftJustify || justification === aegl_enums_2.AETextParagraphJustification.FullJustifyLastLineLeft
        ? 0
        : justification === aegl_enums_2.AETextParagraphJustification.RightJustify || justification === aegl_enums_2.AETextParagraphJustification.FullJustifyLastLineRight
            ? 1
            : 0.5;
}
exports.getAlignRateFromLeft = getAlignRateFromLeft;


/***/ }),

/***/ "./src/aegl/property/tile.ts":
/*!***********************************!*\
  !*** ./src/aegl/property/tile.ts ***!
  \***********************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.getTileMatrixes = void 0;
const aegl_default_values_1 = __webpack_require__(/*! ../aegl-default-values */ "./src/aegl/aegl-default-values.ts");
const property_1 = __webpack_require__(/*! ./property */ "./src/aegl/property/property.ts");
const matrix4_1 = __webpack_require__(/*! ../../libs/math/matrix4 */ "./src/libs/math/matrix4.ts");
/*
关于 Tile 变换处理的备注:
AE 的 Tile 渲染基于像素渲染, 其下的层渲染为像素然后作为输入.
处理 Tile 时会扩展输入的像素.
但是我们在这里使用的是类似 3D 游戏的实时渲染方式, 它将一个图片视为一个对象,
对其的多道变换以及 Tile 都将被作为一系列的变换处理再合成变换矩阵.
由于 Tile 一般用于防止不能覆盖整个画布, 我们假设 Tile 重叠的总是原图的边缘,
那么其相当于在进行完所有的变换之后, 再按照自身坐标系进行重叠,
即将用于重叠的矩阵乘以基底, 即放在矩阵序列的最右侧.

注意 Tile 在渲染宽高比和原图不一致的图形时, 由于坐标结构不同, 所以可能会产生很大的偏差.
因此用户图片必须被裁剪为宽高比和原图一致.
*/
/** 根据 Tile 变换特效计算其作用于对象的变换矩阵以及作用于采样的重复矩阵. */
function getTileMatrixes(effectData, time, videoWidth, videoHeight) {
    let values = (0, property_1.getPropertyValues)(effectData, time, aegl_default_values_1.EffectTileDefaultValues);
    let transformMatrix = getTileTransformMatrix(values, videoWidth, videoHeight);
    let samplingMatrix = getTileSamplingMatrix(values, videoWidth, videoHeight);
    let matrixes = { transformMatrix, samplingMatrix };
    return matrixes;
}
exports.getTileMatrixes = getTileMatrixes;
/** 根据 Tile 变换特效计算其作用于对象的变换矩阵. */
function getTileTransformMatrix(tileValues, videoWidth, videoHeight) {
    let { outputWidth, outputHeight } = tileValues;
    let transform = new matrix4_1.Matrix4();
    let hw = videoWidth / 2;
    let hh = videoHeight / 2;
    transform.translateSelf(-hw, -hh);
    transform.scaleSelf(outputWidth / 100, outputHeight / 100);
    transform.translateSelf(hw, hh);
    return transform;
}
/** 根据 Tile 变换特效计算其作用于采样坐标的变换矩阵. */
function getTileSamplingMatrix(tileValues, videoWidth, videoHeight) {
    let { tileCenter, tileWidth, tileHeight, outputWidth, outputHeight } = tileValues;
    let transform = new matrix4_1.Matrix4();
    // 采样坐标的移动和本身的移动相反.
    // 由于运动坐标系和采样坐标系一个是左手一个是右手, 所以 y 轴需要反向.
    let centerMoves = [
        -(tileCenter[0] / videoWidth - 0.5),
        tileCenter[1] / videoHeight - 0.5,
    ];
    // 先移动 centerMoves, 再移动 -0.5 以进行以中心为原点的缩放.
    transform.translateSelf(...centerMoves);
    transform.translateSelf(-0.5, -0.5);
    transform.scaleSelf(outputWidth / tileWidth, outputHeight / tileHeight);
    transform.translateSelf(0.5, 0.5);
    return transform;
}


/***/ }),

/***/ "./src/aegl/property/time-map.ts":
/*!***************************************!*\
  !*** ./src/aegl/property/time-map.ts ***!
  \***************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.TimeMap = void 0;
const property_1 = __webpack_require__(/*! ./property */ "./src/aegl/property/property.ts");
/** 用于将最顶部的时间映射为合成层内部的时间. */
class TimeMap {
    /** 从层生成一个时间映射对象. */
    static fromLayer(layerData) {
        let { timeRemap, inPoint, startTime } = layerData;
        let timeRemaps = [];
        if (timeRemap) {
            timeRemaps.push(timeRemap);
        }
        else if (startTime !== undefined) {
            if (startTime !== 0) {
                timeRemaps.push(-startTime);
            }
        }
        else {
            if (inPoint !== 0) {
                timeRemaps.push(-inPoint);
            }
        }
        return new TimeMap(timeRemaps);
    }
    /** 从外到内积累的时间映射属性. */
    maps = [];
    constructor(timeRemaps = []) {
        this.maps = timeRemaps;
    }
    /** 合并一个层内部的时间映射, 返回一个新的映射. */
    mergeInner(inner) {
        return new TimeMap([...this.maps, ...inner.maps]);
    }
    /** 合并一个层内部的时间映射, 返回一个新的映射. */
    mergeInnerLayer(layerData) {
        let { timeRemap, inPoint, startTime } = layerData;
        if (timeRemap) {
            return new TimeMap([...this.maps, timeRemap]);
        }
        else if (startTime !== undefined) {
            if (startTime !== 0) {
                return new TimeMap([...this.maps, -startTime]);
            }
            else {
                return this;
            }
        }
        else {
            if (inPoint !== 0) {
                return new TimeMap([...this.maps, -layerData.inPoint]);
            }
            else {
                return this;
            }
        }
    }
    /** 将顶层的时间映射为内部时间. */
    map(time) {
        for (let timeRemap of this.maps) {
            if (Array.isArray(timeRemap)) {
                time = (0, property_1.getPropertyValue)(timeRemap, time);
            }
            else {
                time += timeRemap;
            }
        }
        return time;
    }
    /** 将顶层的时间映射为内部时间, 但是在关键帧区域之外, 仍保持边缘的变化速度. */
    mapAllRange(topTime) {
        let time = topTime;
        for (let timeRemap of this.maps) {
            if (Array.isArray(timeRemap)) {
                time = this.getTimeForAllRange(timeRemap, time);
            }
            else {
                time += timeRemap;
            }
        }
        return time;
    }
    /** 映射单次时间, 在关键帧区域之外, 仍保持边缘的变化速度. */
    getTimeForAllRange(timeRemap, time) {
        if (Array.isArray(timeRemap)) {
            let keyframes = timeRemap;
            let startTime = keyframes[0].time;
            let lastIndex = keyframes.length - 1;
            let endTime = keyframes[lastIndex].time;
            if (time < startTime) {
                let frame0 = keyframes[0];
                let frame1 = keyframes[1];
                let speed = frame0.outEase
                    ? frame0.outEase[0].speed
                    : (frame1.value - frame0.value) / (frame1.time - frame0.time);
                return frame0.value + (time - startTime) * speed;
            }
            else if (time > endTime) {
                let frame0 = keyframes[lastIndex - 1];
                let frame1 = keyframes[lastIndex];
                let speed = frame1.inEase
                    ? frame1.inEase[0].speed
                    : (frame1.value - frame0.value) / (frame1.time - frame0.time);
                return frame1.value + (time - endTime) * speed;
            }
        }
        return (0, property_1.getPropertyValue)(timeRemap, time);
    }
}
exports.TimeMap = TimeMap;


/***/ }),

/***/ "./src/aegl/property/transform.ts":
/*!****************************************!*\
  !*** ./src/aegl/property/transform.ts ***!
  \****************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.createTransformEffectFromLayerData = exports.getTransformFromValues = exports.getTransformValues = void 0;
const property_1 = __webpack_require__(/*! ./property */ "./src/aegl/property/property.ts");
const aegl_default_values_1 = __webpack_require__(/*! ../aegl-default-values */ "./src/aegl/aegl-default-values.ts");
const matrix4_1 = __webpack_require__(/*! ../../libs/math/matrix4 */ "./src/libs/math/matrix4.ts");
/** 根据 transform 数据计算其当前值. */
function getTransformValues(transformData, time) {
    return (0, property_1.getPropertyValues)(transformData, time, aegl_default_values_1.TransformDefaultValues);
}
exports.getTransformValues = getTransformValues;
/** 从已处理的变换数据获得变换矩阵. */
function getTransformFromValues(values) {
    const toRadians = Math.PI / 180;
    // 所有运算均基于左上角位置开始的坐标系, video resolution 指定范围的坐标.
    let { anchorPoint, position, xPosition, yPosition, zPosition, scale, rotation, xRotation, yRotation, zRotation, skewAxis, skew, orientation } = values;
    let { scaleWidth, scaleHeight } = values;
    let transform = new matrix4_1.Matrix4();
    if (anchorPoint) {
        transform.translateSelf(...anchorPoint.map(v => -v));
    }
    // 处理自身旋转.
    if (orientation) {
        transform.rotate3DSelf(...orientation.map(v => v * toRadians));
    }
    // 处理缩放.
    if (scale) {
        transform.scaleSelf(...scale.map(v => v / 100));
    }
    // 只有 AEEffectTransform 会有这两个独立属性.
    if (scaleWidth || scaleHeight) {
        transform.scaleSelf((scaleWidth || 100) / 100, (scaleHeight || 100) / 100);
    }
    // 处理旋转.
    if (rotation || zRotation || yRotation || xRotation) {
        transform.rotate3DSelf((xRotation || 0) * toRadians, (yRotation || 0) * toRadians, (rotation || zRotation || 0) * toRadians);
    }
    // 2D 斜切变换, 未经过详细测试.
    if (skew && skewAxis) {
        transform.rotateSelf(skewAxis * toRadians);
        transform.skewSelf(0, skew * toRadians);
        transform.rotateSelf(-skewAxis * toRadians);
    }
    if (position) {
        transform.translateSelf(...position);
    }
    if (xPosition || yPosition || zPosition) {
        transform.translateSelf(xPosition, yPosition, zPosition);
    }
    return transform;
}
exports.getTransformFromValues = getTransformFromValues;
/** 将一个层的变换属性转为一个变换特效. 需要确保 layerData 的 transform 属性存在. */
function createTransformEffectFromLayerData(layerData) {
    let effectTransform = Object.assign({
        id: layerData.id,
        type: 'transform',
        name: 'Layer Transform',
    }, layerData.transform);
    // 如果设置了 motionBlur, 将 shutterAngle 设置为 180
    // 自身有文字动画的文本层的 motionBlur 在文本层内部渲染.
    let isTextLayerAndHaveAnimaters = layerData.type === 'text' && layerData.animaters;
    if (!isTextLayerAndHaveAnimaters && layerData.motionBlur) {
        effectTransform.shutterAngle = 180;
    }
    return effectTransform;
}
exports.createTransformEffectFromLayerData = createTransformEffectFromLayerData;


/***/ }),

/***/ "./src/aegl/renderer/drawer.ts":
/*!*************************************!*\
  !*** ./src/aegl/renderer/drawer.ts ***!
  \*************************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Drawer = void 0;
/** 组织某一类别的绘制或者多个绘制的基础函数, 例如绘制层, layer style, 多个形状, 多个裁剪等. */
class Drawer {
    /** 当前的数据. */
    data;
    /** 当前渲染器. */
    renderer;
    /** 当前时刻, 非顶层渲染树时刻, 而是内部时刻. */
    time;
    /** 变换状态统计. */
    transformStat;
    /** 当前变换状态. */
    transformStatus;
    constructor(renderer, layerData) {
        this.renderer = renderer;
        this.data = layerData;
    }
    /** 更新变换状态统计. */
    setTransformStat(stat) {
        this.transformStat = stat;
    }
    /** 设置时刻. 可以选择在其中更新与时间相关的属性. */
    setTime(time) {
        this.time = time;
    }
    /** 更新变换属性. 此时已经调用过 setTime. */
    setTransformStatus(status) {
        this.transformStatus = status;
    }
    /** 准备绘制的所有剩余资源, 例如绘制需要的纹理等等. */
    update() { }
    /** 设置或者清除蒙版区域. */
    setMaskArea(_area) { }
    /** 绘制. */
    draw(inputArea = null) {
        return inputArea;
    }
    /** 移除. */
    delete() { }
}
exports.Drawer = Drawer;


/***/ }),

/***/ "./src/aegl/renderer/effects/all.ts":
/*!******************************************!*\
  !*** ./src/aegl/renderer/effects/all.ts ***!
  \******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.getEffectClass = exports.isMultiSamplingEffect = exports.isPixelToPixelEffect = exports.isFullscreenEffect = exports.getEffectInputCount = exports.isRenderableEffect = void 0;
const bulge_1 = __webpack_require__(/*! ./bulge */ "./src/aegl/renderer/effects/bulge.ts");
const motion_blur_1 = __webpack_require__(/*! ./motion-blur */ "./src/aegl/renderer/effects/motion-blur.ts");
const drop_shadow_1 = __webpack_require__(/*! ./drop-shadow */ "./src/aegl/renderer/effects/drop-shadow.ts");
const directional_blur_1 = __webpack_require__(/*! ./directional-blur */ "./src/aegl/renderer/effects/directional-blur.ts");
const tile_1 = __webpack_require__(/*! ./tile */ "./src/aegl/renderer/effects/tile.ts");
const fill_1 = __webpack_require__(/*! ./fill */ "./src/aegl/renderer/effects/fill.ts");
const mask_1 = __webpack_require__(/*! ./mask */ "./src/aegl/renderer/effects/mask.ts");
const gamma_1 = __webpack_require__(/*! ./gamma */ "./src/aegl/renderer/effects/gamma.ts");
const tint_1 = __webpack_require__(/*! ./tint */ "./src/aegl/renderer/effects/tint.ts");
const displacement_map_1 = __webpack_require__(/*! ./displacement-map */ "./src/aegl/renderer/effects/displacement-map.ts");
const blend_1 = __webpack_require__(/*! ./blend */ "./src/aegl/renderer/effects/blend.ts");
const fractal_noise_1 = __webpack_require__(/*! ./fractal-noise */ "./src/aegl/renderer/effects/fractal-noise.ts");
const easy_levels_1 = __webpack_require__(/*! ./easy-levels */ "./src/aegl/renderer/effects/easy-levels.ts");
const ramp_1 = __webpack_require__(/*! ./ramp */ "./src/aegl/renderer/effects/ramp.ts");
const fast_blur_1 = __webpack_require__(/*! ./fast-blur */ "./src/aegl/renderer/effects/fast-blur.ts");
/** 枚举所有的特效类. */
// 尽管看起来这里枚举所有特效会让每次添加特效时需要修改两个文件,
// 然而实际上必须要引用所有的 ts 文件, 所以无法避免修改两个文件.
const EffectMap = {
    bulge: bulge_1.BulgeEffect,
    motionBlur: motion_blur_1.MotionBlurEffect,
    gaussianBlur: fast_blur_1.FastBlurEffect,
    fastBlur: fast_blur_1.FastBlurEffect,
    dropShadow: drop_shadow_1.DropShadowEffect,
    directionalBlur: directional_blur_1.DirectionalBlurEffect,
    tile: tile_1.TileEffect,
    fill: fill_1.FillEffect,
    mask: mask_1.MaskEffect,
    gamma: gamma_1.GammaEffect,
    tint: tint_1.TintEffect,
    displacementMap: displacement_map_1.DisplacementMapEffect,
    blend: blend_1.BlendEffect,
    fractalNoise: fractal_noise_1.FractalNoiseEffect,
    easyLevels: easy_levels_1.EasyLevelsEffect,
    ramp: ramp_1.RampEffect,
};
/** 这里列出了必须要使用片元着色进行的特效渲染, 以及其对应的输入数目. */
const RenderableEffectWithInputCount = new Map([
    ['bulge', 1],
    ['motionBlur', 1],
    ['guassianBlur', 1],
    ['fastBlur', 1],
    ['boxBlur', 1],
    ['dropShadow', 1],
    ['directionalBlur', 1],
    ['tile', 1],
    ['fill', 1],
    ['mask', 2],
    ['gamma', 1],
    ['tint', 1],
    ['displacementMap', 2],
    ['blend', 2],
    ['fractalNoise', 1], // 并不是真的不需要输入, 而是在不需要混合时不需要输入.
    ['easyLevels', 1],
    ['ramp', 1],
]);
/** 这里列出了非像素对齐的特效名称. */
const FullscreenEffects = new Set([
    'bulge',
    'tile',
]);
/** 这里列出了除 Fullscreen Effects 外像素会发生位移的特效. */
const PixelMovedEffects = new Set([
    'displacementMap',
]);
/** 这里列出了会进行多重采样的特效名称. */
const MultiSamplingEffects = new Set([
    'motionBlur',
    'guassianBlur',
    'fastBlur',
    'boxBlur',
    'dropShadow',
    'directionalBlur',
]);
/** 检查特效是否必须有像素输入. */
function isRenderableEffect(effectType) {
    return RenderableEffectWithInputCount.has(effectType);
}
exports.isRenderableEffect = isRenderableEffect;
/** 检查特效是否必须有像素输入. */
function getEffectInputCount(effectType) {
    return RenderableEffectWithInputCount.get(effectType);
}
exports.getEffectInputCount = getEffectInputCount;
/**
 * 检查特效是否属于全屏特效, 即非像素对齐特效,
 * 即这些特效需要将输入进行原样绘制, 外部变换作用于绘制特效, 而内部会重新积累变换矩阵.
 * 在绘制时用于处理输入的参数不用进行投影处理, 原样绘制即可.
 */
function isFullscreenEffect(effectType) {
    return FullscreenEffects.has(effectType);
}
exports.isFullscreenEffect = isFullscreenEffect;
/**
 * 检查特效是否属于像素对齐的特效, 即它可以直接按照外部积累的变换进行绘制.
 * 内部会按照最终的模样绘制, 所以变换矩阵会穿透此特效作用于内部内容.
 * 在绘制时用于处理输入的参数需要进行投影处理.
 */
function isPixelToPixelEffect(effectType) {
    return !FullscreenEffects.has(effectType) && !PixelMovedEffects.has(effectType) && !MultiSamplingEffects.has(effectType);
}
exports.isPixelToPixelEffect = isPixelToPixelEffect;
/**
 * 检查特效是否属于多重采样特效, 多重采样特效大多属于像素对齐特效.
 * 如果为多重采样特效, 那么采样方式应该设置为 Nearest.
 */
function isMultiSamplingEffect(effectType) {
    return MultiSamplingEffects.has(effectType);
}
exports.isMultiSamplingEffect = isMultiSamplingEffect;
/** 根据名称获得特效类. */
function getEffectClass(name) {
    let EffectClass = EffectMap[name];
    if (!EffectClass) {
        throw new Error(`"${name}" is not a registered effect class!`);
    }
    return EffectClass;
}
exports.getEffectClass = getEffectClass;


/***/ }),

/***/ "./src/aegl/renderer/effects/base.ts":
/*!*******************************************!*\
  !*** ./src/aegl/renderer/effects/base.ts ***!
  \*******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Effect = void 0;
const all_1 = __webpack_require__(/*! ./all */ "./src/aegl/renderer/effects/all.ts");
const debug_1 = __webpack_require__(/*! ../../../libs/util/debug */ "./src/libs/util/debug.ts");
const property_1 = __webpack_require__(/*! ../../property/property */ "./src/aegl/property/property.ts");
const aegl_default_values_1 = __webpack_require__(/*! ../../aegl-default-values */ "./src/aegl/aegl-default-values.ts");
const drawer_1 = __webpack_require__(/*! ../drawer */ "./src/aegl/renderer/drawer.ts");
/** 特效用于对输入进行后处理. */
class Effect extends drawer_1.Drawer {
    /** 等待初始化的 promise. */
    ready;
    /** 主绘制对象. */
    toDraw;
    /** 是否是全屏的特效, 例如 Bulge. */
    isFullscreenEffect;
    constructor(renderer, data) {
        super(renderer, data);
        this.isFullscreenEffect = (0, all_1.isFullscreenEffect)(data.type);
        // 稍微延迟调用 initialize 以等待子类初始化完成.
        this.ready = Promise.resolve().then(() => this.initialize());
        debug_1.debug.verbose(`${this.constructor.name} ${this.data.id} created`);
    }
    /** 初始化绘制层, 加载资源和着色器代码等. */
    async initialize() { }
    /** 使用已有的纹理作为输入. */
    setMappedChannel(...mss) {
        this.toDraw.setMappedChannel(...mss);
    }
    /** 不再使用输入纹理. */
    clearChannel() {
        this.toDraw.clearChannel();
    }
    /** 更新变换属性, 此时已经调用过 setTime. */
    setTransformStatus(status) {
        this.transformStatus = status;
        // 对于全屏特效, 需要原样绘制原图, 再应用变换进行绘制.
        // 内部的绘制参数也不用进行投影.
        if (this.isFullscreenEffect) {
            this.toDraw.setTransformStatus(status);
        }
        // 对于像素对齐绘制而言, 这些特效的变换属性穿透此特效层作用于内容,
        // 当前特效不用应用此变换, 仅有透明度在该层绘制.
        // 内部的绘制参数需要进行投影处理.
        else {
            this.toDraw.setTransformStatus(status.cloneOpacity());
        }
    }
    /**
     * 准备绘制的所有剩余资源, 例如绘制需要的纹理等等.
     * 如果一个层被引用两次并且状态信息相同, 那么这个只会被调用一次.
     */
    update() {
        if (this.data.effectOpacity !== undefined) {
            let effectOpacity = (0, property_1.getPropertyValue)(this.data.effectOpacity, this.time, aegl_default_values_1.EffectDefaultValues.effectOpacity) / 100;
            this.toDraw.setUniform('effectOpacity', effectOpacity);
        }
    }
    /** 设置或者清除蒙版区域. */
    setMaskArea(area) {
        this.toDraw.setMaskArea(area);
    }
    /** 进行绘制, 输入内部的绘制区域, 返回绘制的区域. */
    draw(inputArea) {
        this.toDraw.draw();
        return inputArea;
    }
    /**  移除层. */
    delete() {
        this.toDraw.delete();
        debug_1.debug.verbose(`${this.constructor.name} ${this.data.id} deleted`);
    }
}
exports.Effect = Effect;


/***/ }),

/***/ "./src/aegl/renderer/effects/blend.ts":
/*!********************************************!*\
  !*** ./src/aegl/renderer/effects/blend.ts ***!
  \********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.BlendEffect = void 0;
const base_1 = __webpack_require__(/*! ./base */ "./src/aegl/renderer/effects/base.ts");
const all_1 = __webpack_require__(/*! ../../shaders/blends/all */ "./src/aegl/shaders/blends/all.ts");
const to_draw_effect_1 = __webpack_require__(/*! ../to-draws/to-draw-effect */ "./src/aegl/renderer/to-draws/to-draw-effect.ts");
/** 用于绘制颜色混合特效. */
class BlendEffect extends base_1.Effect {
    async initialize() {
        this.toDraw = new to_draw_effect_1.ToDrawEffect({
            renderer: this.renderer,
            fragCode: (0, all_1.getBlendFragCode)(this.data.blendingMode),
        });
    }
    draw(inputArea) {
        this.toDraw.setInputPaintArea(inputArea);
        this.toDraw.draw();
        return inputArea;
    }
}
exports.BlendEffect = BlendEffect;


/***/ }),

/***/ "./src/aegl/renderer/effects/bulge.ts":
/*!********************************************!*\
  !*** ./src/aegl/renderer/effects/bulge.ts ***!
  \********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.BulgeEffect = void 0;
const base_1 = __webpack_require__(/*! ./base */ "./src/aegl/renderer/effects/base.ts");
const property_1 = __webpack_require__(/*! ../../property/property */ "./src/aegl/property/property.ts");
const aegl_default_values_1 = __webpack_require__(/*! ../../aegl-default-values */ "./src/aegl/aegl-default-values.ts");
const to_draw_effect_1 = __webpack_require__(/*! ../to-draws/to-draw-effect */ "./src/aegl/renderer/to-draws/to-draw-effect.ts");
const bulge_frag_1 = __webpack_require__(/*! ../../shaders/effects/bulge.frag */ "./src/aegl/shaders/effects/bulge.frag");
/** 用于绘制鱼眼特效. */
class BulgeEffect extends base_1.Effect {
    async initialize() {
        this.toDraw = new to_draw_effect_1.ToDrawEffect({
            renderer: this.renderer,
            fragCode: bulge_frag_1.default,
        });
    }
    update() {
        super.update();
        let values = (0, property_1.getPropertyValues)(this.data, this.time, aegl_default_values_1.EffectBulgeDefaultValues);
        this.toDraw.setUniform('horizontalRadius', values.horizontalRadius);
        this.toDraw.setUniform('verticalRadius', values.verticalRadius);
        this.toDraw.setUniform('bulgeCenter', values.bulgeCenter);
        this.toDraw.setUniform('bulgeHeight', values.bulgeHeight);
    }
}
exports.BulgeEffect = BulgeEffect;


/***/ }),

/***/ "./src/aegl/renderer/effects/directional-blur.ts":
/*!*******************************************************!*\
  !*** ./src/aegl/renderer/effects/directional-blur.ts ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.DirectionalBlurEffect = void 0;
const base_1 = __webpack_require__(/*! ./base */ "./src/aegl/renderer/effects/base.ts");
const property_1 = __webpack_require__(/*! ../../property/property */ "./src/aegl/property/property.ts");
const to_draw_effect_1 = __webpack_require__(/*! ../to-draws/to-draw-effect */ "./src/aegl/renderer/to-draws/to-draw-effect.ts");
const directional_blur_frag_1 = __webpack_require__(/*! ../../shaders/effects/directional-blur.frag */ "./src/aegl/shaders/effects/directional-blur.frag");
const vector4_1 = __webpack_require__(/*! ../../../libs/math/vector4 */ "./src/libs/math/vector4.ts");
/** 用于绘制径向模糊特效. */
class DirectionalBlurEffect extends base_1.Effect {
    async initialize() {
        let projectOptions = this.renderer.project.options;
        // 用于绘制径向模糊.
        this.toDraw = new to_draw_effect_1.ToDrawEffect({
            renderer: this.renderer,
            fragCode: directional_blur_frag_1.default,
        });
        // 设置采样数.
        let samplingCount = projectOptions.motionBlurSamplingCount;
        this.toDraw.setUniform('samplingCount', samplingCount);
        // 设置边缘镜像.
        this.toDraw.setUniform('repeatEdgePixels', true);
    }
    update() {
        super.update();
        // direction 代表着从上方开始顺时针方向的角度.
        let values = (0, property_1.getPropertyValues)(this.data, this.time);
        let { direction, blurLength } = values;
        let blurVector = this.transformStatus.projectVector(vector4_1.Vector2.fromAngle(direction - 90).multiplyScalarSelf(blurLength));
        // 更新绘制范围和参数.
        this.toDraw.setUniform('blurVector', blurVector.xy);
    }
    draw(inputArea) {
        this.toDraw.setInputPaintArea(inputArea);
        this.toDraw.draw();
        return inputArea;
    }
}
exports.DirectionalBlurEffect = DirectionalBlurEffect;


/***/ }),

/***/ "./src/aegl/renderer/effects/displacement-map.ts":
/*!*******************************************************!*\
  !*** ./src/aegl/renderer/effects/displacement-map.ts ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.DisplacementMapEffect = void 0;
const base_1 = __webpack_require__(/*! ./base */ "./src/aegl/renderer/effects/base.ts");
const property_1 = __webpack_require__(/*! ../../property/property */ "./src/aegl/property/property.ts");
const aegl_default_values_1 = __webpack_require__(/*! ../../aegl-default-values */ "./src/aegl/aegl-default-values.ts");
const to_draw_effect_1 = __webpack_require__(/*! ../to-draws/to-draw-effect */ "./src/aegl/renderer/to-draws/to-draw-effect.ts");
const displacement_map_frag_1 = __webpack_require__(/*! ../../shaders/effects/displacement-map.frag */ "./src/aegl/shaders/effects/displacement-map.frag");
const vector4_1 = __webpack_require__(/*! ../../../libs/math/vector4 */ "./src/libs/math/vector4.ts");
/** 用于绘制移位特效. */
class DisplacementMapEffect extends base_1.Effect {
    async initialize() {
        this.toDraw = new to_draw_effect_1.ToDrawEffect({
            renderer: this.renderer,
            fragCode: displacement_map_frag_1.default,
        });
    }
    update() {
        super.update();
        // 将位移像素进行投影.
        let values = (0, property_1.getPropertyValues)(this.data, this.time, aegl_default_values_1.EffectDisplacementMapDefaultValues);
        let maxDisplacement = new vector4_1.Vector2(values.maxHorizontalDisplacement, values.maxVerticalDisplacement);
        maxDisplacement = this.transformStatus.projectVector(maxDisplacement);
        this.toDraw.setUniform('maxDisplacement', maxDisplacement.xy);
    }
    draw(inputArea) {
        this.toDraw.setInputPaintArea(inputArea);
        this.toDraw.draw();
        return inputArea;
    }
}
exports.DisplacementMapEffect = DisplacementMapEffect;


/***/ }),

/***/ "./src/aegl/renderer/effects/drop-shadow.ts":
/*!**************************************************!*\
  !*** ./src/aegl/renderer/effects/drop-shadow.ts ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.DropShadowEffect = void 0;
const property_1 = __webpack_require__(/*! ../../property/property */ "./src/aegl/property/property.ts");
const aegl_default_values_1 = __webpack_require__(/*! ../../aegl-default-values */ "./src/aegl/aegl-default-values.ts");
const base_1 = __webpack_require__(/*! ./base */ "./src/aegl/renderer/effects/base.ts");
const to_draw_effect_1 = __webpack_require__(/*! ../to-draws/to-draw-effect */ "./src/aegl/renderer/to-draws/to-draw-effect.ts");
const paint_area_1 = __webpack_require__(/*! ../../../libs/area/paint-area */ "./src/libs/area/paint-area.ts");
const transform_status_1 = __webpack_require__(/*! ../tree/transform-status */ "./src/aegl/renderer/tree/transform-status.ts");
const matrix4_1 = __webpack_require__(/*! ../../../libs/math/matrix4 */ "./src/libs/math/matrix4.ts");
const to_draw_drop_shadow_1 = __webpack_require__(/*! ../to-draws/to-draw-drop-shadow */ "./src/aegl/renderer/to-draws/to-draw-drop-shadow.ts");
const drop_shadow_blend_frag_1 = __webpack_require__(/*! ../../shaders/effects/drop-shadow-blend.frag */ "./src/aegl/shaders/effects/drop-shadow-blend.frag");
const color_1 = __webpack_require__(/*! ../../helpers/color */ "./src/aegl/helpers/color.ts");
const vector4_1 = __webpack_require__(/*! ../../../libs/math/vector4 */ "./src/libs/math/vector4.ts");
/** 用于绘制 Drop Shadow 特效. */
class DropShadowEffect extends base_1.Effect {
    /** 用于绘制完阴影后和原图叠加. */
    toBlendShadow;
    /** 阴影偏移矩阵, 表示原始的未经过外部变换处理的阴影偏移. */
    shadowTranslateMatrix;
    async initialize() {
        // 用于绘制输入图像和阴影的叠加.
        // 为什么不分别做两个绘制呢? 先绘制阴影再绘制原图.
        // 原因是如果有外部透明度, 那么原图会因为叠加了透明度而导致下面的阴影透出来.
        this.toBlendShadow = new to_draw_effect_1.ToDrawEffect({
            renderer: this.renderer,
            fragCode: drop_shadow_blend_frag_1.default,
        });
        // 设置原始图的透明度.
        this.toBlendShadow.setUniform('fillOpacity', this.data.shadowOnly !== 1 ? 1 : 0);
        // 用于来回 ping-pong 进行横竖的模糊绘制.
        let projectOptions = this.renderer.project.options;
        let iterateCount = projectOptions.dropShadowRenderingIterateCount;
        let blurRadius = this.data.softness ? (0, property_1.getMaxPropertyValue)(this.data.softness) / 2 : 0;
        let samplingCount = blurRadius * 4 * this.renderer.scaleRatio;
        this.toDraw = new to_draw_drop_shadow_1.ToDrawDropShadow({
            renderer: this.renderer,
            iterateCount,
            samplingCount,
        });
    }
    setMappedChannel(ms) {
        this.toBlendShadow.setMappedChannel(ms);
        this.toDraw.setMappedChannel(ms);
    }
    clearChannel() {
        this.toDraw.clearChannel();
    }
    update() {
        super.update();
        let values = (0, property_1.getPropertyValues)(this.data, this.time, aegl_default_values_1.EffectDropShadowDefaultValues);
        let { width: videoWidth, height: videoHeight } = this.renderer.project.data;
        let { distance, direction } = values;
        let shadowTranslate = this.transformStatus.projectVector(vector4_1.Vector2.fromAngle(direction - 90).multiplyScalarSelf(distance));
        let shadowTranslateMatrix = new matrix4_1.Matrix4().translateSelf(shadowTranslate.x, shadowTranslate.y);
        let shadowOpacity = values.opacity / 100 * this.transformStatus.opacity;
        // 计算阴影变换.
        let shadowTransformStatus = new transform_status_1.TransformStatus(videoWidth, videoHeight, shadowTranslateMatrix, shadowOpacity);
        this.shadowTranslateMatrix = shadowTranslateMatrix;
        this.toDraw.setTransformStatus(shadowTransformStatus);
        // 计算模糊方向向量.
        let blurRadius = this.transformStatus.projectVector(new vector4_1.Vector2(values.softness / 2, values.softness / 2));
        this.toDraw.setBlurRadius(blurRadius);
        // 设置阴影颜色.
        this.toDraw.setUniform('shadowColor', (0, color_1.premultiplyColorArray)(values.shadowColor));
    }
    setMaskArea(area) {
        this.toBlendShadow.setMaskArea(area);
        this.toDraw.setMaskArea(area);
    }
    draw(inputArea) {
        this.toDraw.setInputPaintArea(inputArea);
        // 绘制阴影.
        let shadowMappedSampler = this.toDraw.drawAsSampler();
        // 绘制原图和阴影.
        let drawArea = paint_area_1.PaintArea.union([this.toDraw.getPaintArea(), inputArea]);
        this.toBlendShadow.setInputPaintArea(drawArea);
        this.toBlendShadow.setSubMappedChannel(1, shadowMappedSampler);
        this.toBlendShadow.draw();
        this.toBlendShadow.clearChannel();
        return drawArea;
    }
    delete() {
        super.delete();
        this.toBlendShadow.delete();
    }
}
exports.DropShadowEffect = DropShadowEffect;


/***/ }),

/***/ "./src/aegl/renderer/effects/easy-levels.ts":
/*!**************************************************!*\
  !*** ./src/aegl/renderer/effects/easy-levels.ts ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.EasyLevelsEffect = void 0;
const base_1 = __webpack_require__(/*! ./base */ "./src/aegl/renderer/effects/base.ts");
const property_1 = __webpack_require__(/*! ../../property/property */ "./src/aegl/property/property.ts");
const aegl_default_values_1 = __webpack_require__(/*! ../../aegl-default-values */ "./src/aegl/aegl-default-values.ts");
const to_draw_effect_1 = __webpack_require__(/*! ../to-draws/to-draw-effect */ "./src/aegl/renderer/to-draws/to-draw-effect.ts");
const easy_levels_frag_1 = __webpack_require__(/*! ../../shaders/effects/easy-levels.frag */ "./src/aegl/shaders/effects/easy-levels.frag");
/** 用于绘制鱼眼特效. */
class EasyLevelsEffect extends base_1.Effect {
    async initialize() {
        this.toDraw = new to_draw_effect_1.ToDrawEffect({
            renderer: this.renderer,
            fragCode: easy_levels_frag_1.default,
        });
    }
    update() {
        super.update();
        let values = (0, property_1.getPropertyValues)(this.data, this.time, aegl_default_values_1.EffectEasyLevelsDefaultValues);
        this.toDraw.setUniform('channel', values.channel);
        this.toDraw.setUniform('inputBlack', values.inputBlack);
        this.toDraw.setUniform('inputWhite', values.inputWhite);
        this.toDraw.setUniform('gamma', values.gamma);
        this.toDraw.setUniform('outputBlack', values.outputBlack);
        this.toDraw.setUniform('outputWhite', values.outputWhite);
    }
}
exports.EasyLevelsEffect = EasyLevelsEffect;


/***/ }),

/***/ "./src/aegl/renderer/effects/fast-blur.ts":
/*!************************************************!*\
  !*** ./src/aegl/renderer/effects/fast-blur.ts ***!
  \************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.FastBlurEffect = void 0;
const base_1 = __webpack_require__(/*! ./base */ "./src/aegl/renderer/effects/base.ts");
const property_1 = __webpack_require__(/*! ../../property/property */ "./src/aegl/property/property.ts");
const aegl_default_values_1 = __webpack_require__(/*! ../../aegl-default-values */ "./src/aegl/aegl-default-values.ts");
const to_draw_fast_blur_1 = __webpack_require__(/*! ../to-draws/to-draw-fast-blur */ "./src/aegl/renderer/to-draws/to-draw-fast-blur.ts");
const vector4_1 = __webpack_require__(/*! ../../../libs/math/vector4 */ "./src/libs/math/vector4.ts");
/** 用于绘制高斯模糊特效. */
class FastBlurEffect extends base_1.Effect {
    async initialize() {
        // 用于来回 ping-pong 进行横竖的模糊绘制.
        this.toDraw = new to_draw_fast_blur_1.ToDrawFastBlur({
            renderer: this.renderer,
            iterateCount: this.renderer.project.options.fastBlurRenderingIterateCount,
            samplingCount: this.renderer.project.options.fastBlurSamplingCount,
        });
    }
    update() {
        let values = (0, property_1.getPropertyValues)(this.data, this.time, aegl_default_values_1.EffectBoxBlurDefaultValues);
        let blurRadius = this.transformStatus.projectVector(new vector4_1.Vector2(values.blurriness, values.blurriness));
        // 设置模糊半径和轴.
        this.toDraw.setBlurRadius(blurRadius);
        this.toDraw.setBlurDimension(values.blurDimensions);
    }
    setMappedChannel(...mss) {
        this.toDraw.setMappedChannel(...mss);
    }
    clearChannel() {
        this.toDraw.clearChannel();
    }
    setMaskArea(area) {
        this.toDraw.setMaskArea(area);
    }
    draw(inputArea) {
        this.toDraw.setInputPaintArea(inputArea);
        // 绘制模糊.
        this.toDraw.draw();
        return this.toDraw.getPaintArea();
    }
}
exports.FastBlurEffect = FastBlurEffect;


/***/ }),

/***/ "./src/aegl/renderer/effects/fill.ts":
/*!*******************************************!*\
  !*** ./src/aegl/renderer/effects/fill.ts ***!
  \*******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.FillEffect = void 0;
const base_1 = __webpack_require__(/*! ./base */ "./src/aegl/renderer/effects/base.ts");
const property_1 = __webpack_require__(/*! ../../property/property */ "./src/aegl/property/property.ts");
const aegl_default_values_1 = __webpack_require__(/*! ../../aegl-default-values */ "./src/aegl/aegl-default-values.ts");
const to_draw_effect_1 = __webpack_require__(/*! ../to-draws/to-draw-effect */ "./src/aegl/renderer/to-draws/to-draw-effect.ts");
const fill_frag_1 = __webpack_require__(/*! ../../shaders/effects/fill.frag */ "./src/aegl/shaders/effects/fill.frag");
const color_1 = __webpack_require__(/*! ../../helpers/color */ "./src/aegl/helpers/color.ts");
/** 用于绘制填充特效. */
class FillEffect extends base_1.Effect {
    async initialize() {
        this.toDraw = new to_draw_effect_1.ToDrawEffect({
            renderer: this.renderer,
            fragCode: fill_frag_1.default,
        });
    }
    update() {
        super.update();
        let values = (0, property_1.getPropertyValues)(this.data, this.time, aegl_default_values_1.EffectFillDefaultValues);
        this.toDraw.setUniform('fillColor', (0, color_1.premultiplyColorArray)(values.color));
        this.toDraw.setUniform('fillOpacity', values.opacity / 100);
    }
    draw(inputArea) {
        this.toDraw.setInputPaintArea(inputArea);
        this.toDraw.draw();
        return inputArea;
    }
}
exports.FillEffect = FillEffect;


/***/ }),

/***/ "./src/aegl/renderer/effects/fractal-noise.ts":
/*!****************************************************!*\
  !*** ./src/aegl/renderer/effects/fractal-noise.ts ***!
  \****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.FractalNoiseEffect = void 0;
const base_1 = __webpack_require__(/*! ./base */ "./src/aegl/renderer/effects/base.ts");
const to_draw_effect_1 = __webpack_require__(/*! ../to-draws/to-draw-effect */ "./src/aegl/renderer/to-draws/to-draw-effect.ts");
const fractal_noise_frag_1 = __webpack_require__(/*! ../../shaders/effects/fractal-noise.frag */ "./src/aegl/shaders/effects/fractal-noise.frag");
const property_1 = __webpack_require__(/*! ../../property/property */ "./src/aegl/property/property.ts");
const aegl_default_values_1 = __webpack_require__(/*! ../../aegl-default-values */ "./src/aegl/aegl-default-values.ts");
const transform_1 = __webpack_require__(/*! ../../property/transform */ "./src/aegl/property/transform.ts");
/** 用于绘制分形噪声特效. */
class FractalNoiseEffect extends base_1.Effect {
    async initialize() {
        this.toDraw = new to_draw_effect_1.ToDrawEffect({
            renderer: this.renderer,
            fragCode: fractal_noise_frag_1.default,
        });
    }
    update() {
        super.update();
        let values = (0, property_1.getPropertyValues)(this.data, this.time, aegl_default_values_1.EffectFractalNoiseDefaultValues);
        this.toDraw.setUniform('contrast', values.contrast / 100);
        this.toDraw.setUniform('brightness', values.brightness / 100);
        this.toDraw.setUniform('complexity', values.complexity);
        this.toDraw.setUniform('subInfluence', values.subInfluence / 100);
        let transformValues = Object.assign({}, aegl_default_values_1.TransformDefaultValues, {
            rotation: values.rotation,
            scale: values.scale,
            scaleWidth: values.scaleWidth,
            scaleHeight: values.scaleHeight,
            anchorPoint: [this.renderer.project.data.width / 2, this.renderer.project.data.height / 2, 0],
            position: [...values.offsetTurbulence, 0],
        });
        let subTransformValues = Object.assign({}, aegl_default_values_1.TransformDefaultValues, {
            rotation: values.subRotation,
            scaleWidth: values.subScaling,
            scaleHeight: values.subScaling,
            anchorPoint: values.centerSubscale ? [this.renderer.project.data.width / 2, this.renderer.project.data.height / 2, 0] : [0, 0, 0],
            position: [...values.subOffset, 0],
        });
        // 噪声采样坐标的变换是其顶点坐标变换的逆变换.
        let transform = (0, transform_1.getTransformFromValues)(transformValues).inverse();
        let subTransform = (0, transform_1.getTransformFromValues)(subTransformValues).inverse();
        this.toDraw.setUniform('noiseTransform', transform.toFloat32Array());
        this.toDraw.setUniform('subNoiseTransform', subTransform.toFloat32Array());
    }
    draw(inputArea) {
        this.toDraw.setInputPaintArea(inputArea);
        this.toDraw.draw();
        return inputArea;
    }
}
exports.FractalNoiseEffect = FractalNoiseEffect;


/***/ }),

/***/ "./src/aegl/renderer/effects/gamma.ts":
/*!********************************************!*\
  !*** ./src/aegl/renderer/effects/gamma.ts ***!
  \********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.GammaEffect = void 0;
const base_1 = __webpack_require__(/*! ./base */ "./src/aegl/renderer/effects/base.ts");
const property_1 = __webpack_require__(/*! ../../property/property */ "./src/aegl/property/property.ts");
const aegl_default_values_1 = __webpack_require__(/*! ../../aegl-default-values */ "./src/aegl/aegl-default-values.ts");
const to_draw_effect_1 = __webpack_require__(/*! ../to-draws/to-draw-effect */ "./src/aegl/renderer/to-draws/to-draw-effect.ts");
const gamma_frag_1 = __webpack_require__(/*! ../../shaders/effects/gamma.frag */ "./src/aegl/shaders/effects/gamma.frag");
/** 用于绘制鱼眼特效. */
class GammaEffect extends base_1.Effect {
    async initialize() {
        this.toDraw = new to_draw_effect_1.ToDrawEffect({
            renderer: this.renderer,
            fragCode: gamma_frag_1.default,
        });
    }
    update() {
        super.update();
        let values = (0, property_1.getPropertyValues)(this.data, this.time, aegl_default_values_1.EffectGammaDefaultValues);
        this.toDraw.setUniform('redGamma', values.redGamma);
        this.toDraw.setUniform('redPedestal', values.redPedestal);
        this.toDraw.setUniform('redGain', values.redGain);
        this.toDraw.setUniform('greenGamma', values.greenGamma);
        this.toDraw.setUniform('greenPedestal', values.greenPedestal);
        this.toDraw.setUniform('greenGain', values.greenGain);
        this.toDraw.setUniform('blueGamma', values.blueGamma);
        this.toDraw.setUniform('bluePedestal', values.bluePedestal);
        this.toDraw.setUniform('blueGain', values.blueGain);
    }
}
exports.GammaEffect = GammaEffect;


/***/ }),

/***/ "./src/aegl/renderer/effects/mask.ts":
/*!*******************************************!*\
  !*** ./src/aegl/renderer/effects/mask.ts ***!
  \*******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.MaskEffect = void 0;
const base_1 = __webpack_require__(/*! ./base */ "./src/aegl/renderer/effects/base.ts");
const to_draw_effect_1 = __webpack_require__(/*! ../to-draws/to-draw-effect */ "./src/aegl/renderer/to-draws/to-draw-effect.ts");
const mask_alpha_frag_1 = __webpack_require__(/*! ../../shaders/effects/mask-alpha.frag */ "./src/aegl/shaders/effects/mask-alpha.frag");
const mask_luminance_frag_1 = __webpack_require__(/*! ../../shaders/effects/mask-luminance.frag */ "./src/aegl/shaders/effects/mask-luminance.frag");
const aegl_default_values_1 = __webpack_require__(/*! ../../aegl-default-values */ "./src/aegl/aegl-default-values.ts");
/** 用于绘制蒙版特效. */
class MaskEffect extends base_1.Effect {
    async initialize() {
        let trackMatteType = this.data.trackMatteType || aegl_default_values_1.EffectMaskDefaultValues.trackMatteType;
        let trackMatteInverted = trackMatteType === 'ALPHA_INVERTED' || trackMatteType === 'LUMAINANCE_INVERTED';
        this.toDraw = new to_draw_effect_1.ToDrawEffect({
            renderer: this.renderer,
            fragCode: trackMatteType == 'ALPHA' ? mask_alpha_frag_1.default : mask_luminance_frag_1.default,
        });
        this.toDraw.setUniform('inverted', trackMatteInverted);
    }
    draw(inputArea) {
        this.toDraw.setInputPaintArea(inputArea);
        this.toDraw.draw();
        return inputArea;
    }
}
exports.MaskEffect = MaskEffect;


/***/ }),

/***/ "./src/aegl/renderer/effects/motion-blur.ts":
/*!**************************************************!*\
  !*** ./src/aegl/renderer/effects/motion-blur.ts ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.MotionBlurEffect = void 0;
const base_1 = __webpack_require__(/*! ./base */ "./src/aegl/renderer/effects/base.ts");
const to_draw_motion_blur_1 = __webpack_require__(/*! ../to-draws/to-draw-motion-blur */ "./src/aegl/renderer/to-draws/to-draw-motion-blur.ts");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
const property_1 = __webpack_require__(/*! ../../property/property */ "./src/aegl/property/property.ts");
const motion_1 = __webpack_require__(/*! ../../property/motion */ "./src/aegl/property/motion.ts");
/** 用于绘制运动模糊特效. */
class MotionBlurEffect extends base_1.Effect {
    async initialize() {
        // 用于绘制 Motion Blur 效果.
        this.toDraw = new to_draw_motion_blur_1.ToDrawMotionBlur({
            renderer: this.renderer,
        });
        // 默认情况下运动模糊会镜像边缘, 以使得图像的边缘不会泛黑.
        this.toDraw.setRepeatEdgePixels(true);
    }
    /** 更新运动矩阵的基准值, 稍后需要将其乘以曝光时间以得到真正的运动矩阵. */
    setBaseMotionMatrix(motionMatrix) {
        // 计算运动模糊的曝光时间, 以及在该段时间变换矩阵的近似微分.
        let totalShutterAngle = (0, ff_1.sum)(this.data.shutterAngles.map(angle => (0, property_1.getPropertyValue)(angle, this.time)));
        let frameRate = this.renderer.project.options.frameRate;
        let exposureTime = (0, motion_1.getExposureTime)(totalShutterAngle, frameRate);
        this.toDraw.setMotionMatrix(motionMatrix.multiplyScalar(exposureTime));
    }
    draw(inputArea) {
        this.toDraw.setInputPaintArea(inputArea);
        this.toDraw.draw();
        return this.toDraw.getPaintArea();
    }
}
exports.MotionBlurEffect = MotionBlurEffect;


/***/ }),

/***/ "./src/aegl/renderer/effects/ramp.ts":
/*!*******************************************!*\
  !*** ./src/aegl/renderer/effects/ramp.ts ***!
  \*******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.RampEffect = void 0;
const base_1 = __webpack_require__(/*! ./base */ "./src/aegl/renderer/effects/base.ts");
const property_1 = __webpack_require__(/*! ../../property/property */ "./src/aegl/property/property.ts");
const aegl_default_values_1 = __webpack_require__(/*! ../../aegl-default-values */ "./src/aegl/aegl-default-values.ts");
const to_draw_effect_1 = __webpack_require__(/*! ../to-draws/to-draw-effect */ "./src/aegl/renderer/to-draws/to-draw-effect.ts");
const ramp_frag_1 = __webpack_require__(/*! ../../shaders/effects/ramp.frag */ "./src/aegl/shaders/effects/ramp.frag");
const color_1 = __webpack_require__(/*! ../../helpers/color */ "./src/aegl/helpers/color.ts");
/** 用于绘制填充特效. */
class RampEffect extends base_1.Effect {
    async initialize() {
        this.toDraw = new to_draw_effect_1.ToDrawEffect({
            renderer: this.renderer,
            fragCode: ramp_frag_1.default,
        });
    }
    // 由于起始和结束坐标均受到外部变换影响, 这里看起来应当处理外部变换.
    // 但是由于我们可以访问到原始的顶点坐标, 可以直接使用它来进行线性插值.
    update() {
        super.update();
        let values = (0, property_1.getPropertyValues)(this.data, this.time, aegl_default_values_1.EffectRampDefaultValues);
        this.toDraw.setUniform('startOfRamp', values.startOfRamp);
        this.toDraw.setUniform('startColor', (0, color_1.premultiplyColorArray)(values.startColor));
        this.toDraw.setUniform('endOfRamp', values.endOfRamp);
        this.toDraw.setUniform('endColor', (0, color_1.premultiplyColorArray)(values.endColor));
        this.toDraw.setUniform('endOfRamp', values.endOfRamp);
        this.toDraw.setUniform('rampShape', values.rampShape);
        this.toDraw.setUniform('blendWithOriginal', values.blendWithOriginal / 100);
    }
    draw(inputArea) {
        this.toDraw.setInputPaintArea(inputArea);
        this.toDraw.draw();
        return inputArea;
    }
}
exports.RampEffect = RampEffect;


/***/ }),

/***/ "./src/aegl/renderer/effects/tile.ts":
/*!*******************************************!*\
  !*** ./src/aegl/renderer/effects/tile.ts ***!
  \*******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.TileEffect = void 0;
const base_1 = __webpack_require__(/*! ./base */ "./src/aegl/renderer/effects/base.ts");
const to_draw_effect_1 = __webpack_require__(/*! ../to-draws/to-draw-effect */ "./src/aegl/renderer/to-draws/to-draw-effect.ts");
const tile_1 = __webpack_require__(/*! ../../property/tile */ "./src/aegl/property/tile.ts");
// 用于绘制 Motion Tile 特效.
class TileEffect extends base_1.Effect {
    async initialize() {
        this.toDraw = new to_draw_effect_1.ToDrawEffect({
            renderer: this.renderer,
        });
    }
    setTransformStatus(status) {
        let { width: videoWidth, height: videoHeight } = this.renderer.project.data;
        let { transformMatrix, samplingMatrix } = (0, tile_1.getTileMatrixes)(this.data, this.time, videoWidth, videoHeight);
        // Tile 特效的变换需要合并 tile 变换和外部变换.
        status.mergeTransformMatrix(transformMatrix);
        status.mergeSamplingMatrix(samplingMatrix);
        super.setTransformStatus(status);
    }
    draw() {
        // 输出范围与输入无关, 不需要输出输入绘制区域.
        this.toDraw.draw();
        return this.toDraw.getPaintArea();
    }
}
exports.TileEffect = TileEffect;


/***/ }),

/***/ "./src/aegl/renderer/effects/tint.ts":
/*!*******************************************!*\
  !*** ./src/aegl/renderer/effects/tint.ts ***!
  \*******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.TintEffect = void 0;
const base_1 = __webpack_require__(/*! ./base */ "./src/aegl/renderer/effects/base.ts");
const to_draw_effect_1 = __webpack_require__(/*! ../to-draws/to-draw-effect */ "./src/aegl/renderer/to-draws/to-draw-effect.ts");
const tint_frag_1 = __webpack_require__(/*! ../../shaders/effects/tint.frag */ "./src/aegl/shaders/effects/tint.frag");
const property_1 = __webpack_require__(/*! ../../property/property */ "./src/aegl/property/property.ts");
const color_1 = __webpack_require__(/*! ../../helpers/color */ "./src/aegl/helpers/color.ts");
const aegl_default_values_1 = __webpack_require__(/*! ../../aegl-default-values */ "./src/aegl/aegl-default-values.ts");
/** 用于绘制蒙版特效. */
class TintEffect extends base_1.Effect {
    async initialize() {
        this.toDraw = new to_draw_effect_1.ToDrawEffect({
            renderer: this.renderer,
            fragCode: tint_frag_1.default,
        });
    }
    update() {
        super.update();
        let values = (0, property_1.getPropertyValues)(this.data, this.time, aegl_default_values_1.EffectTintDefaultValues);
        this.toDraw.setUniform('mapBlackTo', (0, color_1.premultiplyColorArray)(values.mapBlackTo));
        this.toDraw.setUniform('mapWhiteTo', (0, color_1.premultiplyColorArray)(values.mapWhiteTo));
        this.toDraw.setUniform('amountToTint', values.amountToTint / 100);
    }
    draw(inputArea) {
        this.toDraw.setInputPaintArea(inputArea);
        this.toDraw.draw();
        return inputArea;
    }
}
exports.TintEffect = TintEffect;


/***/ }),

/***/ "./src/aegl/renderer/layer-style/all.ts":
/*!**********************************************!*\
  !*** ./src/aegl/renderer/layer-style/all.ts ***!
  \**********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.getLayerStyleClass = void 0;
const original_1 = __webpack_require__(/*! ./original */ "./src/aegl/renderer/layer-style/original.ts");
const drop_shadow_1 = __webpack_require__(/*! ./drop-shadow */ "./src/aegl/renderer/layer-style/drop-shadow.ts");
/** 枚举所有的层样式特效类. */
const LayerStyleMap = {
    dropShadow: drop_shadow_1.DropShadowLayerStyle,
    original: original_1.LayerStyleDrawOriginal,
};
/** 根据名称获得层样式特效类. */
function getLayerStyleClass(name) {
    let LayerStyleClass = LayerStyleMap[name];
    if (!LayerStyleClass) {
        throw new Error(`"${name}" is not a registered layer style class!`);
    }
    return LayerStyleClass;
}
exports.getLayerStyleClass = getLayerStyleClass;


/***/ }),

/***/ "./src/aegl/renderer/layer-style/base.ts":
/*!***********************************************!*\
  !*** ./src/aegl/renderer/layer-style/base.ts ***!
  \***********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.LayerStyle = void 0;
const drawer_1 = __webpack_require__(/*! ../drawer */ "./src/aegl/renderer/drawer.ts");
/**
 * 层样式特效用于对输入进行处理.
 * 和 Effect 特效极其类似, 唯一的区别是它完全由层托管, 因此不用设置 id.
 */
class LayerStyle extends drawer_1.Drawer {
    /** 等待初始化的 promise. */
    ready;
    /** 主绘制对象. */
    toDraw;
    constructor(renderer, effectData) {
        super(renderer, effectData);
        // 稍微延迟调用 initialize 以等待子类初始化完成.
        this.ready = Promise.resolve().then(() => this.initialize());
    }
    /** 初始化绘制层, 加载资源和着色器代码等. */
    async initialize() { }
    /** 使用已有的纹理作为输入. */
    setMappedChannel(...mss) {
        this.toDraw.setMappedChannel(...mss);
    }
    /** 不再使用输入纹理. */
    clearChannel() {
        this.toDraw.clearChannel();
    }
    /** 设置或者清除蒙版区域. */
    setMaskArea(area) {
        this.toDraw.setMaskArea(area);
    }
    /** 进行绘制, 输入内部的绘制区域, 返回绘制的区域. */
    draw(inputArea) {
        this.toDraw.draw();
        return inputArea;
    }
    /**  移除层. */
    delete() {
        this.toDraw.delete();
    }
}
exports.LayerStyle = LayerStyle;


/***/ }),

/***/ "./src/aegl/renderer/layer-style/drop-shadow.ts":
/*!******************************************************!*\
  !*** ./src/aegl/renderer/layer-style/drop-shadow.ts ***!
  \******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.DropShadowLayerStyle = void 0;
const property_1 = __webpack_require__(/*! ../../property/property */ "./src/aegl/property/property.ts");
const aegl_default_values_1 = __webpack_require__(/*! ../../aegl-default-values */ "./src/aegl/aegl-default-values.ts");
const paint_area_1 = __webpack_require__(/*! ../../../libs/area/paint-area */ "./src/libs/area/paint-area.ts");
const transform_status_1 = __webpack_require__(/*! ../tree/transform-status */ "./src/aegl/renderer/tree/transform-status.ts");
const matrix4_1 = __webpack_require__(/*! ../../../libs/math/matrix4 */ "./src/libs/math/matrix4.ts");
const to_draw_drop_shadow_1 = __webpack_require__(/*! ../to-draws/to-draw-drop-shadow */ "./src/aegl/renderer/to-draws/to-draw-drop-shadow.ts");
const layer_style_drop_shadow_blend_frag_1 = __webpack_require__(/*! ../../shaders/effects/layer-style-drop-shadow-blend.frag */ "./src/aegl/shaders/effects/layer-style-drop-shadow-blend.frag");
const color_1 = __webpack_require__(/*! ../../helpers/color */ "./src/aegl/helpers/color.ts");
const base_1 = __webpack_require__(/*! ./base */ "./src/aegl/renderer/layer-style/base.ts");
const to_draw_effect_1 = __webpack_require__(/*! ../to-draws/to-draw-effect */ "./src/aegl/renderer/to-draws/to-draw-effect.ts");
const vector4_1 = __webpack_require__(/*! ../../../libs/math/vector4 */ "./src/libs/math/vector4.ts");
/** 用于绘制 Drop Shadow 特效. */
class DropShadowLayerStyle extends base_1.LayerStyle {
    /** 用于绘制完阴影后和原图叠加. */
    toBlendShadow;
    /** 当前时刻的属性值. */
    values;
    /** 阴影偏移. */
    shadowTranslateMatrix;
    async initialize() {
        // 用于绘制输入图像和阴影的叠加.
        // 为什么不分别做两个绘制呢? 先绘制阴影再绘制原图.
        // 原因是如果有外部透明度, 那么原图会因为叠加了透明度而导致下面的阴影透出来.
        this.toBlendShadow = new to_draw_effect_1.ToDrawEffect({
            renderer: this.renderer,
            fragCode: layer_style_drop_shadow_blend_frag_1.default,
        });
        // 用于来回 ping-pong 进行横竖的模糊绘制.
        let projectOptions = this.renderer.project.options;
        let iterateCount = projectOptions.dropShadowRenderingIterateCount;
        let blurRadius = this.data.size ? (0, property_1.getMaxPropertyValue)(this.data.size) : 0;
        let samplingCount = blurRadius * 4 * this.renderer.scaleRatio;
        this.toDraw = new to_draw_drop_shadow_1.ToDrawDropShadow({
            renderer: this.renderer,
            iterateCount,
            samplingCount,
        });
    }
    setMappedChannel(ms) {
        this.toBlendShadow.setMappedChannel(ms);
        this.toDraw.setMappedChannel(ms);
    }
    clearChannel() {
        this.toDraw.clearChannel();
    }
    setTime(time) {
        super.setTime(time);
        this.values = (0, property_1.getPropertyValues)(this.data, time, aegl_default_values_1.LayerStyleDropShadowDefaultValues);
    }
    update() {
        let { width: videoWidth, height: videoHeight } = this.renderer.project.data;
        let { distance, angle } = this.values;
        // angle 参数代表着从左侧开始逆时针旋转的角度.
        let shadowTranslate = this.transformStatus.projectVector(vector4_1.Vector2.fromAngle(180 - angle).multiplyScalarSelf(distance));
        let shadowTranslateMatrix = new matrix4_1.Matrix4().translateSelf(shadowTranslate.x, shadowTranslate.y);
        let shadowOpacity = this.values.opacity / 100 * this.transformStatus.opacity;
        let shadowStatus = new transform_status_1.TransformStatus(videoWidth, videoHeight, shadowTranslateMatrix, shadowOpacity);
        this.shadowTranslateMatrix = shadowTranslateMatrix;
        this.toDraw.setTransformStatus(shadowStatus);
        // 计算模糊方向向量.
        let blurRadius = this.transformStatus.projectVector(new vector4_1.Vector2(this.values.size / 2, this.values.size / 2));
        this.toDraw.setBlurRadius(blurRadius);
        // 设置阴影颜色.
        this.toDraw.setUniform('shadowColor', (0, color_1.premultiplyColorArray)(this.values.color));
    }
    setMaskArea(area) {
        this.toBlendShadow.setMaskArea(area);
        this.toDraw.setMaskArea(area);
    }
    /** 设置原图的填充透明度. */
    setFillOpacity(fillOpacity) {
        this.toBlendShadow.setUniform('fillOpacity', fillOpacity);
    }
    draw(inputArea) {
        this.toDraw.setInputPaintArea(inputArea);
        // 绘制阴影.
        let shadowMappedSampler = this.toDraw.drawAsSampler();
        // 绘制原图和阴影.
        let drawArea = paint_area_1.PaintArea.union([this.toDraw.getPaintArea(), inputArea]);
        this.toBlendShadow.setInputPaintArea(drawArea);
        this.toBlendShadow.setSubMappedChannel(1, shadowMappedSampler);
        this.toBlendShadow.draw();
        this.toBlendShadow.clearChannel();
        return drawArea;
    }
    delete() {
        super.delete();
        this.toBlendShadow.delete();
    }
}
exports.DropShadowLayerStyle = DropShadowLayerStyle;


/***/ }),

/***/ "./src/aegl/renderer/layer-style/layer-style-drawer.ts":
/*!*************************************************************!*\
  !*** ./src/aegl/renderer/layer-style/layer-style-drawer.ts ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.LayerStyleDrawer = void 0;
const to_draw_transform_1 = __webpack_require__(/*! ../to-draws/to-draw-transform */ "./src/aegl/renderer/to-draws/to-draw-transform.ts");
const aegl_default_values_1 = __webpack_require__(/*! ../../aegl-default-values */ "./src/aegl/aegl-default-values.ts");
const all_1 = __webpack_require__(/*! ./all */ "./src/aegl/renderer/layer-style/all.ts");
const paint_area_1 = __webpack_require__(/*! ../../../libs/area/paint-area */ "./src/libs/area/paint-area.ts");
const property_1 = __webpack_require__(/*! ../../property/property */ "./src/aegl/property/property.ts");
const drawer_1 = __webpack_require__(/*! ../drawer */ "./src/aegl/renderer/drawer.ts");
/** 辅助绘制类, 用于处理 layer style 的绘制. */
class LayerStyleDrawer extends drawer_1.Drawer {
    /**
     * 用于绘制内部的绘制内容以及和 layerStyle 绘制内容的叠加.
     * 内部的多个绘制结果必须先叠加, 然后再一次绘制到外层画布, 否则叠加顺序的不同会让结果不同.
     */
    toBlendLayerStyle;
    /** 用于绘制 layerStyle. 注意其顺序不可调换. */
    styles;
    constructor(renderer, data) {
        super(renderer, data);
        this.initializeToDraws();
    }
    /** 初始化 layerStyle 的绘制. */
    initializeToDraws() {
        this.toBlendLayerStyle = new to_draw_transform_1.ToDrawTransform({
            renderer: this.renderer,
        });
        let blendingOption = this.data.blendingOption || aegl_default_values_1.LayerStyleBlendingOptionDefaultValues;
        let fillOpacity = blendingOption.fillOpacity;
        let toDraws = {};
        // 在有必要时增加一部原图绘制.
        // 由于阴影绘制可以直接叠加原图, 所以绘制阴影时不再绘制原图.
        if (fillOpacity) {
            let FillLayerStyleClass = (0, all_1.getLayerStyleClass)('original');
            toDraws.fill = new FillLayerStyleClass(this.renderer, this.data);
        }
        for (let name of Object.keys(this.data)) {
            if (name === 'blendingOption') {
                continue;
            }
            let LayerStyleClass = (0, all_1.getLayerStyleClass)(name);
            toDraws[name] = new LayerStyleClass(this.renderer, this.data[name]);
        }
        this.styles = toDraws;
    }
    /** 设置最合适的采样过滤方式. */
    setTransformStat(stat) {
        super.setTransformStat(stat);
        for (let layerStyleEffect of Object.values(this.styles)) {
            layerStyleEffect.setTransformStat(stat);
        }
    }
    /** 更新时间. */
    setTime(time) {
        super.setTime(time);
        for (let layerStyleEffect of Object.values(this.styles)) {
            layerStyleEffect.setTime(time);
        }
    }
    /** 更新顶点数据的变换矩阵. */
    setTransformStatus(status) {
        super.setTransformStatus(status);
        for (let layerStyleEffect of Object.values(this.styles)) {
            layerStyleEffect.setTransformStatus(status);
        }
    }
    /** 更新参数. */
    update() {
        for (let layerStyleEffect of Object.values(this.styles)) {
            layerStyleEffect.update();
        }
    }
    /** 绘制层的样式特效, 返回新的内容绘制函数. */
    willDraw(contentSampler, contentPaintArea) {
        let { mappedSampler, paintArea } = this.renderer.drawAsMappedSamplerFromFn(() => {
            return this.drawLayerStyle(contentSampler, contentPaintArea);
        });
        if (!paintArea) {
            return null;
        }
        this.toBlendLayerStyle.setMappedChannel(mappedSampler);
        this.toBlendLayerStyle.setInputPaintArea(paintArea);
        return () => {
            this.toBlendLayerStyle.draw();
            return paintArea;
        };
    }
    /** 逐层绘制 layer style. */
    drawLayerStyle(contentSampler, contentPaintArea) {
        let areas = [];
        // 以内部绘制内容作为模板, 绘制每一个 layerStyle 作为下一个绘制的输入.
        for (let name of Object.keys(this.styles).reverse()) {
            let style = this.styles[name];
            // dropShadow 比较特殊, 如果存在的话可以直接把原图也绘制了.
            if (name === 'dropShadow') {
                style.setFillOpacity(this.getFillOpacity());
            }
            style.setMappedChannel(contentSampler);
            let area = style.draw(contentPaintArea);
            areas.push(area);
            style.clearChannel();
        }
        return paint_area_1.PaintArea.union(areas);
    }
    /** 获得当前原图的填充透明度. */
    getFillOpacity() {
        let blendingOption = this.data.blendingOption || aegl_default_values_1.LayerStyleBlendingOptionDefaultValues;
        let fillOpacity = (0, property_1.getPropertyValue)(blendingOption.fillOpacity, this.time) / 100;
        return fillOpacity;
    }
    delete() {
        super.delete();
        for (let layerStyleEffect of Object.values(this.styles)) {
            layerStyleEffect.delete();
        }
        this.toBlendLayerStyle.delete();
    }
}
exports.LayerStyleDrawer = LayerStyleDrawer;


/***/ }),

/***/ "./src/aegl/renderer/layer-style/original.ts":
/*!***************************************************!*\
  !*** ./src/aegl/renderer/layer-style/original.ts ***!
  \***************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.LayerStyleDrawOriginal = void 0;
const property_1 = __webpack_require__(/*! ../../property/property */ "./src/aegl/property/property.ts");
const aegl_default_values_1 = __webpack_require__(/*! ../../aegl-default-values */ "./src/aegl/aegl-default-values.ts");
const base_1 = __webpack_require__(/*! ./base */ "./src/aegl/renderer/layer-style/base.ts");
const to_draw_effect_1 = __webpack_require__(/*! ../to-draws/to-draw-effect */ "./src/aegl/renderer/to-draws/to-draw-effect.ts");
/** 用于绘制原图. */
class LayerStyleDrawOriginal extends base_1.LayerStyle {
    async initialize() {
        this.toDraw = new to_draw_effect_1.ToDrawEffect({
            renderer: this.renderer,
        });
    }
    update() {
        let values = (0, property_1.getPropertyValues)(this.data, this.time, aegl_default_values_1.LayerStyleBlendingOptionDefaultValues);
        this.toDraw.setUniform('iOpacity', values.fillOpacity / 100);
    }
    draw(inputArea) {
        this.toDraw.setInputPaintArea(inputArea);
        this.toDraw.draw();
        return inputArea;
    }
}
exports.LayerStyleDrawOriginal = LayerStyleDrawOriginal;


/***/ }),

/***/ "./src/aegl/renderer/layers/audio.ts":
/*!*******************************************!*\
  !*** ./src/aegl/renderer/layers/audio.ts ***!
  \*******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.AudioLayer = void 0;
const base_1 = __webpack_require__(/*! ./base */ "./src/aegl/renderer/layers/base.ts");
const property_1 = __webpack_require__(/*! ../../property/property */ "./src/aegl/property/property.ts");
const debug_1 = __webpack_require__(/*! ../../../libs/util/debug */ "./src/libs/util/debug.ts");
const media_1 = __webpack_require__(/*! ../../helpers/media */ "./src/aegl/helpers/media.ts");
/**
 * 用于播放音乐.
 * 在 Web 中, 音乐的播放由一个 Audio 标签控制, 并且独立于主线程, 所以这里的代码只是控制时间轴.
 */
class AudioLayer extends base_1.Layer {
    media;
    mediaVolume = 1;
    needToPlay = false;
    playing = false;
    async initialize() {
        this.media = await this.renderer.resourceLoader.loadAudio(this.data);
        // 设置音量.
        this.media.volume = 1;
        // 设置循环.
        this.media.loop = true;
    }
    active() {
        if (!this.activated) {
            super.active();
            // 这个时候的时刻是不准确的, 只有 update 的时候才是经过映射后的正确时刻.
            this.needToPlay = true;
        }
    }
    deactive() {
        if (this.activated) {
            super.deactive();
            this.media.pause();
            this.playing = false;
        }
    }
    /** 同步音频播放, time 可能在可播放范围之外. */
    async syncTime(time) {
        let mediaTime = Math.max(time, 0);
        let duration = this.media.duration;
        // 重复播放.
        if (mediaTime > duration) {
            mediaTime %= duration;
        }
        if (this.media.ended && this.activated) {
            this.needToPlay = true;
        }
        let needToUpdateMediaTime = !(0, media_1.isSameFrameTimes)(mediaTime, this.media.currentTime);
        if (needToUpdateMediaTime && this.needToPlay) {
            this.media.currentTime = mediaTime;
        }
        if (this.needToPlay) {
            let timeEnd = debug_1.debug.timeStart('Audio Playing');
            try {
                await this.media.play();
                this.playing = true;
            }
            catch (err) {
                debug_1.debug.log(err);
            }
            timeEnd();
            this.needToPlay = false;
        }
    }
    update() {
        if (this.activated) {
            // 分贝增减处理.
            let audioLevel = (0, property_1.getPropertyValue)(this.data.audioLevels, this.time, [0, 0]);
            let volume = Math.pow(10, audioLevel[0] / 10);
            if (volume !== this.mediaVolume) {
                this.media.volume = volume;
                this.mediaVolume = volume;
            }
        }
    }
}
exports.AudioLayer = AudioLayer;


/***/ }),

/***/ "./src/aegl/renderer/layers/base.ts":
/*!******************************************!*\
  !*** ./src/aegl/renderer/layers/base.ts ***!
  \******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Layer = void 0;
const debug_1 = __webpack_require__(/*! ../../../libs/util/debug */ "./src/libs/util/debug.ts");
const drawer_1 = __webpack_require__(/*! ../drawer */ "./src/aegl/renderer/drawer.ts");
/** 层代表了一个原始的输出音频或者像素数据的地方. */
class Layer extends drawer_1.Drawer {
    /** 等待初始化的 promise. */
    ready;
    /** 是否被激活, 例如音乐在播放. */
    activated = false;
    constructor(renderer, layerData) {
        super(renderer, layerData);
        // 稍微延迟调用 initialize 以等待子类初始化完成.
        this.ready = Promise.resolve().then(() => this.initialize());
        debug_1.debug.verbose(`${this.constructor.name} ${this.data.id} created`);
    }
    /** 当进行正常播放开始时调用. */
    active() {
        if (!this.activated) {
            this.activated = true;
        }
    }
    /** 当停止播放或者结束时调用. */
    deactive() {
        if (this.activated) {
            this.activated = false;
        }
    }
    /**
     * 仅用于进行状态的异步同步, 例如视频和音频的时间同步.
     * 需要特别注意的是, 如果一个视频层在同一时间被引用两次,
     * 并且两次的时间还不同的话, 那么最终他们出来的画面会完全相同.
     * 注意在播放的情况下, 由于预加载下一帧数据的机制存在,
     * 可能上一帧和下一帧时刻都会触发时间非常接近的同步.
     */
    async syncTime(_innerTime) { }
    /** 移除层. */
    delete() {
        this.deactive();
        debug_1.debug.verbose(`${this.constructor.name} ${this.data.id} deleted`);
    }
}
exports.Layer = Layer;


/***/ }),

/***/ "./src/aegl/renderer/layers/camera.ts":
/*!********************************************!*\
  !*** ./src/aegl/renderer/layers/camera.ts ***!
  \********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.CameraLayer = void 0;
const base_1 = __webpack_require__(/*! ./base */ "./src/aegl/renderer/layers/base.ts");
/** 用于处理摄影机. */
class CameraLayer extends base_1.Layer {
    toDraw;
    async initialize() {
        // 用于绘制焦外成像效果.
        // this.toDraw = new ToDrawTransform(this.renderer)
    }
}
exports.CameraLayer = CameraLayer;


/***/ }),

/***/ "./src/aegl/renderer/layers/composite.ts":
/*!***********************************************!*\
  !*** ./src/aegl/renderer/layers/composite.ts ***!
  \***********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.CompositeLayer = void 0;
const pixel_1 = __webpack_require__(/*! ./pixel */ "./src/aegl/renderer/layers/pixel.ts");
const to_draw_transform_1 = __webpack_require__(/*! ../to-draws/to-draw-transform */ "./src/aegl/renderer/to-draws/to-draw-transform.ts");
/** 用于合并多个层. */
class CompositeLayer extends pixel_1.PixelLayer {
    async initialize() {
        await super.initialize();
        this.toDraw = new to_draw_transform_1.ToDrawTransform({
            renderer: this.renderer,
        });
    }
    setToDrawTransformStatus(status) {
        // 外部变换会穿透而作用于内部, 因此只保留透明度处理.
        this.toDraw.setTransformStatus(status.cloneOpacity());
    }
}
exports.CompositeLayer = CompositeLayer;


/***/ }),

/***/ "./src/aegl/renderer/layers/image-video.ts":
/*!*************************************************!*\
  !*** ./src/aegl/renderer/layers/image-video.ts ***!
  \*************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ImageVideoLayer = void 0;
const pixel_1 = __webpack_require__(/*! ./pixel */ "./src/aegl/renderer/layers/pixel.ts");
const to_draw_image_video_1 = __webpack_require__(/*! ../to-draws/to-draw-image-video */ "./src/aegl/renderer/to-draws/to-draw-image-video.ts");
const sampler_1 = __webpack_require__(/*! ../../../libs/webgl/sampler */ "./src/libs/webgl/sampler.ts");
const shared_resources_1 = __webpack_require__(/*! ../../helpers/shared-resources */ "./src/aegl/helpers/shared-resources.ts");
/** 用于绘制图片和视频. */
class ImageVideoLayer extends pixel_1.PixelLayer {
    /** 用于进行裁剪绘制. */
    mediaShared;
    /** 多媒体元素. */
    media;
    /** 将多媒体元素进行裁剪绘制之后形成的纹理. */
    croppedSampler;
    /** 用于进行裁剪绘制. */
    toCropMedia = null;
    /** 初始化共享多媒体资源的对象. */
    initializeMediaShared() {
        this.mediaShared = new shared_resources_1.SharedResource(this.getMediaPath());
    }
    /** 初始化 toDraw 对象, 供子对象调用.  */
    async initializeToDraw() {
        let fragCode = this.getToDrawVertexCode();
        this.toDraw = new to_draw_image_video_1.ToDrawImageVideo({
            renderer: this.renderer,
            fragCode,
        });
        let w = this.data.width;
        let h = this.data.height;
        let coords = [
            [0, 0],
            [0, h],
            [w, 0],
            [w, h],
        ];
        let textureCoords = [
            [0, 1],
            [0, 0],
            [1, 1],
            [1, 0],
        ];
        this.toDraw.setCoords(coords, textureCoords);
        if (this.willCropMedia()) {
            await this.initializeToCropMedia();
            await this.setMedia();
            // 图像裁剪的话, 处理一次就足够了.
            if (this.data.type === 'image') {
                await this.mediaShared.deleteUnique('toCropMedia');
            }
        }
        else {
            await this.setMedia();
        }
    }
    /** 获取着色代码. */
    getToDrawVertexCode() {
        return undefined;
    }
    /** 获取多媒体资源的路径. */
    getMediaPath() {
        return this.renderer.resourceLoader.getLayerPath(this.data);
    }
    /** 是否需要对源进行裁剪. */
    willCropMedia() {
        let { mediaWidth, mediaHeight } = this.data;
        let w = this.data.width;
        let h = this.data.height;
        // 因为比例相同不需要进行裁剪.
        if (Math.round(h * mediaWidth / mediaHeight) === w) {
            return false;
        }
        else {
            return true;
        }
    }
    /** 初始化裁剪绘制. */
    async initializeToCropMedia() {
        this.toCropMedia = await this.mediaShared.unique('toCropMedia', () => this.createToCropMedia(), () => this.deleteToCropMedia());
    }
    /** 移除共享裁剪绘制. */
    async deleteToCropMedia() {
        this.toCropMedia.delete();
        this.toCropMedia = null;
    }
    /** 初始化裁剪绘制. */
    createToCropMedia() {
        let { mediaWidth, mediaHeight } = this.data;
        let w = this.data.width;
        let h = this.data.height;
        if (w > mediaWidth) {
            h = Math.round(h / w * mediaWidth);
            w = mediaWidth;
        }
        if (h > mediaHeight) {
            w = Math.round(w / h * mediaHeight);
            h = mediaHeight;
        }
        let coords = [
            [0, 0],
            [0, h],
            [w, 0],
            [w, h],
        ];
        let textureCoords = this.getCroppedTextureCoords();
        let toCropMedia = new to_draw_image_video_1.ToDrawImageVideo({
            renderer: this.renderer,
        });
        toCropMedia.setCoords(coords, textureCoords);
        return toCropMedia;
    }
    /** 获得经过了 cover 处理的纹理采样坐标. */
    getCroppedTextureCoords() {
        let { mediaWidth, mediaHeight, mediaPosition } = this.data;
        let w = this.data.width;
        let h = this.data.height;
        let t = 1;
        let b = 0;
        let l = 0;
        let r = 1;
        // 在原图采样范围为 [0, 1] 的尺度下, 计算实际显示范围的采样坐标.
        if (mediaWidth / mediaHeight > w / h) {
            let samplingWidth = (mediaHeight / mediaWidth) / (h / w);
            l = (1 - samplingWidth) * mediaPosition[0];
            r = samplingWidth + l;
        }
        else {
            let samplingHeight = (mediaWidth / mediaHeight) / (w / h);
            t = 1 + (samplingHeight - 1) * mediaPosition[1];
            b = t - samplingHeight;
        }
        let textureCoords = [
            [l, t],
            [l, b],
            [r, t],
            [r, b],
        ];
        return textureCoords;
    }
    /** 更新用于绘制的多媒体资源. */
    async setMedia() {
        if (this.toCropMedia) {
            // 几个相同资源的层存在时只会更新一次.
            let sampler = await this.mediaShared.syncOnce('updateMedia', async () => {
                await this.setMediaOf(this.toCropMedia);
                return this.cropMediaAsSampler();
            });
            this.toDraw.setChannel(sampler);
        }
        else {
            await this.setMediaOf(this.toDraw);
        }
    }
    /** 更新绘制对象的多媒体资源. */
    async setMediaOf(toDraw) {
        toDraw.setSubMedia(0, this.media);
    }
    /** 进行裁剪绘制. */
    cropMediaAsSampler() {
        let toCropMedia = this.toCropMedia;
        let antialiasType = false;
        let params = { filter: sampler_1.SamplerFilter.Linear };
        let area = toCropMedia.getPaintArea();
        let videoWidth = this.renderer.project.data.width;
        let videoHeight = this.renderer.project.data.height;
        let textureFrame = this.renderer.sw.textureFrameManager.request(area, videoWidth, videoHeight, antialiasType, 1, params);
        textureFrame.active();
        toCropMedia.draw();
        textureFrame.deactive();
        return textureFrame.getSampler();
    }
    /**
     * 将绘制对象导出为一个映射纹理使用.
     * 注意此纹理对象使用 Nearest 采样.
     */
    drawAsMappedSampler() {
        let mappedSampler = this.extractMappedSampler();
        if (mappedSampler) {
            let paintArea = this.toDraw.getPaintArea();
            return {
                mappedSampler,
                paintArea,
            };
        }
        return super.drawAsMappedSampler();
    }
    /** 从绘制对象导出映射纹理对象. */
    extractMappedSampler() {
        // 如果需要进行内部额外绘制, 则不能直接导出为纹理.
        if (this.layerStyleDrawer || this.maskDrawer) {
            return null;
        }
        return this.toDraw.extractMappedSampler();
    }
    delete() {
        super.delete();
        this.mediaShared.delete();
    }
}
exports.ImageVideoLayer = ImageVideoLayer;


/***/ }),

/***/ "./src/aegl/renderer/layers/image.ts":
/*!*******************************************!*\
  !*** ./src/aegl/renderer/layers/image.ts ***!
  \*******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ImageLayer = void 0;
const image_worker_decoder_1 = __webpack_require__(/*! ../../../libs/util/image-worker-decoder */ "./src/libs/util/image-worker-decoder.ts");
const image_video_1 = __webpack_require__(/*! ./image-video */ "./src/aegl/renderer/layers/image-video.ts");
/** 用于绘制图片. */
// 注意: 这里实现的方式为上传原图, 然后客户端根据 viewport 执行线性插值.
// 产生的问题是经过 (绝大多数时候是缩小) 线性插值后, 图像会略微模糊.
// 因为我们的目标是快速实时预览, 在此按照不同的 viewport 尺寸处理图像是划不来的.
// 所以建议在需要生成高质量的视频时, 首先将图像使用立方插值处理为和缩放处理的分辨率相一致.
// 并且尽量使用 None 采样, 或者在 Linear 或者 Mipmap 采样时尽量将像素对齐.
class ImageLayer extends image_video_1.ImageVideoLayer {
    async initialize() {
        await super.initialize();
        let shouldLoadLayerSoon = this.renderer.shouldLoadLayerSoon(this.data);
        let supportWorkerDecoding = (0, image_worker_decoder_1.supportsDecodeImageInWorker)();
        // 为当前层时, 需要尽可能快得将其加载.
        if (shouldLoadLayerSoon || !supportWorkerDecoding) {
            let image = await this.renderer.resourceLoader.loadImage(this.data);
            this.media = image;
            this.data.mediaWidth = image.naturalWidth;
            this.data.mediaHeight = image.naturalHeight;
        }
        // 处于预加载阶段, 将其通过 worker 解码然后再加载.
        else {
            let imageData = await this.renderer.resourceLoader.loadDecodedImage(this.data);
            this.media = imageData;
            this.data.mediaWidth = imageData.width;
            this.data.mediaHeight = imageData.height;
        }
        /** 初始化资源共享. */
        this.initializeMediaShared();
        // 初始化图片绘制对象.
        await this.initializeToDraw();
    }
}
exports.ImageLayer = ImageLayer;


/***/ }),

/***/ "./src/aegl/renderer/layers/pixel.ts":
/*!*******************************************!*\
  !*** ./src/aegl/renderer/layers/pixel.ts ***!
  \*******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.PixelLayer = void 0;
const renderable_1 = __webpack_require__(/*! ./renderable */ "./src/aegl/renderer/layers/renderable.ts");
const sampler_1 = __webpack_require__(/*! ../../../libs/webgl/sampler */ "./src/libs/webgl/sampler.ts");
const aegl_enums_1 = __webpack_require__(/*! ../../aegl-enums */ "./src/aegl/aegl-enums.ts");
/** 所有具有尺寸和像素数据的层的基类. */
class PixelLayer extends renderable_1.RenderableLayer {
    toDraw;
    /** 设置最合适的采样过滤方式. */
    setTransformStat(stat) {
        super.setTransformStat(stat);
        let params = stat.getSuggestedSamplingParameters();
        if (this.data.samplingQuality === aegl_enums_1.AESamplingQuality.Nearest) {
            params.filter = sampler_1.SamplerFilter.Nearest;
        }
        this.toDraw.setSamplingParameters(params);
    }
    /** 更新顶点数据的变换矩阵. */
    setTransformStatus(status) {
        super.setTransformStatus(status);
        this.setToDrawTransformStatus(status);
    }
    /** 更新 `toDraw` 绘制对象的变换. */
    setToDrawTransformStatus(status) {
        this.toDraw.setTransformStatus(status);
    }
    /** 设置蒙版区域. */
    setMaskArea(area) {
        this.toDraw.setMaskArea(area);
    }
    /** 使用已有的纹理作为输入. */
    setMappedChannel(...mss) {
        this.toDraw.setMappedChannel(...mss);
    }
    /** 不再使用输入纹理. */
    clearChannel() {
        this.toDraw.clearChannel();
    }
    /** 实际绘制像素内容. */
    drawMainContent() {
        this.toDraw.draw();
        return this.toDraw.getPaintArea();
    }
    delete() {
        super.delete();
        this.toDraw.delete();
    }
}
exports.PixelLayer = PixelLayer;


/***/ }),

/***/ "./src/aegl/renderer/layers/renderable-mask.ts":
/*!*****************************************************!*\
  !*** ./src/aegl/renderer/layers/renderable-mask.ts ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.RenderableShapeMaskDrawer = void 0;
const paint_area_1 = __webpack_require__(/*! ../../../libs/area/paint-area */ "./src/libs/area/paint-area.ts");
const property_1 = __webpack_require__(/*! ../../property/property */ "./src/aegl/property/property.ts");
const drawer_1 = __webpack_require__(/*! ../drawer */ "./src/aegl/renderer/drawer.ts");
const group_1 = __webpack_require__(/*! ../shapes/group */ "./src/aegl/renderer/shapes/group.ts");
const to_draw_effect_1 = __webpack_require__(/*! ../to-draws/to-draw-effect */ "./src/aegl/renderer/to-draws/to-draw-effect.ts");
const to_draw_fast_blur_1 = __webpack_require__(/*! ../to-draws/to-draw-fast-blur */ "./src/aegl/renderer/to-draws/to-draw-fast-blur.ts");
const mask_blend_frag_1 = __webpack_require__(/*! ../../shaders/effects/mask-blend.frag */ "./src/aegl/shaders/effects/mask-blend.frag");
const mask_alpha_frag_1 = __webpack_require__(/*! ../../shaders/effects/mask-alpha.frag */ "./src/aegl/shaders/effects/mask-alpha.frag");
const vector4_1 = __webpack_require__(/*! ../../../libs/math/vector4 */ "./src/libs/math/vector4.ts");
const aegl_enums_1 = __webpack_require__(/*! ../../aegl-enums */ "./src/aegl/aegl-enums.ts");
/** 辅助绘制类, 用于处理裁剪路径的绘制. */
class RenderableShapeMaskDrawer extends drawer_1.Drawer {
    /** 用于绘制裁剪蒙版. */
    shapes;
    /** 用于逐层绘制蒙版. */
    toBlendMask = null;
    /** 用于绘制最终蒙版和内容的叠加. */
    toBlendFinalMask = null;
    /** 用于绘制裁剪蒙版的羽化效果. */
    toDrawMaskFeather = null;
    /** 是否会进行裁剪绘制. */
    forClipping = false;
    constructor(renderer, data) {
        super(renderer, data);
        this.initializeShapesAndToDraws();
    }
    /** 初始化裁剪路径的绘制. */
    initializeShapesAndToDraws() {
        let masks = this.data.filter(mask => mask.maskMode !== aegl_enums_1.AEMaskMode.None);
        let hasFeather = masks.some(mask => mask.maskFeather);
        let hasSubtractMask = masks.some(mask => mask.maskMode === aegl_enums_1.AEMaskMode.Subtract);
        // 只有当仅有一步绘制, 并且无羽化以及非减除模式时才启用裁剪绘制.
        // 这样可以减少一步绘制.
        this.forClipping = masks.length === 1 && !hasFeather && !hasSubtractMask;
        // 创建形状绘制对象.
        this.shapes = masks.map(mask => this.createMaskShape(mask));
        // 只有非裁剪绘制下, 才需要这些绘制对象.
        if (!this.forClipping) {
            // 绘制每一层模板.
            this.toBlendMask = new to_draw_effect_1.ToDrawEffect({
                renderer: this.renderer,
                fragCode: mask_blend_frag_1.default,
            });
            // 合并最终的蒙版和内容.
            this.toBlendFinalMask = new to_draw_effect_1.ToDrawEffect({
                renderer: this.renderer,
                fragCode: mask_alpha_frag_1.default,
            });
            // 绘制蒙版的羽化效果.
            this.toDrawMaskFeather = new to_draw_fast_blur_1.ToDrawFastBlur({
                renderer: this.renderer,
                samplingCount: this.renderer.project.options.fastBlurSamplingCount,
                iterateCount: this.renderer.project.options.fastBlurRenderingIterateCount,
            });
        }
    }
    /** 创建一个裁剪路径. */
    createMaskShape(mask) {
        let data = {
            path: mask.maskPath,
            fill: { color: [1, 1, 1, 1] }, // 设置白色填充色.
        };
        let shape = new group_1.ShapeGroupDrawer(this.renderer, data, this.forClipping);
        shape.initialize();
        return shape;
    }
    /** 设置最合适的采样过滤方式. */
    setTransformStat(stat) {
        super.setTransformStat(stat);
        for (let shape of this.shapes) {
            shape.setTransformStat(stat);
        }
    }
    /** 更新时间. */
    setTime(time) {
        super.setTime(time);
        for (let shape of this.shapes) {
            shape.setTime(time);
        }
    }
    /** 更新顶点数据的变换矩阵. */
    setTransformStatus(status) {
        super.setTransformStatus(status);
        for (let shape of this.shapes) {
            shape.setTransformStatus(status);
        }
    }
    /** 更新参数. */
    update() {
        for (let shape of this.shapes) {
            shape.update();
        }
    }
    /** 绘制形状裁剪蒙版, 返回是否继续绘制. */
    willDraw(contentSampler, contentPaintArea) {
        if (this.forClipping) {
            return this.willDrawClipping(contentSampler, contentPaintArea);
        }
        else {
            return this.willDrawNormalBlending(contentSampler, contentPaintArea);
        }
    }
    /** 绘制形状裁剪蒙版, 返回是否继续绘制. */
    willDrawClipping(contentSampler, contentPaintArea) {
        let paintArea = contentPaintArea;
        for (let i = 0; i < this.data.length; i++) {
            let maskShape = this.shapes[i];
            let isLastStep = i === this.data.length - 1;
            let drawFn = null;
            // 绘制每一步裁剪.
            drawFn = this.willDrawEachClipping(maskShape, contentSampler, paintArea);
            // 非最后一步, 将绘制结果替代之前的内容, 并且更新绘制区域.
            if (isLastStep || !drawFn) {
                return drawFn;
            }
            // 将绘制函数进行绘制, 然后传递给下一步裁剪.
            // 会进行抗锯齿处理.
            let { mappedSampler: maskSampler, paintArea: maskPaintArea } = this.renderer.drawAsMappedSamplerFromFn(drawFn, true);
            contentSampler = maskSampler;
            paintArea = paint_area_1.PaintArea.cross([paintArea, maskPaintArea]);
            // 不需要再进行绘制.
            if (!paintArea) {
                break;
            }
        }
        return null;
    }
    /** 绘制裁剪蒙版时直接裁剪原图, 返回最后一步绘制的函数. */
    willDrawEachClipping(maskShape, inputSampler, inputPaintArea) {
        maskShape.setMappedChannel(inputSampler);
        maskShape.setMaskArea(inputPaintArea);
        return () => {
            let paintArea = maskShape.draw();
            maskShape.clearChannel();
            return paintArea;
        };
    }
    /** 绘制形状裁剪蒙版, 返回绘制函数. */
    willDrawNormalBlending(contentSampler, contentPaintArea) {
        let maskSampler = null;
        let toBlendFinalMask = this.toBlendFinalMask;
        for (let i = 0; i < this.data.length; i++) {
            let maskData = this.data[i];
            let maskShape = this.shapes[i];
            // 逐步合并蒙版.
            maskSampler = this.drawMaskBlending(maskData, maskShape, maskSampler, contentPaintArea);
        }
        // 将绘制函数进行绘制, 然后传递给下一步裁剪.
        toBlendFinalMask.setInputPaintArea(contentPaintArea);
        toBlendFinalMask.setMappedChannel(maskSampler, contentSampler);
        return () => {
            toBlendFinalMask.draw();
            toBlendFinalMask.clearChannel();
            return contentPaintArea;
        };
    }
    /** 合并两个蒙版图. */
    drawMaskBlending(maskData, maskShape, lastMaskSampler, contentPaintArea) {
        // 设置裁剪区为内容绘制区.
        maskShape.setMaskArea(contentPaintArea);
        let toDrawMaskFeather = this.toDrawMaskFeather;
        let toBlendMask = this.toBlendMask;
        // 由于有 Subtract 的存在, 内部 mask 的绘制区始终使用 content 区域.
        // 也可以动态决定如何处理绘制区域, 例如 add 时选择 cross,
        // subtract 时不变.
        toBlendMask.setInputPaintArea(contentPaintArea);
        // 首先绘制此蒙版, 会进行抗锯齿.
        let { mappedSampler: currentMaskSampler, paintArea: currentMaskPaintArea } = this.renderer.drawAsMappedSamplerFromFn(() => {
            return maskShape.draw();
        }, true);
        // 输入 0 为之前的蒙版图, 1 为现在的蒙版图.
        if (lastMaskSampler) {
            toBlendMask.setSubMappedChannel(0, lastMaskSampler);
        }
        else {
            toBlendMask.setSubMappedChannel(0, this.renderer.sw.textureFrameManager.getEmptyMappedSampler());
        }
        // 绘制裁剪蒙版为纹理, 会进行抗锯齿.
        if (maskData.maskFeather) {
            // 进行羽化处理.
            let maskFeather = (0, property_1.getPropertyValue)(maskData.maskFeather, this.time);
            toDrawMaskFeather.setBlurRadius(this.transformStatus.projectVector(new vector4_1.Vector2(...maskFeather)));
            toDrawMaskFeather.setInputPaintArea(currentMaskPaintArea);
            toDrawMaskFeather.setMappedChannel(currentMaskSampler);
            let maskFeatherSampler = toDrawMaskFeather.drawAsSampler();
            toDrawMaskFeather.clearChannel();
            toBlendMask.setSubMappedChannel(1, maskFeatherSampler);
        }
        else {
            toBlendMask.setSubMappedChannel(1, currentMaskSampler);
        }
        toBlendMask.setUniform('maskMode', maskData.maskMode);
        toBlendMask.setUniform('isFirst', !lastMaskSampler);
        // 绘制为纹理.
        return this.renderer.drawAsMappedSamplerFromFn(() => {
            toBlendMask.draw();
            toBlendMask.clearChannel();
            return contentPaintArea;
        }, true).mappedSampler;
    }
    delete() {
        for (let shape of this.shapes) {
            shape.delete();
        }
        if (this.toBlendMask) {
            this.toBlendMask.delete();
        }
        if (this.toBlendFinalMask) {
            this.toBlendFinalMask.delete();
        }
        if (this.toDrawMaskFeather) {
            this.toDrawMaskFeather.delete();
        }
    }
}
exports.RenderableShapeMaskDrawer = RenderableShapeMaskDrawer;


/***/ }),

/***/ "./src/aegl/renderer/layers/renderable.ts":
/*!************************************************!*\
  !*** ./src/aegl/renderer/layers/renderable.ts ***!
  \************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.RenderableLayer = void 0;
const base_1 = __webpack_require__(/*! ./base */ "./src/aegl/renderer/layers/base.ts");
const simple_webgl_1 = __webpack_require__(/*! ../../../libs/webgl/simple-webgl */ "./src/libs/webgl/simple-webgl.ts");
const layer_style_drawer_1 = __webpack_require__(/*! ../layer-style/layer-style-drawer */ "./src/aegl/renderer/layer-style/layer-style-drawer.ts");
const renderable_mask_1 = __webpack_require__(/*! ./renderable-mask */ "./src/aegl/renderer/layers/renderable-mask.ts");
/** 所有可绘制层的基类. */
class RenderableLayer extends base_1.Layer {
    /** 用于组织 layer style 的绘制. */
    layerStyleDrawer = null;
    /** 用于组织 mask 的绘制. */
    maskDrawer = null;
    async initialize() {
        // 绘制 LayerStyle.
        if (this.data.layerStyle) {
            this.layerStyleDrawer = new layer_style_drawer_1.LayerStyleDrawer(this.renderer, this.data.layerStyle);
        }
        // 绘制裁剪路径.
        if (this.data.masks) {
            this.maskDrawer = new renderable_mask_1.RenderableShapeMaskDrawer(this.renderer, this.data.masks);
        }
    }
    /** 设置最合适的采样过滤方式. */
    setTransformStat(stat) {
        super.setTransformStat(stat);
        if (this.layerStyleDrawer) {
            this.layerStyleDrawer.setTransformStat(stat);
        }
        if (this.maskDrawer) {
            this.maskDrawer.setTransformStat(stat);
        }
    }
    /** 更新时间. */
    setTime(time) {
        super.setTime(time);
        if (this.layerStyleDrawer) {
            this.layerStyleDrawer.setTime(time);
        }
        if (this.maskDrawer) {
            this.maskDrawer.setTime(time);
        }
    }
    /** 更新顶点数据的变换矩阵. */
    setTransformStatus(status) {
        super.setTransformStatus(status);
        if (this.layerStyleDrawer) {
            this.layerStyleDrawer.setTransformStatus(status);
        }
        if (this.maskDrawer) {
            this.maskDrawer.setTransformStatus(status);
        }
    }
    /** 更新参数. */
    update() {
        if (this.layerStyleDrawer) {
            this.layerStyleDrawer.update();
        }
        if (this.maskDrawer) {
            this.maskDrawer.update();
        }
    }
    draw() {
        // 绘制实际的内容的函数.
        let drawFn = () => {
            return this.drawMainContent();
        };
        // 绘制层的 layer style 和蒙版.
        if (this.layerStyleDrawer || this.maskDrawer) {
            // 绘制主要内容为纹理输入.
            let { mappedSampler, paintArea } = this.renderer.drawAsMappedSamplerFromFn(drawFn, this.getSuggestedAntialiasType());
            if (!paintArea) {
                return null;
            }
            // 绘制 layer style.
            if (this.layerStyleDrawer) {
                drawFn = this.layerStyleDrawer.willDraw(mappedSampler, paintArea);
                // 再度绘制为裁剪路径的输入.
                if (drawFn && this.maskDrawer) {
                    ({ mappedSampler, paintArea } = this.renderer.drawAsMappedSamplerFromFn(drawFn));
                    if (!paintArea) {
                        return null;
                    }
                }
            }
            // 绘制裁剪路径.
            if (drawFn && this.maskDrawer) {
                drawFn = this.maskDrawer.willDraw(mappedSampler, paintArea);
            }
        }
        if (!drawFn) {
            return null;
        }
        // 设置和以下的层的叠加方式.
        // 必须通过单独着色才能处理的叠加已经编译为特效绘制步骤.
        let canSetBlendMode = this.data.blendingMode && simple_webgl_1.SimpleWebGL.supportsBlendMode(simple_webgl_1.SimpleWebGLBlendMode[this.data.blendingMode]);
        if (canSetBlendMode) {
            this.renderer.sw.setBlendMode(simple_webgl_1.SimpleWebGLBlendMode[this.data.blendingMode]);
        }
        let paintArea = drawFn();
        if (canSetBlendMode) {
            this.renderer.sw.resetBlendMode();
        }
        return paintArea;
    }
    /** 绘制内容为纹理数据. */
    drawAsMappedSampler() {
        // 是否进行多重采样的决定条件比较复杂.
        let antialiasType = !this.layerStyleDrawer && !this.maskDrawer
            ? this.getSuggestedAntialiasType()
            : !!this.maskDrawer && this.maskDrawer.forClipping;
        return this.renderer.drawAsMappedSamplerFromFn(() => {
            return this.draw();
        }, antialiasType);
    }
    /** 是否使用抗锯齿方式绘制内容. */
    getSuggestedAntialiasType() {
        return this.transformStat.getSuggestedAntialiasType();
    }
    delete() {
        super.delete();
        if (this.layerStyleDrawer) {
            this.layerStyleDrawer.delete();
        }
        if (this.maskDrawer) {
            this.maskDrawer.delete();
        }
    }
}
exports.RenderableLayer = RenderableLayer;


/***/ }),

/***/ "./src/aegl/renderer/layers/shape.ts":
/*!*******************************************!*\
  !*** ./src/aegl/renderer/layers/shape.ts ***!
  \*******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ShapeLayer = void 0;
const rect_1 = __webpack_require__(/*! ../shapes/rect */ "./src/aegl/renderer/shapes/rect.ts");
const paint_area_1 = __webpack_require__(/*! ../../../libs/area/paint-area */ "./src/libs/area/paint-area.ts");
const ellipse_1 = __webpack_require__(/*! ../shapes/ellipse */ "./src/aegl/renderer/shapes/ellipse.ts");
const renderable_1 = __webpack_require__(/*! ./renderable */ "./src/aegl/renderer/layers/renderable.ts");
const group_1 = __webpack_require__(/*! ../shapes/group */ "./src/aegl/renderer/shapes/group.ts");
/** 代表了一个形状层, 可以包含多个子形状. */
class ShapeLayer extends renderable_1.RenderableLayer {
    shapes;
    /** 是否用于蒙版填充绘制. */
    forFill = false;
    async initialize() {
        await super.initialize();
        this.shapes = this.data.contents.map(content => this.createShape(content));
    }
    createShape(content) {
        let shape;
        switch (content.type) {
            case 'rect':
                shape = new rect_1.ShapeRectDrawer(this.renderer, content);
                break;
            case 'ellipse':
                shape = new ellipse_1.ShapeEllipseDrawer(this.renderer, content);
                break;
            case 'group':
                shape = new group_1.ShapeGroupDrawer(this.renderer, content);
                break;
            case 'trim':
            default:
                throw new Error(`Can't render shape in type "${content.type}"!`);
        }
        shape.initialize();
        return shape;
    }
    setTransformStat(stat) {
        super.setTransformStat(stat);
        for (let shape of this.shapes) {
            shape.setTransformStat(stat);
        }
    }
    setTime(time) {
        super.setTime(time);
        for (let shape of this.shapes) {
            shape.setTime(time);
        }
    }
    setTransformStatus(status) {
        super.setTransformStatus(status);
        for (let shape of this.shapes) {
            shape.setTransformStatus(status);
        }
    }
    update() {
        super.update();
        for (let shape of this.shapes) {
            shape.update();
        }
    }
    setMaskArea(area) {
        for (let shape of this.shapes) {
            shape.setMaskArea(area);
        }
    }
    /** 使用纹理直接进行填充绘制. */
    setMappedChannel(mappedSampler) {
        for (let shape of this.shapes) {
            shape.setMappedChannel(mappedSampler);
        }
    }
    /** 清除填充纹理. */
    clearChannel() {
        for (let shape of this.shapes) {
            shape.clearChannel();
        }
    }
    getSuggestedAntialiasType() {
        return true;
    }
    drawMainContent() {
        let areas = [];
        for (let shape of this.shapes) {
            let area = shape.draw();
            areas.push(area);
        }
        return paint_area_1.PaintArea.union(areas);
    }
    delete() {
        super.delete();
        for (let shape of this.shapes) {
            shape.delete();
        }
    }
}
exports.ShapeLayer = ShapeLayer;


/***/ }),

/***/ "./src/aegl/renderer/layers/solid.ts":
/*!*******************************************!*\
  !*** ./src/aegl/renderer/layers/solid.ts ***!
  \*******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SolidLayer = void 0;
const pixel_1 = __webpack_require__(/*! ./pixel */ "./src/aegl/renderer/layers/pixel.ts");
const to_draw_transform_1 = __webpack_require__(/*! ../to-draws/to-draw-transform */ "./src/aegl/renderer/to-draws/to-draw-transform.ts");
const solid_color_frag_1 = __webpack_require__(/*! ../../shaders/layer/solid-color.frag */ "./src/aegl/shaders/layer/solid-color.frag");
/** 用于绘制固定颜色. */
class SolidLayer extends pixel_1.PixelLayer {
    async initialize() {
        await super.initialize();
        this.toDraw = new to_draw_transform_1.ToDrawTransform({
            renderer: this.renderer,
            fragCode: solid_color_frag_1.default
        });
        this.toDraw.setUniform('solidColor', [...this.data.color, 1]);
    }
}
exports.SolidLayer = SolidLayer;


/***/ }),

/***/ "./src/aegl/renderer/layers/text.ts":
/*!******************************************!*\
  !*** ./src/aegl/renderer/layers/text.ts ***!
  \******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.TextLayer = void 0;
const pixel_1 = __webpack_require__(/*! ./pixel */ "./src/aegl/renderer/layers/pixel.ts");
const sampler_1 = __webpack_require__(/*! ../../../libs/webgl/sampler */ "./src/libs/webgl/sampler.ts");
const text_atlas_1 = __webpack_require__(/*! ../text-atlas/text-atlas */ "./src/aegl/renderer/text-atlas/text-atlas.ts");
const text_1 = __webpack_require__(/*! ../../property/text */ "./src/aegl/property/text.ts");
const to_draw_transform_1 = __webpack_require__(/*! ../to-draws/to-draw-transform */ "./src/aegl/renderer/to-draws/to-draw-transform.ts");
const todraw_1 = __webpack_require__(/*! ../../../libs/webgl/todraw */ "./src/libs/webgl/todraw.ts");
const to_draw_motion_blur_1 = __webpack_require__(/*! ../to-draws/to-draw-motion-blur */ "./src/aegl/renderer/to-draws/to-draw-motion-blur.ts");
const paint_area_1 = __webpack_require__(/*! ../../../libs/area/paint-area */ "./src/libs/area/paint-area.ts");
const to_draw_multiple_1 = __webpack_require__(/*! ../to-draws/to-draw-multiple */ "./src/aegl/renderer/to-draws/to-draw-multiple.ts");
__webpack_require__(/*! ../../plugins/text-animaters/all */ "./src/aegl/plugins/text-animaters/all.ts");
const fonts_list_1 = __webpack_require__(/*! ../../helpers/fonts-list */ "./src/aegl/helpers/fonts-list.ts");
const to_draw_fast_blur_1 = __webpack_require__(/*! ../to-draws/to-draw-fast-blur */ "./src/aegl/renderer/to-draws/to-draw-fast-blur.ts");
const vector4_1 = __webpack_require__(/*! ../../../libs/math/vector4 */ "./src/libs/math/vector4.ts");
const motion_1 = __webpack_require__(/*! ../../property/motion */ "./src/aegl/property/motion.ts");
/** 用于绘制文字. */
class TextLayer extends pixel_1.PixelLayer {
    /** 合并绘制多个文字. */
    toBlendText = null;
    /** 诸葛绘制运动模糊. */
    toDrawMotionBlur = null;
    /** 文字贴图对象. */
    textAtlas;
    /** 用于保存字符布局的对象. */
    charPositions;
    /** 记录了之前的文字动画变换矩阵. */
    previousCharTransformsAtTime = null;
    /** 记录了当前的文字动画变换矩阵. */
    currentCharTransformsAtTime = null;
    /** 外部变换产生的运动矩阵, 已经经过投影. */
    outerMotionMatrix = null;
    /** 存储每个文字的运动矩阵, 已经经过投影. */
    charMotionMatrixes = null;
    /** 用户进行外部变换的逆向变换. */
    flatProjectionMatrixInverse;
    /** 用于绘制文字模糊动画. */
    toDrawBlur = null;
    /** 文字贴图对应的采样器. */
    sampler;
    /** 存储每个文字的模糊半径动画参数. */
    charBlurList = null;
    async initialize() {
        await super.initialize();
        // 加载字体列表.
        await fonts_list_1.FontList.ensure();
        // 初始化绘制对象.
        this.initializeToDraws();
        // 初始化文字贴图对象.
        await this.initializeTextAtlas();
        this.renderer.on('resize', this.onResize, this);
    }
    /** 初始化绘制对象. */
    initializeToDraws() {
        // 用于绘制逐个文字.
        this.toDraw = new to_draw_multiple_1.ToDrawMultiple({
            renderer: this.renderer,
            type: this.data.animaters ? todraw_1.ToDrawType.TriangleStrip : todraw_1.ToDrawType.Triangles,
        });
        // 创建采样器但是先不上传数据.
        // 但是在更新 transformStat 时可以顺利更新并且持久化此状态.
        this.sampler = new sampler_1.PixelSampler(this.renderer.sw, null);
        this.toDraw.setChannel(this.sampler);
        // 用于绘制最终文字.
        if (this.data.motionBlur && this.data.animaters) {
            // 用于绘制 Motion Blur 效果.
            this.toDrawMotionBlur = new to_draw_motion_blur_1.ToDrawMotionBlur({ renderer: this.renderer });
        }
        else {
            // 用于绘制最终生成的多个文字.
            this.toBlendText = new to_draw_transform_1.ToDrawTransform({ renderer: this.renderer });
        }
        // 用于绘制文字模糊动画.
        if (this.data.animaters && this.data.animaters.some(animater => animater.properties.blur)) {
            this.toDrawBlur = new to_draw_fast_blur_1.ToDrawFastBlur({
                renderer: this.renderer,
                iterateCount: 1,
                samplingCount: this.renderer.project.options.fastBlurSamplingCount,
            });
        }
    }
    /** 初始化文字贴图. */
    async initializeTextAtlas() {
        let context = this.renderer.sw.context;
        let maxTextureSize = context.getParameter(context.MAX_TEXTURE_SIZE);
        let inEncodingMode = this.renderer.project.mode === 'encoding';
        let videoHeight = this.renderer.project.data.height;
        this.textAtlas = new text_atlas_1.TextAtlas(this.data, maxTextureSize, videoHeight, {
            interfaceScaling: this.renderer.scaleRatio,
            transformScaling: 1,
            textSuperSamplingRate: this.renderer.project.options.textSuperSamplingRate,
        });
        if (!inEncodingMode) {
            this.textAtlas.on('fontloaded', this.onFontLoaded, this);
        }
        // 预绘制 0 时刻的文字贴图, 绝大部分时候可以命中.
        await this.updateTextAtlasCanvas(0, true);
    }
    /** 当文字加载之后触发. */
    onFontLoaded() {
        this.renderer.mayUpdateAfterLayerUpdated(this.data);
    }
    onResize() {
        // 当尺寸变化时重新生成 TextAtlas, 主要原因是确保刚好渲染在 2x 当前的尺寸下, 否则会产生一定程度的模糊.
        if (this.textAtlas) {
            this.textAtlas.state.interfaceScaling = this.renderer.scaleRatio;
        }
    }
    /** 同步时间. */
    async syncTime(time) {
        await this.updateTextAtlasCanvas(time, this.renderer.project.mode === 'encoding');
    }
    /** 同步进行字体的加载. */
    async updateTextAtlasCanvas(time, sync) {
        this.textAtlas.setTime(time);
        this.textAtlas.state.text = this.getCurrentText();
        let updatedOfCanvas = await this.textAtlas.tryUpdateCanvas(sync);
        if (updatedOfCanvas !== text_atlas_1.TextAtlasUpdatedOfCanvas.Nothing) {
            this.sampler.updateData(this.textAtlas.canvas);
        }
    }
    /** 获取当前需要渲染的文本. */
    getCurrentText() {
        // 至少包含一个空格这样就不会产生因为无数据的错误.
        return this.data.text || this.renderer.project.options.textPlaceholder || ' ';
    }
    setTransformStatus(status) {
        super.setTransformStatus(status);
        this.flatProjectionMatrixInverse = this.toDraw.transformStatus.getFlatProjectionMatrix().inverse();
    }
    update() {
        super.update();
        this.updateTextAtlas();
        if (this.data.animaters) {
            this.updateAnimaters();
        }
    }
    /** 更新文字的各类坐标. */
    updateTextAtlas() {
        if (this.textAtlas.state.shouldUpdateCharPosition()) {
            this.charPositions = this.textAtlas.generateCharPositions();
            let coords = this.charPositions.getVertexCoords();
            let textureCoords = this.charPositions.getTextureCoords();
            let indices = this.data.animaters ? undefined : this.charPositions.getCoordIndices();
            this.toDraw.setCoords(coords, textureCoords, indices);
        }
    }
    /** 更新文字动画. */
    updateAnimaters() {
        let { charTransforms, charOpacityList, charBlurList } = this.getPerCharAnimationProperties(this.time);
        this.toDraw.setSubTransformMatrixes(charTransforms);
        this.toDraw.setSubOpacityList(charOpacityList);
        if (this.data.motionBlur) {
            this.updateMotionMatrixes(charTransforms);
        }
        this.charBlurList = charBlurList.map(([x, y]) => new vector4_1.Vector2(x, y));
    }
    /**
     * 通过时间获得当前时刻的逐文字变换状态和透明度状态.
     * 作为一个通用函数提供而不设置 this 属性.
     */
    getPerCharAnimationProperties(time) {
        let charIndices = this.charPositions.getCharIndices();
        let allAnimaterValues = (0, text_1.getTextAnimaterProperties)(this.data, time, charIndices);
        let charTransforms = this.charPositions.getPerTextTransforms(allAnimaterValues);
        let charOpacityList = allAnimaterValues.map(v => v.opacity / 100);
        let charBlurList = allAnimaterValues.map(v => v.blur);
        return { charTransforms, charOpacityList, charBlurList };
    }
    /** 更新逐个文字的运动矩阵. */
    updateMotionMatrixes(charTransforms) {
        this.previousCharTransformsAtTime = null;
        // 1ms 到 50ms 内的状态有效.
        if (this.currentCharTransformsAtTime) {
            let timeOffset = this.time - this.currentCharTransformsAtTime.time;
            let absTimeOffset = Math.abs(timeOffset);
            if (absTimeOffset <= 0.05 && absTimeOffset >= 0.001) {
                this.previousCharTransformsAtTime = this.currentCharTransformsAtTime;
            }
        }
        // 如果不能从已生成的状态获得一个可对比的状态, 那么则新生成.
        if (!this.previousCharTransformsAtTime) {
            // 尝试向前一帧生成一个变换状态, 如果超过安全时间则向后生成. 然后将其写入 previousTransformStatusMap.
            let timeOffset = 0.015;
            let previousTime = this.time - timeOffset;
            if (previousTime < this.data.inPoint) {
                timeOffset = -0.015;
            }
            this.previousCharTransformsAtTime = {
                transforms: this.getPerCharAnimationProperties(this.time - timeOffset).charTransforms,
                time: this.time - timeOffset
            };
        }
        // 更新当前状态.
        this.currentCharTransformsAtTime = { transforms: charTransforms, time: this.time };
        // 计算曝光时间.
        let frameRate = this.renderer.project.options.frameRate;
        let exposureTime = (0, motion_1.getExposureTime)(180, frameRate);
        let previousCharTransformMatrixes = this.previousCharTransformsAtTime.transforms;
        let currentCharTransformMatrixes = this.currentCharTransformsAtTime.transforms;
        let diffMatrixes = currentCharTransformMatrixes.map((cm, index) => cm.minus(previousCharTransformMatrixes[index]));
        let timeOffset = this.currentCharTransformsAtTime.time - this.previousCharTransformsAtTime.time;
        let charMotionMatrixes = diffMatrixes.map(matrix => matrix.multiplyScalar(exposureTime / timeOffset));
        let flatProjectionMatrix = this.toDraw.transformStatus.getFlatProjectionMatrix();
        this.charMotionMatrixes = charMotionMatrixes.map(matrix => flatProjectionMatrix.multiply(matrix));
    }
    /** 更新外部运动矩阵. */
    setBaseMotionMatrix(motionMatrix) {
        // 曝光角度固定为 180.
        let frameRate = this.renderer.project.options.frameRate;
        let exposureTime = (0, motion_1.getExposureTime)(180, frameRate);
        this.outerMotionMatrix = motionMatrix.multiplyScalar(exposureTime);
    }
    drawMainContent() {
        if (this.toDrawMotionBlur || this.toDrawBlur) {
            return this.drawEachSeperately();
        }
        else {
            return this.drawAllTogether();
        }
    }
    /** 绘制逐个文字到当前画布. */
    drawEachSeperately() {
        let areas = [];
        for (let i = 0; i < this.charPositions.getLength(); i++) {
            let { mappedSampler, paintArea } = this.drawEachCharAsSampler(i);
            // 没有内容时, 不继续往下绘制.
            if (!mappedSampler || !paintArea) {
                continue;
            }
            let drawFn = null;
            // 将绘制函数处理绘制到纹理缓存, 返回是否有有效内容.
            let processDrawing = () => {
                if (drawFn) {
                    ({ mappedSampler, paintArea } = this.renderer.drawAsMappedSamplerFromFn(drawFn));
                    if (!mappedSampler || !paintArea) {
                        return false;
                    }
                }
                return true;
            };
            // 绘制逐文字模糊动画.
            if (this.toDrawBlur) {
                if (!processDrawing()) {
                    continue;
                }
                drawFn = this.willDrawBlur(i, mappedSampler, paintArea);
            }
            // 绘制运动模糊.
            if (this.toDrawMotionBlur) {
                if (!processDrawing()) {
                    continue;
                }
                drawFn = this.willDrawMotionBlur(i, mappedSampler, paintArea);
            }
            if (drawFn) {
                areas.push(drawFn());
            }
        }
        return paint_area_1.PaintArea.union(areas);
    }
    /** 绘制文字原图. */
    drawEachCharAsSampler(index) {
        let paintArea = this.toDraw.getPaintAreaByIndex(index);
        if (!paintArea) {
            return { mappedSampler: null, paintArea };
        }
        // 2x 超级采样绘制文字.
        // 没有使用全屏缓存, 因为 2x 的全屏缓存实在太大了, 而文字一般都很小
        let textureFrame = this.renderer.requestPartialTextureFrame(paintArea, false, 2);
        textureFrame.active();
        this.toDraw.drawFromIndex(index);
        textureFrame.deactive();
        let mappedSampler = textureFrame.getMappedSampler();
        return { mappedSampler, paintArea };
    }
    /** 准备绘制运动模糊. */
    willDrawMotionBlur(index, inputSampler, inputPaintArea) {
        let toDrawMotionBlur = this.toDrawMotionBlur;
        let outerMotionMatrix = this.outerMotionMatrix;
        let currentCharTransform = this.currentCharTransformsAtTime.transforms[index];
        // 运动矩阵的微分:
        // (A + dA) * (B + dB) - AB
        //     = A * dB + dA * B + dA * dB
        let outerMotionMatrixPart = outerMotionMatrix.multiply(currentCharTransform);
        let charMotionMatrixPart = this.charMotionMatrixes[index];
        // 这里的矩阵作用于原始的文字坐标, 还需要将其转换为作用于投影坐标.
        // M1 * RawCoord = M2 * FlatProjectionMatrix * RawCoord
        // M2 = M1 * FlatProjectionMatrix^-1
        let finalMotionMatrixForRawCoords = outerMotionMatrixPart.add(charMotionMatrixPart);
        let finalMotionMatrix = finalMotionMatrixForRawCoords.multiply(this.flatProjectionMatrixInverse);
        // 将文字绘制结果推送到运动模糊渲染, 并且直接渲染到当前画布上.
        toDrawMotionBlur.setMotionMatrix(finalMotionMatrix);
        toDrawMotionBlur.setInputPaintArea(inputPaintArea);
        toDrawMotionBlur.setMappedChannel(inputSampler);
        return () => {
            toDrawMotionBlur.draw();
            toDrawMotionBlur.clearChannel();
            return toDrawMotionBlur.getPaintArea();
        };
    }
    /** 绘制运动模糊. */
    willDrawBlur(index, inputSampler, inputPaintArea) {
        let toDrawBlur = this.toDrawBlur;
        toDrawBlur.setBlurRadius(this.transformStatus.projectVector(this.charBlurList[index]));
        toDrawBlur.setInputPaintArea(inputPaintArea);
        toDrawBlur.setMappedChannel(inputSampler);
        return () => {
            toDrawBlur.draw();
            toDrawBlur.clearChannel();
            return toDrawBlur.getPaintArea();
        };
    }
    /** 绘制不包含运动模糊的文字到当前画布. */
    drawAllTogether() {
        let textPaintArea = this.toDraw.getPaintArea();
        let textureFrame = null;
        // 只有占据空间时才需要绘制.
        if (textPaintArea) {
            // 申请一个和实际渲染范围贴近的纹理缓存, 并且进行 2x 超级采样.
            // 由于会使用 mipmap 采样, 所以这个超级采样倍率大于 2 不会有提升.
            textureFrame = this.renderer.requestPartialTextureFrame(textPaintArea, false, 2);
            textureFrame.active();
            this.toDraw.draw();
            textureFrame.deactive();
            // 将已绘制的 2x 超级采样文字输出到当前画布上.
            this.toBlendText.setInputPaintArea(textPaintArea);
            this.toBlendText.setMappedChannel(textureFrame.getMappedSampler());
            this.toBlendText.draw();
            this.toBlendText.clearChannel();
        }
        return textPaintArea;
    }
    delete() {
        super.delete();
        if (this.toDrawMotionBlur) {
            this.toDrawMotionBlur.delete();
        }
        if (this.toDrawBlur) {
            this.toDrawBlur.delete();
        }
        if (this.toBlendText) {
            this.toBlendText.delete();
        }
        this.renderer.off('resize', this.onResize, this);
        this.textAtlas.off('fontloaded', this.onFontLoaded, this);
    }
}
exports.TextLayer = TextLayer;


/***/ }),

/***/ "./src/aegl/renderer/layers/video-per-frame.ts":
/*!*****************************************************!*\
  !*** ./src/aegl/renderer/layers/video-per-frame.ts ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.VideoPerFrameLayer = void 0;
const video_frames_extractor_1 = __webpack_require__(/*! ../../helpers/video-frames-extractor */ "./src/aegl/helpers/video-frames-extractor.ts");
const image_video_1 = __webpack_require__(/*! ./image-video */ "./src/aegl/renderer/layers/image-video.ts");
const image_alpha_frag_1 = __webpack_require__(/*! ../../shaders/layer/image-alpha.frag */ "./src/aegl/shaders/layer/image-alpha.frag");
/** 用于是视频中导出图片帧然后逐帧渲染视频. */
class VideoPerFrameLayer extends image_video_1.ImageVideoLayer {
    /** 对应着一个视频帧的 alpha 部分. */
    mediaAlpha;
    /** 是否导出 Alpha 数据. */
    extractAlphaChannel = false;
    /** 上一帧的时刻. */
    lastFrameTime = 0;
    /** 用于共享视频帧. */
    framesExtractor;
    /** 上一次的进度. */
    lastProgress = 0;
    async initialize() {
        await super.initialize();
        /** 初始化资源共享. */
        this.initializeMediaShared();
        /** 初始化帧导出器. */
        await this.initializeFramesExtractor();
        /** 获取首帧. */
        let mediaInfo = this.framesExtractor.mediaInfo;
        // 当资源处于预加载状态时, 会申请 0 位置的帧, 从而打乱顺序视频帧获取.
        //let bundle = await this.framesExtractor.getCurrentFrame()
        //this.media = bundle.image
        //this.mediaAlpha = bundle.alpha
        /** 初始化绘制数据. */
        this.extractAlphaChannel = this.framesExtractor.extractAlphaChannel;
        this.data.mediaWidth = mediaInfo.video.width;
        this.data.mediaHeight = mediaInfo.video.height;
        // 根据 media 信息修正数据.
        this.data.duration = mediaInfo.duration;
        this.data.frameRate = mediaInfo.video.frameRate;
        /** 初始化图像绘制对象. */
        await this.initializeToDraw();
    }
    /** 猜测视频是否有 Alpha 通道. */
    mayHaveAlphaChannel() {
        // 可替换的用户素材认为总是没有 Alpha 通道.
        if (this.data.replaceable) {
            return false;
        }
        // 作为蒙版的话, 由于需要查找内容层, 所以直接通过 mediaInfo 来检查.
        // if (this.data.isTrackMatte) {
        // 	return this.data.trackMatteType.startsWith('ALPHA')
        // }
        return true;
    }
    /** 获取着色代码. */
    getToDrawVertexCode() {
        return this.extractAlphaChannel ? image_alpha_frag_1.default : undefined;
    }
    /** 更新多媒体纹理数据. */
    async setMediaOf(toDraw) {
        await super.setMediaOf(toDraw);
        if (this.extractAlphaChannel) {
            toDraw.setSubMedia(1, this.mediaAlpha);
        }
    }
    /** 初始化共享视频帧导出器. */
    async initializeFramesExtractor() {
        this.framesExtractor = await this.mediaShared.unique('framesExtractor', async () => this.createFramesExtractor(), async () => this.deleteFramesExtractor());
    }
    /** 创建帧导出器. */
    async createFramesExtractor() {
        let mayExtractAlphaChannel = this.mayHaveAlphaChannel();
        let framesExtractor = new video_frames_extractor_1.VideoFramesExtractor(this.getMediaPath(), 'jpeg', mayExtractAlphaChannel);
        await framesExtractor.ready;
        framesExtractor.on('progress', this.renderer.project.encoder.getFramesExtractProgressFn());
        return framesExtractor;
    }
    /** 移除共享视频帧导出器. */
    async deleteFramesExtractor() {
        this.framesExtractor.delete();
    }
    /** 同步更新视频画面, time 可能在可播放范围之外. */
    async syncTime(time) {
        let mediaTime = Math.max(time, 0);
        let duration = this.framesExtractor.mediaInfo.duration;
        // 重复播放.
        if (this.data.loop && this.data.loop > 1 && time > duration) {
            time %= duration;
        }
        else {
            mediaTime = Math.min(time, duration);
        }
        let bundle = (await this.framesExtractor.getFrameAtTime(mediaTime));
        if (bundle) {
            this.media = bundle.image;
            this.mediaAlpha = bundle.alpha;
            await this.setMedia();
            this.lastFrameTime = time;
        }
    }
    extractMappedSampler() {
        if (this.extractAlphaChannel) {
            return null;
        }
        return super.extractMappedSampler();
    }
    delete() {
        super.delete();
    }
}
exports.VideoPerFrameLayer = VideoPerFrameLayer;


/***/ }),

/***/ "./src/aegl/renderer/layers/video.ts":
/*!*******************************************!*\
  !*** ./src/aegl/renderer/layers/video.ts ***!
  \*******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.VideoLayer = void 0;
const property_1 = __webpack_require__(/*! ../../property/property */ "./src/aegl/property/property.ts");
const debug_1 = __webpack_require__(/*! ../../../libs/util/debug */ "./src/libs/util/debug.ts");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
const media_1 = __webpack_require__(/*! ../../helpers/media */ "./src/aegl/helpers/media.ts");
const image_video_1 = __webpack_require__(/*! ./image-video */ "./src/aegl/renderer/layers/image-video.ts");
const browser_1 = __webpack_require__(/*! ../../helpers/browser */ "./src/aegl/helpers/browser.ts");
/** 用于播放视频. */
// 在 Web 中, 视频的播放由一个 Video 标签控制, 并且独立于主线程, 所以这里的代码只不过控制下时间轴以及更新视频纹理.
// 需要注意的是当包含视频时, 拖动时间轴会略微产生卡顿, 这是因为视频解码器必须跳到一个新的位置重新开始解码产生的.
// 它跟视频解码速度以及显存带宽有很大关系.
// 可能解决方式其一是将视频作为 3D 纹理传入, 但是会占用大量显存 (例如 2s 的 1080p 视频占用 2 * 1920 * 1080 * 4 * 60 = 1G 显存), 明显不能这样.
// 最可取的解决方式是降低视频分辨率.
class VideoLayer extends image_video_1.ImageVideoLayer {
    mediaVolume = 1;
    /** 需要进行播放. */
    needToPlay = false;
    /** 用于导出视频帧. */
    framesExtractor = null;
    async initialize() {
        await super.initialize();
        this.media = await this.renderer.resourceLoader.loadVideo(this.data);
        this.data.mediaWidth = this.media.videoWidth;
        this.data.mediaHeight = this.media.videoHeight;
        // 声音设置为 0.
        this.media.volume = 1;
        // 设置循环.
        if (this.data.loop && this.data.loop > 1) {
            this.media.loop = true;
        }
        // 初始化视频帧导出器.
        // 系统直接将视频推送入 WebGL 数据会产生绿屏问题, 猜测为显卡驱动问题.
        // 必须将数据先送回 CPU, 再度发送到 GPU 才能解决此问题.
        // 但是仍然难以避免少数的绿屏现象.
        let isMac = (0, browser_1.isMacSystem)();
        if (isMac) {
            this.framesExtractor = new media_1.VideoFrameExtractor();
        }
        /** 初始化资源共享. */
        this.initializeMediaShared();
        /** 初始化图像绘制对象. */
        await this.initializeToDraw();
    }
    /** 更新多媒体纹理数据. */
    async setMediaOf(toDraw) {
        if (this.framesExtractor) {
            let canvas = await this.framesExtractor.extract(this.media);
            toDraw.setSubMedia(0, canvas);
        }
        else {
            await super.setMediaOf(toDraw);
        }
    }
    active() {
        if (!this.activated) {
            super.active();
            // 取消之前的延时暂停.
            this.mediaShared.syncEvery('pause', async () => {
                return false;
            });
            // 这个时候的时刻是不准确的, 只有 updateTime 获得的时间才是经过映射后的正确时刻.
            // 所以不立即同步视频时刻和开始播放.
            if (this.media.paused) {
                this.needToPlay = true;
            }
        }
    }
    deactive() {
        if (this.activated) {
            super.deactive();
            // 不立即暂停, 等待继续播放.
            this.mediaShared.syncEvery('pause', async () => {
                await (0, ff_1.sleep)(16);
                return true;
            })
                .then((toPause) => {
                if (toPause) {
                    this.media.pause();
                }
            });
        }
    }
    /** 同步更新视频画面, time 可能在可播放范围之外 */
    async syncTime(time) {
        // 几个相同资源的视频层存在时只会更新一次.
        await this.mediaShared.syncOnce('updateTime', async () => {
            await this.updateMediaTime(time);
        });
        // 一旦有数据就更新, 经过测试检查帧时刻以决定是否更新会略微卡顿.
        if (this.media.readyState >= this.media.HAVE_CURRENT_DATA) {
            await this.setMedia();
        }
    }
    /** 更新视频时间和视频帧. */
    async updateMediaTime(time) {
        let mediaTime = Math.max(time, 0);
        let duration = this.media.duration;
        let frameRate = this.data.frameRate;
        let shouldPlay = time >= 0 && this.needToPlay;
        // 将帧定位到帧的左右位置的中间位置. 这样可以更好地保持同步.
        if (!this.activated) {
            mediaTime += 0.5 / frameRate;
        }
        // 重复播放.
        if (this.data.loop && this.data.loop > 1 && mediaTime > duration) {
            mediaTime %= duration;
        }
        else {
            mediaTime = Math.min(mediaTime, duration);
        }
        let inSameFrame = (0, media_1.isSameFrameTimes)(mediaTime, this.media.currentTime, this.data.frameRate);
        // 如果正在播放, 对于其时刻误差的容忍度会很高, 而暂停状态下或者重新开始播放时帧时刻必须一致.
        let needToUpdateMediaTime = (shouldPlay || !this.activated) && !inSameFrame
            || this.activated && Math.abs(mediaTime - this.media.currentTime) > 1;
        // 需要播放或者处于非播放状态时需要同步时间.
        if (needToUpdateMediaTime) {
            this.media.currentTime = mediaTime;
        }
        // 同步播放.
        if (shouldPlay) {
            let timeEnd = debug_1.debug.timeStart('Video Playing');
            // 播放有可能被暂停打断.
            // 不能不等待其播放完成, 否则一些本来应该被遮住的场景会漏出来.
            try {
                await this.media.play();
            }
            catch (err) {
                debug_1.debug.log(err);
            }
            timeEnd();
            this.needToPlay = false;
        }
        // 如果在非激活状态并且和上一帧的时间差超过了原视频两帧间的距离, 则更新视频并且等待解码.
        if (!this.activated && needToUpdateMediaTime) {
            if (this.media.readyState < this.media.HAVE_CURRENT_DATA) {
                // 等待解码完成, 否则这里绘制的还是之前的图像.
                await this.waitForVideoDecoded();
            }
        }
    }
    /** 等待视频解码完成. */
    async waitForVideoDecoded() {
        let timeEnd = debug_1.debug.timeStart('Video Decoding');
        // 在少数时候, 视频 seek 将会超过 1s.
        let timeLimit = 1000;
        let success = await (0, media_1.waitForVideoDecoded)(this.media, timeLimit);
        if (success) {
            timeEnd();
        }
    }
    update() {
        if (this.activated) {
            // 分贝增减处理.
            let audioLevel = (0, property_1.getPropertyValue)(this.data.audioLevels, this.time, [0, 0]);
            let volume = Math.pow(10, audioLevel[0] / 10);
            if (volume !== this.mediaVolume) {
                this.media.volume = volume;
                this.mediaVolume = volume;
            }
        }
    }
}
exports.VideoLayer = VideoLayer;


/***/ }),

/***/ "./src/aegl/renderer/queue.ts":
/*!************************************!*\
  !*** ./src/aegl/renderer/queue.ts ***!
  \************************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.UpdatingQueue = void 0;
/**
 * 处理渲染队列, 多个渲染请求可能合并到一起进行一个渲染.
 * 注意它的内部并没有限制每帧期间最多只进行一次渲染,
 * 而是一旦一个渲染的指定发送完毕即进行下一个渲染.
 */
class UpdatingQueue {
    updater;
    constructor(updater) {
        this.updater = updater;
    }
    /** 正在进行更新的 promise. */
    updatingPromise = null;
    /** 最近一次更新任务的时间. */
    latestTime = null;
    /** 由 enqueue 返回的 promise 所配对的 resolve 函数组成的数组. */
    resolveRejects = [];
    /**
     * 将一个更新添加到队列,
     * 如果更多的更新加入, 那么只会更新最后一个.
     * 但是更新完成后会 resolve 每次添加更新返回的 promise.
     */
    async enqueue(time) {
        let promise = new Promise((resolve, reject) => {
            if (time !== null) {
                this.latestTime = time;
            }
            this.resolveRejects.push([resolve, reject]);
        });
        // 等待一个 microtask 周期, 这样如果一次推送多个更新,
        // 他们会一起进行更新.
        await Promise.resolve();
        if (!this.updatingPromise) {
            this.update();
        }
        await promise;
    }
    /**
     * 更新任务, 队列内只有最后一个会用于更新, 其他的只调用 resolve.
     * 如果更新完成之后队列内有任务, 则会继续进行更新.
     */
    async update() {
        while (this.resolveRejects.length > 0) {
            let resolveRejects = this.resolveRejects;
            this.resolveRejects = [];
            this.updatingPromise = this.updater(this.latestTime);
            this.latestTime = null;
            try {
                await this.updatingPromise;
                for (let [resolve] of resolveRejects) {
                    resolve();
                }
            }
            catch (err) {
                for (let [, reject] of resolveRejects) {
                    reject(err);
                }
            }
            this.updatingPromise = null;
            resolveRejects = [];
            // 等待一个 Micro Task 周期, 因为有可能在此期间进来新的更新.
            await Promise.resolve();
        }
    }
    /** 清空更新队列, 即使有任务正在更新, 也不会调用 resolve. */
    clear() {
        this.latestTime = null;
        this.resolveRejects = [];
    }
}
exports.UpdatingQueue = UpdatingQueue;


/***/ }),

/***/ "./src/aegl/renderer/renderer.ts":
/*!***************************************!*\
  !*** ./src/aegl/renderer/renderer.ts ***!
  \***************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Renderer = void 0;
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
const render_tree_1 = __webpack_require__(/*! ./tree/render-tree */ "./src/aegl/renderer/tree/render-tree.ts");
const queue_1 = __webpack_require__(/*! ./queue */ "./src/aegl/renderer/queue.ts");
const framerate_calculator_1 = __webpack_require__(/*! ../helpers/framerate-calculator */ "./src/aegl/helpers/framerate-calculator.ts");
/**
 * 此类用于管理层以及其关联的渲染树的调度.
 * 它起到了一个沟通所有用于渲染的类之间的桥梁的作用.
 */
class Renderer extends ff_1.Emitter {
    sw;
    /** 相关联的项目. */
    project;
    /** 资源加载器. */
    resourceLoader;
    /**
     * 当前实际绘制和原视频的缩放百分比.
     * 由于之后可能会渲染任意宽高比的视频, 所以该字段可能会拆分为两个.
     */
    scaleRatio = 1;
    /** 像素分辨率比例, 例如 2 代表使用 2x 的 Retina 模式绘制. */
    pixelRatio;
    /** 是否已开始进行渲染. 用于阻止在所有资源准备完成全外部调用产生的渲染. */
    started = false;
    /** 当前视频所处时刻. */
    time = 0.00000001;
    /** 是否处于暂停状态. 处于播放完成状态时也为 true. */
    paused = true;
    /** 是否处于播放完成状态. */
    ended = false; // 当播放结束时, paused 也会被置为 true.
    /** 渲染树. */
    tree;
    /** 时间轴. */
    timeline;
    /** 用于记录播放起始时刻. */
    startTimeInMS = 0;
    /** 用于记录帧循环的 id. */
    animationFrameId = -1;
    /** 更新队列. */
    queue;
    /** 用以清空资源的倒计时. */
    clearTimeout = null;
    /** 当前正在进行的更新所对应的 promise. */
    updatePromise = null;
    /** 预加载下一帧的 promise. */
    preloadingNextFramePromise = null;
    /** 帧率计算器. */
    frameRateCalculator = new framerate_calculator_1.FrameRateCalculator();
    constructor(project, sw) {
        super();
        this.project = project;
        this.resourceLoader = project.resourceLoader;
        // 设置 webgl 管理类.
        this.sw = sw;
        // 必须设置时间, 否则时间为 0 时部分层的边界会重叠.
        this.timeline = project.timeline;
        // 预览模式下把像素占满, 编码模式下固定为 1.
        this.pixelRatio = this.project.mode === 'previewing' ? devicePixelRatio : 1;
        this.tree = new render_tree_1.RenderTree(this);
        this.queue = new queue_1.UpdatingQueue((time) => this.updateFromQueue(time));
        this.initResolution();
        // 更新层时, 将对应层对象重建.
        // 更新项目时, 将所有的层对象重建.
        project.on('updateproject', this.doUpdatingProject, this);
        project.on('updatetimeline', this.doUpdatingTimeline, this);
        project.on('updatelayer', this.doUpdatingLayer, this);
        project.on('updateeffect', this.doUpdatingEffect, this);
        project.on('update', this.doUpdating, this);
    }
    /** 初始化或者设置了 project 之后, 设置分辨率属性. */
    initResolution() {
        this.scaleRatio = this.sw.height / this.project.data.height;
        this.sw.setUniform('iVideoResolution', [this.project.data.width, this.project.data.height]);
        this.sw.setUniform('iResolution', [this.sw.width, this.sw.height]);
    }
    /** 是否正在播放. */
    get playing() {
        return !this.paused;
    }
    /**
     * 当项目发生了一些总体的属性变更时重新创建所有的层和效果.
     * 例如项目全局属性被重设, 增减层, 调整层的时间等.
     */
    async doUpdatingProject() {
        await this.waitUpdateCompleted();
        this.initResolution();
        this.tree.clear();
        // 在最末尾增加场景之后, 还可以继续往后播放, 于是需要撤销结束状态.
        if (this.ended && this.time < this.project.data.duration) {
            this.ended = false;
        }
        if (this.time > this.project.data.duration) {
            this.setTime(this.project.data.duration);
        }
        else if (this.started && this.paused) {
            await this.enqueUpdate();
        }
    }
    /** 当更新了时间轴, 而其他数据无更新之时. */
    async doUpdatingTimeline() {
        await this.waitUpdateCompleted();
        // 在最末尾增加场景之后, 还可以继续往后播放, 于是需要撤销结束状态.
        if (this.ended && this.time < this.project.data.duration) {
            this.ended = false;
        }
        if (this.time > this.project.data.duration) {
            await this.setTime(this.project.data.duration);
        }
        else if (this.started && this.paused) {
            await this.enqueUpdate();
        }
    }
    /** 当层发生了属性变更之后重新加载它, 渲染树也会被更新. */
    async doUpdatingLayer(layerData) {
        await this.waitUpdateCompleted();
        this.tree.deleteLayerFromId(layerData.id);
        // 如果处于暂停状态, 即稍后不会更新, 则需要更新视图.
        if (this.started && this.paused) {
            await this.enqueUpdate();
        }
    }
    /** 当层发生了可实时更新的属性变更之后做重绘. */
    async doUpdating(_layerData) {
        await this.waitUpdateCompleted();
        if (this.started && this.paused) {
            await this.enqueUpdate();
        }
    }
    /**
     * 当特效发生了属性变更之后重新加载它, 渲染树也会被更新.
     * 注意 transform 等非渲染特效属性是实时更新的, 更改他们不用重渲染.
     */
    async doUpdatingEffect(effectData) {
        await this.waitUpdateCompleted();
        this.tree.deleteEffectFromId(effectData.id);
        // 如果处于暂停状态, 即稍后不会更新, 则需要更新视图.
        if (this.started && this.paused) {
            await this.enqueUpdate();
        }
    }
    /** 设置 canvas 元素的尺寸以及实际渲染的像素尺寸. 如果有必要会更新绘制. */
    async setCanvasSize(width, height) {
        await this.waitUpdateCompleted();
        this.sw.setCanvasSize(width, height, this.pixelRatio);
        this.sw.setUniform('iResolution', [this.sw.width, this.sw.height]);
        this.scaleRatio = this.sw.height / this.project.data.height;
        this.emit('resize');
        if (this.started && this.paused) {
            await this.enqueUpdate();
        }
    }
    /** 设置像素分辨率比例, 例如 2 代表使用 2x 的 Retina 模式绘制. 如果有必要会更新绘制. */
    async setPixelRatio(pixelRatio = 1) {
        this.pixelRatio = pixelRatio;
        if (this.started && this.paused) {
            await this.enqueUpdate();
        }
    }
    /** 检查是否进行了所有的初始化. */
    checkIfEveryThingReady() {
        // if (this.sw.height === 0) {
        // 	throw new Error(`Please call "renderer.setCanvasSize(w, h)" before do any rendering!`)
        // }
    }
    /** 从当前时刻开始播放或者从暂停状态恢复播放. */
    async play() {
        this.checkIfEveryThingReady();
        this.endPlaying();
        this.paused = false;
        this.ended = false;
        // 确保预加载了稍后所需要的所有资源, 这样可以防止预览过程中的卡顿.
        if (this.started) {
            await this.prepareNextResources();
        }
        // 在初次播放时确保预加载了所有资源, 这样可以防止预览过程中的卡顿.
        else {
            await this.prepareAllResources();
        }
        // 这里有一个地方需要特别注意, `requestAnimationFrame` 的参数并不和 `performance.now()` 相同,
        // 而是和此帧的起始时刻相同, 一般比后者略小.
        // 为了时间参数的均衡, 我们一致使用 `requestAnimationFrame` 提供的参数而不是 `performance.now()`.
        this.animationFrameId = requestAnimationFrame(async (timestamp) => {
            // 可能资源加载完后处于暂停状态了.
            if (this.paused) {
                return;
            }
            this.startTimeInMS = timestamp - this.time * 1000;
            let timestampGetter = this.latestAnimationFrameTimestampGetter(timestamp);
            // 激活音视频层.
            // 不可省略, 因为只有更新渲染树时才会调用激活, 而播放时可能没有渲染树更新.
            this.tree.activeCurrentLayers();
            // 开始帧率计算.
            this.frameRateCalculator.restart();
            // 开始绘制.
            await this.playFrame(timestamp);
            // 起始的过程可能涉及到视频解码和启动, 会耗费超过一帧的时间.
            // 此时应当更新起始时间戳, 让其和最近一次显示器刷新的时刻对齐, 
            // 以防止音视频时刻落后整个动画的时刻.
            let newTimestamp = timestampGetter();
            this.startTimeInMS = newTimestamp - this.time * 1000;
        });
        this.emit('play');
    }
    /** 返回最近的一个浏览器刷新的时间戳. */
    latestAnimationFrameTimestampGetter(currentTimestamp) {
        let frameId;
        let request = () => {
            frameId = requestAnimationFrame((timestamp) => {
                currentTimestamp = timestamp;
                request();
            });
        };
        request();
        return () => {
            cancelAnimationFrame(frameId);
            return currentTimestamp;
        };
    }
    /** 根据动画循环获得时刻绘制一帧, 注意这里在上一帧的资源加载完成并且绘制完成之前不会试图绘制下一帧. */
    async playFrame(currentTime) {
        // 如果外部暂停发生在上一个 animation frame 结束后,
        // 而下一个 animation frame 尚未开始时的异步过程中,
        // 那么暂停会失败, 所以这里需要再进行一次判断.
        if (this.paused) {
            return;
        }
        // 计算帧率.
        this.frameRateCalculator.trigger(currentTime);
        // 判断播放时间段.
        let timeInMs = currentTime - this.startTimeInMS;
        let duration = this.project.data.duration;
        if (timeInMs >= duration * 1000) {
            await this.enqueUpdate(duration);
            this.pause();
            this.ended = true;
            this.emit('end');
        }
        else {
            await this.enqueUpdate(timeInMs / 1000);
            this.animationFrameId = requestAnimationFrame((timeStamp) => this.playFrame(timeStamp));
        }
    }
    /** 结束播放. */
    endPlaying() {
        cancelAnimationFrame(this.animationFrameId);
        if (this.playing && !this.ended) {
            this.tree.deactiveCurrentLayers();
        }
    }
    /** 从某个时刻开始播放. */
    async playFrom(time) {
        this.checkIfEveryThingReady();
        this.setTimeProperty(time);
        await this.play();
    }
    /** 暂停. */
    pause() {
        if (this.playing) {
            this.endPlaying();
            this.paused = true;
            this.emit('pause');
        }
    }
    /** 手动设置当前的时刻, 单位秒. 一般来自于用户拖动时间轴. */
    async setTime(time) {
        this.checkIfEveryThingReady();
        this.ended = false;
        await this.enqueUpdate(time);
    }
    /**
     * 进行队列更新, 如果上一帧没有更新完, 不会反复更新.
     * 但是仍会确保最后一次更新.
     * 此外也可以调用以用于在当前更新完成后获得回调.
     */
    async enqueUpdate(time = null) {
        return await this.queue.enqueue(time);
    }
    /** 当层的状态改变时选择是否进行重绘. */
    async mayUpdateAfterLayerUpdated(layerData) {
        if (this.tree.isLayerBeCurrent(layerData) && this.paused) {
            await this.enqueUpdate();
        }
    }
    /**
     * 返回是否应当尽可能快地加载层数据, 此时会在主线程解码图片.
     * worker 线程解码图片能降低主线程负载, 但是整体更加耗费时间.
     */
    shouldLoadLayerSoon(layerData) {
        return this.tree.isLayerBeCurrent(layerData) || !this.started;
    }
    /** 从队列中调用的实际会进行的更新, 请不要自己调用. */
    async updateFromQueue(time) {
        if (time !== null) {
            this.setTimeProperty(time);
        }
        this.updatePromise = this.update();
        await this.updatePromise;
        this.updatePromise = null;
    }
    /** 等待当前的更新结束, 即所有指令都已经发送完步, 如果有的话. */
    async waitUpdateCompleted() {
        if (this.updatePromise) {
            await this.updatePromise;
        }
    }
    /**
     * 设置时间属性.
     * 当顺序播放时更新当前时刻和进行绘制, 时间参数会被自动约束到范围内.
     * 这里的参数 time 会增加 0.0001s.
     * 原因是我们根据时刻获得层时, 左右都可以等于, 如果一个当前时刻刚好和某两个层的切换时刻相等,
     * 那么此帧两个层会同时绘制, 这会带来一些不必要的性能问题, 有时还会产生错误.
     */
    setTimeProperty(time) {
        this.time = (0, ff_1.constrain)(time, 0, this.project.data.duration);
        this.tree.updateTime(this.time);
        this.emit('updatetime', this.time);
    }
    /** 更新绘制, 也可以当时间不变时更新绘制结果. */
    async update() {
        // 必须在开头时清理, 否则如果中间的绘制过程太长, 例如编码时.
        // 那么会因为资源被意外清理而产生错误.
        this.cancelClearingResources();
        // 处理当前帧数据, 在播放时绝大部分时候都会由于前一帧时刻的预加载而实际不做处理.
        await this.checkRenderTree(this.time);
        // 同步层的时间.
        await this.tree.syncLayersTime();
        // 进行绘制.
        this.draw();
        this.started = true;
        // 预加载下一帧的数据. 注意这里不会等待.
        if (this.playing) {
            this.preloadNextFrame();
        }
        else {
            this.willClearResourcesLater();
        }
    }
    /** 预加载下一帧. */
    async preloadNextFrame() {
        let frameDuration = this.frameRateCalculator.getFrameDuration();
        // 16ms 只是一个参考值, 实际渲染的帧率和其并没有直接关系.
        // 如果发生了更新, 则立刻同步层的时间以激活视频和音频的播放.
        let updated = await this.checkRenderTree(this.time + frameDuration);
        if (updated) {
            await this.tree.syncLayersTime();
        }
    }
    /** 预加载下一帧所需的层数据. 返回是否发生了更新. */
    async checkRenderTree(time) {
        // 如果上一帧开始处理的当前帧的数据仍在处理中, 则等待它完成.
        if (this.preloadingNextFramePromise) {
            await this.preloadingNextFramePromise;
        }
        let layerDatas = this.timeline.getMutatedLayerDatas(time);
        if (layerDatas) {
            this.preloadingNextFramePromise = this.updateRenderTree(layerDatas);
            await this.preloadingNextFramePromise;
            this.preloadingNextFramePromise = null;
            // 激活刚创建的音视频层, 必须在绘制之后, 因为绘制渲染树时会更新时间.
            if (this.playing) {
                this.tree.activeCurrentLayers();
            }
            this.emit('updatetree', time);
        }
        return !!layerDatas;
    }
    /** 更新渲染树, 并且会进行绘制. */
    async updateRenderTree(layerDatas) {
        let startSafeTime = this.timeline.getStartSafeTime();
        await this.tree.updateLayerDatas(layerDatas, startSafeTime);
        // 在播放或者编码时, 绘制完成后预加载资源, 但是不做等待.
        if (this.playing || this.project.mode === 'encoding') {
            this.preloadNextResources();
        }
    }
    /** 准备好所有的要加载的资源, 只在初始化时调用. */
    async prepareAllResources() {
        // 60s 一般情况下都足够了. 更多的话可能会造成内存占用过高.
        let layerDatas = this.timeline.getMutatedPreloadLayerDatas(this.time, 0, 60);
        if (layerDatas) {
            await this.tree.preloadResources(layerDatas, true);
        }
    }
    /** 准备好当前时刻以及稍后所需要的资源. */
    async prepareNextResources() {
        let layerDatas = this.timeline.getMutatedPreloadLayerDatas(this.time);
        if (layerDatas) {
            await this.tree.preloadResources(layerDatas, true);
        }
    }
    /** 预加载当前时刻以及之后需要的资源. */
    preloadNextResources() {
        let layerDatas = this.timeline.getMutatedPreloadLayerDatas(this.time);
        if (layerDatas) {
            this.tree.preloadResources(layerDatas, false);
        }
    }
    /** 开始清理倒计时, 一分钟之后如果未有新的渲染则清理掉资源. */
    willClearResourcesLater() {
        let timeoutSeconds = this.project.options.clearResourcesAfterNoInteractionForSeconds;
        if (timeoutSeconds) {
            this.clearTimeout = setTimeout(() => {
                this.project.clearResoures();
            }, timeoutSeconds * 1000);
        }
    }
    /** 结束清理倒计时. */
    cancelClearingResources() {
        if (this.clearTimeout) {
            clearTimeout(this.clearTimeout);
            this.clearTimeout = null;
        }
    }
    /** 根据绘制区域申请一个纹理缓存. */
    requestPartialTextureFrame(area, antialias = false, superSampling = 1, params = {}) {
        let rasterArea = area
            .scale(this.scaleRatio)
            .round();
        return this.sw.textureFrameManager.requestPartial(rasterArea, antialias, superSampling, params);
    }
    /** 绘制内容为纹理数据, 返回纹理缓存对象以及绘制区域. */
    drawAsMappedSamplerFromFn(drawContentFn, antialiasType = false, params = {}) {
        let textureFrame = this.sw.textureFrameManager.requestFull(antialiasType, 1, params);
        textureFrame.active();
        let paintArea = drawContentFn();
        textureFrame.deactive();
        let mappedSampler = textureFrame.getMappedSampler();
        if (!paintArea) {
            mappedSampler.release();
        }
        return {
            mappedSampler,
            paintArea,
        };
    }
    /** 绘制层和特效, 可在外部调用以更新绘制. */
    draw() {
        this.tree.draw();
    }
    /**
     * 清除渲染树的资源占用.
     * 注意这个方法不能独立调用, 它必须通过 project.clear 调用,
     * 来同时清理 timeline 才能正常工作.
     */
    clear() {
        this.cancelClearingResources();
        this.endPlaying();
        this.tree.clear();
        this.queue.clear();
    }
    /** 删除渲染器以及其释放其所有资源. */
    delete() {
        this.clear();
        this.sw.loseContext();
    }
}
exports.Renderer = Renderer;


/***/ }),

/***/ "./src/aegl/renderer/shapes/base.ts":
/*!******************************************!*\
  !*** ./src/aegl/renderer/shapes/base.ts ***!
  \******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.VectorShapeBaseDrawer = void 0;
const todraw_1 = __webpack_require__(/*! ../../../libs/webgl/todraw */ "./src/libs/webgl/todraw.ts");
const property_1 = __webpack_require__(/*! ../../property/property */ "./src/aegl/property/property.ts");
const to_draw_transform_1 = __webpack_require__(/*! ../to-draws/to-draw-transform */ "./src/aegl/renderer/to-draws/to-draw-transform.ts");
const solid_fill_frag_1 = __webpack_require__(/*! ../../shaders/shape/solid-fill.frag */ "./src/aegl/shaders/shape/solid-fill.frag");
const shape_fill_frag_1 = __webpack_require__(/*! ../../shaders/shape/shape-fill.frag */ "./src/aegl/shaders/shape/shape-fill.frag");
const aegl_default_values_1 = __webpack_require__(/*! ../../aegl-default-values */ "./src/aegl/aegl-default-values.ts");
const transform_1 = __webpack_require__(/*! ../../property/transform */ "./src/aegl/property/transform.ts");
const matrix4_1 = __webpack_require__(/*! ../../../libs/math/matrix4 */ "./src/libs/math/matrix4.ts");
const drawer_1 = __webpack_require__(/*! ../drawer */ "./src/aegl/renderer/drawer.ts");
/** 形状基类. */
class VectorShapeBaseDrawer extends drawer_1.Drawer {
    /** 是否用于裁剪蒙版绘制,. */
    forClipping;
    /** 用于填充绘制的类型. */
    fillToDrawType = todraw_1.ToDrawType.TriangleStrip;
    /** 用于描边绘制的类型. */
    strokeToDrawType = todraw_1.ToDrawType.TriangleStrip;
    /** 用于进行填充绘制. */
    toDrawFill = null;
    /** 用于进行描边绘制. */
    toDrawStroke = null;
    /** 当前顶点等数据是否随时间更新, transform 不在此列. */
    isDataDynamic;
    /** 当前的参数值. */
    values;
    /** 经过处理之后的当前的填充参数. */
    fillValues;
    /** 经过处理之后的当前的描边参数. */
    strokeValues;
    constructor(renderer, data, forClipping = false) {
        super(renderer, data);
        this.forClipping = forClipping;
        this.isDataDynamic = this.checkIsDataDynamic();
    }
    /**
     * 初始化着色对象.
     * 它作为独立函数这样可以让子类的原型函数的设置一定在初始化之前.
     */
    initialize() {
        // 绘制填充.
        if (this.data.fill) {
            this.toDrawFill = new to_draw_transform_1.ToDrawTransform({
                renderer: this.renderer,
                type: this.fillToDrawType,
                fragCode: this.getFragCode(),
            });
        }
        // 绘制描边.
        // 这两个绘制对象其实可以合并为一个, 但是需要另外管理顶点数据.
        // 所以简单起见将两个绘制对象分开.
        if (this.data.stroke) {
            this.toDrawStroke = new to_draw_transform_1.ToDrawTransform({
                renderer: this.renderer,
                type: this.strokeToDrawType,
                fragCode: this.getFragCode(),
            });
        }
    }
    /** 获取片元着色代码 */
    getFragCode() {
        return this.forClipping ? shape_fill_frag_1.default : solid_fill_frag_1.default;
    }
    /**
     * 形状形状是否是时刻相关的.
     * 按说分别检查填充和描边似乎更好, 不过实际并没有多大的效率提升.
     */
    checkIsDataDynamic() {
        if (this.data.stroke) {
            if ((0, property_1.isPropertyValueBeKeyFrames)(this.data.stroke.strokeWidth)
                || this.data.stroke.dashOffset && (0, property_1.isPropertyValueBeKeyFrames)(this.data.stroke.dashOffset)
                || this.data.stroke.dashes && this.data.stroke.dashes.some(d => (0, property_1.isPropertyValueBeKeyFrames)(d))) {
                return true;
            }
        }
        return false;
    }
    /** 更新当前时刻. */
    setTime(time) {
        this.time = time;
        // 生成当前时刻的填充的值.
        if (this.data.fill) {
            this.fillValues = (0, property_1.getPropertyValues)(this.data.fill, this.time, aegl_default_values_1.ShapeFillDefaultValues);
        }
        // 生成当前时刻的描边的值.
        if (this.data.stroke) {
            let values = this.strokeValues = (0, property_1.getPropertyValues)(this.data.stroke, this.time, aegl_default_values_1.ShapeStrokeDefaultValues);
            // 对每个 dash 动画取值.
            if (values.dashes) {
                values.dashes = values.dashes.map(v => {
                    return (0, property_1.getPropertyValue)(v, this.time);
                });
            }
        }
    }
    /** 设置变换状态. */
    setTransformStatus(status) {
        super.setTransformStatus(status);
        // 合并形状上的变换.
        if (this.data.transform) {
            let values = (0, transform_1.getTransformValues)(this.data.transform, this.time);
            status.mergeTransformValues(values);
        }
        // 合并自身的位置信息.
        if (this.data.position) {
            let transform = new matrix4_1.Matrix4();
            transform.translateSelf(...this.values.position);
            status.mergeTransformMatrix(transform);
        }
        if (this.fillValues && this.toDrawFill) {
            // 合并内部填充透明度.
            let fillStatus = status;
            let opacity = this.fillValues.opacity / 100;
            if (opacity !== 1) {
                fillStatus = status.clone();
                fillStatus.mergeOpacity(opacity);
            }
            this.toDrawFill.setTransformStatus(fillStatus);
        }
        if (this.strokeValues && this.toDrawStroke) {
            // 合并内部描边透明度.
            let strokeStatus = status;
            let opacity = this.strokeValues.opacity / 100;
            if (opacity !== 1) {
                strokeStatus = status.clone();
                strokeStatus.mergeOpacity(opacity);
            }
            this.toDrawStroke.setTransformStatus(strokeStatus);
        }
    }
    /** 更新一些参数. */
    update() {
        // 生成当前时刻的填充的值.
        if (this.fillValues && this.toDrawFill) {
            this.toDrawFill.setUniform('solidColor', this.fillValues.color);
        }
        // 生成当前时刻的描边的值.
        if (this.strokeValues && this.toDrawStroke) {
            this.toDrawStroke.setUniform('solidColor', this.strokeValues.color);
        }
        // 更新顶点数据.
        this.updateCoords();
    }
    /** 更新顶点数据, 如果有必要的话. */
    updateCoords() {
        if (this.toDrawFill && (this.isDataDynamic || !this.toDrawFill.vertices)) {
            let { coords, indices } = this.getFillCoords();
            this.toDrawFill.setCoords(coords, undefined, indices);
        }
        if (this.toDrawStroke && (this.isDataDynamic || !this.toDrawStroke.vertices)) {
            let { coords, indices } = this.getStrokCoords();
            this.toDrawStroke.setCoords(coords, undefined, indices);
        }
    }
    /** 设置裁剪矩形区域. */
    setMaskArea(area) {
        if (this.toDrawFill) {
            this.toDrawFill.setMaskArea(area);
        }
        if (this.toDrawStroke) {
            this.toDrawStroke.setMaskArea(area);
        }
    }
    /** 使用纹理直接进行填充绘制. */
    setMappedChannel(mappedSampler) {
        if (this.toDrawFill) {
            this.toDrawFill.setMappedChannel(mappedSampler);
        }
        if (this.toDrawStroke) {
            this.toDrawStroke.setMappedChannel(mappedSampler);
        }
    }
    /** 清除填充纹理. */
    clearChannel() {
        if (this.toDrawFill) {
            this.toDrawFill.clearChannel();
        }
        if (this.toDrawStroke) {
            this.toDrawStroke.clearChannel();
        }
    }
    /** 绘制形状, 输出绘制影响的矩形范围. */
    draw() {
        // 绘制填充.
        if (this.toDrawFill) {
            this.toDrawFill.draw();
        }
        // 绘制描边.
        if (this.toDrawStroke) {
            this.toDrawStroke.draw();
        }
        return this.getPaintArea();
    }
    getPaintArea() {
        if (this.toDrawStroke) {
            return this.toDrawStroke.getPaintArea();
        }
        else if (this.toDrawFill) {
            return this.toDrawFill.getPaintArea();
        }
        return null;
    }
    delete() {
        if (this.toDrawFill) {
            this.toDrawFill.delete();
        }
        if (this.toDrawStroke) {
            this.toDrawStroke.delete();
        }
    }
}
exports.VectorShapeBaseDrawer = VectorShapeBaseDrawer;


/***/ }),

/***/ "./src/aegl/renderer/shapes/ellipse.ts":
/*!*********************************************!*\
  !*** ./src/aegl/renderer/shapes/ellipse.ts ***!
  \*********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ShapeEllipseDrawer = void 0;
const base_1 = __webpack_require__(/*! ./base */ "./src/aegl/renderer/shapes/base.ts");
const property_1 = __webpack_require__(/*! ../../property/property */ "./src/aegl/property/property.ts");
const aegl_default_values_1 = __webpack_require__(/*! ../../aegl-default-values */ "./src/aegl/aegl-default-values.ts");
const polygon_line_1 = __webpack_require__(/*! ../../../libs/curves/polygon-line */ "./src/libs/curves/polygon-line.ts");
const todraw_1 = __webpack_require__(/*! ../../../libs/webgl/todraw */ "./src/libs/webgl/todraw.ts");
/** 椭圆形状. */
class ShapeEllipseDrawer extends base_1.VectorShapeBaseDrawer {
    /** 用于填充绘制的类型. */
    fillToDrawType = todraw_1.ToDrawType.TriangleFan;
    checkIsDataDynamic() {
        if ((0, property_1.isPropertyValueBeKeyFrames)(this.data.size)) {
            return true;
        }
        return super.checkIsDataDynamic();
    }
    update() {
        this.values = (0, property_1.getPropertyValues)(this.data, this.time, aegl_default_values_1.ShapeRectDefaultValues);
        super.update();
    }
    getFillCoords() {
        let vertexCoords = this.getVertexCoords();
        let coords = [
            [0, 0],
            ...vertexCoords,
            vertexCoords[0],
        ];
        return { coords };
    }
    getStrokCoords() {
        let vertexCoords = this.getVertexCoords();
        let strokeWidth = this.strokeValues.strokeWidth;
        let coords = (0, polygon_line_1.triangulatePolygonLine)(vertexCoords, strokeWidth, true);
        return { coords };
    }
    getVertexCoords() {
        let coords = [];
        let hw = this.values.size[0] / 2;
        let hh = this.values.size[1] / 2;
        let r = Math.max(hw, hh);
        // 大致满足圆弧和线段相差不到 0.1px.
        // 可能需要考虑外部缩放, 但是目前暂时不考虑.
        let d = 2 / Math.sqrt(10 * r);
        // d 应当被 PI / 2 整除, 即它会刚好和 90° 的整数倍对齐.
        d = Math.PI / 2 / Math.round(Math.PI / 2 / d);
        // 生成椭圆形的采样点.
        for (let i = 0; i < 6.2832; i += d) {
            coords.push([hw * Math.cos(i), hh * Math.sin(i)]);
        }
        return coords;
    }
}
exports.ShapeEllipseDrawer = ShapeEllipseDrawer;


/***/ }),

/***/ "./src/aegl/renderer/shapes/group.ts":
/*!*******************************************!*\
  !*** ./src/aegl/renderer/shapes/group.ts ***!
  \*******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ShapeGroupDrawer = void 0;
const base_1 = __webpack_require__(/*! ./base */ "./src/aegl/renderer/shapes/base.ts");
const property_1 = __webpack_require__(/*! ../../property/property */ "./src/aegl/property/property.ts");
const polygon_line_1 = __webpack_require__(/*! ../../../libs/curves/polygon-line */ "./src/libs/curves/polygon-line.ts");
const aegl_default_values_1 = __webpack_require__(/*! ../../aegl-default-values */ "./src/aegl/aegl-default-values.ts");
const todraw_1 = __webpack_require__(/*! ../../../libs/webgl/todraw */ "./src/libs/webgl/todraw.ts");
/** 通用路径. */
class ShapeGroupDrawer extends base_1.VectorShapeBaseDrawer {
    /** 使用扇形绘制凸多边形. */
    fillToDrawType = todraw_1.ToDrawType.TriangleFan;
    /** 用于描边绘制的类型. */
    strokeToDrawType = todraw_1.ToDrawType.TriangleStrip;
    /** 当前的路径参数值. */
    pathValues;
    checkIsDataDynamic() {
        // 如果路径是动态信息的话.
        if ((0, property_1.isPropertyValueBeKeyFrames)(this.data.path)) {
            return true;
        }
        return super.checkIsDataDynamic();
    }
    update() {
        this.values = (0, property_1.getPropertyValues)(this.data, this.time, aegl_default_values_1.ShapeGroupDefaultValues);
        this.pathValues = (0, property_1.getComplexPropertyValues)(this.data.path, this.time);
        super.update();
    }
    getFillCoords() {
        let coords = this.pathValues.vertices;
        return { coords };
    }
    getStrokCoords() {
        let vertexCoords = this.pathValues.vertices;
        let strokeWidth = this.strokeValues.strokeWidth;
        let coords = (0, polygon_line_1.triangulatePolygonLine)(vertexCoords, strokeWidth, this.pathValues.closed);
        return { coords };
    }
}
exports.ShapeGroupDrawer = ShapeGroupDrawer;


/***/ }),

/***/ "./src/aegl/renderer/shapes/rect.ts":
/*!******************************************!*\
  !*** ./src/aegl/renderer/shapes/rect.ts ***!
  \******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ShapeRectDrawer = void 0;
const base_1 = __webpack_require__(/*! ./base */ "./src/aegl/renderer/shapes/base.ts");
const property_1 = __webpack_require__(/*! ../../property/property */ "./src/aegl/property/property.ts");
const aegl_default_values_1 = __webpack_require__(/*! ../../aegl-default-values */ "./src/aegl/aegl-default-values.ts");
const polygon_line_1 = __webpack_require__(/*! ../../../libs/curves/polygon-line */ "./src/libs/curves/polygon-line.ts");
/** 矩形形状. */
class ShapeRectDrawer extends base_1.VectorShapeBaseDrawer {
    checkIsDataDynamic() {
        if ((0, property_1.isPropertyValueBeKeyFrames)(this.data.size)
            || (0, property_1.isPropertyValueBeKeyFrames)(this.data.roundness)) {
            return true;
        }
        return super.checkIsDataDynamic();
    }
    update() {
        this.values = (0, property_1.getPropertyValues)(this.data, this.time, aegl_default_values_1.ShapeRectDefaultValues);
        super.update();
    }
    getFillCoords() {
        let hw = this.values.size[0] / 2;
        let hh = this.values.size[1] / 2;
        let coords = [
            [-hw, -hh],
            [-hw, hh],
            [hw, -hh],
            [hw, hh],
        ];
        return { coords };
    }
    getStrokCoords() {
        let hw = this.values.size[0] / 2;
        let hh = this.values.size[1] / 2;
        let strokeWidth = this.strokeValues.strokeWidth;
        // 这里的点是顺序出现的, 顺时针或者逆时针关系不大, 最后的三角形带都会被处理为顺时针.
        // 注意这里的顶点连接顺序和填充的不同.
        let vertexCoords = [
            [-hw, -hh],
            [hw, -hh],
            [hw, hh],
            [-hw, hh],
        ];
        let coords = (0, polygon_line_1.triangulatePolygonLine)(vertexCoords, strokeWidth, true);
        return { coords };
    }
}
exports.ShapeRectDrawer = ShapeRectDrawer;


/***/ }),

/***/ "./src/aegl/renderer/text-atlas/font-measurement.ts":
/*!**********************************************************!*\
  !*** ./src/aegl/renderer/text-atlas/font-measurement.ts ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.getFontMeasurement = void 0;
const fonts_list_1 = __webpack_require__(/*! ../../helpers/fonts-list */ "./src/aegl/helpers/fonts-list.ts");
let TheSVG;
let TheSVGText1;
let TheSVGText2;
const TestString = 'A quick brown fox jump over the lazy dog.';
/** 用于记录字体的测量信息. */
const SVGFontMeasurementMap = new Map();
/**
 * 字母左右侧的 margin 间距, 用于防止字母紧挨着绘制时产生重叠.
 * 此外许多的艺术字体经常会溢出其 font box.
 * 所以应当被替换为逐字体分析.
 * 实际内存开销会增加此数值的双倍.
 */
const MaxSidesBearing = 0.5;
/** 初始化用于测量的元素吧可看看v卡卡 . */
function initializeSVGElement() {
    let svgNS = 'http://www.w3.org/2000/svg';
    let svg = document.createElementNS(svgNS, 'svg');
    svg.style.position = 'fixed';
    svg.style.top = '0';
    svg.style.visibility = 'hidden';
    svg.style.fontSize = '100px';
    let text1 = document.createElementNS(svgNS, 'text');
    text1.setAttribute('x', '0');
    text1.setAttribute('y', '0');
    text1.style.dominantBaseline = 'alphabetic';
    text1.textContent = TestString;
    svg.appendChild(text1);
    let text2 = document.createElementNS(svgNS, 'text');
    text2.setAttribute('x', '0');
    text2.setAttribute('y', '0');
    text2.style.dominantBaseline = 'middle';
    text2.textContent = TestString;
    svg.appendChild(text2);
    TheSVG = svg;
    TheSVGText1 = text1;
    TheSVGText2 = text2;
}
/** 获得字体的测量信息, 此时字体已加载. */
function getFontMeasurement(fontFamily, fontStyle) {
    let info;
    if (fonts_list_1.FontList.has(fontFamily)) {
        let fontData = fonts_list_1.FontList.get(fontFamily, fontStyle);
        info = {
            ascent: fontData.winAscent,
            descent: fontData.winDescent,
            xHeight: fontData.xHeight,
            boxHeight: fontData.boxHeight,
            leftBearing: -fontData.minLeftSideBearing,
            rightBearing: -fontData.minRightSideBearing,
            yMin: fontData.yMin,
            yMax: fontData.yMax,
        };
    }
    else {
        info = calcFontMeasurement(fontFamily);
    }
    // yMax 至少设置为 1, 否则字高很低的一些英文字体混入中文时会被截断.
    info.yMax = Math.max(info.yMax, 1);
    // 某些字体行高过分了, 将其限制在 1.2.
    if (info.boxHeight > 1.2) {
        let diff = (info.boxHeight - 1.2) / 2;
        info.ascent -= diff;
        info.descent += diff;
        info.boxHeight = 1.2;
    }
    return info;
}
exports.getFontMeasurement = getFontMeasurement;
/** 通过一个 SVG 元素来推测文字的 */
function calcFontMeasurement(fontFamily) {
    if (SVGFontMeasurementMap.has(fontFamily)) {
        return SVGFontMeasurementMap.get(fontFamily);
    }
    if (!TheSVG) {
        initializeSVGElement();
    }
    // 经过测试, HTML 标签不能严格按照各类基线进行布局, Canvas measureText 同样无法返回准确的字体测量信息,
    // 所以这里使用 svg 测试文字的布局信息.
    TheSVG.style.fontFamily = fontFamily;
    document.body.appendChild(TheSVG);
    let textBounding1 = TheSVGText1.getBoundingClientRect();
    let textBounding2 = TheSVGText2.getBoundingClientRect();
    let boxHeight = textBounding1.height / 100;
    let baselineToAscentLine = -textBounding1.top / 100;
    let xMiddleToAscentLine = -textBounding2.top / 100;
    let descent = boxHeight - baselineToAscentLine;
    let xHeight = (baselineToAscentLine - xMiddleToAscentLine) * 2;
    let ascent = baselineToAscentLine;
    let info = {
        ascent,
        descent,
        xHeight,
        boxHeight,
        leftBearing: MaxSidesBearing,
        rightBearing: MaxSidesBearing,
        yMin: -descent,
        yMax: ascent,
    };
    SVGFontMeasurementMap.set(fontFamily, info);
    document.body.removeChild(TheSVG);
    return info;
}


/***/ }),

/***/ "./src/aegl/renderer/text-atlas/text-atlas-char-positions.ts":
/*!*******************************************************************!*\
  !*** ./src/aegl/renderer/text-atlas/text-atlas-char-positions.ts ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.TextAtlasCharPositions = void 0;
const transform_1 = __webpack_require__(/*! ../../property/transform */ "./src/aegl/property/transform.ts");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
const matrix4_1 = __webpack_require__(/*! ../../../libs/math/matrix4 */ "./src/libs/math/matrix4.ts");
const text_1 = __webpack_require__(/*! ../../property/text */ "./src/aegl/property/text.ts");
/** 用于记录每个文字的位置数据以及提供导出顶点数据, 采样数据和索引数据. */
class TextAtlasCharPositions {
    textAtlas;
    /** 已生成好的顶点数据. */
    vertexCoords;
    /** 逐个文字的布局情况. */
    layouts;
    constructor(textAtlas, lineLayouts, vertexCoords) {
        this.textAtlas = textAtlas;
        this.vertexCoords = vertexCoords;
        this.initializeLayouts(lineLayouts);
    }
    /** 初始化逐文字布局信息. */
    initializeLayouts(lineLayouts) {
        let layouts = [];
        let charIndexExcludeSpace = 0;
        let wordIndex = 0;
        let isLastCharBeEmpty = true;
        for (let charIndex = 0; charIndex < lineLayouts.length; charIndex++) {
            let layout = lineLayouts[charIndex];
            let { char } = layout;
            let isEmptyChar = /\s/.test(char);
            if (!isEmptyChar && charIndex > 0) {
                charIndexExcludeSpace++;
            }
            let isStartOfLine = charIndex === 0 || layout.lineIndex > lineLayouts[charIndex - 1].lineIndex;
            let isStartOfWord = isLastCharBeEmpty && !isEmptyChar;
            isLastCharBeEmpty = isEmptyChar;
            if ((isStartOfLine || isStartOfWord) && charIndex > 0) {
                wordIndex++;
            }
            layouts.push(Object.assign(layout, {
                charIndex,
                charIndexExcludeSpace,
                wordIndex,
            }));
        }
        this.layouts = layouts;
    }
    getLength() {
        return this.layouts.length;
    }
    /** 获得逐个字符的索引信息. */
    getCharIndices() {
        return this.layouts;
    }
    /** 获得顶点数据. */
    getVertexCoords() {
        return this.vertexCoords;
    }
    /** 获得文字的采样坐标. */
    getTextureCoords() {
        let textureCoords = [];
        let { w, h } = this.textAtlas.renderedCanvasSize;
        for (let { char } of this.layouts) {
            let { x1, y1, x2, y2 } = this.textAtlas.renderedCharRectMap.get(char);
            let tx1 = x1 / w;
            let tx2 = x2 / w;
            let ty1 = 1.0 - y1 / h;
            let ty2 = 1.0 - y2 / h;
            textureCoords.push([tx1, ty1], [tx1, ty2], [tx2, ty1], [tx2, ty2]);
        }
        return textureCoords;
    }
    /** 获得文字用于进行索引绘制的索引. */
    getCoordIndices() {
        let indices = [];
        for (let i = 0; i < this.layouts.length; i++) {
            let start = i * 4;
            indices.push(start, start + 1, start + 2, start + 1, start + 2, start + 3);
        }
        return indices;
    }
    /** 根据之前的文字的索引以及文字动画参数计算逐个文字的变换矩阵. */
    getPerTextTransforms(allAnimaterValues) {
        let transforms = [];
        let moves = this.getTrackingMoves(allAnimaterValues);
        for (let i = 0; i < allAnimaterValues.length; i++) {
            let animaterValues = allAnimaterValues[i];
            let [anchorX, anchorY] = this.layouts[i].anchorPoint;
            let textMatrix = (0, transform_1.getTransformFromValues)(animaterValues);
            let transform = new matrix4_1.Matrix4();
            let moveX = moves ? moves[i] : 0;
            // 注意这里的 anchorPoint 和一般的变换时不同的, 一般的变换有 position 平衡 anchorPoint, 但是这里的只起到一个变换锚点的作用.
            transform.translateSelf(-anchorX, -anchorY);
            transform.leftMultiplySelf(textMatrix);
            transform.translateSelf(anchorX + moveX, anchorY);
            transforms.push(transform);
        }
        return transforms;
    }
    /** 计算文字因为 tracking amount 而产生的位移. */
    getTrackingMoves(allAnimaterValues) {
        let hasTrackingAmountSet = allAnimaterValues.some(v => v.trackingAmount);
        if (!hasTrackingAmountSet) {
            return null;
        }
        let alignRate = (0, text_1.getAlignRateFromLeft)(this.textAtlas.state.values.justification);
        let fontSize = this.textAtlas.state.values.fontSize;
        let moves = [];
        let lines = Object.values((0, ff_1.groupBy)(this.layouts, layout => layout.lineIndex));
        let charStartIndexOfLine = 0;
        for (let lineLayouts of lines) {
            // 计算逐个文字向右的扩展距离.
            let expands = allAnimaterValues.slice(charStartIndexOfLine, charStartIndexOfLine + lineLayouts.length).map((v) => {
                return (0, text_1.getLetterSpacingFronTrackingAmount)(fontSize, v.trackingAmount || 0);
            });
            // 计算总的扩展距离.
            let totalExpands = (0, ff_1.sum)(expands);
            // 最左侧的位移.
            let left = -totalExpands * alignRate;
            // 计算逐个字符的左侧位移.
            for (let i = 0; i < expands.length; i++) {
                moves.push(left + expands[i] / 2);
                left += expands[i];
            }
            charStartIndexOfLine += lineLayouts.length;
        }
        return moves;
    }
}
exports.TextAtlasCharPositions = TextAtlasCharPositions;


/***/ }),

/***/ "./src/aegl/renderer/text-atlas/text-atlas-state.ts":
/*!**********************************************************!*\
  !*** ./src/aegl/renderer/text-atlas/text-atlas-state.ts ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.TextAtlasState = void 0;
const font_measurement_1 = __webpack_require__(/*! ./font-measurement */ "./src/aegl/renderer/text-atlas/font-measurement.ts");
const color_1 = __webpack_require__(/*! ../../helpers/color */ "./src/aegl/helpers/color.ts");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
const fonts_list_1 = __webpack_require__(/*! ../../helpers/fonts-list */ "./src/aegl/helpers/fonts-list.ts");
/**
 * 用于对一个 TextAtlas 的状态进行管理和比对.
 * 但是不负责产生实际的元素操作.
 * 完全可读写.
 */
class TextAtlasState {
    /** 当前文本. */
    text = '';
    /** 用户界面缩放比. */
    interfaceScaling;
    /** 外部变换累计缩放比. */
    transformScaling;
    /** 文字超采样倍率. */
    textSuperSamplingRate;
    /** 当前数据值. */
    values;
    /** 文字状态标识. */
    idenfitier = null;
    /** 用于记录当前的上下文状态 id, 跟随 Canvas 的更新而累加. */
    canvasId = 0;
    /** 顶点状态标识. */
    charPositionIdenfitier = null;
    /** Canvas 画布上下文的属性. */
    contextState;
    /** 记录渲染的像素属性. */
    renderIn;
    /** 字体的测量信息. */
    fontMeasurement;
    constructor(options = {}) {
        this.interfaceScaling = options.interfaceScaling || 1;
        this.transformScaling = options.transformScaling || 1;
        this.textSuperSamplingRate = options.textSuperSamplingRate || 2;
    }
    /** 生成文字层的状态标识, 相同标识则可以共用同一个文字纹理. */
    generateContextStateIdentifier() {
        let values = this.values;
        let identifier = {
            fontFamily: values.fontFamily,
            fontSize: values.fontSize,
            fontStyle: values.fontStyle,
            fauxBold: values.fauxBold,
            fauxItalic: values.fauxItalic,
            fillColor: values.fillColor,
            strokeColor: values.strokeWidth ? values.strokeColor : undefined,
            strokeWidth: values.strokeColor ? values.strokeWidth : undefined,
            scaling: this.interfaceScaling * this.transformScaling,
        };
        return identifier;
    }
    /** 生成文字层的顶点状态标识, 相同标识则可以共用同一个顶点坐标. */
    generateCharPositionIdentifier() {
        let values = this.values;
        let identifier = {
            // 一旦贴图改变, 也必须重新生成坐标,
            // 重新生成的贴图可能不包含贴图的部分文字.
            contextStateId: this.canvasId,
            fontFamily: values.fontFamily,
            fontSize: values.fontSize,
            fontStyle: values.fontStyle,
            fauxBold: values.fauxBold,
            fauxItalic: values.fauxItalic,
            tracking: values.tracking,
            strokeWidth: values.strokeColor ? values.strokeWidth : undefined,
            text: this.text,
            scaling: this.interfaceScaling * this.transformScaling,
        };
        return identifier;
    }
    /** 是否需要进行状态更新, 一个周期只能被调用一次. */
    shouldUpdateContextState() {
        let identifier = this.generateContextStateIdentifier();
        let shouldUpdate = !(0, ff_1.deepEqual)(identifier, this.idenfitier);
        if (shouldUpdate) {
            this.prepareContextState();
            this.idenfitier = identifier;
        }
        return shouldUpdate;
    }
    /** 当 Canvas 发生了变更时触发. */
    onCanvasUpdated() {
        this.canvasId++;
    }
    /** 准备上下文参数. */
    prepareContextState() {
        let { fillColor, strokeColor, strokeWidth, fontSize, fontFamily } = this.values;
        let fontScaling = this.interfaceScaling * this.transformScaling * this.textSuperSamplingRate;
        let renderInFontSize = Math.round(fontSize * fontScaling);
        let state = {};
        let fontStyle = this.getFontStyle();
        state.font = `${fontStyle || ''} ${renderInFontSize}px "${fontFamily}"`;
        state.textAlign = 'left'; // 总是从左侧开始渲染文字, 生成顶点时会计量实际对齐方式.
        state.textBaseline = 'alphabetic'; // 按照基线对齐.
        state.lineWidth = (strokeWidth || 0) * fontScaling;
        state.fillStyle = (0, color_1.colorArrayToString)(fillColor);
        state.strokeStyle = (0, color_1.colorArrayToString)(strokeColor);
        this.contextState = state;
        this.fontMeasurement = (0, font_measurement_1.getFontMeasurement)(fontFamily, this.values.fontStyle);
        this.prepareRenderInProperties(renderInFontSize, fontStyle);
    }
    /** 准备一些渲染数字变量. */
    prepareRenderInProperties(renderInFontSize, fontStyle) {
        let { leftBearing, rightBearing, ascent, yMax, boxHeight } = this.fontMeasurement;
        // 倾斜时扩大右侧的留白, 大约 10°.
        if (fontStyle.includes('italic')) {
            rightBearing += 0.15;
        }
        // 计算其他渲染像素属性.
        let renderInMaxHeight = Math.ceil(renderInFontSize * (this.fontMeasurement.yMax - this.fontMeasurement.yMin));
        let renderInLeftBearing = Math.ceil(renderInFontSize * leftBearing) + 2;
        let renderInRightBearing = Math.ceil(renderInFontSize * rightBearing) + 2;
        this.renderIn = {
            fontSize: renderInFontSize,
            maxHeight: renderInMaxHeight,
            boxHeight: renderInFontSize * boxHeight,
            ascent: renderInFontSize * ascent,
            yMax: renderInFontSize * yMax,
            leftBearing: renderInLeftBearing,
            rightBearing: renderInRightBearing,
        };
    }
    /** 获得 fontStyle. */
    getFontStyle() {
        let weight = fonts_list_1.FontList.getCSSFontWeight(this.values.fontStyle);
        let style = fonts_list_1.FontList.getCSSFontStyle(this.values.fontStyle);
        if (this.values.fauxBold && weight === 'normal') {
            weight = 'bold';
        }
        if (this.values.fauxItalic && style === 'normal') {
            style = ' italic';
        }
        if (weight === 'normal') {
            weight = '';
        }
        if (style === 'normal') {
            style = '';
        }
        return (weight + style).trim();
    }
    /** 返回是否应当更新输出的顶点信息. 一个周期只能被调用一次. */
    shouldUpdateCharPosition() {
        let identifier = this.generateCharPositionIdentifier();
        let shouldUpdate = !(0, ff_1.deepEqual)(identifier, this.charPositionIdenfitier);
        if (shouldUpdate) {
            this.charPositionIdenfitier = identifier;
        }
        return shouldUpdate;
    }
}
exports.TextAtlasState = TextAtlasState;


/***/ }),

/***/ "./src/aegl/renderer/text-atlas/text-atlas.ts":
/*!****************************************************!*\
  !*** ./src/aegl/renderer/text-atlas/text-atlas.ts ***!
  \****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.TextAtlas = exports.TextAtlasUpdatedOfCanvas = void 0;
const property_1 = __webpack_require__(/*! ../../property/property */ "./src/aegl/property/property.ts");
const text_1 = __webpack_require__(/*! ../../property/text */ "./src/aegl/property/text.ts");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
const aegl_default_values_1 = __webpack_require__(/*! ../../aegl-default-values */ "./src/aegl/aegl-default-values.ts");
const text_atlas_state_1 = __webpack_require__(/*! ./text-atlas-state */ "./src/aegl/renderer/text-atlas/text-atlas-state.ts");
const text_2 = __webpack_require__(/*! ../../helpers/text */ "./src/aegl/helpers/text.ts");
const text_atlas_char_positions_1 = __webpack_require__(/*! ./text-atlas-char-positions */ "./src/aegl/renderer/text-atlas/text-atlas-char-positions.ts");
const debug_1 = __webpack_require__(/*! ../../../libs/util/debug */ "./src/libs/util/debug.ts");
/** 标记 TextAtlas 更新了啥. */
var TextAtlasUpdatedOfCanvas;
(function (TextAtlasUpdatedOfCanvas) {
    /** 未有任何更新. */
    TextAtlasUpdatedOfCanvas[TextAtlasUpdatedOfCanvas["Nothing"] = 0] = "Nothing";
    /** 更新了内容, 但是 Canvas 尺寸未变. */
    TextAtlasUpdatedOfCanvas[TextAtlasUpdatedOfCanvas["Content"] = 1] = "Content";
    /** 更新了 Canvas 的尺寸, 内容可能发生了更新. */
    TextAtlasUpdatedOfCanvas[TextAtlasUpdatedOfCanvas["Size"] = 2] = "Size";
})(TextAtlasUpdatedOfCanvas || (exports.TextAtlasUpdatedOfCanvas = TextAtlasUpdatedOfCanvas = {}));
/** 用于将指定的文本绘制入一个 canvas. */
class TextAtlas extends ff_1.Emitter {
    /** 关联的文字层数据. */
    data;
    /** 纹理的最大尺寸. */
    maxTextureSize;
    /** 视频高度. */
    videoHeight;
    /** 当前字体加载所对应的 promise. */
    loadingFontPromise = null;
    /** 自上一次绘制贴图后字体加载是否发生了进度变更. */
    moreFontsLoadedAfterRendering = false;
    /** Canvas 元素上下文. */
    context;
    /** 当前 Canvas 元素. */
    canvas;
    /** 记录所有状态, 完全可读写. */
    state;
    /** 每个字符在渲染后画布上的坐标, 包含了留白. */
    renderedCharRectMap;
    /** 实际渲染的每个字符的布局宽度信息, 不包含留白. */
    renderedCharWidthMap;
    /** 下一个字母包含留白的左上角在渲染后画布上的起始布局坐标位置. */
    renderedNextCharPosition = { x: 0, y: 0 };
    /** 已渲染的总的画布尺寸. */
    renderedCanvasSize = { w: 0, h: 0 };
    constructor(data, maxTextureSize, videoHeight, options = {}) {
        super();
        this.data = data;
        this.maxTextureSize = maxTextureSize;
        this.videoHeight = videoHeight;
        this.state = new text_atlas_state_1.TextAtlasState(options);
        this.canvas = document.createElement('canvas');
        this.context = this.canvas.getContext("2d");
    }
    /** 更新当前时刻. */
    setTime(time) {
        this.state.values = (0, property_1.getPropertyValues)(this.data, time, aegl_default_values_1.TextLayerDefaultValues);
    }
    /** 如果需要的话进行更新, 返回是否做了更新. */
    async tryUpdateCanvas(sync) {
        let updatedOfCanvas = TextAtlasUpdatedOfCanvas.Nothing;
        // 发生了环境变更.
        if (this.state.shouldUpdateContextState()) {
            this.updateContextState();
            await this.loadFontFaces(sync);
            updatedOfCanvas = this.rerenderAllChars();
        }
        else {
            // 提取唯一的字符, 然后检查所有的字符之前是否都渲染了.
            let allUniqueChars = (0, ff_1.unique)([...this.state.text]);
            let notRenderedChars = (0, ff_1.unique)([...allUniqueChars]).filter(char => !this.renderedCharRectMap.has(char));
            // 渲染更多的字符, 字体需要重新加载.
            if (notRenderedChars.length > 0) {
                await this.loadFontFaces(sync);
                updatedOfCanvas = this.renderMoreChars(notRenderedChars, allUniqueChars);
            }
            // 字体已经在加载, 不用再加载了. 但是由于字体加载进度变化, 文字必须重新渲染.
            if (this.moreFontsLoadedAfterRendering) {
                updatedOfCanvas = this.rerenderAllChars();
            }
        }
        if (updatedOfCanvas !== TextAtlasUpdatedOfCanvas.Nothing) {
            this.state.onCanvasUpdated();
        }
        return updatedOfCanvas;
    }
    /** 将上下文状态恢复到上一次存储的状态. */
    updateContextState() {
        for (let name of Object.keys(this.state.contextState)) {
            this.context[name] = this.state.contextState[name];
        }
    }
    /** 当状态更改时重新渲染所有文字. 返回是否更新了 Cnavas 尺寸. */
    rerenderAllChars() {
        this.clearRenderedResults();
        let allUniqueChars = (0, ff_1.unique)([...this.state.text]);
        return this.renderMoreChars(allUniqueChars, allUniqueChars);
    }
    /** 清除已绘制结果. */
    clearRenderedResults() {
        this.renderedCharRectMap = new Map();
        this.renderedCharWidthMap = new Map();
        this.renderedNextCharPosition = { x: 0, y: 0 };
        // 这里不清除绘制缓存, 因为之后可能会重新分配缓存, 不用清除之前的缓存.
    }
    /** 加载字体. */
    async loadFontFaces(sync) {
        let loadingFontPromise = new Promise(async (resolve) => {
            // 获得所有匹配的 FontFace 对象.
            await document.fonts.load(this.state.contextState.font, this.state.text);
            if (loadingFontPromise === this.loadingFontPromise && alreadyReturned) {
                this.moreFontsLoadedAfterRendering = true;
                this.emit('fontloaded');
            }
            resolve();
        });
        this.loadingFontPromise = loadingFontPromise;
        // 如果此函数还未返回, 那么没有必要触发 fontloaded 事件.
        let alreadyReturned = false;
        // 同步模式下等待字体完全加载完成.
        if (sync) {
            await loadingFontPromise;
        }
        // 异步模式下等待最多 200ms, 如果仍不完成则结束等待.
        else {
            await Promise.race([loadingFontPromise, (0, ff_1.sleep)(200)]);
        }
        alreadyReturned = true;
    }
    /** 渲染到 canvans 元素. 返回是否更新了 Canvas 尺寸. */
    renderMoreChars(notRenderedChars, allUniqueChars) {
        let { values } = this.state;
        let reuseRenderResult = this.renderedCharRectMap.size > 0;
        let updatedOfCanvas = TextAtlasUpdatedOfCanvas.Content;
        // 计算所有字符宽度.
        this.calcCharWidths(notRenderedChars);
        // 计算文字布局, 取得新的画布宽高.
        let { coords, width, height } = this.layoutChars(notRenderedChars);
        let { w: oldWidth, h: oldHeight } = this.renderedCanvasSize;
        let newWidth = Math.max(width, oldWidth);
        let newHeight = Math.max(height, oldHeight);
        if (newWidth > this.maxTextureSize || newHeight > this.maxTextureSize) {
            // 不能再减少字符.
            if (this.renderedCharRectMap.size === allUniqueChars.length) {
                throw new Error(`Text Atlas size execeed because too many unique characters to render!`);
            }
            // 重新绘制.
            else {
                return this.rerenderAllChars();
            }
        }
        // 将原先的绘制结果拷贝.
        if (newWidth > oldWidth || newHeight > oldHeight) {
            let timeEnd = debug_1.debug.timeStart(`Allocating TextAtlas Canvas in size "${newWidth}x${newHeight}"`);
            let renderResult = reuseRenderResult ? this.context.getImageData(0, 0, this.canvas.width, this.canvas.height) : null;
            this.canvas.width = Math.ceil(newWidth);
            this.canvas.height = Math.ceil(newHeight);
            // 重设尺寸之后所有的状态会被重置, 在此将其恢复.
            this.updateContextState();
            // 写入之前的绘制的结果.
            if (renderResult) {
                this.context.putImageData(renderResult, 0, 0);
            }
            timeEnd();
            // 记录当前的 canvas 尺寸.
            this.renderedCanvasSize = { w: newWidth, h: newHeight };
            updatedOfCanvas = TextAtlasUpdatedOfCanvas.Size;
        }
        // 清除之前的绘制.
        else if (!reuseRenderResult) {
            this.context.clearRect(0, 0, oldWidth, oldHeight);
        }
        // 绘制剩余文字.
        for (let { char, x, y } of coords) {
            if (values.strokeWidth && values.strokeColor) {
                this.context.strokeText(char, x, y);
            }
            if (values.fillColor) {
                this.context.fillText(char, x, y);
            }
        }
        // 已加载的字体都已经渲染.
        this.moreFontsLoadedAfterRendering = false;
        return updatedOfCanvas;
    }
    /** 进行字母布局, 返回像素渲染产生的尺寸, 和 2 个整数次方对齐. */
    layoutChars(chars) {
        let { leftBearing, rightBearing, maxHeight, yMax } = this.state.renderIn;
        let { x, y } = this.renderedNextCharPosition;
        let baselineY = y + yMax;
        let coords = [];
        for (let char of chars) {
            let charWidth = this.renderedCharWidthMap.get(char);
            // 包含了留白的左右侧坐标.
            let width = charWidth + leftBearing + rightBearing;
            let right = x + width;
            // 溢出了行, 进行换行.
            if (right > this.maxTextureSize) {
                x = 0;
                y += maxHeight;
                baselineY += maxHeight;
            }
            coords.push({
                char,
                x: x + leftBearing,
                y: baselineY,
            });
            // 边缘的坐标 0.5 被栅格化为 0.5 透明度的一个像素,
            // 外部采样时如果 MSAA 存在, 那么这个像素会被再度叠加 0.5 的透明度变为 0.25.
            // 所以在绘制文字时需要关闭 MSAA.
            this.renderedCharRectMap.set(char, {
                x1: x,
                y1: y,
                x2: x + width,
                y2: y + maxHeight,
            });
            x = right;
        }
        // 存储下次布局开始的位置.
        this.renderedNextCharPosition = { x, y };
        let isMultipleLine = Math.round(y / maxHeight) > 0;
        let width = isMultipleLine ? this.maxTextureSize : Math.pow(2, Math.ceil(Math.log(x) / Math.log(2)));
        let height = Math.pow(2, Math.ceil(Math.log(y + maxHeight) / Math.log(2)));
        return { coords, width, height };
    }
    /** 计算每个字符的宽度. */
    calcCharWidths(chars) {
        for (let char of chars) {
            if (!this.renderedCharWidthMap.has(char)) {
                let w = this.context.measureText(char).width;
                this.renderedCharWidthMap.set(char, w);
            }
        }
    }
    /** 解析文字的度量信息并且返回顶点坐标. */
    generateCharPositions() {
        let renderIn = this.state.renderIn;
        let { fontSize } = this.state.values;
        // scaleBackRatio 将当前渲染的大小转为输出的原始坐标大小.
        // 以下所有均基于输出像素坐标的运算.
        let scaleBackRatio = fontSize / renderIn.fontSize;
        let boxHeight = renderIn.boxHeight * scaleBackRatio;
        let maxHeight = renderIn.maxHeight * scaleBackRatio;
        let leftBearing = renderIn.leftBearing * scaleBackRatio;
        let rightBearing = renderIn.rightBearing * scaleBackRatio;
        let yMax = renderIn.yMax * scaleBackRatio;
        let textLines = this.measureTextLines();
        let vertexCoords = [];
        let layouts = [];
        let yPercentage = this.getPositionYPercentage();
        for (let i = 0; i < textLines.length; i++) {
            let { text, xPositions } = textLines[i];
            // 垂直居中时的基线 y 坐标.
            let baselineY = (i - (textLines.length - 1) * yPercentage) * boxHeight;
            // 计算顶部和底部坐标, 为基线到字体框上边以及额外的上下文字边界.
            // 注意计算底部坐标时需要使用经过了整数对齐的总高度.
            let yTop = baselineY - yMax;
            let yBot = yTop + maxHeight;
            let anchorPointY = baselineY;
            for (let j = 0; j < xPositions.length; j++) {
                let char = text[j];
                // 原始坐标下的字母左侧坐标, 不包含留白.
                let left = xPositions[j] * scaleBackRatio;
                // 原始坐标下的字母宽度.
                let charWidth = this.renderedCharWidthMap.get(char) * scaleBackRatio;
                // 字母 X 方向中心坐标.
                let anchorPointX = left + charWidth / 2;
                // 增加左右留白再计算 x 坐标.
                let x1 = left - leftBearing;
                let x2 = left + charWidth + rightBearing;
                // 生成每个文字的顶点坐标.
                vertexCoords.push([x1, yTop], [x1, yBot], [x2, yTop], [x2, yBot]);
                // 生成每个文字的布局信息.
                layouts.push({
                    char,
                    charWidth,
                    anchorPoint: [anchorPointX, anchorPointY],
                    lineIndex: i,
                });
            }
        }
        return new text_atlas_char_positions_1.TextAtlasCharPositions(this, layouts, vertexCoords);
    }
    /** 计算多行时第一行的基线的移动位置. */
    getPositionYPercentage() {
        let yPercentage = 0.5;
        if (this.data.transform && (this.data.transform.position || this.data.transform.yPosition)) {
            let positionY = this.data.transform.position
                ? (0, property_1.getPropertyValue)(this.data.transform.position, 0)[1]
                : (0, property_1.getPropertyValue)(this.data.transform.yPosition, 0);
            yPercentage = positionY / this.videoHeight;
        }
        return yPercentage;
    }
    /** 进行多行文字布局. */
    measureTextLines() {
        let { text } = this.state;
        let { fontSize: renderInFontSize } = this.state.renderIn;
        let { fontSize, boxTextSize } = this.state.values;
        // scaleBackRatio 将当前渲染的大小转为未经过变换处理的输出的原始坐标大小.
        // 注意以下的 "render" 以及 "pixel" 两类变量.
        let scaleBackRatio = fontSize / renderInFontSize;
        let textLine = this.measureOneLineText(this.state.text);
        let { lineWidth: totalRenderWidth } = textLine;
        let textLines = [textLine];
        let maxRenderLineWidth = Infinity;
        // 如果有设置文字包含框, 则检查是否可以进行多行布局.
        if (boxTextSize) {
            maxRenderLineWidth = boxTextSize[0] / scaleBackRatio;
        }
        if (totalRenderWidth > maxRenderLineWidth || text.includes('\n')) {
            // 文字包含框高度足以容纳多行.
            textLines = this.splitTextLines(textLine, maxRenderLineWidth);
        }
        return textLines;
    }
    /** 计算实际的文字的渲染尺寸, 返回实际渲染的每个文字的左侧 x 坐标等. */
    measureOneLineText(text) {
        // 这里的坐标计算均基于实际渲染的坐标.
        let { fontSize: renderInFontSize } = this.state.renderIn;
        let { tracking, justification } = this.state.values;
        let letterSpacing = (0, text_1.getLetterSpacingFronTracking)(renderInFontSize, tracking);
        let metrics = this.measureText(text);
        let totalWidth = metrics.width + letterSpacing * (text.length - 1);
        let advances = metrics.advances;
        let xPositions = [];
        let alignRate = (0, text_1.getAlignRateFromLeft)(justification);
        let anchorLeft = alignRate * totalWidth;
        for (let i = 0; i < text.length; i++) {
            let charLeft = advances[i];
            // 字符边距的累计.
            let spaces = i * letterSpacing;
            // 最终的左侧坐标.
            let xPosition = -anchorLeft + charLeft + spaces;
            xPositions.push(xPosition);
        }
        return {
            text,
            xPositions,
            lineWidth: totalWidth,
            letterSpacing,
            wrapInEnd: false,
        };
    }
    /** 测量文本. */
    measureText(text) {
        let metrics = this.context.measureText(text);
        // 关于 advances, 请注意, 它不是每个字符的左侧坐标,
        // 恰恰相反, 它是从 0 个开始的每个字符进行布局之后的右侧坐标.
        let advances = metrics.advances;
        // 对于 Firefox, 由于不支持 advances, 所以通过计算递增文字的宽度来近似.
        if (!advances) {
            advances = [0];
            // 这里通过测量添加每个字符的宽度, 再减去最后一个字符的宽度来获得这个字符的左侧坐标.
            for (let i = 1; i < text.length; i++) {
                let char = text[i];
                let subText = text.slice(0, i + 1);
                let charRight = i === text.length - 1 ? metrics.width : this.context.measureText(subText).width;
                let charWidth = this.renderedCharWidthMap.get(char);
                advances.push(charRight - charWidth);
            }
            metrics.advances = advances;
        }
        return metrics;
    }
    /** 将单行测量结果转为多行. */
    splitTextLines(textLine, maxLineWidth) {
        let { text, xPositions, lineWidth: totalWidth, letterSpacing } = textLine;
        let lines = [];
        let startIndex = 0;
        for (let i = 0; i < xPositions.length; i++) {
            // 直到第 i 个字符右侧的总字符宽度.
            let startX = xPositions[startIndex];
            let char = text[i];
            let width = i === xPositions.length - 1
                ? totalWidth - (startX - xPositions[0])
                : xPositions[i + 1] - letterSpacing - startX;
            // 遇到超出限制宽度时, 或者遇到换行.
            if (width > maxLineWidth || char === '\n') {
                let nextLineStartIndex = i;
                let wrapInEnd = false;
                // 处理单词边界.
                if (width > maxLineWidth) {
                    nextLineStartIndex = (0, text_2.reverseFindWordStartIndex)(text, i);
                    wrapInEnd = true;
                    // 如果起始位置即是单词边界, 也就是一行显示不完一个单词, 此时强行分隔.
                    if (nextLineStartIndex <= startIndex) {
                        nextLineStartIndex = i;
                    }
                }
                let textOfLine = text.slice(startIndex, nextLineStartIndex);
                let xPositionsOfLine = xPositions.slice(startIndex, nextLineStartIndex);
                // 行宽度为第一个文字左侧到最后一个文字右侧的距离.
                let lineWidth = xPositions[nextLineStartIndex] - letterSpacing - startX;
                lines.push({
                    text: textOfLine,
                    xPositions: xPositionsOfLine,
                    lineWidth,
                    letterSpacing,
                    wrapInEnd,
                });
                startIndex = nextLineStartIndex;
            }
        }
        // 生成最后一行数据.
        if (startIndex < xPositions.length) {
            let textOfLastLine = text.slice(startIndex);
            let xPositionsOfLastLine = xPositions.slice(startIndex);
            let lastLineWidth = totalWidth - (0, ff_1.sum)(lines.map(l => l.lineWidth + letterSpacing));
            lines.push({
                text: textOfLastLine,
                xPositions: xPositionsOfLastLine,
                lineWidth: lastLineWidth,
                letterSpacing,
                wrapInEnd: false,
            });
        }
        if (lines.length > 1) {
            for (let i = 0; i < lines.length; i++) {
                let currentLine = lines[i];
                let prevLineWrapInEnd = i > 0 && lines[i - 1].wrapInEnd;
                this.alignLinePositions(currentLine, prevLineWrapInEnd);
            }
        }
        return lines;
    }
    /** 重新调整 x 坐标以重新平衡每一行. */
    alignLinePositions(line, wrapInStart) {
        let alignRate = (0, text_1.getAlignRateFromLeft)(this.state.values.justification);
        let { text, lineWidth, xPositions, letterSpacing, wrapInEnd } = line;
        // 如果在结尾处断开, 那么应当排除最末尾的空白字符的占位.
        if (wrapInEnd && (0, text_2.isWhiteSpaceChar)(text[text.length - 1])) {
            lineWidth = xPositions[xPositions.length - 1] - xPositions[0] - letterSpacing;
            xPositions = xPositions.slice(0, -1);
            text = text.slice(0, -1);
        }
        // 开头位置换行时, 将换行符排除占位.
        if (text[0] === '\n' || wrapInStart && (0, text_2.isWhiteSpaceChar)(text[0])) {
            lineWidth -= xPositions[1] - xPositions[0];
            xPositions = xPositions.slice(1);
            text = text.slice(1);
        }
        let anchorLeft = alignRate * lineWidth;
        let moveX = -anchorLeft - xPositions[0];
        line.text = text;
        line.xPositions = xPositions.map(x => x + moveX);
    }
}
exports.TextAtlas = TextAtlas;


/***/ }),

/***/ "./src/aegl/renderer/to-draws/to-draw-drop-shadow.ts":
/*!***********************************************************!*\
  !*** ./src/aegl/renderer/to-draws/to-draw-drop-shadow.ts ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ToDrawDropShadow = void 0;
const gauss_blur_1 = __webpack_require__(/*! ../../../libs/math/gauss-blur */ "./src/libs/math/gauss-blur.ts");
const to_draw_fast_blur_1 = __webpack_require__(/*! ./to-draw-fast-blur */ "./src/aegl/renderer/to-draws/to-draw-fast-blur.ts");
const drop_shadow_frag_1 = __webpack_require__(/*! ../../shaders/effects/drop-shadow.frag */ "./src/aegl/shaders/effects/drop-shadow.frag");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
/** 用于绘制 Drop Shadow 特效. */
class ToDrawDropShadow extends to_draw_fast_blur_1.ToDrawFastBlur {
    constructor(options) {
        super(Object.assign(options, {
            samplingCount: (0, ff_1.constrain)(options.samplingCount, 1, options.renderer.project.options.maxDropShadowSamplingCount)
        }));
    }
    /** 将原始的着色器做一些采样数的替换处理, samplingCount 已经经过了 2 的次方对齐以及最大值限制. */
    getFragCode(samplingCount) {
        let priorities = samplingCount === 1
            ? [{ x: 0, p: 1 }]
            : (0, gauss_blur_1.generate1DGaussBlurPriorities)(samplingCount);
        let samplingCode = priorities.map(({ x, p }) => {
            let pString = p === 1 ? '1.0' : p.toString();
            return `\talpha += sampling(iChannel[0], textureCoord + ${x}.0 * d).a * ${pString};`;
        }).join('\n').replace(/\+(\s*)-/g, '-$1');
        let code = drop_shadow_frag_1.default.replace('float samplingCount = 1.0;', `float samplingCount = ${samplingCount}.0;`)
            .replace('alpha += sampling(iChannel[0], textureCoord).a;', samplingCode);
        return code;
    }
    /** 获取迭代次数, 如果不需要模糊则返回 0. */
    getTotalIterateCount(radius) {
        let multiply = 2;
        let count = this.samplingCount === 1 || radius.x === 0 && radius.y === 0 ? 1 : this.iterateCount * multiply;
        return count;
    }
}
exports.ToDrawDropShadow = ToDrawDropShadow;


/***/ }),

/***/ "./src/aegl/renderer/to-draws/to-draw-effect.ts":
/*!******************************************************!*\
  !*** ./src/aegl/renderer/to-draws/to-draw-effect.ts ***!
  \******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ToDrawEffect = void 0;
const to_draw_transform_1 = __webpack_require__(/*! ./to-draw-transform */ "./src/aegl/renderer/to-draws/to-draw-transform.ts");
/**
 * 相比原始的 ToDraw 对象, 它可以更加方便地设置变换矩阵和透明度等参数.
 * 此外它可以计算当前对象的绘制范围, 以及将其反馈给下一个绘制流程来减小其片元着色范围.
 *
 * 此外此对象还有一些 API 用于绘制一个独立的图片或者视频, 此时它可能会包含一个裁剪矩阵.
 */
class ToDrawEffect extends to_draw_transform_1.ToDrawTransform {
    /** 设置固定不动的参数. */
    initializeUniforms() {
        super.initializeUniforms();
        this.setUniform('effectOpacity', 1);
    }
}
exports.ToDrawEffect = ToDrawEffect;


/***/ }),

/***/ "./src/aegl/renderer/to-draws/to-draw-fast-blur.ts":
/*!*********************************************************!*\
  !*** ./src/aegl/renderer/to-draws/to-draw-fast-blur.ts ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ToDrawFastBlur = void 0;
const aegl_enums_1 = __webpack_require__(/*! ../../aegl-enums */ "./src/aegl/aegl-enums.ts");
const gauss_blur_1 = __webpack_require__(/*! ../../../libs/math/gauss-blur */ "./src/libs/math/gauss-blur.ts");
const fast_blur_frag_1 = __webpack_require__(/*! ../../shaders/effects/fast-blur.frag */ "./src/aegl/shaders/effects/fast-blur.frag");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
const to_draw_effect_1 = __webpack_require__(/*! ./to-draw-effect */ "./src/aegl/renderer/to-draws/to-draw-effect.ts");
/** 用于绘制类似于高斯模糊的 Fast Box 模糊特效. */
class ToDrawFastBlur extends to_draw_effect_1.ToDrawEffect {
    /** 当前模糊半径. */
    blurRadius;
    /** 模糊所影响的轴. */
    blurDimension = aegl_enums_1.AEEffectGaussianBlurDimension.Both;
    constructor(options) {
        super(Object.assign(options, {
            samplingCount: (0, ff_1.constrain)(options.samplingCount, 1, options.renderer.project.options.fastBlurSamplingCount)
        }));
    }
    initializeOptions(options) {
        let iterateCount = options.iterateCount || 1;
        let samplingCount = this.getBestSamplingCount(options.samplingCount, iterateCount);
        (0, ff_1.assignIf)(options, {
            fragCode: this.getFragCode(samplingCount),
        });
        super.initializeOptions(options);
        this.iterateCount = iterateCount;
        this.samplingCount = samplingCount;
        // 默认边缘不做镜像重复.
        this.setRepeatEdgePixels(false);
    }
    /** 将原始的着色器做一些采样数的替换处理, samplingCount 已经经过了 2 的次方对齐以及最大值限制. */
    getFragCode(samplingCount) {
        let priorities = samplingCount === 1
            ? [{ x: 0, p: 1 }]
            : (0, gauss_blur_1.generate1DGaussBlurPriorities)(samplingCount);
        let samplingCode = priorities.map(({ x, p }) => {
            let pString = p === 1 ? '1.0' : p.toString();
            return `\tcolor += sampling(iChannel[0], textureCoord + (${x}.0 + noiseValue) * d) * ${pString};`;
        }).join('\n').replace(/\+(\s*)-/g, '-$1');
        let code = fast_blur_frag_1.default.replace('float samplingCount = 1.0;', `float samplingCount = ${samplingCount}.0;`)
            .replace('color += sampling(iChannel[0], textureCoord + (0.0 + noiseValue) * d);', samplingCode);
        return code;
    }
    /** 获得最合适的采样数, 返回最接近的 2 的整数次方. */
    getBestSamplingCount(samplingCount, iterateCount) {
        // 将 radius 拆解为 iterateCount / 2 个值, 其平方和等于直径的平方.
        let count = samplingCount * Math.sqrt(1 / iterateCount);
        // 2 的整数次方.
        let exp = Math.round(Math.log(count) / Math.log(2));
        exp = Math.max(exp, 0);
        return Math.pow(2, exp);
    }
    /** 设置模糊半径. */
    setBlurRadius(radius) {
        this.blurRadius = radius;
    }
    /** 设置模糊所影响的轴. */
    setBlurDimension(dimension) {
        this.blurDimension = dimension;
    }
    /** 设置是否镜像边缘.. */
    setRepeatEdgePixels(repeat) {
        this.setUniform('repeatEdgePixels', repeat);
    }
    /**
     * 计算高斯模糊, 稍后将其绘制到外部画布.
     * 注意纹理缓存绘制一定不能放入 draw 方法内部, draw 只是一个最终输出.
     */
    drawAsSampler() {
        return this.drawBlurInner(true);
    }
    /** 计算高斯模糊, 直接将其绘制到外部画布. */
    draw() {
        this.drawBlurInner(false);
    }
    /** 在设置输入绘制区域之前, 请确保已设置 `blurRadius`. */
    setInputPaintArea(inputArea) {
        // 按照半径扩展绘制范围.
        let projectedBlurRadius = this.transformStatus.projectVector(this.blurRadius).multiplyScalar(Math.sqrt(this.iterateCount));
        let blurArea = inputArea.extend(...projectedBlurRadius.xy);
        super.setInputPaintArea(blurArea);
    }
    /** 绘制高斯模糊, 可选直接绘制到画布还是导出为纹理数据. */
    drawBlurInner(asSampler) {
        // 拆解为 iterateCount / 2 个半径, 其平方和等于原始半径的平方.
        let subRadius = this.blurRadius.multiplyScalar(Math.sqrt(1 / this.iterateCount));
        let iterateCount = this.getTotalIterateCount(subRadius);
        let outputTextureFrame = null;
        let transformStatus = this.transformStatus;
        // 在初始时均在原地运行, 只有最后一次计量变换.
        this.initializeUniforms();
        for (let i = 0; i < iterateCount; i++) {
            // 最后一次绘制才计量变换.
            if (i === iterateCount - 1) {
                this.setTransformStatus(transformStatus);
            }
            // 设置采样的径向向量, 它和所用纹理在栅格化之前的分辨率有关.
            // 由于我们只在一个小范围内绘制, 所以纹理采样的偏移半径也需要经过采样变换矩阵处理,
            // 但是忽略这个矩阵的 translate 部分, 只保留 scale 部分, 于是将齐次坐标部分设置为 0.
            let blurRadius = this.getIterateBlurRadius(subRadius, i);
            this.setUniform('blurRadius', blurRadius);
            // 申请一个和实际渲染范围贴近的纹理缓存.
            let drawInTextureFrame = i < iterateCount - 1 || asSampler;
            let textureFrame = drawInTextureFrame
                ? this.renderer.sw.textureFrameManager.requestFull()
                : null;
            if (textureFrame) {
                textureFrame.active();
            }
            // 调用父绘制.
            super.draw();
            if (textureFrame) {
                textureFrame.deactive();
            }
            // 将绘制的内容作为下一步的输入.
            if (i < iterateCount - 1) {
                this.setMappedChannel(textureFrame.getMappedSampler());
            }
            else {
                // 导出模糊绘制纹理.
                outputTextureFrame = textureFrame;
                this.clearChannel();
            }
        }
        if (outputTextureFrame) {
            return outputTextureFrame.getMappedSampler();
        }
        else {
            return null;
        }
    }
    /** 获取迭代次数, 如果不需要模糊则返回 1. */
    getTotalIterateCount(radius) {
        let multiply = this.blurDimension === aegl_enums_1.AEEffectGaussianBlurDimension.Both ? 2 : 1;
        let count = this.samplingCount === 1 || radius.x === 0 && radius.y === 0 ? 1 : this.iterateCount * multiply;
        return count;
    }
    /**
     * 获得当前循环的采样半径向量.
     * 其中 pixelWidth 和 pixelHeight 指定当前使用的纹理在原始的视频坐标系下对应的分辨率.
     */
    getIterateBlurRadius(radius, index) {
        let isHerizontal = this.blurDimension === aegl_enums_1.AEEffectGaussianBlurDimension.Herizontal
            || this.blurDimension === aegl_enums_1.AEEffectGaussianBlurDimension.Both && index % 2 === 0;
        if (isHerizontal) {
            return [radius.x, 0];
        }
        else {
            return [0, radius.y];
        }
    }
}
exports.ToDrawFastBlur = ToDrawFastBlur;


/***/ }),

/***/ "./src/aegl/renderer/to-draws/to-draw-image-video.ts":
/*!***********************************************************!*\
  !*** ./src/aegl/renderer/to-draws/to-draw-image-video.ts ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ToDrawImageVideo = void 0;
const sampler_1 = __webpack_require__(/*! ../../../libs/webgl/sampler */ "./src/libs/webgl/sampler.ts");
const matrix4_1 = __webpack_require__(/*! ../../../libs/math/matrix4 */ "./src/libs/math/matrix4.ts");
const vector4_1 = __webpack_require__(/*! ../../../libs/math/vector4 */ "./src/libs/math/vector4.ts");
const mapped_sampler_1 = __webpack_require__(/*! ../../../libs/webgl/mapped-sampler */ "./src/libs/webgl/mapped-sampler.ts");
const to_draw_transform_1 = __webpack_require__(/*! ./to-draw-transform */ "./src/aegl/renderer/to-draws/to-draw-transform.ts");
/**
 * 相比 ToDrawTransform, 仅用于绘制图片或者视频.
 */
class ToDrawImageVideo extends to_draw_transform_1.ToDrawTransform {
    /** 设置或者更新指定索引位置的多媒体资源. */
    setSubMedia(index, media) {
        let sampler = this.getSubSampler('iChannel', index);
        if (sampler) {
            sampler.updateData(media);
        }
        else {
            sampler = new sampler_1.PixelSampler(this.sw, media);
            let mappedSampler = new mapped_sampler_1.MappedSampler(sampler);
            this.setSubMappedChannel(index, mappedSampler);
        }
    }
    /*
    如果一个图片要进行特效处理, 那么一般的方法是先将这个图片按照当前变换状态进行绘制,
    然后绘制为纹理缓存作为特效的输入.
    在假设采样坐标都在 0~1 范围内时, 很明显这个图片其实本身可以作为直接的输入.
    这样可以节省一道纹理缓存绘制, 但是需要进行一个采样映射处理:
    设原始坐标为 C, 对应的采样坐标为 T, 二者的关系为 T = Mm * C.
    C 经过了变换而最终绘制的坐标为 C' = Mt * C, 对应的采样坐标为 T' = Ms * T.
    而最终的绘制的坐标对应的最终的纹理缓存的采样坐标由一个固定的变换矩阵 Mo 决定, 即 T'' = Mo * C'.
    现在我们希望得到一个变换 M 从最终的采样坐标 T'' 映射到原始的采样坐标 T, 即:
    T' = M * T''
    Ms * T = M * Mo * C'
    Ms * Mm * C = M * Mo * Mt * C
    M = Ms * Mm * (Mo * Mt)^-1
    */
    /** 将当前绘制对象直接导出为一个映射纹理. */
    extractMappedSampler() {
        // 如果经过了三维点投影, 由于经过了齐次坐标处理, 无法通过三维投影后的坐标还原出原始的坐标, 此时查询原始坐标会失败.
        if (this.transformStatus.is3DProjection()) {
            return null;
        }
        // 构建映射采样器.
        let mappedSampler = this.mappedSamplers[0];
        let { sampler } = mappedSampler;
        let matrix = this.getTextureMappedMatrix();
        return new mapped_sampler_1.MappedSampler(sampler, matrix);
    }
    /** 将当前的运行变换效果累积到采样坐标的变换上面. */
    getTextureMappedMatrix() {
        // 如果一个图片要进行特效处理, 那么一般的方法是先将这个图片按照当前变换状态进行绘制,
        // 然后绘制为纹理缓存作为特效的输入.
        // 在假设采样坐标都在 0~1 范围内时, 很明显这个图片其实本身可以作为直接的输入.
        // 这样可以节省一道纹理缓存绘制, 但是需要进行一个采样映射处理:
        // 设原始坐标为 C, 对应的采样坐标为 T, 二者的关系为 T = Mm * C.
        // C 经过了变换而最终绘制的坐标为 C' = Mt * C, 对应的采样坐标为 T' = Ms * T.
        // 而最终的绘制的坐标对应的最终的纹理缓存的采样坐标由一个固定的变换矩阵 Mo 决定, 即 T'' = Mo * C'.
        // 现在我们希望得到一个变换 M 从最终的采样坐标 T'' 映射到原始的采样坐标 T, 即:
        // T' = M * T''
        // Ms * T = M * Mo * C'
        // Ms * Mm * C = M * Mo * Mt * C
        // M = Ms * Mm * (Mo * Mt)^-1
        // 自身变换矩阵.
        let { width: videoWidth, height: videoHeight } = this.renderer.project.data;
        let transformMatrix = this.transformStatus.transformMatrix;
        let samplingMatrix = this.transformStatus.samplingMatrix;
        // 从当前的坐标到纹理采样坐标的变换矩阵.
        let coords = this.coords.map(c => c.slice(0, 2));
        let textureCoords = this.textureCoords;
        // 从最终绘制的原始视频像素坐标到纹理缓存的采样坐标的变换矩阵.
        let viewportToTexture = new matrix4_1.Matrix4(1 / videoWidth, 0, 0, 0, 0, -1 / videoHeight, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1);
        // 转为矢量.
        let coordsVectorArray = coords.slice(0, 3).map(coord => {
            return new vector4_1.Vector3(...coord, 1);
        });
        let textureCoordsVectorArray = textureCoords.slice(0, 3).map(coord => {
            return new vector4_1.Vector3(...coord, 1);
        });
        // 从当前的坐标到纹理采样坐标的变换矩阵.
        let coordsMatrix3 = matrix4_1.Matrix3.fromVectors(...coordsVectorArray);
        let textureCoordsMatrix3 = matrix4_1.Matrix3.fromVectors(...textureCoordsVectorArray);
        // M * F = T
        // M = T * F^-1
        let coordToTextureCoord = matrix4_1.Matrix4.fromMatrix3(textureCoordsMatrix3.multiply(coordsMatrix3.inverse()));
        // 计算最终的采样坐标映射矩阵.
        return samplingMatrix
            .multiply(coordToTextureCoord)
            .multiply(viewportToTexture
            .multiply(transformMatrix)
            .inverse());
    }
}
exports.ToDrawImageVideo = ToDrawImageVideo;


/***/ }),

/***/ "./src/aegl/renderer/to-draws/to-draw-motion-blur.ts":
/*!***********************************************************!*\
  !*** ./src/aegl/renderer/to-draws/to-draw-motion-blur.ts ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ToDrawMotionBlur = void 0;
const matrix4_1 = __webpack_require__(/*! ../../../libs/math/matrix4 */ "./src/libs/math/matrix4.ts");
const paint_area_1 = __webpack_require__(/*! ../../../libs/area/paint-area */ "./src/libs/area/paint-area.ts");
const motion_blur_frag_1 = __webpack_require__(/*! ../../shaders/effects/motion-blur.frag */ "./src/aegl/shaders/effects/motion-blur.frag");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
const to_draw_effect_1 = __webpack_require__(/*! ./to-draw-effect */ "./src/aegl/renderer/to-draws/to-draw-effect.ts");
/** 提供了对于运动模糊的区域检测. */
class ToDrawMotionBlur extends to_draw_effect_1.ToDrawEffect {
    /** 外部累计变换相对于一帧时间的微分, 经过了投影再转为像素坐标的处理. */
    motionMatrix;
    /** 计算出的绘制区域. */
    motionArea;
    initializeOptions(options) {
        (0, ff_1.assignIf)(options, {
            fragCode: motion_blur_frag_1.default,
        });
        super.initializeOptions(options);
    }
    /** 设置固定不动的参数. */
    initializeUniforms() {
        super.initializeUniforms();
        // 设置采样数.
        let projectOptions = this.renderer.project.options;
        let samplingCount = projectOptions.motionBlurSamplingCount;
        this.setUniform('samplingCount', samplingCount);
        this.setUniform('repeatEdgePixels', false);
    }
    /**
     * 设置采样时是否镜像边缘, 默认为 false.
     * 一般在处理图像时应当设置为 true, 处理文字时应当设置为 false.
     */
    setRepeatEdgePixels(repeat) {
        this.setUniform('repeatEdgePixels', repeat);
    }
    /** 设置处理运动模糊所使用的偏移矩阵, 此矩阵已经经过了投影再转为像素坐标的处理. */
    setMotionMatrix(matrix) {
        this.motionMatrix = matrix;
        this.setUniform('motionMatrix', matrix.toFloat32Array());
    }
    /** 设置输入绘制区域, 请确保在此之前设置 `motionMatrix`. */
    setInputPaintArea(area) {
        this.setMotionAreaFromInputArea(area);
        super.setInputPaintArea(this.motionArea);
    }
    /** 获取当前的绘制属性所影响到的矩形范围. */
    setMotionAreaFromInputArea(inputArea) {
        // 通过投影后的运动矩阵和当前的绘制区域还原之前的绘制区域.
        // 假设向右运动, 那么会在左侧产生拖影, 所以这里是使用 `motionMatrix` 的负值.
        let previousArea = inputArea.multiplyBy(matrix4_1.Matrix4.I.minus(this.motionMatrix));
        // 合并两个区域.
        this.motionArea = paint_area_1.PaintArea.union([previousArea, inputArea]);
    }
    /** 获取当前的绘制属性所影响到的矩形范围. */
    getPaintArea() {
        return this.motionArea;
    }
}
exports.ToDrawMotionBlur = ToDrawMotionBlur;


/***/ }),

/***/ "./src/aegl/renderer/to-draws/to-draw-multiple.ts":
/*!********************************************************!*\
  !*** ./src/aegl/renderer/to-draws/to-draw-multiple.ts ***!
  \********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ToDrawMultiple = void 0;
const paint_area_1 = __webpack_require__(/*! ../../../libs/area/paint-area */ "./src/libs/area/paint-area.ts");
const to_draw_transform_1 = __webpack_require__(/*! ./to-draw-transform */ "./src/aegl/renderer/to-draws/to-draw-transform.ts");
/**
 * 相比 ToDrawTransform, 它可以绘制多个几何结构, 并且每个结构拥有自己独立的额外变换状态.
 * 不过不设置多个变换时, 它也可以只绘制一个几何结构.
 */
class ToDrawMultiple extends to_draw_transform_1.ToDrawTransform {
    subTransformMatrixs = null;
    charOpacityList = null;
    /** 更新应用于每个几何体的额外变换. */
    setSubTransformMatrixes(matrix) {
        this.subTransformMatrixs = matrix;
    }
    /** 更新应用于每个几何体的额外透明度. */
    setSubOpacityList(opacityList) {
        this.charOpacityList = opacityList;
    }
    /** 获得当前指定索引的几何体的变换矩阵. */
    getTransformMatrixByIndex(index) {
        return this.transformStatus.transformMatrix.multiply(this.subTransformMatrixs[index]);
    }
    draw() {
        if (this.subTransformMatrixs) {
            // 这里有三种可选的顶点处理方式:
            // 其一是轮流切换顶点和矩阵再每次绘制一个文字.
            // 其二是每个顶点都设置一个变换矩阵然后进行一次索引绘制, 矩阵会重复四次.
            // 其三是将顶点转为固定顶点加变动的矩阵, 然后这个矩阵和外部矩阵合并, 再进行实例绘制.
            // 相比之下第三种最简单, 所以选择它.
            for (let i = 0; i < this.subTransformMatrixs.length; i++) {
                this.drawFromIndex(i);
            }
        }
        else {
            super.draw();
        }
    }
    /** 绘制第几个几何体. */
    drawFromIndex(index) {
        // 此时 `subTransformMatrixes` 和 `subOpacityArray` 一定存在.
        let subTransform = this.subTransformMatrixs[index];
        let subOpacity = this.charOpacityList[index];
        let finalTransformMatrix = this.transformStatus.transformMatrix.multiply(subTransform);
        this.setUniform('iTransform', finalTransformMatrix.toFloat32Array());
        this.setUniform('iOpacity', subOpacity * this.transformStatus.opacity);
        super.draw(index * 4, 4);
    }
    /** 获取当前的绘制属性所影响到的矩形范围. */
    getPaintArea() {
        let areas = [];
        for (let i = 0; i < this.coords.length / 4; i++) {
            areas.push(this.getPaintAreaByIndex(i));
        }
        return paint_area_1.PaintArea.union(areas);
    }
    /** 获得由 index 指定的索引位置的几何对象的区域. */
    getPaintAreaByIndex(index) {
        let coords = this.coords.slice(index * 4, index * 4 + 4);
        let subTransform = this.subTransformMatrixs ? this.subTransformMatrixs[index] : null;
        if (subTransform) {
            return this.transformStatus.getProjectedPaintAreaAfterSubTransform(coords, subTransform);
        }
        else {
            return this.transformStatus.getProjectedPaintArea(coords);
        }
    }
}
exports.ToDrawMultiple = ToDrawMultiple;


/***/ }),

/***/ "./src/aegl/renderer/to-draws/to-draw-transform.ts":
/*!*********************************************************!*\
  !*** ./src/aegl/renderer/to-draws/to-draw-transform.ts ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ToDrawTransform = void 0;
const transform_status_1 = __webpack_require__(/*! ../tree/transform-status */ "./src/aegl/renderer/tree/transform-status.ts");
const transform_vert_1 = __webpack_require__(/*! ../../shaders/transform.vert */ "./src/aegl/shaders/transform.vert");
const transform_frag_1 = __webpack_require__(/*! ../../shaders/layer/transform.frag */ "./src/aegl/shaders/layer/transform.frag");
const todraw_1 = __webpack_require__(/*! ../../../libs/webgl/todraw */ "./src/libs/webgl/todraw.ts");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
const mapped_sampler_1 = __webpack_require__(/*! ../../../libs/webgl/mapped-sampler */ "./src/libs/webgl/mapped-sampler.ts");
/**
 * 相比原始的 ToDraw 对象, 它可以更加方便地设置变换矩阵和透明度等参数.
 * 此外它可以计算当前对象的绘制范围, 以及将其反馈给下一个绘制流程来减小其片元着色范围.
 *
 * 此外此对象还有一些 API 用于绘制一个独立的图片或者视频, 此时它可能会包含一个裁剪矩阵.
 */
class ToDrawTransform extends todraw_1.ToDraw {
    /** 视频渲染对象. */
    renderer;
    /** 当前绘制所需进行的裁剪区域. */
    scissor = null;
    /** 应用于顶点的变换状态. */
    transformStatus;
    /** 原始的顶点坐标, 每个坐标应当至少包含两个或者三个数字. */
    coords;
    /** 纹理采样坐标. 如果绘制不需要纹理, 或者纹理坐标可由顶点坐标映射的话, 它的值为 null. */
    textureCoords = null;
    /** 用于记录当前引用的映射纹理. */
    mappedSamplers = [];
    constructor(options) {
        super(options.renderer.sw, options);
        this.renderer = options.renderer;
        this.initializeUniforms();
    }
    initializeOptions(options) {
        (0, ff_1.assignIf)(options, {
            vertCode: transform_vert_1.default,
            fragCode: transform_frag_1.default,
        });
        super.initializeOptions(options);
    }
    /** 设置固定不动的参数. */
    initializeUniforms() {
        let { width: videoWidth, height: videoHeight } = this.renderer.project.data;
        this.setTransformStatus(new transform_status_1.TransformStatus(videoWidth, videoHeight));
    }
    /** 更新变换状态. */
    setTransformStatus(status) {
        let { transformMatrix, projectionMatrix, samplingMatrix } = status;
        this.setUniform('iTransform', transformMatrix.toFloat32Array());
        this.setUniform('iProjection', projectionMatrix.toFloat32Array());
        this.setUniform('iSamplingTransform', samplingMatrix.toFloat32Array());
        this.setUniform('iOpacity', status.opacity);
        this.transformStatus = status;
    }
    /** 更新变换状态统计. */
    setSamplingParameters(params) {
        let samplers = this.getSampler('iChannel');
        if (samplers) {
            for (let sampler of samplers) {
                sampler.updateParameters(params);
            }
        }
    }
    /** 设置数字类型的顶点坐标和相关数据, 注意两个坐标必须一一对应. */
    setCoords(coords, textureCoords, indices) {
        this.coords = coords;
        let data = {
            vPosition: coords.flat(),
        };
        // 如果 textureCoords 有设置, 我们认为它对应着一个大背景中的一个小块,
        // 并且在溢出 0~1 的采样坐标范围时, 也应该在这一小块上重复.
        // 因此我们将采样坐标重新映射到 0~1, 然后经过外层矩阵的计算,
        // 进行裁剪和处理重复, 在最后再转为局部坐标.
        if (textureCoords) {
            this.textureCoords = textureCoords;
            data.vTextureCoord = textureCoords.flat();
        }
        this.setVertices(data, coords.length, indices);
    }
    /** 设置采样器. */
    setChannel(...samplers) {
        let mappedSamplers = samplers.map(sampler => new mapped_sampler_1.MappedSampler(sampler));
        this.setMappedChannel(...mappedSamplers);
    }
    /** 设置映射纹理采样器. */
    setMappedChannel(...mappedSamplers) {
        this.mappedSamplers = mappedSamplers;
        this.useSampler('iChannel', ...mappedSamplers.map(sm => sm.sampler));
        this.setUniform('iChannelMap', new Float32Array(mappedSamplers.map(sm => sm.mapMatrix.data).flat()));
    }
    /** 设置指定的索引位置的映射纹理采样器. */
    setSubMappedChannel(index, mappedSampler) {
        this.mappedSamplers[index] = mappedSampler;
        this.useSubSampler('iChannel', index, mappedSampler.sampler);
        this.setUniform('iChannelMap', new Float32Array(this.mappedSamplers.map(sm => sm.mapMatrix.data).flat()));
    }
    /** 不再使用采样器. */
    clearChannel() {
        this.mappedSamplers = [];
        this.unuseSampler('iChannel');
    }
    /**
     * 设置顶点区域为矩形绘制区域, 矩形外不会实际产生绘制.
     * 仅适用于后期特效的绘制, 注意它会破坏顶点和采样坐标.
     */
    setInputPaintArea(area) {
        let { width: videoWidth, height: videoHeight } = this.renderer.project.data;
        let { x1, y1, x2, y2 } = area;
        let tx1 = x1 / videoWidth;
        let tx2 = x2 / videoWidth;
        let ty1 = 1 - y1 / videoHeight;
        let ty2 = 1 - y2 / videoHeight;
        let coords = [
            [x1, y1],
            [x1, y2],
            [x2, y1],
            [x2, y2],
        ];
        let textureCoords = [
            [tx1, ty1],
            [tx1, ty2],
            [tx2, ty1],
            [tx2, ty2],
        ];
        this.setCoords(coords, textureCoords);
    }
    /**
     * 获取当前的绘制属性所影响到的矩形范围.
     * 其中的用于生成绘制区域的坐标是经过最终绘制到的区域在原始视频分辨率下的像素坐标.
     */
    getPaintArea() {
        return this.transformStatus.getProjectedPaintArea(this.coords);
    }
    /**
     * 设置绘制的裁剪区域, 矩形外不会实际产生绘制.
     * 只影响接下来的一次绘制. 即使不需要设置 mask, 也需要在绘制前传递一个 null 来清除上一次的设置.
     * 在大部分时候使用 setPaintArea 和 setMaskArea 有着相同的效果,
     * 但是如果一个区域有 tile 以及外部投影, 那么必须使用 setPaintArea 来扩充顶点范围.
     */
    setMaskArea(area) {
        if (area) {
            // 稍微向外扩张以解决一些像素刚好对齐但是绘制仍然有偏差的问题. 参考 1107 模板.
            let rasterArea = area
                .scale(this.renderer.scaleRatio)
                .extend(2)
                .round();
            let x = rasterArea.x1;
            let y = this.sw.height - rasterArea.y2;
            let w = rasterArea.width;
            let h = rasterArea.height;
            this.scissor = [x, y, w, h];
        }
        else {
            this.scissor = null;
        }
    }
    /** 清除裁剪绘制区域. */
    beforeDraw() {
        super.beforeDraw();
        if (!this.vertices) {
            this.setFullscreenCoords();
        }
        if (this.scissor) {
            this.sw.setScissor(...this.scissor);
        }
    }
    /** 设置默认的全屏的顶点和采样坐标数据. */
    setFullscreenCoords() {
        let { width: videoWidth, height: videoHeight } = this.renderer.project.data;
        let w = videoWidth;
        let h = videoHeight;
        let coords = [
            [0, 0],
            [0, h],
            [w, 0],
            [w, h],
        ];
        let textureCoords = [
            [0, 1],
            [0, 0],
            [1, 1],
            [1, 0],
        ];
        this.setCoords(coords, textureCoords);
    }
    /** 清除裁剪绘制区域. */
    afterDraw() {
        super.afterDraw();
        if (this.scissor) {
            this.sw.clearScissor();
        }
    }
}
exports.ToDrawTransform = ToDrawTransform;


/***/ }),

/***/ "./src/aegl/renderer/tree/base-manager.ts":
/*!************************************************!*\
  !*** ./src/aegl/renderer/tree/base-manager.ts ***!
  \************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.BaseManager = void 0;
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
/**
 * 用于管理当前需要渲染的以及预加载的层和特效.
 * 它从 JSON 数据创建对应的层和特效, 以及缓存他们.
 */
class BaseManager {
    /** 渲染器. */
    renderer;
    /** 存储当前时刻应当绘制的对象. */
    currentIds = new Set();
    /** 存储当前时刻已创建的对象, 包含应当会绘制的对象, 以及预创建用于加载资源的对象. */
    oMap = new Map();
    /** 存储当前时刻已创建或者正在创建的对象 id. */
    allIds = new Set();
    /** 存储创建对象的 promise, 以防止重复创建同一个对象. */
    creationPromises = new Map();
    /** 预加载的递增 id. */
    prepareId = 0;
    constructor(renderer) {
        this.renderer = renderer;
    }
    /** 根据 id 获得已创建的对象. */
    getFromId(id) {
        return this.oMap.get(id);
    }
    /** 激活当前对象. */
    activeCurrent() {
        for (let id of this.currentIds) {
            if (this.oMap.has(id)) {
                this.active(this.oMap.get(id));
            }
        }
    }
    /** 关闭当前对象的激活状态. */
    deactiveCrrrent() {
        for (let id of this.currentIds) {
            if (this.oMap.has(id)) {
                this.deactive(this.oMap.get(id));
            }
        }
    }
    /** 移除所有的对象. */
    clear() {
        for (let id of this.oMap.keys()) {
            this.deleteFromId(id);
        }
    }
    /** 移除一个不再使用的对象. */
    deleteFromId(id) {
        let o = this.oMap.get(id);
        if (o) {
            o.delete();
            this.currentIds.delete(id);
            this.oMap.delete(id);
        }
        this.allIds.delete(id);
    }
    /** 获得当前所有需要绘制的对象.. */
    getCurrentDatas() {
        return [...this.currentIds].map(id => this.oMap.get(id));
    }
    /** 查询 id 所对应的对象是否为当前对象. */
    isCurrentId(id) {
        return this.currentIds.has(id);
    }
    /** 更新当前时刻所有的待绘制对象. 可支持并发调用. */
    async setCurrentDatas(datas) {
        let ids = datas.map(l => l.id);
        let currentIds = new Set(ids);
        // 处理不再激活的对象. 待激活的对象的激活会在外部调用.
        for (let id of this.currentIds) {
            if (!currentIds.has(id)) {
                let o = this.oMap.get(id);
                if (o) {
                    this.deactive(o);
                }
            }
        }
        this.currentIds = currentIds;
        // 确保这些对象已创建.
        let promises = datas.map(data => {
            return this.ensure(data);
        });
        await Promise.all(promises);
    }
    /** 根据对象属性获得已有的或者新建对象. */
    async ensure(data) {
        let { id } = data;
        if (this.oMap.has(id)) {
            return this.oMap.get(id);
        }
        // 尽管在上对象同步创建所有的对象, 但是一组数据中可能存在 id 重复的情况.
        // 所以要么唯一化 id, 要么保存创建的异步过程.
        if (this.creationPromises.has(id)) {
            return this.creationPromises.get(id);
        }
        // 加入到所有 id 列表.
        this.allIds.add(id);
        // 创建对象.
        let promise = this.create(data);
        this.creationPromises.set(id, promise);
        let o = await promise;
        this.creationPromises.delete(id);
        // 如果仍在列表中, 将其保留.
        if (this.allIds.has(id)) {
            this.oMap.set(id, o);
        }
        // 否则直接将其删除.
        else {
            o.delete();
        }
        return o;
    }
    /** 预创建对象对象来加载资源. 可支持并发调用. */
    async prepare(datas, syncMode) {
        let ids = new Set(datas.map(v => v.id));
        let currentPrepareId = ++this.prepareId;
        let promises = [];
        // 先将其加入, 表示正在创建.
        for (let id of ids) {
            this.allIds.add(id);
        }
        // 预创建新的对象.
        // 这里的创建请求不并发, 这样可以防止一瞬间挤满 CPU.
        for (let data of datas) {
            if (this.allIds.has(data.id)) {
                let promise = this.ensure(data);
                // 同步模式下并发调用.
                if (syncMode) {
                    promises.push(promise);
                }
                // 为了避免多个预加载任务长时间占用 CPU, 将其通过 Macro Task 运行.
                else {
                    await (0, ff_1.sleep)(0);
                    await promise;
                    /** 因为新的预加载任务到来, 中止预加载. */
                    if (this.prepareId !== currentPrepareId) {
                        return;
                    }
                }
            }
        }
        if (promises.length > 0) {
            await Promise.all(promises);
        }
        // 移除不再需要的对象. 但是由于有可能预加载的对象不包含所有激活的对象, 此时不移除激活的对象.
        for (let id of [...this.allIds]) {
            if (!ids.has(id) && !this.currentIds.has(id)) {
                this.deleteFromId(id);
            }
        }
    }
}
exports.BaseManager = BaseManager;


/***/ }),

/***/ "./src/aegl/renderer/tree/compile-render-tree.ts":
/*!*******************************************************!*\
  !*** ./src/aegl/renderer/tree/compile-render-tree.ts ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.compileToRenderTree = exports.isTransformableRenderNodeType = exports.isRenderableLayeRenderNodeType = exports.isLayerRenderNodeType = exports.RenderNodeType = void 0;
const all_1 = __webpack_require__(/*! ../effects/all */ "./src/aegl/renderer/effects/all.ts");
const transform_stat_1 = __webpack_require__(/*! ./transform-stat */ "./src/aegl/renderer/tree/transform-stat.ts");
const util_1 = __webpack_require__(/*! ../../../libs/webgl/util */ "./src/libs/webgl/util.ts");
const transform_1 = __webpack_require__(/*! ../../property/transform */ "./src/aegl/property/transform.ts");
const aegl_default_values_1 = __webpack_require__(/*! ../../aegl-default-values */ "./src/aegl/aegl-default-values.ts");
const time_map_1 = __webpack_require__(/*! ../../property/time-map */ "./src/aegl/property/time-map.ts");
const simple_webgl_1 = __webpack_require__(/*! ../../../libs/webgl/simple-webgl */ "./src/libs/webgl/simple-webgl.ts");
/** 渲染节点的类型. */
var RenderNodeType;
(function (RenderNodeType) {
    /** 图像和视频等拥有像素的内容. */
    RenderNodeType[RenderNodeType["PixelLayer"] = 0] = "PixelLayer";
    /** 形状图层. */
    RenderNodeType[RenderNodeType["ShapeLayer"] = 1] = "ShapeLayer";
    /** 音频等无像素的内容. */
    RenderNodeType[RenderNodeType["AudioLayer"] = 2] = "AudioLayer";
    /** 摄影机层. */
    RenderNodeType[RenderNodeType["CameraLayer"] = 3] = "CameraLayer";
    /** 合成层. */
    RenderNodeType[RenderNodeType["CompositeLayer"] = 4] = "CompositeLayer";
    /** 占位层, 不进行绘制, 只是用于表述层结构, 一般来源于拆解的合成. */
    RenderNodeType[RenderNodeType["PlaceholderLayer"] = 5] = "PlaceholderLayer";
    /** 特效节点, 每个特效层会拥有自己的着色. */
    RenderNodeType[RenderNodeType["Effect"] = 6] = "Effect";
})(RenderNodeType || (exports.RenderNodeType = RenderNodeType = {}));
/** 返回是否为层对应的渲染节点. */
function isLayerRenderNodeType(type) {
    return type !== RenderNodeType.Effect;
}
exports.isLayerRenderNodeType = isLayerRenderNodeType;
/** 返回是否为可渲染层对应的渲染节点. */
function isRenderableLayeRenderNodeType(type) {
    return type !== RenderNodeType.Effect && type !== RenderNodeType.AudioLayer;
}
exports.isRenderableLayeRenderNodeType = isRenderableLayeRenderNodeType;
/** 返回渲染节点是否可进行变换. */
function isTransformableRenderNodeType(type) {
    return type !== RenderNodeType.AudioLayer;
}
exports.isTransformableRenderNodeType = isTransformableRenderNodeType;
/**
 * 编译一个树形层结构到一个绘制树结构, 然后由外层的 Renderer 进行渲染.
 * 注意返回的树的节点顺序是按照需要绘制的顺序排列的. 和原始的层顺序刚好相反.
 */
function compileToRenderTree(layerDatas) {
    return new RenderTreeNodesCompiler().compile(layerDatas);
}
exports.compileToRenderTree = compileToRenderTree;
class RenderTreeNodesCompiler {
    /** 当前时间映射. */
    timeMap = new time_map_1.TimeMap();
    /** 是否处于一个 3D 层内部或者自身是 3D 层. */
    inThreeD = false;
    /** 是否在 3D 层上, 例如 3D 层或者其上的特效节点. */
    beThreeD = false;
    /** 当前正在处理的层的兄弟层. */
    siblingLayerDatas;
    /** 顶层节点. */
    topNodes = [];
    /** 编译渲染树. */
    compile(layerDatas) {
        let nodes = this.compileLayers(layerDatas, [], this.timeMap);
        // 从上到下遍历生成层的 transformStat 来记录层是否经过了指定类型的变换.
        (0, transform_stat_1.generateTransformStat)(nodes);
        return [...this.topNodes, ...nodes];
    }
    /**
     * 从下到上编译 AE 的层结构到一个绘制树结构, 然后由外层的 Renderer 进行渲染.
     * 注意返回的树的节点顺序是按照需要绘制的顺序排列的. 和原始的层顺序刚好相反.
     */
    compileLayers(layerDatas, inputs, timeMap) {
        // 因为需要传递的参数太多, 所以将这几个作为类属性放置.
        let outerInThreeD = this.inThreeD;
        let outerBeThreeD = this.beThreeD;
        let outerSiblingLayerDatas = this.siblingLayerDatas;
        let outerTimeMap = this.timeMap;
        // 不会被绘制的层需要被排除.
        let unPaintedLayerIds = this.getUnPaintedLayerIds(layerDatas);
        this.siblingLayerDatas = layerDatas;
        this.timeMap = timeMap;
        for (let i = layerDatas.length - 1; i >= 0; i--) {
            let layerData = layerDatas[i];
            // 外部为 3D 层, 那么内部会继承.
            this.inThreeD = outerInThreeD || !!layerData.threeD;
            this.beThreeD = !!layerData.threeD;
            // 跳过隐藏层.
            if (unPaintedLayerIds.has(layerData.id)) {
                continue;
            }
            switch (layerData.type) {
                // 处理像素层.
                case 'image':
                case 'video':
                case 'text':
                case 'solid':
                    inputs = this.compilePixelLayer(layerData, inputs);
                    break;
                // 处理形状层.
                case 'shape':
                    inputs = this.compileShapeLayer(layerData, inputs);
                    break;
                // 处理合成层.
                case 'composite':
                    inputs = this.compileCompositeLayer(layerData, inputs);
                    break;
                // 摄影机层改用特效处理.
                case 'camera':
                    inputs = this.compileCameraLayer(layerData, inputs);
                    break;
                // 处理音频层.
                case 'audio':
                    this.topNodes.push(this.compileAudiolLayer(layerData));
                    break;
                // 处理调整层.
                case 'adjustment':
                    inputs = this.compileAdjustmentLayer(layerData, inputs);
                    break;
                // 空层不作处理, 子层链接它并且使用其变换.
                case 'empty':
                    break;
                default:
                    throw new Error(`Can't compile layer in type "${layerData.type}"!`);
            }
        }
        this.inThreeD = outerInThreeD;
        this.beThreeD = outerBeThreeD;
        this.siblingLayerDatas = outerSiblingLayerDatas;
        this.timeMap = outerTimeMap;
        return inputs;
    }
    /** 获取所有不会进行绘制的层 id, 但是不包含根据层类型明确不绘制的层. */
    getUnPaintedLayerIds(layerDatas) {
        let unPaintedLayerIds = new Set();
        for (let layerData of layerDatas) {
            if (!layerData.effects) {
                continue;
            }
            for (let effectData of layerData.effects) {
                switch (effectData.type) {
                    // 如果是 tile 特效并且有超过一个输入, 才将其作为特效渲染.
                    // 如果仅有一个输入, 则作为矩阵叠加.
                    case 'displacementMap':
                        let mapLayerId = effectData.displacementMapLayerId;
                        unPaintedLayerIds.add(mapLayerId);
                }
            }
        }
        return unPaintedLayerIds;
    }
    /** 用于根据参数创建一个渲染节点. */
    createRenderNode(type, data, inputs) {
        let nodeId = (0, util_1.generateUniqueID)();
        let node = {
            id: nodeId,
            type,
            data,
            inThreeD: this.inThreeD,
            beThreeD: this.beThreeD,
            inputs,
            effects: [],
            timeMap: this.timeMap,
            transformStat: null,
        };
        return node;
    }
    /** 编译单个像素输出层. */
    compilePixelLayer(layerData, siblingInputs) {
        let node = this.createRenderNode(RenderNodeType.PixelLayer, layerData, null);
        return this.compileRenderableLayer(layerData, [node], siblingInputs);
    }
    /** 编译单个音频层. */
    compileAudiolLayer(layerData) {
        let node = this.createRenderNode(RenderNodeType.AudioLayer, layerData, null);
        return node;
    }
    /** 编译单个像素输出层. */
    compileShapeLayer(layerData, siblingInputs) {
        let node = this.createRenderNode(RenderNodeType.ShapeLayer, layerData, null);
        return this.compileRenderableLayer(layerData, [node], siblingInputs);
    }
    /** 编译可渲染层. */
    compileRenderableLayer(layerData, inputs, siblingInputs) {
        // 将变换作为变换特效处理. 这样可以使得其保证特效处理的一致性.
        if (layerData.transform) {
            let effect = (0, transform_1.createTransformEffectFromLayerData)(layerData);
            inputs = this.compileEffects([effect], inputs, layerData);
        }
        // 链接父层的变换属性.
        if (layerData.parentId) {
            inputs = this.linkParentLayer(layerData, inputs);
        }
        // 编译特效.
        if (layerData.effects) {
            inputs = this.compileEffects(layerData.effects, inputs, layerData);
        }
        // 编译蒙版, 它作用于下方的最近的输入.
        if (layerData.isTrackMatte) {
            let contentLayerData = this.getNextLayer(layerData);
            if (contentLayerData.hasTrackMatte) {
                inputs = this.compileMaskEffect(layerData, contentLayerData, inputs, siblingInputs);
            }
            else {
                inputs = [];
            }
        }
        // 如果没有对应的蒙版图, 则可能不用渲染.
        if (layerData.hasTrackMatte) {
            let maskLayerData = this.getPreviousLayer(layerData);
            // 没有对应的蒙版层存在.
            if (!maskLayerData || !maskLayerData.isTrackMatte) {
                // 此两类蒙版在没有蒙版层存在时不需要渲染.
                if (['ALPHA', 'LUMAINANCE'].includes(layerData.trackMatteType)) {
                    inputs = [];
                }
            }
        }
        // 编译以进行颜色混合.
        if (inputs.length > 0 && layerData.blendingMode && !simple_webgl_1.SimpleWebGL.supportsBlendMode(simple_webgl_1.SimpleWebGLBlendMode[layerData.blendingMode])) {
            inputs = this.compileBlendingEffect(layerData, inputs, siblingInputs);
            // 已编译的同级节点全部作为底图输入混合特效.
            siblingInputs = [];
        }
        siblingInputs.push(...inputs);
        return siblingInputs;
    }
    /** 获取前一个层. */
    getPreviousLayer(layerData) {
        let index = this.siblingLayerDatas.findIndex(l => l.id === layerData.id);
        return index > 0 ? this.siblingLayerDatas[index - 1] : null;
    }
    /** 获取后一个层. */
    getNextLayer(layerData) {
        let index = this.siblingLayerDatas.findIndex(l => l.id === layerData.id);
        return index < this.siblingLayerDatas.length - 1 ? this.siblingLayerDatas[index + 1] : null;
    }
    // 链接到父层的变换属性到当前层.
    linkParentLayer(layerData, inputs) {
        let parentId = layerData.parentId;
        // 将父层的变换属性作为变换特效拷贝到当前层, 并放在自身变换的下面, 其他变换的上面.
        // 由于我们编译为渲染树后会破坏之前的
        while (parentId) {
            let parentLayerData = this.siblingLayerDatas.find(data => data.id === parentId);
            if (!parentLayerData) {
                break;
            }
            if (parentLayerData.transform) {
                let effect = (0, transform_1.createTransformEffectFromLayerData)(parentLayerData);
                // 父层只有 transform 属性发挥作用, opacity 不发挥作用.
                delete effect.opacity;
                inputs = this.compileEffects([effect], inputs, layerData);
            }
            parentId = parentLayerData.parentId;
        }
        return inputs;
    }
    /** 编译特效. */
    compileEffects(effectDatas, inputs, layerData) {
        for (let effectData of effectDatas) {
            let renderable = (0, all_1.isRenderableEffect)(effectData.type);
            switch (effectData.type) {
                // 如果是 tile 特效并且有超过一个输入, 才将其作为特效渲染.
                // 如果仅有一个输入, 则作为矩阵叠加.
                case 'tile':
                    if (inputs.length === 1) {
                        renderable = false;
                    }
                    break;
            }
            // 可渲染特效, 加入一个特效渲染任务以及一个帧缓存绘制步骤.
            if (renderable) {
                inputs = this.compileRenderableEffect(effectData, inputs);
            }
            // 不可渲染特效, 加入到节点的特效列表.
            else {
                // 拥有 shutterAngle 设置的 transform, 加入 motion blur 渲染步骤.
                // 变换属性需要累积到这个特效节点上, 从而让其能够捕获变换矩阵, 从而计算其微分.
                // 拥有文字动画的文本层的特效会在内部处理.
                let shouldCompileMotionBlur = effectData.type === 'transform'
                    && effectData.shutterAngle
                    && !(layerData.type === 'text' && layerData.animaters);
                if (shouldCompileMotionBlur) {
                    inputs = this.compileMotionBlur(effectData.shutterAngle, inputs);
                }
                // 将非渲染特效加入到渲染节点的特效列表.
                inputs.forEach(node => {
                    node.effects.push({
                        effect: effectData,
                        timeMap: this.timeMap,
                    });
                });
            }
        }
        return inputs;
    }
    /** 编译会实际产生绘制的特效. */
    compileRenderableEffect(effectData, inputs) {
        let effectInputCount = (0, all_1.getEffectInputCount)(effectData.type);
        switch (effectData.type) {
            // 如果是 tile 特效并且有超过一个输入, 才将其作为特效渲染.
            // 如果仅有一个输入, 则作为矩阵叠加.
            case 'displacementMap':
                let mapLayerId = effectData.displacementMapLayerId;
                let mapLayerData = this.siblingLayerDatas.find(l => l.id === mapLayerId);
                switch (mapLayerData.type) {
                    // 处理像素层.
                    case 'image':
                    case 'video':
                    case 'text':
                    case 'solid':
                        inputs = this.compilePixelLayer(mapLayerData, inputs);
                        break;
                    // 处理形状层.
                    case 'shape':
                        inputs = this.compileShapeLayer(mapLayerData, inputs);
                        break;
                    default:
                        throw new Error(`displacementMap Effect doesn't support "${mapLayerData.type}" layer as a map layer!`);
                }
                break;
        }
        // 无任何输入但是要求有输入, 或者输入数目不足, 此时不对其进行渲染.
        if (inputs.length < effectInputCount) {
            if (inputs.length === 0) {
                return inputs;
            }
        }
        // 通过纹理缓冲输入创建特效渲染节点.
        let effectNode = this.createRenderNode(RenderNodeType.Effect, effectData, inputs);
        return [effectNode];
    }
    /** 编译运动模糊. 多个相邻的运动模糊将会被合并. */
    compileMotionBlur(shutterAngle, inputs) {
        // 判断是否已经包含了运动模糊.
        let alreadyBeMotionBlurInput = inputs.length === 1
            && inputs[0].type === RenderNodeType.Effect
            && inputs[0].data.type === 'motionBlur';
        if (alreadyBeMotionBlurInput) {
            let data = inputs[0].data;
            data.shutterAngles.push(shutterAngle);
            return inputs;
        }
        else {
            let effect = {
                id: (0, util_1.generateUniqueID)(),
                name: 'Temp Motion Blur',
                type: 'motionBlur',
                shutterAngles: [shutterAngle],
            };
            return this.compileRenderableEffect(effect, inputs);
        }
    }
    /** 编译蒙版. */
    compileMaskEffect(layerData, contentLayerData, inputs, siblingInputs) {
        if (siblingInputs.length > 0) {
            // 对多个输入进行合并.
            if (inputs.length > 1) {
                inputs = this.compositeInputs(RenderNodeType.CompositeLayer, layerData, inputs);
            }
            let contentInput = siblingInputs.pop();
            inputs.push(contentInput);
            let tempMaskData = {
                id: (0, util_1.generateUniqueID)(),
                type: 'mask',
                name: 'Temp Mask',
                trackMatteType: contentLayerData.trackMatteType || aegl_default_values_1.EffectMaskDefaultValues.trackMatteType,
            };
            return [this.createRenderNode(RenderNodeType.Effect, tempMaskData, inputs)];
        }
        else {
            return [];
        }
    }
    /** 编译颜色混合. */
    compileBlendingEffect(layerData, inputs, siblingInputs) {
        // 对多个输入进行合并.
        if (inputs.length > 1) {
            inputs = this.compositeInputs(RenderNodeType.CompositeLayer, layerData, inputs);
        }
        // 需要将下方的层合并起来作为输入时, 创建一个临时的合成层将他们包裹.
        if (siblingInputs.length > 1) {
            let tempCompositeLayer = {
                id: (0, util_1.generateUniqueID)(),
                name: 'Temp Composite',
                type: 'composite',
            };
            siblingInputs = this.compositeInputs(RenderNodeType.CompositeLayer, tempCompositeLayer, siblingInputs);
        }
        if (siblingInputs.length > 0) {
            inputs.push(siblingInputs[0]);
        }
        let tempBlendData = {
            id: (0, util_1.generateUniqueID)(),
            type: 'blend',
            name: 'Temp Blend',
            blendingMode: layerData.blendingMode,
        };
        return [this.createRenderNode(RenderNodeType.Effect, tempBlendData, inputs)];
    }
    /** 编译调整层. */
    compileAdjustmentLayer(layerData, inputs) {
        if (layerData.effects) {
            inputs = this.compileEffects(layerData.effects, inputs, layerData);
        }
        return inputs;
    }
    /**
     * 编译合成层.
     * 注意如果合成层内仅包含调整层, 则整个合成层用于调整并且影响之下的图层.
     */
    compileCompositeLayer(compLayerData, siblingInputs) {
        let layerDatas = compLayerData.layers;
        let forAdjustment = this.isForAdjustment(compLayerData);
        let innerTimeMap = this.timeMap.mergeInnerLayer(compLayerData);
        // 合成层仅用于调整, 将当前的结果作为其输入, 此时其上的 effects 无效.
        if (forAdjustment) {
            siblingInputs = this.compileLayers(layerDatas, siblingInputs, innerTimeMap);
        }
        // 合成层会输出, 此时将其添加到当前的输出中.
        else {
            let inputs = this.compileLayers(layerDatas, [], innerTimeMap);
            let shouldComposite = this.mustCompositeInputs(compLayerData, inputs);
            let nodeType = shouldComposite ? RenderNodeType.CompositeLayer : RenderNodeType.CompositeLayer;
            inputs = this.compositeInputs(nodeType, compLayerData, inputs);
            siblingInputs = this.compileRenderableLayer(compLayerData, inputs, siblingInputs);
        }
        return siblingInputs;
    }
    /** 对于一个合成层, 是否必须将其绘制到一个纹理缓存之后再与下方的层合并. */
    mustCompositeInputs(compLayerData, inputs) {
        // 如果作为一个将被进行蒙版处理的层, 则将其合并作为输入.
        // 如果本身是蒙版层, 稍后会在编译特效时被合并.
        // 另外如果两个输入都是透明的, 那么其分别绘制到背景上和合成后再绘制到背景上的结果是不同, 必须做合成.
        if (inputs.length > 1
            && (compLayerData.hasTrackMatte
                || compLayerData.transform && compLayerData.transform.opacity !== undefined)) {
            return true;
        }
        // 如果有 layerStyle, 也必须做内部纹理缓存绘制处理.
        if (compLayerData.layerStyle || compLayerData.masks) {
            return true;
        }
        // 如果有特效, 需要将多个输入合并为一个时, 也会产生新的合并.
        // 在此跳过, 会于之后编译特效时自动处理.
        return false;
    }
    /** 合并多个输入为一个合成节点. */
    compositeInputs(nodeType, compLayerData, inputs) {
        let node = this.createRenderNode(nodeType, compLayerData, inputs);
        return [node];
    }
    /** 检查合成层是否单纯用于调整, 即不包含有任何绘制输入. */
    isForAdjustment(compLayerData) {
        let unPaintedLayerIds = this.getUnPaintedLayerIds(compLayerData.layers);
        return compLayerData.layers.every(layerData => {
            return layerData.type === 'adjustment'
                || layerData.type === 'camera'
                || layerData.type === 'empty'
                || layerData.type === 'audio'
                || layerData.type === 'composite' && this.isForAdjustment(layerData)
                || unPaintedLayerIds.has(layerData.id);
        });
    }
    /** 编译摄影机层, 其矩阵为最终投影变换矩阵, 不可和外部的矩阵叠加. */
    compileCameraLayer(layerData, inputs) {
        // 无任何输入时我们认为它是一个空输入, 也应当只有空输出.
        if (inputs.length === 0) {
            return inputs;
        }
        // 摄影机层和其他层不同, 它需要子输入.
        // 由层对象内部决定是否进行帧缓存处理.
        let node = this.createRenderNode(RenderNodeType.CameraLayer, layerData, inputs);
        // 链接父层.
        if (layerData.parentId) {
            node = this.linkParentLayer(layerData, [node])[0];
        }
        // 编译特效.
        if (layerData.effects) {
            node = this.compileEffects(layerData.effects, [node], layerData)[0];
        }
        return [node];
    }
}


/***/ }),

/***/ "./src/aegl/renderer/tree/effect-manager.ts":
/*!**************************************************!*\
  !*** ./src/aegl/renderer/tree/effect-manager.ts ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.EffectManager = void 0;
const base_manager_1 = __webpack_require__(/*! ./base-manager */ "./src/aegl/renderer/tree/base-manager.ts");
const compile_render_tree_1 = __webpack_require__(/*! ./compile-render-tree */ "./src/aegl/renderer/tree/compile-render-tree.ts");
const all_1 = __webpack_require__(/*! ../effects/all */ "./src/aegl/renderer/effects/all.ts");
const all_2 = __webpack_require__(/*! ../effects/all */ "./src/aegl/renderer/effects/all.ts");
/** 用于管理当前需要渲染的特效以及预加载的特效. */
class EffectManager extends base_manager_1.BaseManager {
    /** 从渲染节点过滤出可渲染的特效数据. */
    static filterEffectDatasFromRenderNodes(nodes) {
        let datas = [];
        for (let node of nodes) {
            if (node.type === compile_render_tree_1.RenderNodeType.Effect) {
                datas.push(node.data);
            }
            if (node.inputs) {
                datas.push(...EffectManager.filterEffectDatasFromRenderNodes(node.inputs));
            }
        }
        return datas;
    }
    /** 获得层数据中的可预加载资源的特效数据. */
    static filterRenderableEffectDatas(layerDatas) {
        let effectDatas = [];
        for (let layerData of layerDatas) {
            if (layerData.effects) {
                for (let effectData of layerData.effects) {
                    if ((0, all_2.isRenderableEffect)(effectData.type)) {
                        effectDatas.push(effectData);
                    }
                }
            }
            if (layerData.type === 'composite' && layerData.layers) {
                effectDatas.push(...this.filterRenderableEffectDatas(layerData.layers));
            }
        }
        return effectDatas;
    }
    /** 激活特效, 无行为. */
    active() { }
    /** 取消激活特效, 无行为. */
    deactive() { }
    /** 根据特效属性创建 effect 对象. */
    async create(effectData) {
        let EffectClass = (0, all_1.getEffectClass)(effectData.type);
        let effect = new EffectClass(this.renderer, effectData);
        await effect.ready;
        return effect;
    }
}
exports.EffectManager = EffectManager;


/***/ }),

/***/ "./src/aegl/renderer/tree/layer-manager.ts":
/*!*************************************************!*\
  !*** ./src/aegl/renderer/tree/layer-manager.ts ***!
  \*************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.LayerManager = void 0;
const image_1 = __webpack_require__(/*! ../layers/image */ "./src/aegl/renderer/layers/image.ts");
const text_1 = __webpack_require__(/*! ../layers/text */ "./src/aegl/renderer/layers/text.ts");
const audio_1 = __webpack_require__(/*! ../layers/audio */ "./src/aegl/renderer/layers/audio.ts");
const base_manager_1 = __webpack_require__(/*! ./base-manager */ "./src/aegl/renderer/tree/base-manager.ts");
const video_1 = __webpack_require__(/*! ../layers/video */ "./src/aegl/renderer/layers/video.ts");
const compile_render_tree_1 = __webpack_require__(/*! ./compile-render-tree */ "./src/aegl/renderer/tree/compile-render-tree.ts");
const camera_1 = __webpack_require__(/*! ../layers/camera */ "./src/aegl/renderer/layers/camera.ts");
const shape_1 = __webpack_require__(/*! ../layers/shape */ "./src/aegl/renderer/layers/shape.ts");
const solid_1 = __webpack_require__(/*! ../layers/solid */ "./src/aegl/renderer/layers/solid.ts");
const composite_1 = __webpack_require__(/*! ../layers/composite */ "./src/aegl/renderer/layers/composite.ts");
const video_per_frame_1 = __webpack_require__(/*! ../layers/video-per-frame */ "./src/aegl/renderer/layers/video-per-frame.ts");
/**
 * 用于管理当前需要渲染的层以及预加载的层.
 * 它会从 JSON 数据创建对应的层, 以及缓存这些层.
 */
class LayerManager extends base_manager_1.BaseManager {
    /** 从渲染节点过滤出可直接渲染的层数据. */
    static filterLayerDatasFromRenderNodes(nodes) {
        let datas = [];
        for (let node of nodes) {
            if ((0, compile_render_tree_1.isLayerRenderNodeType)(node.type)) {
                datas.push(node.data);
            }
            if (node.inputs) {
                datas.push(...LayerManager.filterLayerDatasFromRenderNodes(node.inputs));
            }
        }
        return datas;
    }
    /** 从原始层数据过滤出可加载资源的层数据. */
    static filterRenderableLayerDatas(layerDatas) {
        let filteredDatas = [];
        for (let data of layerDatas) {
            if (data.type === 'composite') {
                filteredDatas.push(...LayerManager.filterRenderableLayerDatas(data.layers));
            }
            else if (!['adjustment', 'empty'].includes(data.type)) {
                filteredDatas.push(data);
            }
        }
        return filteredDatas;
    }
    /** 激活层. */
    active(layer) {
        layer.active();
    }
    /** 取消激活层. */
    deactive(layer) {
        layer.deactive();
    }
    /** 根据层属性创建 Layer 对象. */
    async create(data) {
        let layer;
        switch (data.type) {
            case 'image':
                layer = new image_1.ImageLayer(this.renderer, data);
                break;
            case 'text':
                layer = new text_1.TextLayer(this.renderer, data);
                break;
            case 'audio':
                layer = new audio_1.AudioLayer(this.renderer, data);
                break;
            case 'video':
                if (this.renderer.project.mode === 'encoding') {
                    layer = new video_per_frame_1.VideoPerFrameLayer(this.renderer, data);
                }
                else {
                    layer = new video_1.VideoLayer(this.renderer, data);
                }
                break;
            case 'camera':
                layer = new camera_1.CameraLayer(this.renderer, data);
                break;
            case 'shape':
                layer = new shape_1.ShapeLayer(this.renderer, data);
                break;
            case 'solid':
                layer = new solid_1.SolidLayer(this.renderer, data);
                break;
            case 'composite':
                layer = new composite_1.CompositeLayer(this.renderer, data);
                break;
            default:
                throw new Error(`Can't render layers in type "${data.type}"!`);
        }
        await layer.ready;
        return layer;
    }
}
exports.LayerManager = LayerManager;


/***/ }),

/***/ "./src/aegl/renderer/tree/render-tree.ts":
/*!***********************************************!*\
  !*** ./src/aegl/renderer/tree/render-tree.ts ***!
  \***********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.RenderTree = void 0;
const compile_render_tree_1 = __webpack_require__(/*! ./compile-render-tree */ "./src/aegl/renderer/tree/compile-render-tree.ts");
const layer_manager_1 = __webpack_require__(/*! ./layer-manager */ "./src/aegl/renderer/tree/layer-manager.ts");
const effect_manager_1 = __webpack_require__(/*! ./effect-manager */ "./src/aegl/renderer/tree/effect-manager.ts");
const sampler_1 = __webpack_require__(/*! ../../../libs/webgl/sampler */ "./src/libs/webgl/sampler.ts");
const transform_status_1 = __webpack_require__(/*! ./transform-status */ "./src/aegl/renderer/tree/transform-status.ts");
const motion_blur_1 = __webpack_require__(/*! ../effects/motion-blur */ "./src/aegl/renderer/effects/motion-blur.ts");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
const paint_area_1 = __webpack_require__(/*! ../../../libs/area/paint-area */ "./src/libs/area/paint-area.ts");
const all_1 = __webpack_require__(/*! ../effects/all */ "./src/aegl/renderer/effects/all.ts");
const image_video_1 = __webpack_require__(/*! ../layers/image-video */ "./src/aegl/renderer/layers/image-video.ts");
const rect_area_1 = __webpack_require__(/*! ../../../libs/area/rect-area */ "./src/libs/area/rect-area.ts");
const text_1 = __webpack_require__(/*! ../layers/text */ "./src/aegl/renderer/layers/text.ts");
/** 空绘制, 指代一个没有绘制内容的绘制结果. */
const EmptyDrawResult = {
    mappedSamplers: [],
    paintArea: null,
};
/** 这个类用于根据渲染节点进行渲染, 以及处理层和特效对象的创建和注销. */
class RenderTree {
    sw;
    /** 当前项目. */
    project;
    /** 用于管理层对象. */
    layerManager;
    /** 用于管理特效对象. */
    effectManager;
    /** 用于当前阶段的渲染节点. */
    nodes;
    /** 当前时刻, 和 renderer 保持同步. */
    time = 0;
    /** 记录当前的渲染节点的安全的左侧时刻, 即, 在左侧越过该时刻会导致渲染更新. */
    startSafeTime = 0;
    /** 用于存储当前时刻的变换状态 */
    currentTransformStatusRecord = null;
    /** 用于存储前一时刻的变换状态 */
    previousTransformStatusRecord = null;
    constructor(renderer) {
        //this.renderer = renderer
        this.sw = renderer.sw;
        this.project = renderer.project;
        this.layerManager = new layer_manager_1.LayerManager(renderer);
        this.effectManager = new effect_manager_1.EffectManager(renderer);
    }
    /** 根据 id 移除一个层对象. */
    deleteLayerFromId(id) {
        this.layerManager.deleteFromId(id);
    }
    /** 根据 id 移除一个特效对象. */
    deleteEffectFromId(id) {
        this.effectManager.deleteFromId(id);
    }
    /**
     * 清除已准备好的所有层, 并且之后重建他们.
     * 由于资源已通过 ResourceLoader 对象缓存, 所以不会重复加载.
     */
    clear() {
        this.layerManager.clear();
        this.effectManager.clear();
        this.nodes = [];
    }
    /** 激活绘制对象. 注意应当在绘制一次之后再激活对象. */
    activeCurrentLayers() {
        this.layerManager.activeCurrent();
    }
    /** 取消激活绘制对象. */
    deactiveCurrentLayers() {
        this.layerManager.deactiveCrrrent();
    }
    /** 查询层是否正被渲染. */
    isLayerBeCurrent(layerData) {
        return this.layerManager.isCurrentId(layerData.id);
    }
    /** 更新当前时刻. */
    updateTime(time) {
        this.time = time;
    }
    /**
     * 更新当前需要渲染的层.
     * 注意这个时候 time 是从左侧或者右侧进入的时间, 可能是范围内任意时刻.
     * 而这个 startSafeTime 确实是左侧的起始时刻.
     */
    async updateLayerDatas(layerDatas, startSafeTime) {
        this.startSafeTime = startSafeTime;
        // 更新渲染节点.
        this.nodes = (0, compile_render_tree_1.compileToRenderTree)(layerDatas);
        // 更新以及确保所有的层和特效已创建和初始化.
        await this.layerManager.setCurrentDatas(layer_manager_1.LayerManager.filterLayerDatasFromRenderNodes(this.nodes));
        await this.effectManager.setCurrentDatas(effect_manager_1.EffectManager.filterEffectDatasFromRenderNodes(this.nodes));
        // 更新层的变换状态统计.
        this.updateTransformStat();
        // 由于渲染树更新, 所以变换状态过期.
        this.currentTransformStatusRecord = null;
    }
    /** 同步更新渲染树的层节点, 主要用于同步视频. */
    async syncLayersTime() {
        await this.syncLayerNodesTime(this.nodes);
    }
    /** 用于递归同步更新渲染树的层节点. */
    async syncLayerNodesTime(nodes) {
        let promises = [];
        for (let node of nodes) {
            switch (node.type) {
                case compile_render_tree_1.RenderNodeType.PixelLayer:
                case compile_render_tree_1.RenderNodeType.AudioLayer:
                    let layer = this.layerManager.getFromId(node.data.id);
                    let innerTimeMap = node.timeMap.mergeInnerLayer(node.data);
                    // 这个时间是内部时间在范围外部仍会有变化, 即可能获得负值.
                    let time = innerTimeMap.mapAllRange(this.time);
                    promises.push(layer.syncTime(time));
                    break;
            }
            if (node.inputs) {
                promises.push(this.syncLayerNodesTime(node.inputs));
            }
        }
        await Promise.all(promises);
    }
    /** 用于更新所有层的变换状态统计. */
    updateTransformStat() {
        this.updateSubTransformStat(this.nodes);
    }
    /** 用于更新子层的变换状态统计. */
    updateSubTransformStat(nodes) {
        for (let node of nodes) {
            if (!(0, compile_render_tree_1.isTransformableRenderNodeType)(node.type)) {
                continue;
            }
            switch (node.type) {
                // 特效节点需要变换状态统计.
                case compile_render_tree_1.RenderNodeType.Effect:
                    let effect = this.effectManager.getFromId(node.data.id);
                    effect.setTransformStat(node.transformStat);
                    break;
                // 像素节点需要变换状态统计.
                default:
                    let layer = this.layerManager.getFromId(node.data.id);
                    layer.setTransformStat(node.transformStat);
                    break;
            }
            if (node.inputs) {
                this.updateSubTransformStat(node.inputs);
            }
        }
    }
    /** 每一帧时绘制层和特效. */
    draw() {
        // 更新变换状态.
        this.generateRenderNodeTransformStatus();
        // 绘制节点.
        this.sw.clear();
        this.drawNodes(this.nodes, null);
    }
    /** 用于在渲染树不变时更新当前的变换状态, 会写入到 currentTransformStatusMap. */
    generateRenderNodeTransformStatus() {
        let { width: videoWidth, height: videoHeight } = this.project.data;
        this.previousTransformStatusRecord = null;
        // 1ms 到 50ms 内的状态有效.
        if (this.currentTransformStatusRecord) {
            let timeOffset = this.time - this.currentTransformStatusRecord.time;
            let absTimeOffset = Math.abs(timeOffset);
            if (absTimeOffset <= 0.05 && absTimeOffset >= 0.001) {
                this.previousTransformStatusRecord = this.currentTransformStatusRecord;
            }
        }
        // 如果不能从已生成的状态获得一个可对比的状态, 那么则新生成.
        if (!this.previousTransformStatusRecord) {
            // 尝试向前一帧生成一个变换状态, 如果超过安全时间则向后生成. 然后将其写入 previousTransformStatusMap.
            let timeOffset = 0.01;
            let previousTime = this.time - timeOffset;
            if (previousTime < this.startSafeTime) {
                timeOffset = -0.01;
            }
            this.previousTransformStatusRecord = new transform_status_1.TransformStatusRecord(this.nodes, this.time - timeOffset, videoWidth, videoHeight);
        }
        // 生成当前的变换状态.
        this.currentTransformStatusRecord = new transform_status_1.TransformStatusRecord(this.nodes, this.time, videoWidth, videoHeight);
    }
    /** 用于递归绘制渲染树的节点. 返回一个绘制影响的区域. */
    drawNodes(nodes, maskArea) {
        let areas = [];
        this.orderNodes(nodes);
        for (let node of nodes) {
            switch (node.type) {
                case compile_render_tree_1.RenderNodeType.PixelLayer:
                    areas.push(this.drawPixelNode(node, maskArea));
                    break;
                case compile_render_tree_1.RenderNodeType.ShapeLayer:
                    areas.push(this.drawShapeNode(node, maskArea));
                    break;
                case compile_render_tree_1.RenderNodeType.CameraLayer:
                    areas.push(this.drawCameraNode(node, maskArea));
                    break;
                case compile_render_tree_1.RenderNodeType.AudioLayer:
                    this.updateAudioNode(node);
                    break;
                case compile_render_tree_1.RenderNodeType.CompositeLayer:
                    areas.push(this.drawCompositeNode(node, maskArea));
                    break;
                case compile_render_tree_1.RenderNodeType.PlaceholderLayer:
                    areas.push(this.drawPlaceholderNode(node, maskArea));
                    break;
                case compile_render_tree_1.RenderNodeType.Effect:
                    areas.push(this.drawEffectNode(node, maskArea));
                    break;
            }
        }
        areas = areas.filter(v => v);
        return paint_area_1.PaintArea.union(areas);
    }
    /** 排序渲染节点. */
    orderNodes(nodes) {
        // 只有相邻的 3d 层才需要排序.
        nodes.sort((a, b) => {
            let deepA = this.getNodeDeep(a);
            let deepB = this.getNodeDeep(b);
            // 2D 层之间以及和 3D 层不进行排序.
            if (deepA === 0 || deepB === 0) {
                return 0;
            }
            return deepA - deepB;
        });
    }
    /** 获取节点的内部的首个层的深度. */
    getNodeDeep(node) {
        // 需要本身作为一个 3D 层, 否则不用排序.
        if (!node.beThreeD) {
            return 0;
        }
        let layerTransformStatus = this.currentTransformStatusRecord.get(node.id);
        if (!layerTransformStatus) {
            return 0;
        }
        // 获取该层的深度.
        let deep = layerTransformStatus.layerDeep;
        // 做适当的舍入以避免计算误差.
        let z = (0, ff_1.toDecimal)(deep, 4);
        return z;
    }
    /** 更新非像素层对应的节点. */
    updateAudioNode(node) {
        let time = node.timeMap.map(this.time);
        let layer = this.layerManager.getFromId(node.data.id);
        layer.setTime(time);
        layer.update();
    }
    /** 绘制像素层对应的节点. */
    drawPixelNode(node, maskArea) {
        this.updateLayerNode(node);
        let layer = this.layerManager.getFromId(node.data.id);
        layer.setMaskArea(maskArea);
        return layer.draw();
    }
    /** 更新像素层或者形状层对应的节点. */
    updateLayerNode(node) {
        let time = node.timeMap.mapAllRange(this.time);
        let layer = this.layerManager.getFromId(node.data.id);
        let status = this.currentTransformStatusRecord.get(node.id);
        layer.setTime(time);
        layer.setTransformStatus(status);
        layer.update();
        /** 更新运动模糊特效的参数. */
        if (layer instanceof text_1.TextLayer && node.data.motionBlur) {
            this.updateMotionBlurMatrix(layer, node);
        }
    }
    /** 绘制形状层对应的节点. */
    drawShapeNode(node, maskArea) {
        this.updateLayerNode(node);
        let layer = this.layerManager.getFromId(node.data.id);
        layer.setMaskArea(maskArea);
        return layer.draw();
    }
    /** 绘制摄影机层对应的节点. */
    drawCameraNode(node, maskArea) {
        let layer = this.layerManager.getFromId(node.data.id);
        this.updateLayerNode(node);
        let area = this.drawNodes(node.inputs, maskArea);
        return layer.draw(area);
    }
    /** 绘制合成层. */
    drawCompositeNode(node, maskArea) {
        let layer = this.layerManager.getFromId(node.data.id);
        this.updateLayerNode(node);
        let { mappedSamplers, paintArea } = this.drawSingleFrameInput(node, node.inputs, maskArea);
        layer.setMappedChannel(...mappedSamplers);
        layer.draw();
        layer.clearChannel();
        return paintArea;
    }
    /** 绘制合成层. */
    drawPlaceholderNode(node, maskArea) {
        return this.drawNodes(node.inputs, maskArea);
    }
    /** 绘制特效对应的节点. */
    drawEffectNode(node, maskArea) {
        let time = node.timeMap.map(this.time);
        let data = node.data;
        let inputs = node.inputs;
        let currentStatus = this.currentTransformStatusRecord.get(node.id);
        let effect = this.effectManager.getFromId(data.id);
        let isMaskEffect = data.type === 'mask';
        let drawResult;
        effect.setTime(time);
        effect.setTransformStatus(currentStatus);
        effect.update();
        effect.setMaskArea(maskArea);
        /** 更新运动模糊特效的参数. */
        if (effect instanceof motion_blur_1.MotionBlurEffect) {
            this.updateMotionBlurMatrix(effect, node);
        }
        if (isMaskEffect) {
            drawResult = this.drawMaskFrameInputs(node, inputs, maskArea);
        }
        else {
            drawResult = this.drawFrameInputs(node, inputs, maskArea);
        }
        let { mappedSamplers, paintArea } = drawResult;
        if (paintArea) {
            // 将输入作为参数送到特效的纹理. 结束后释放引用.
            effect.setMappedChannel(...mappedSamplers);
            let area = effect.draw(paintArea);
            effect.clearChannel();
            return area;
        }
        else {
            return null;
        }
    }
    /** 更新运动模糊特效的参数. */
    // 注意这里的运动模糊的计算和 AE 的不同之处:
    // 在 AE 的运动模糊渲染中, 运动模糊只作用于当前的这个运动, 外部的运动不会产生运动模糊累加.
    // 其相当于当前的运动的微分矩阵再左乘外部变换矩阵的非平移部分.
    // 但是在此我们假设只有一道运动模糊渲染, 并且外侧变换只包含或者不包含平移部分.
    updateMotionBlurMatrix(effectOrText, node) {
        let previousStatus = this.previousTransformStatusRecord.get(node.id);
        let currentStatus = this.currentTransformStatusRecord.get(node.id);
        // 计算在该段时间变换矩阵的近似微分.
        // 注意这里和 AE 的运动模糊渲染的区别, 这里将所有的外层运动合并后处理, 但是 AE 只处理当前层的运动.
        // 如果我们需要实现 AE 的运动模糊, 应当只计算此层自身的变换的微分.
        // 另外注意一个问题是我们进行纹理缓存渲染时基于整体的变换, 最后的渲染仍依赖外部的变换.
        let previousProjectionMatrix = previousStatus.getFlatProjectionMatrix();
        let currentProjectionMatrix = currentStatus.getFlatProjectionMatrix();
        let diffMatrix = currentProjectionMatrix.minus(previousProjectionMatrix);
        let timeOffset = this.currentTransformStatusRecord.time - this.previousTransformStatusRecord.time;
        let baseMotionMatrix = diffMatrix.multiplyScalar(1 / timeOffset);
        effectOrText.setBaseMotionMatrix(baseMotionMatrix);
    }
    /** 将其下的所有纹理缓存输入都准备好, 即将需要绘制入纹理缓存的输入全部绘制. */
    drawFrameInputs(node, inputs, maskArea) {
        let data = node.data;
        let inputCount = (0, all_1.getEffectInputCount)(data.type);
        let drawResult;
        // 多个输入的情况.
        if (inputCount > 1) {
            drawResult = this.drawMultipleFrameInputs(node, inputs, maskArea);
        }
        // 单个输入的情况.
        else if (inputCount === 1 && inputs.length > 0) {
            drawResult = this.drawSingleFrameInput(node, inputs, maskArea);
        }
        // 不需要输入, 但是有输入, 此时只获取输入的绘制区域.
        else if (inputCount === 0 && inputs.length > 0) {
            let { width, height } = this.project.data;
            let fullscreenArea = new rect_area_1.RectArea(0, 0, width, height);
            drawResult = {
                mappedSamplers: [],
                paintArea: fullscreenArea,
            };
        }
        // 无输入.
        else {
            drawResult = EmptyDrawResult;
        }
        return drawResult;
    }
    /** 绘制 Mask 的纹理缓存输入. */
    drawMaskFrameInputs(node, inputs, maskArea) {
        let [maskInput, contentInput] = inputs;
        // 首先绘制蒙版, 蒙版一般都会比原图小.
        let { mappedSamplers: [maskSampler], paintArea: maskPaintArea } = this.drawSingleFrameInput(node, [maskInput], maskArea);
        let paintArea = maskArea;
        // 裁剪区域无绘制, 返回空绘制.
        if (!maskPaintArea) {
            return EmptyDrawResult;
        }
        // 绘制所返回的区域都不计量所应用的 mask, 所以这里需要将内外 mask 区域求交.
        paintArea = paint_area_1.PaintArea.cross([paintArea, maskPaintArea]);
        // 绘制内容.
        let { mappedSamplers: [contentSampler], paintArea: contentPaintArea } = this.drawSingleFrameInput(node, [contentInput], maskArea);
        // 内容区域无绘制, 返回空绘制.
        if (!maskPaintArea) {
            return EmptyDrawResult;
        }
        // 绘制所返回的区域都不计量所应用的 mask, 所以这里需要将内外 mask 区域求交.
        paintArea = paint_area_1.PaintArea.cross([paintArea, contentPaintArea]);
        // 实际的 Mask 绘制会使用两个绘制区域的交集.
        let mappedSamplers = [maskSampler, contentSampler];
        return {
            mappedSamplers,
            paintArea: maskPaintArea,
        };
    }
    /** 绘制多个纹理缓存输入. */
    drawMultipleFrameInputs(node, inputs, maskArea) {
        let drawResults = [];
        for (let input of inputs) {
            drawResults.push(this.drawSingleFrameInput(node, [input], maskArea));
        }
        let mappedSamplers = drawResults.map(v => v.mappedSamplers).flat();
        let paintAreas = drawResults.map(v => v.paintArea).filter(v => v);
        let paintArea = paint_area_1.PaintArea.union(paintAreas);
        return {
            mappedSamplers,
            paintArea,
        };
    }
    /** 将输入渲染到一个纹理缓存上. */
    drawSingleFrameInput(node, inputs, maskArea) {
        let extractResult = this.extractMediaMappedSampler(node, inputs);
        if (extractResult) {
            extractResult.paintArea = paint_area_1.PaintArea.cross([extractResult.paintArea, maskArea]);
            return extractResult;
        }
        let effectType = node.data.type;
        let antialiasType;
        let params;
        // 如果是逐像素对齐特效, 那么使用临近采样即可.
        if (node.type === compile_render_tree_1.RenderNodeType.Effect && (0, all_1.isPixelToPixelEffect)(effectType)) {
            antialiasType = node.transformStat.getSuggestedAntialiasType();
            // 由于纹理缓存原样渲染到画布, 所以固定使用临近采样.
            params = { filter: sampler_1.SamplerFilter.Linear };
        }
        // 如果是全屏特效, 采样必须连续, 所以需要使用 Linear.
        // 如果是多重采样特效, 大多数时候都使用 Nearest 采样即可,
        // 其多重采样特性会削弱非线性采样产生的不连续.
        // 但是有一种情况特殊, 例如 drop shadow 的模糊半径为 0, 此时会原地采样,
        // 如果此时又遇到了外部的变换动画, 那么 Nearest 采样将会产生跳跃.
        else {
            antialiasType = false;
            // 由于纹理缓存大多数时候和最后采样差距不大, 所以固定使用线性采样.
            params = { filter: sampler_1.SamplerFilter.Linear };
        }
        // 如果需要渲染形状或者抗锯齿的内容, 则使用抗锯齿模式.
        let useMSAA = inputs.some(node => {
            return node.type === compile_render_tree_1.RenderNodeType.ShapeLayer
                || node.transformStat && node.transformStat.getSuggestedAntialiasType();
        });
        if (useMSAA) {
            antialiasType = true;
        }
        // 绘制内容到纹理缓存. 创建纹理缓存可以实时完成, 所以这里没有预先创建.
        // 这个纹理缓存总是全屏大小的, 这样可以充分使用已有的缓存.
        // 尽管看起来需要的纹理缓存数目和整个渲染树的 Frame 节点数目相同,
        // 但是实际上需要的纹理缓存数目等于渲染树的某条路径中的最大 Frame 节点数目.
        let textureFrame = this.sw.textureFrameManager.requestFull(antialiasType, 1, params);
        textureFrame.active();
        let paintArea = this.drawNodes(inputs, maskArea);
        textureFrame.deactive();
        let mappedSamplers = [textureFrame.getMappedSampler()];
        // 没有实际绘制内容时将绘制的纹理立即释放.
        if (!paintArea) {
            mappedSamplers.forEach(mappedSampler => mappedSampler.release());
            mappedSamplers = [];
        }
        return {
            mappedSamplers,
            paintArea,
        };
    }
    /** 不渲染而直接使用层的纹理并且进行映射. */
    extractMediaMappedSampler(node, inputs) {
        let effectData = node.data;
        // 多重采样特效如果直接输出纹理, 会降低其渲染效果.
        if ((0, all_1.isMultiSamplingEffect)(effectData.type)) {
            return null;
        }
        let isSinglePixelLayer = inputs.length === 1 && inputs[0].type === compile_render_tree_1.RenderNodeType.PixelLayer;
        if (!isSinglePixelLayer) {
            return null;
        }
        let layer = this.layerManager.getFromId(inputs[0].data.id);
        if (!(layer instanceof image_video_1.ImageVideoLayer)) {
            return null;
        }
        this.updateLayerNode(inputs[0]);
        // 注意这里不使用纹理缓存所设置的采样方式.
        // 因为需要它能平滑过渡到不使用此特效时的绘制结果.
        let { mappedSampler, paintArea } = layer.drawAsMappedSampler();
        if (!paintArea) {
            return null;
        }
        return {
            mappedSamplers: [mappedSampler],
            paintArea,
        };
    }
    /** 预创建层对象来加载资源. */
    async preloadResources(layerDatas, syncMode) {
        try {
            await this.layerManager.prepare(layer_manager_1.LayerManager.filterRenderableLayerDatas(layerDatas), syncMode);
            await this.effectManager.prepare(effect_manager_1.EffectManager.filterRenderableEffectDatas(layerDatas), syncMode);
        }
        catch (err) {
            console.warn(err);
        }
    }
}
exports.RenderTree = RenderTree;


/***/ }),

/***/ "./src/aegl/renderer/tree/transform-stat.ts":
/*!**************************************************!*\
  !*** ./src/aegl/renderer/tree/transform-stat.ts ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.generateNodeListTransformStat = exports.generateTransformStat = exports.TransformStat = void 0;
const compile_render_tree_1 = __webpack_require__(/*! ./compile-render-tree */ "./src/aegl/renderer/tree/compile-render-tree.ts");
const property_1 = __webpack_require__(/*! ../../property/property */ "./src/aegl/property/property.ts");
const sampler_1 = __webpack_require__(/*! ../../../libs/webgl/sampler */ "./src/libs/webgl/sampler.ts");
const all_1 = __webpack_require__(/*! ../effects/all */ "./src/aegl/renderer/effects/all.ts");
/** 标识当前一个时间段的变换是否包含了缩放, 旋转等的统计信息, 从而决定纹理的采样方式. */
class TransformStat {
    /** 是否进行了旋转, 如果旋转则应当在帧缓存绘制时启用多重采样.*/
    rotated;
    /** 是否有变换动画, 如果有的话则应当至少使用 Linear 类型采样. */
    hasAnimations;
    constructor(rotated = false, hasAnimations = false) {
        this.rotated = rotated;
        this.hasAnimations = hasAnimations;
    }
    /** 合并变换. */
    mergeTransformSelf(transform) {
        if (transform.rotation || transform.skew) {
            this.rotated = true;
        }
        for (let [key, value] of Object.entries(transform)) {
            if ((0, property_1.isPropertyValueBeKeyFrames)(value) && key !== 'opacity' && key !== 'shutterAngle') {
                this.hasAnimations = true;
                break;
            }
        }
    }
    /** 合并摄影机变换. */
    mergeCameraSelf() {
        // 摄影机的出现通常都意味着会进行各种动画.
        // 所以我们不再判断而直接将这些属性设置为 true.
        this.rotated = true;
        this.hasAnimations = true;
    }
    /** 拷贝. */
    clone() {
        return new TransformStat(this.rotated, this.hasAnimations);
    }
    /** 从多媒体资源或者特效的变换状态统计获得一个推荐的采样方式. */
    getSuggestedSamplingParameters() {
        // MipmapLinear 有一个小问题就是会让图像看起来有一些模糊, 所以一般仅在有动画时才启用.
        // 但是由于最终的渲染效果大小不一, 所以我们还是固定使用它.
        // 它的唯一缺点是渲染很小的视频时会有些模糊.
        let filter = sampler_1.SamplerFilter.MipmapLinear;
        return { filter };
    }
    /** 从变换状态统计获得是否推荐开启抗锯齿. */
    getSuggestedAntialiasType() {
        return this.rotated || this.hasAnimations;
    }
}
exports.TransformStat = TransformStat;
/** 当渲染树生成之后, 为其自动向下计算变换状态统计. */
function generateTransformStat(nodes) {
    generateNodeListTransformStat(nodes, new TransformStat);
}
exports.generateTransformStat = generateTransformStat;
/** 生成子变换属性. 此外还会对渲染树做微调. */
function generateNodeListTransformStat(nodes, outerStat) {
    for (let i = 0; i < nodes.length; i++) {
        let node = nodes[i];
        // 跳过音频层.
        if (!(0, compile_render_tree_1.isTransformableRenderNodeType)(node.type)) {
            continue;
        }
        // 合并特效上面的变换并且记录变换属性.
        // 此时 transform 已被合并到 effect transform.
        let stat = mergeEffectsTransformStat(node.effects, outerStat);
        switch (node.type) {
            case compile_render_tree_1.RenderNodeType.Effect:
                // 没有运动效果但是勾选了运动模糊非常常见, 此时我们将其移除.
                if (node.data.type === 'motionBlur' && !stat.hasAnimations) {
                    let inputs = node.inputs;
                    inputs.forEach(childNode => childNode.effects.push(...node.effects));
                    nodes.splice(i--, 1, ...inputs);
                    node.inputs = null;
                }
                break;
        }
        // 设置变换统计.
        node.transformStat = stat;
        // 递归生成子节点的变换属性.
        if (node.inputs) {
            let childStat = stat.clone();
            // 对于全屏特效, 不累计外部变换, 从初始状态重新开始累积.
            let reCollectTransform = node.type === compile_render_tree_1.RenderNodeType.Effect && (0, all_1.isFullscreenEffect)(node.data.type);
            if (reCollectTransform) {
                childStat = new TransformStat();
            }
            generateNodeListTransformStat(node.inputs, childStat);
        }
    }
}
exports.generateNodeListTransformStat = generateNodeListTransformStat;
/** 合并特效的变换状态统计. */
function mergeEffectsTransformStat(effects, outerStat) {
    let stat = outerStat.clone();
    for (let { effect } of effects) {
        switch (effect.type) {
            // 一般的变换层.
            case 'transform':
                stat.mergeTransformSelf(effect);
                break;
            // 摄影机层.
            case 'camera':
                stat.mergeCameraSelf();
                break;
        }
    }
    return stat;
}


/***/ }),

/***/ "./src/aegl/renderer/tree/transform-status.ts":
/*!****************************************************!*\
  !*** ./src/aegl/renderer/tree/transform-status.ts ***!
  \****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.TransformStatusRecord = exports.TransformStatus = void 0;
const compile_render_tree_1 = __webpack_require__(/*! ./compile-render-tree */ "./src/aegl/renderer/tree/compile-render-tree.ts");
const matrix4_1 = __webpack_require__(/*! ../../../libs/math/matrix4 */ "./src/libs/math/matrix4.ts");
const transform_1 = __webpack_require__(/*! ../../property/transform */ "./src/aegl/property/transform.ts");
const tile_1 = __webpack_require__(/*! ../../property/tile */ "./src/aegl/property/tile.ts");
const camera_1 = __webpack_require__(/*! ../../property/camera */ "./src/aegl/property/camera.ts");
const all_1 = __webpack_require__(/*! ../effects/all */ "./src/aegl/renderer/effects/all.ts");
const projection_1 = __webpack_require__(/*! ../../property/projection */ "./src/aegl/property/projection.ts");
const vector4_1 = __webpack_require__(/*! ../../../libs/math/vector4 */ "./src/libs/math/vector4.ts");
const paint_area_1 = __webpack_require__(/*! ../../../libs/area/paint-area */ "./src/libs/area/paint-area.ts");
const property_1 = __webpack_require__(/*! ../../property/property */ "./src/aegl/property/property.ts");
/** 绘制渲染树时, 从外到内累计变换状态. */
class TransformStatus {
    /** 视频宽. */
    videoWidth;
    /** 视频高. */
    videoHeight;
    /** 从外部累积而来的顶点坐标变换矩阵. */
    transformMatrix;
    /** 由 tile 产生的采样坐标变换矩阵. */
    samplingMatrix;
    /** 用于将像素坐标转为 -1~1 的 OpenGL 坐标. */
    projectionMatrix;
    /** 从外到内叠加的透明度. */
    opacity;
    /**
     * 获取变换将其大致放置的像素深度.
     * 会返回一个负值, 其绝对值代表着距离摄影机的垂直距离.
     * 仅当 3D 模式下存在, 2D 模式下固定为 0.
     */
    deep = 0;
    /** 所关联的层的像素深度. */
    layerDeep = 0;
    constructor(videoWidth, videoHeight, transformMatrix = matrix4_1.Matrix4.I, opacity = 1, samplingMatrix = matrix4_1.Matrix4.I, projectionMatrix = (0, projection_1.get2DProjectionMatrix)(videoWidth, videoHeight)) {
        this.transformMatrix = transformMatrix;
        this.samplingMatrix = samplingMatrix;
        this.projectionMatrix = projectionMatrix;
        this.opacity = opacity;
        this.videoWidth = videoWidth;
        this.videoHeight = videoHeight;
    }
    /** 拷贝. */
    clone() {
        return new TransformStatus(this.videoWidth, this.videoHeight, this.transformMatrix, this.opacity, this.samplingMatrix, this.projectionMatrix);
    }
    /** 仅拷贝 opacity, 其他重置为默认. */
    cloneOpacity() {
        return new TransformStatus(this.videoWidth, this.videoHeight, matrix4_1.Matrix4.I, this.opacity);
    }
    /** 设置深度值. */
    setDeep(deep) {
        this.deep = deep;
    }
    /** 设置所关联层的深度值. */
    setLayerDeep(deep) {
        this.layerDeep = deep;
    }
    /** 设置投影矩阵. */
    setProjectionMatrix(projectionMatrix) {
        this.projectionMatrix = projectionMatrix;
    }
    /** 合并观察矩阵. */
    mergeLookAtMatrix(lookAtMatrix) {
        this.transformMatrix = lookAtMatrix.multiply(this.transformMatrix);
    }
    /** 合并 transform 属性值. */
    mergeTransformValues(values) {
        let transform = (0, transform_1.getTransformFromValues)(values);
        this.mergeTransformMatrix(transform);
        this.mergeOpacity(values.opacity / 100);
    }
    /** 合并一个内部的变换矩阵. */
    mergeTransformMatrix(matrix) {
        this.transformMatrix = this.transformMatrix.multiply(matrix);
    }
    /** 合并一个内部的采样变换矩阵. */
    mergeSamplingMatrix(matrix) {
        this.samplingMatrix = this.samplingMatrix.multiply(matrix);
    }
    /** 合并透明度. */
    mergeOpacity(opacity) {
        this.opacity *= opacity;
    }
    /** 是否为 3D 投影. */
    is3DProjection() {
        return (0, projection_1.is3DProjectionMatrix)(this.projectionMatrix);
    }
    /** 获取坐标经过了将坐标进行变换和投影, 然后再通过投影恢复到像素坐标产生的最终坐标. */
    getProjectedPaintArea(numCoords) {
        let coords = (0, projection_1.getFinalProjectedCoords)(numCoords, this.transformMatrix, this.projectionMatrix, this.videoWidth, this.videoHeight);
        return paint_area_1.PaintArea.fromCoords(coords);
    }
    /** 获取坐标经过了将坐标进行变换和投影, 然后再通过投影恢复到像素坐标产生的最终坐标. */
    getProjectedPaintAreaAfterSubTransform(numCoords, subTransform) {
        let coords = (0, projection_1.getFinalProjectedCoords)(numCoords, this.transformMatrix.multiply(subTransform), this.projectionMatrix, this.videoWidth, this.videoHeight);
        return paint_area_1.PaintArea.fromCoords(coords);
    }
    /**
     * 根据变换矩阵以及投影矩阵计算最终的绘制像素坐标的平面变换.
     * 产生的矩阵可以用于处理例如阴影偏移等二维向量, 将其转为需要最终绘制的投影参数.
     */
    getFlatProjectionMatrix() {
        return (0, projection_1.getFlatProjectionMatrix)(this.transformMatrix, this.projectionMatrix, this.videoWidth, this.videoHeight);
    }
    /**
     * 对应用于原始坐标的内部变换进行处理, 将其转为应用于最终的投影像素坐标的平面变换.
     * 注意返回矩阵仅包含原先的变换在另一个线性空间的等价变换, 不包含外部的变换.
     */
    projectMatrix(innerTransform) {
        // 以 drop shadow 的偏移为例:
        // 这个阴影偏移的变换是在原始的坐标系内完成的,
        // 但是现在之前的绘制步骤中已经处理了所有的外部变换,
        // 所以我们将这个阴影变换转到当前的坐标系内:
        // 设原始的坐标为 C, 基底为 B, 外部变换为 M, 阴影变换为 S,
        // 经过外部变换之后的坐标为 C', 对应的阴影变换为 S', 则:
        // M * C = C'
        // M * S * C = S' * C' = S' * M * C
        // M * S = S' * M
        // S' = M * S * M^-1
        let flatProjectionMatrix = this.getFlatProjectionMatrix();
        let flatProjectionMatrixInverse = flatProjectionMatrix.inverse();
        return flatProjectionMatrix.multiply(innerTransform).multiply(flatProjectionMatrixInverse);
    }
    /**
     * 将矢量进行投影, 返回投影产生的像素坐标.
     * 它实际上是 `projectMatrix` 方法的一个特例.
     */
    projectVector(vector) {
        let flatProjectionMatrix = this.getFlatProjectionMatrix();
        let v4 = flatProjectionMatrix.transfer4(new vector4_1.Vector4(...vector.xy, 0, 0));
        return new vector4_1.Vector2(...v4.xy).multiplyScalarSelf(this.getDeepScaling());
    }
    /** 获取因为深度信息而产生的缩放比. */
    getDeepScaling() {
        if (this.layerDeep === 0) {
            return 1;
        }
        else {
            return this.deep / this.layerDeep;
        }
    }
}
exports.TransformStatus = TransformStatus;
/** 由渲染节点的变换状态组成的记录. */
class TransformStatusRecord {
    /** 变换状态所属的时刻. */
    time;
    /** 用于保存所有子变换的映射表. */
    map = new Map();
    /** 视频宽. */
    videoWidth;
    /** 视频高. */
    videoHeight;
    /** 初始状态, 即 2D 模式下无任何变动时的状态. */
    initialStatus;
    /** 最近处理过的层深度. */
    justProcessedLayerDeep = 0;
    constructor(nodes, treeTime, videoWidth, videoHeight) {
        this.time = treeTime;
        this.videoWidth = videoWidth;
        this.videoHeight = videoHeight;
        this.generateInitialStatus();
        this.generateNodeListStatus(nodes, this.initialStatus, (0, camera_1.getDefaultCameraLookAtMatrix)(videoWidth, videoHeight), (0, camera_1.getDefaultCameraProjectionMatrix)(videoWidth, videoHeight));
    }
    /** 根据 id 获取变换状态记录. */
    get(id) {
        return this.map.get(id);
    }
    /** 获得初始变换状态. */
    generateInitialStatus() {
        this.initialStatus = Object.seal(new TransformStatus(this.videoWidth, this.videoHeight));
    }
    /** 生成渲染节点列表的变换状态. */
    generateNodeListStatus(nodes, parentStatus, cameraLookAtMatrix, cameraProjectionMatrix) {
        for (let node of nodes) {
            // 跳过音频层.
            if (!(0, compile_render_tree_1.isTransformableRenderNodeType)(node.type)) {
                continue;
            }
            this.generateNodeStatus(node, parentStatus, cameraLookAtMatrix, cameraProjectionMatrix);
        }
    }
    /** 生成渲染节点的变换状态. */
    generateNodeStatus(node, parentStatus, cameraLookAtMatrix, cameraProjectionMatrix) {
        let selfStatus = parentStatus.clone();
        let childStatus;
        // 合并当前节点的变换.
        this.mergeTransformTypeEffects(node, selfStatus);
        // 如何理解作用于摄影机层上的变换?
        // 外部作用于摄影机以及物体的变换相当于线性变换整个场景, 不影响最终投影效果.
        // 单独作用于摄影机的变换, 等价于对物体做逆变换.
        if (node.type === compile_render_tree_1.RenderNodeType.CameraLayer) {
            childStatus = parentStatus.clone();
        }
        else {
            childStatus = selfStatus.clone();
        }
        switch (node.type) {
            // 摄影机层, 合并层本身的变换.
            case compile_render_tree_1.RenderNodeType.CameraLayer:
                let data = node.data;
                let time = node.timeMap.map(this.time);
                cameraLookAtMatrix = (0, camera_1.getCameraLayerLookAtMatrix)(data, time, selfStatus.transformMatrix);
                cameraProjectionMatrix = (0, camera_1.getCameraLayerProjectionMatrix)(data, time, this.videoWidth, this.videoHeight);
                break;
        }
        // 存储当前节点的变换状态, 可能会合并摄影机变换和投影矩阵.
        let threeD = node.inThreeD;
        if (threeD) {
            selfStatus.mergeLookAtMatrix(cameraLookAtMatrix);
            selfStatus.setProjectionMatrix(cameraProjectionMatrix);
        }
        this.map.set(node.id, selfStatus);
        // 递归生成子节点的变换状态.
        if (node.inputs) {
            switch (node.type) {
                case compile_render_tree_1.RenderNodeType.Effect:
                    // 对于全屏特效, 将特效需要的输入渲染到一个满屏的纹理上, 然后作为输入.
                    if ((0, all_1.isFullscreenEffect)(node.data.type)) {
                        childStatus = this.initialStatus.clone();
                    }
                    // 对于逐像素对齐渲染到纹理缓存节点, 内部的渲染将会合并外部所有变换.
                    // 但是 opacity 除外, opacity 会在该特效渲染节点处理.
                    // 这样内部的 drop shadow 等会按照原始的透明度生成阴影.
                    else {
                        childStatus.opacity = 1;
                    }
                    break;
                case compile_render_tree_1.RenderNodeType.CompositeLayer:
                    // 合成层的变换作用于内部, 但是透明度作用于自身.
                    childStatus.opacity = 1;
                    break;
            }
            // 生成子节点的变换.
            this.generateNodeListStatus(node.inputs, childStatus, cameraLookAtMatrix, cameraProjectionMatrix);
        }
        this.generateDeeps(node, selfStatus);
    }
    /** 合并变换特效. */
    mergeTransformTypeEffects(node, status) {
        let effects = node.effects;
        let tileTransformMatrix = null;
        // 变换特效从上到下作用于原始图像, 而我们的矩阵从外向内叠加, 所以这里从下方开始.
        for (let i = effects.length - 1; i >= 0; i--) {
            let { effect, timeMap } = effects[i];
            let time = timeMap.map(this.time);
            switch (effect.type) {
                case 'transform':
                    let values = (0, transform_1.getTransformValues)(effect, time);
                    status.mergeTransformValues(values);
                    break;
                case 'tile':
                    let { transformMatrix, samplingMatrix } = (0, tile_1.getTileMatrixes)(effect, time, this.videoWidth, this.videoHeight);
                    // 注意这里 tile 生成的顶点变换矩阵被乘在最内部, 即先于其他变换作用.
                    tileTransformMatrix = tileTransformMatrix ? tileTransformMatrix.multiply(transformMatrix) : transformMatrix;
                    status.mergeSamplingMatrix(samplingMatrix);
                    break;
            }
        }
        // 合并 tile 矩阵到变换矩阵.
        if (tileTransformMatrix) {
            status.mergeTransformMatrix(tileTransformMatrix);
        }
    }
    /** 计算深度值. */
    generateDeeps(node, status) {
        // 3D 节点, 更新其深度值.
        if (!node.inThreeD) {
            return;
        }
        let layerTransform = node.data.transform;
        let anchoroPint;
        if (layerTransform && layerTransform.anchorPoint) {
            anchoroPint = (0, property_1.getPropertyValue)(layerTransform.anchorPoint, this.time);
        }
        else {
            anchoroPint = [this.videoWidth / 2, this.videoHeight / 2, 0];
        }
        let deep = this.getLayerDeep(status.transformMatrix, anchoroPint);
        status.setDeep(deep);
        if ((0, compile_render_tree_1.isRenderableLayeRenderNodeType)(node.type)) {
            status.setLayerDeep(deep);
            this.justProcessedLayerDeep = deep;
        }
        else {
            status.setLayerDeep(this.justProcessedLayerDeep);
        }
    }
    /**
     * 获取变换将其大致放置的像素深度.
     * 会返回一个负值, 其绝对值代表着距离摄影机的垂直距离.
     */
    getLayerDeep(transformMatrix, anchorPoint) {
        let transferedAnchorPoint = transformMatrix.transfer3(new vector4_1.Vector3(...anchorPoint));
        return transferedAnchorPoint.z;
    }
}
exports.TransformStatusRecord = TransformStatusRecord;


/***/ }),

/***/ "./src/aegl/shaders/blends/all.ts":
/*!****************************************!*\
  !*** ./src/aegl/shaders/blends/all.ts ***!
  \****************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.getBlendFragCode = void 0;
const overlay_frag_1 = __webpack_require__(/*! ./overlay.frag */ "./src/aegl/shaders/blends/overlay.frag");
const multiply_frag_1 = __webpack_require__(/*! ./multiply.frag */ "./src/aegl/shaders/blends/multiply.frag");
const screen_frag_1 = __webpack_require__(/*! ./screen.frag */ "./src/aegl/shaders/blends/screen.frag");
const difference_frag_1 = __webpack_require__(/*! ./difference.frag */ "./src/aegl/shaders/blends/difference.frag");
// 参考:
// https://github.com/jamieowen/glsl-blend
// https://www.w3.org/TR/compositing-1/#blendinghardlight
/** 进行混合的着色器代码. */
const BlendingModeFragCodeMap = {
    MULTIPLY: multiply_frag_1.default,
    SCREEN: screen_frag_1.default,
    OVERLAY: overlay_frag_1.default,
    DIFFERENCE: difference_frag_1.default,
};
/**
 * 用于进行颜色混合绘制.
 * 由于 ToDraw 对象的扩展的可能性非常大, 例如顶点处理, 蒙版和裁剪处理等.
 * 所以这里只提供一个简单的函数用于获取着色代码. 而不提供一个类供着色.
 */
function getBlendFragCode(mode) {
    let fragCode = BlendingModeFragCodeMap[mode];
    if (!fragCode) {
        throw new Error(`Please config fragment codes for blending mode "${mode}"!`);
    }
    return fragCode;
}
exports.getBlendFragCode = getBlendFragCode;


/***/ }),

/***/ "./src/aegl/shaders/blends/difference.frag":
/*!*************************************************!*\
  !*** ./src/aegl/shaders/blends/difference.frag ***!
  \*************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ("#version 300 es\n#ifdef GL_ES\nprecision mediump float;\n#endif\nin vec2 fTextureCoord;\nout vec4 fragColor;\nuniform sampler2D iChannel[2];\nuniform mat4 iChannelMap[2];\nvec4 getFragColor() {\nvec2 textureCoord0 = (iChannelMap[0] * vec4(fTextureCoord, 0, 1)).xy;\nvec2 textureCoord1 = (iChannelMap[1] * vec4(fTextureCoord, 0, 1)).xy;\nvec4 source = texture(iChannel[0], textureCoord0);\nvec4 dest = texture(iChannel[1], textureCoord1);\nreturn dest * (1.0 - source.a) + abs(dest * source.a - source);\n}\nvoid main() {\nfragColor = getFragColor();\n}\n");

/***/ }),

/***/ "./src/aegl/shaders/blends/multiply.frag":
/*!***********************************************!*\
  !*** ./src/aegl/shaders/blends/multiply.frag ***!
  \***********************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ("#version 300 es\n#ifdef GL_ES\nprecision mediump float;\n#endif\nin vec2 fTextureCoord;\nout vec4 fragColor;\nuniform sampler2D iChannel[2];\nuniform mat4 iChannelMap[2];\nvec4 getFragColor() {\nvec2 textureCoord0 = (iChannelMap[0] * vec4(fTextureCoord, 0, 1)).xy;\nvec2 textureCoord1 = (iChannelMap[1] * vec4(fTextureCoord, 0, 1)).xy;\nvec4 source = texture(iChannel[0], textureCoord0);\nvec4 dest = texture(iChannel[1], textureCoord1);\nreturn dest * (1.0 - source.a) + dest * source;\n}\nvoid main() {\nfragColor = getFragColor();\n}\n");

/***/ }),

/***/ "./src/aegl/shaders/blends/overlay.frag":
/*!**********************************************!*\
  !*** ./src/aegl/shaders/blends/overlay.frag ***!
  \**********************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ("#version 300 es\n#ifdef GL_ES\nprecision mediump float;\n#endif\nin vec2 fTextureCoord;\nout vec4 fragColor;\nuniform sampler2D iChannel[2];\nuniform mat4 iChannelMap[2];\nvec4 getFragColor() {\nvec2 textureCoord0 = (iChannelMap[0] * vec4(fTextureCoord, 0, 1)).xy;\nvec2 textureCoord1 = (iChannelMap[1] * vec4(fTextureCoord, 0, 1)).xy;\nvec4 source = texture(iChannel[0], textureCoord0);\nvec4 dest = texture(iChannel[1], textureCoord1);\nreturn source.a > 0.5\n? dest * (1.0 - source.a) + dest * source\n: dest * (1.0 - source.a) + (dest * source.a + source - dest * source);\n}\nvoid main() {\nfragColor = getFragColor();\n}\n");

/***/ }),

/***/ "./src/aegl/shaders/blends/screen.frag":
/*!*********************************************!*\
  !*** ./src/aegl/shaders/blends/screen.frag ***!
  \*********************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ("#version 300 es\n#ifdef GL_ES\nprecision mediump float;\n#endif\nin vec2 fTextureCoord;\nout vec4 fragColor;\nuniform sampler2D iChannel[2];\nuniform mat4 iChannelMap[2];\nvec4 getFragColor() {\nvec2 textureCoord0 = (iChannelMap[0] * vec4(fTextureCoord, 0, 1)).xy;\nvec2 textureCoord1 = (iChannelMap[1] * vec4(fTextureCoord, 0, 1)).xy;\nvec4 source = texture(iChannel[0], textureCoord0);\nvec4 dest = texture(iChannel[1], textureCoord1);\nreturn dest * (1.0 - source.a) + (dest * source.a + source - dest * source);\n}\nvoid main() {\nfragColor = getFragColor();\n}\n");

/***/ }),

/***/ "./src/aegl/shaders/effects/bulge.frag":
/*!*********************************************!*\
  !*** ./src/aegl/shaders/effects/bulge.frag ***!
  \*********************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ("#version 300 es\n#ifdef GL_ES\nprecision mediump float;\n#endif\nin vec4 fRawCoord;\nin vec2 fTextureCoord;\nout vec4 fragColor;\nuniform vec2 iResolution;\nuniform vec2 iVideoResolution;\nuniform sampler2D iChannel[1];\nuniform mat4 iChannelMap[1];\nuniform float iOpacity;\nuniform float effectOpacity;\nuniform float horizontalRadius;\nuniform float verticalRadius;\nuniform vec2 bulgeCenter;\nuniform float bulgeHeight;\nfloat bulgeNumber(float x, float height) {\nreturn 1.0 / (1.0 + (1.0 - x) * height);\n}\nvec2 bulgeCoord(vec2 coord, float height) {\nfloat r = length(coord);\nreturn coord * bulgeNumber(r, height);\n}\nvec4 getFragColor() {\nvec2 maxRadius = vec2(horizontalRadius, verticalRadius);\nvec2 origin = bulgeCenter;\nvec2 coord = vec2(fRawCoord.x, fRawCoord.y) - origin;\nvec2 coordRelative = coord / maxRadius;\nvec2 newCoord = origin + maxRadius * bulgeCoord(coordRelative, bulgeHeight);\nvec2 mappedTextureCoord = newCoord / iVideoResolution;\nmappedTextureCoord.y = 1.0 - mappedTextureCoord.y;\nmappedTextureCoord = (iChannelMap[0] * vec4(mappedTextureCoord, 0, 1)).xy;\nvec4 color = texture(iChannel[0], mappedTextureCoord);\nvec2 textureCoord = (iChannelMap[0] * vec4(fTextureCoord, 0, 1)).xy;\nvec4 inputColor = texture(iChannel[0], textureCoord);\ncolor = mix(inputColor, color, effectOpacity);\ncolor *= iOpacity;\nreturn color;\n}\nvoid main() {\nfragColor = getFragColor();\n}\n");

/***/ }),

/***/ "./src/aegl/shaders/effects/directional-blur.frag":
/*!********************************************************!*\
  !*** ./src/aegl/shaders/effects/directional-blur.frag ***!
  \********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ("#version 300 es\n#ifdef GL_ES\nprecision mediump float;\n#endif\nin vec2 fTextureCoord;\nout vec4 fragColor;\nuniform vec2 iResolution;\nuniform vec2 iVideoResolution;\nuniform sampler2D iChannel[1];\nuniform mat4 iChannelMap[1];\nuniform float iOpacity;\nuniform float effectOpacity;\nuniform mat4 iSamplingTransform;\nuniform vec2 blurVector;\nuniform int samplingCount;\nuniform bool repeatEdgePixels;\nfloat seedRandom2(vec2 v) {\nreturn fract(sin(dot(v, vec2(12.9898, 78.233))) * 43758.5453);\n}\nfloat noise2(vec2 v) {\nvec2 i = floor(v);\nvec2 f = fract(v);\nvec2 u = f * f * (3.0 - 2.0 * f);\nfloat a = seedRandom2(i);\nfloat b = seedRandom2(i + vec2(1, 0));\nfloat c = seedRandom2(i + vec2(0, 1));\nfloat d = seedRandom2(i + vec2(1, 1));\nreturn mix(a, b, u.x) +\n(c - a) * u.y * (1.0 - u.x) +\n(d - b) * u.x * u.y;\n}\nfloat stepRange(float value, float minValue, float maxValue) {\nfloat diffToCenter = abs(value - (minValue + maxValue) / 2.0);\nfloat halfRange = (maxValue - minValue) / 2.0;\nreturn 1.0 - step(halfRange, diffToCenter);\n}\nvec4 sampling(sampler2D sampler, vec2 textureCoord) {\nvec4 color = texture(sampler, textureCoord);\nif (!repeatEdgePixels) {\ncolor *= stepRange(textureCoord.x, 0.0, 1.0) * stepRange(textureCoord.y, 0.0, 1.0);\n}\nreturn color;\n}\nvec4 motionSampling(sampler2D sampler, vec2 textureCoord, vec2 textureMotionV, int sampleCount, float frequency) {\nvec4 totalColor = vec4(0);\nfloat noiseValue = noise2(gl_FragCoord.xy * frequency);\nfor (int i = 0; i < sampleCount; i++) {\nfloat rate = (float(i) + noiseValue) / float(sampleCount);\nvec2 coord = textureCoord + rate * textureMotionV;\nvec4 color = sampling(sampler, coord);\ntotalColor += color;\n}\nreturn totalColor / float(sampleCount);\n}\nvec4 getFragColor() {\nvec2 textureMotionV = blurVector / iVideoResolution;\ntextureMotionV.y = -textureMotionV.y;\ntextureMotionV = (iSamplingTransform * vec4(textureMotionV, 0, 0)).xy;\ntextureMotionV = (iChannelMap[0] * vec4(textureMotionV, 0, 0)).xy;\nvec2 textureCoord = (iChannelMap[0] * vec4(fTextureCoord, 0, 1)).xy;\nvec4 color = motionSampling(iChannel[0], textureCoord, textureMotionV, samplingCount, 2.0);\nvec4 inputColor = texture(iChannel[0], textureCoord);\ncolor = mix(inputColor, color, effectOpacity);\ncolor *= iOpacity;\nreturn color;\n}\nvoid main() {\nfragColor = getFragColor();\n}\n");

/***/ }),

/***/ "./src/aegl/shaders/effects/displacement-map.frag":
/*!********************************************************!*\
  !*** ./src/aegl/shaders/effects/displacement-map.frag ***!
  \********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ("#version 300 es\n#ifdef GL_ES\nprecision mediump float;\n#endif\nin vec2 fTextureCoord;\nout vec4 fragColor;\nuniform vec2 iResolution;\nuniform vec2 iVideoResolution;\nuniform sampler2D iChannel[2];\nuniform mat4 iChannelMap[2];\nuniform float iOpacity;\nuniform float effectOpacity;\nuniform vec2 \t maxDisplacement;\nvec4 getFragColor() {\nvec2 textureCoord0 = (iChannelMap[0] * vec4(fTextureCoord, 0, 1)).xy;\nvec2 textureCoord1 = (iChannelMap[1] * vec4(fTextureCoord, 0, 1)).xy;\nvec4 displacementColor = texture(iChannel[1], textureCoord1);\nfloat luminance = 0.299 * displacementColor.r + 0.587 * displacementColor.g + 0.114 * displacementColor.b;\nvec2 displacement = (2.0 * luminance - 1.0) * maxDisplacement / iVideoResolution;\ndisplacement.y = - displacement.y;\nvec2 displacedTextureCoord = textureCoord0 + displacement;\nvec4 color = texture(iChannel[0], displacedTextureCoord);\nvec4 inputColor = texture(iChannel[0], textureCoord0);\ncolor = mix(inputColor, color, effectOpacity);\ncolor *= iOpacity;\nreturn color;\n}\nvoid main() {\nfragColor = getFragColor();\n}\n");

/***/ }),

/***/ "./src/aegl/shaders/effects/drop-shadow-blend.frag":
/*!*********************************************************!*\
  !*** ./src/aegl/shaders/effects/drop-shadow-blend.frag ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ("#version 300 es\n#ifdef GL_ES\nprecision mediump float;\n#endif\nin vec2 fTextureCoord;\nout vec4 fragColor;\nuniform vec2 iResolution;\nuniform vec2 iVideoResolution;\nuniform sampler2D iChannel[2];\nuniform mat4 iChannelMap[2];\nuniform float iOpacity;\nuniform float effectOpacity;\nuniform float fillOpacity;\nvec4 getFragColor() {\nvec2 textureCoord0 = (iChannelMap[0] * vec4(fTextureCoord, 0, 1)).xy;\nvec2 textureCoord1 = (iChannelMap[1] * vec4(fTextureCoord, 0, 1)).xy;\nvec4 color = texture(iChannel[0], textureCoord0);\nvec4 shadowColor = texture(iChannel[1], textureCoord1);\ncolor *= fillOpacity;\ncolor = shadowColor * (1.0 - color.a) + color;\nvec4 inputColor = texture(iChannel[0], textureCoord0);\ncolor = mix(inputColor, color, effectOpacity);\ncolor *= iOpacity;\nreturn color;\n}\nvoid main() {\nfragColor = getFragColor();\n}\n");

/***/ }),

/***/ "./src/aegl/shaders/effects/drop-shadow.frag":
/*!***************************************************!*\
  !*** ./src/aegl/shaders/effects/drop-shadow.frag ***!
  \***************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ("#version 300 es\n#ifdef GL_ES\nprecision mediump float;\n#endif\nin vec2 fTextureCoord;\nout vec4 fragColor;\nuniform vec2 iResolution;\nuniform vec2 iVideoResolution;\nuniform sampler2D iChannel[1];\nuniform mat4 iChannelMap[1];\nuniform float iOpacity;\nuniform vec4 shadowColor;\nuniform mat4 iSamplingTransform;\nuniform vec2 blurRadius;\nfloat stepRange(float value, float minValue, float maxValue) {\nfloat diffToCenter = abs(value - (minValue + maxValue) / 2.0);\nfloat halfRange = (maxValue - minValue) / 2.0;\nreturn 1.0 - step(halfRange, diffToCenter);\n}\nvec4 sampling(sampler2D sampler, vec2 textureCoord) {\ntextureCoord.x = min(textureCoord.x, 1.0);\ntextureCoord.x = max(textureCoord.x, 0.0);\ntextureCoord.y = min(textureCoord.y, 1.0);\ntextureCoord.y = max(textureCoord.y, 0.0);\nvec4 color = texture(sampler, textureCoord);\nreturn color;\n}\nvec4 getFragColor() {\nfloat samplingCount = 1.0;\nvec2 d = vec4(blurRadius * 2.0 / iVideoResolution, 0, 0).xy;\nd = (iSamplingTransform * vec4(d, 0, 0)).xy;\nd = (iChannelMap[0] * vec4(d, 0, 0)).xy;\nd /= samplingCount;\nfloat alpha = 0.0;\nvec2 textureCoord = (iChannelMap[0] * vec4(fTextureCoord, 0, 1)).xy;\nalpha += sampling(iChannel[0], textureCoord).a;\nvec4 color = shadowColor * alpha;\ncolor *= iOpacity;\nreturn color;\n}\nvoid main() {\nfragColor = getFragColor();\n}\n");

/***/ }),

/***/ "./src/aegl/shaders/effects/easy-levels.frag":
/*!***************************************************!*\
  !*** ./src/aegl/shaders/effects/easy-levels.frag ***!
  \***************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ("#version 300 es\n#ifdef GL_ES\nprecision mediump float;\n#endif\nin vec2 fTextureCoord;\nout vec4 fragColor;\nuniform vec2 iResolution;\nuniform vec2 iVideoResolution;\nuniform sampler2D iChannel[1];\nuniform mat4 iChannelMap[1];\nuniform float iOpacity;\nuniform float effectOpacity;\nuniform int channel;\nuniform float inputBlack;\nuniform float inputWhite;\nuniform float gamma;\nuniform float outputBlack;\nuniform float outputWhite;\nfloat adjustChannel(float c) {\nc = (c - inputBlack) / (inputWhite - inputBlack);\nc = pow(c, 1.0 / gamma);\nc = (c - outputBlack) / (outputWhite - outputBlack);\nreturn c;\n}\nvec4 getFragColor() {\nvec2 textureCoord = (iChannelMap[0] * vec4(fTextureCoord, 0, 1)).xy;\nvec4 color = texture(iChannel[0], textureCoord);\nswitch (channel) {\ncase 1:\ncolor.r = adjustChannel(color.r);\ncolor.g = adjustChannel(color.g);\ncolor.b = adjustChannel(color.b);\nbreak;\ncase 2:\ncolor.r = adjustChannel(color.r);\nbreak;\ncase 3:\ncolor.g = adjustChannel(color.g);\nbreak;\ncase 4:\ncolor.b = adjustChannel(color.b);\nbreak;\ncase 5:\ncolor.a = adjustChannel(color.a);\nbreak;\n}\nvec4 inputColor = texture(iChannel[0], textureCoord);\ncolor = mix(inputColor, color, effectOpacity);\ncolor *= iOpacity;\nreturn color;\n}\nvoid main() {\nfragColor = getFragColor();\n}\n");

/***/ }),

/***/ "./src/aegl/shaders/effects/fast-blur.frag":
/*!*************************************************!*\
  !*** ./src/aegl/shaders/effects/fast-blur.frag ***!
  \*************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ("#version 300 es\n#ifdef GL_ES\nprecision mediump float;\n#endif\nin vec2 fTextureCoord;\nout vec4 fragColor;\nuniform vec2 iResolution;\nuniform vec2 iVideoResolution;\nuniform sampler2D iChannel[1];\nuniform mat4 iChannelMap[1];\nuniform float iOpacity;\nuniform float effectOpacity;\nuniform mat4 iSamplingTransform;\nuniform vec2 blurRadius;\nuniform bool repeatEdgePixels;\nfloat seedRandom2(vec2 v) {\nreturn fract(sin(dot(v, vec2(12.9898, 78.233))) * 43758.5453);\n}\nfloat noise2(vec2 v) {\nvec2 i = floor(v);\nvec2 f = fract(v);\nvec2 u = f * f * (3.0 - 2.0 * f);\nfloat a = seedRandom2(i);\nfloat b = seedRandom2(i + vec2(1, 0));\nfloat c = seedRandom2(i + vec2(0, 1));\nfloat d = seedRandom2(i + vec2(1, 1));\nreturn mix(a, b, u.x) +\n(c - a)* u.y * (1.0 - u.x) +\n(d - b) * u.x * u.y;\n}\nfloat stepRange(float value, float minValue, float maxValue) {\nfloat diffToCenter = abs(value - (minValue + maxValue) / 2.0);\nfloat halfRange = (maxValue - minValue) / 2.0;\nreturn 1.0 - step(halfRange, diffToCenter);\n}\nvec4 sampling(sampler2D sampler, vec2 textureCoord) {\nvec4 color = texture(sampler, textureCoord);\nif (!repeatEdgePixels) {\ncolor *= stepRange(textureCoord.x, 0.0, 1.0) * stepRange(textureCoord.y, 0.0, 1.0);\n}\nreturn color;\n}\nvec4 getFragColor() {\nfloat samplingCount = 1.0;\nvec2 d = vec4(blurRadius * 2.0 / iVideoResolution, 0, 0).xy;\nd = (iSamplingTransform * vec4(d, 0, 0)).xy;\nd = (iChannelMap[0] * vec4(d, 0, 0)).xy;\nd /= samplingCount;\nvec4 color = vec4(0);\nfloat noiseValue = noise2(gl_FragCoord.xy * 2.0);\nvec2 textureCoord = (iChannelMap[0] * vec4(fTextureCoord, 0, 1)).xy;\ncolor += sampling(iChannel[0], textureCoord + (0.0 + noiseValue) * d);\nvec4 inputColor = texture(iChannel[0], textureCoord);\ncolor = mix(inputColor, color, effectOpacity);\ncolor *= iOpacity;\nreturn color;\n}\nvoid main() {\nfragColor = getFragColor();\n}");

/***/ }),

/***/ "./src/aegl/shaders/effects/fill.frag":
/*!********************************************!*\
  !*** ./src/aegl/shaders/effects/fill.frag ***!
  \********************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ("#version 300 es\n#ifdef GL_ES\nprecision mediump float;\n#endif\nin vec2 fTextureCoord;\nout vec4 fragColor;\nuniform vec2 iResolution;\nuniform vec2 iVideoResolution;\nuniform sampler2D iChannel[1];\nuniform mat4 iChannelMap[1];\nuniform float iOpacity;\nuniform float effectOpacity;\nuniform vec4 \t fillColor;\nuniform float fillOpacity;\nvec4 getFragColor() {\nvec2 textureCoord = (iChannelMap[0] * vec4(fTextureCoord, 0, 1)).xy;\nfloat colorAlpha = texture(iChannel[0], textureCoord).a;\nvec4 color = fillColor * colorAlpha;\ncolor *= fillOpacity;\nvec4 inputColor = texture(iChannel[0], textureCoord);\ncolor = mix(inputColor, color, effectOpacity);\ncolor *= iOpacity;\nreturn color;\n}\nvoid main() {\nfragColor = getFragColor();\n}\n");

/***/ }),

/***/ "./src/aegl/shaders/effects/fractal-noise.frag":
/*!*****************************************************!*\
  !*** ./src/aegl/shaders/effects/fractal-noise.frag ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ("#version 300 es\n#ifdef GL_ES\nprecision mediump float;\n#endif\nin vec4 fRawCoord;\nin vec2 fTextureCoord;\nout vec4 fragColor;\nuniform vec2 iResolution;\nuniform vec2 iVideoResolution;\nuniform sampler2D iChannel[1];\nuniform mat4 iChannelMap[1];\nuniform float iOpacity;\nuniform float effectOpacity;\nuniform float \t contrast;\nuniform float brightness;\nuniform float complexity;\nuniform float subInfluence;\nuniform mat4 noiseTransform;\nuniform mat4 subNoiseTransform;\nfloat random2(vec2 v) {\nreturn fract(sin(dot(v, vec2(12.9898, 78.233))) * 43758.5453);\n}\nfloat noise2(vec2 v) {\nvec2 i = floor(v);\nvec2 f = fract(v);\nvec2 u = f * f * (3.0 - 2.0 * f);\nfloat a = random2(i);\nfloat b = random2(i + vec2(1.0, 0.0));\nfloat c = random2(i + vec2(0.0, 1.0));\nfloat d = random2(i + vec2(1.0, 1.0));\nreturn mix(a, b, u.x) +\n(c - a)* u.y * (1.0 - u.x) +\n(d - b) * u.x * u.y;\n}\nvec4 getFragColor() {\nvec2 pixelCoord = (noiseTransform * vec4(fRawCoord.xy, 0, 1)).xy;\nfloat noiseRadiusInPx = 50.0;\nvec2 noiseCoord = pixelCoord / noiseRadiusInPx;\nfloat influence = 1.0;\nfloat sum = 0.0;\nfloat total = 0.0;\nfloat loopCount = ceil(complexity);\nfor (float i = 0.0; i <= loopCount; i += 1.0) {\nfloat noiseValue = noise2(noiseCoord);\nfloat smoothValue = smoothstep(0.0, 1.0, noiseValue);\nfloat complexityRate = max(complexity + 1.0 - i, 1.0);\nsum += smoothValue * influence * complexityRate;\ntotal += influence * complexityRate;\nnoiseCoord = (subNoiseTransform * vec4(noiseCoord, 0, 1)).xy;\ninfluence *= subInfluence;\n}\nfloat value = sum / total;\nvalue = (value - 0.5) * contrast + 0.5 + brightness;\nvec4 color = vec4(value, value, value, 1);\nvec2 textureCoord = (iChannelMap[0] * vec4(fTextureCoord, 0, 1)).xy;\nvec4 inputColor = texture(iChannel[0], textureCoord);\ncolor = mix(inputColor, color, effectOpacity);\ncolor *= iOpacity;\nreturn color;\n}\nvoid main() {\nfragColor = getFragColor();\n}\n");

/***/ }),

/***/ "./src/aegl/shaders/effects/gamma.frag":
/*!*********************************************!*\
  !*** ./src/aegl/shaders/effects/gamma.frag ***!
  \*********************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ("#version 300 es\n#ifdef GL_ES\nprecision mediump float;\n#endif\nin vec2 fTextureCoord;\nout vec4 fragColor;\nuniform vec2 iResolution;\nuniform vec2 iVideoResolution;\nuniform sampler2D iChannel[1];\nuniform mat4 iChannelMap[1];\nuniform float iOpacity;\nuniform float effectOpacity;\nuniform float redGamma;\nuniform float redPedestal;\nuniform float redGain;\nuniform float greenGamma;\nuniform float greenPedestal;\nuniform float greenGain;\nuniform float blueGamma;\nuniform float bluePedestal;\nuniform float blueGain;\nvec4 getFragColor() {\nvec2 textureCoord = (iChannelMap[0] * vec4(fTextureCoord, 0, 1)).xy;\nvec4 color = texture(iChannel[0], textureCoord);\ncolor.r = pow(color.r * redGain + redPedestal, 1.0 / redGamma);\ncolor.g = pow(color.g * greenGain + greenPedestal, 1.0 / greenGamma);\ncolor.b = pow(color.b * blueGain + bluePedestal, 1.0 / blueGamma);\nvec4 inputColor = texture(iChannel[0], textureCoord);\ncolor = mix(inputColor, color, effectOpacity);\ncolor *= iOpacity;\nreturn color;\n}\nvoid main() {\nfragColor = getFragColor();\n}\n");

/***/ }),

/***/ "./src/aegl/shaders/effects/layer-style-drop-shadow-blend.frag":
/*!*********************************************************************!*\
  !*** ./src/aegl/shaders/effects/layer-style-drop-shadow-blend.frag ***!
  \*********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ("#version 300 es\n#ifdef GL_ES\nprecision mediump float;\n#endif\nin vec2 fTextureCoord;\nout vec4 fragColor;\nuniform vec2 iResolution;\nuniform vec2 iVideoResolution;\nuniform sampler2D iChannel[2];\nuniform mat4 iChannelMap[2];\nuniform float iOpacity;\nuniform float effectOpacity;\nuniform float fillOpacity;\nvec4 getFragColor() {\nvec2 textureCoord0 = (iChannelMap[0] * vec4(fTextureCoord, 0, 1)).xy;\nvec2 textureCoord1 = (iChannelMap[1] * vec4(fTextureCoord, 0, 1)).xy;\nvec4 color = texture(iChannel[0], textureCoord0);\nvec4 shadowColor = texture(iChannel[1], textureCoord1);\ncolor = shadowColor * (1.0 - color.a) + color * fillOpacity;\nvec4 inputColor = texture(iChannel[0], textureCoord0);\ncolor = mix(inputColor, color, effectOpacity);\ncolor *= iOpacity;\nreturn color;\n}\nvoid main() {\nfragColor = getFragColor();\n}\n");

/***/ }),

/***/ "./src/aegl/shaders/effects/mask-alpha.frag":
/*!**************************************************!*\
  !*** ./src/aegl/shaders/effects/mask-alpha.frag ***!
  \**************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ("#version 300 es\n#ifdef GL_ES\nprecision mediump float;\n#endif\nin vec2 fTextureCoord;\nout vec4 fragColor;\nuniform vec2 iResolution;\nuniform vec2 iVideoResolution;\nuniform sampler2D iChannel[2];\nuniform mat4 iChannelMap[2];\nuniform float iOpacity;\nuniform bool inverted;\nvec4 getFragColor() {\nvec2 textureCoord0 = (iChannelMap[0] * vec4(fTextureCoord, 0, 1)).xy;\nvec2 textureCoord1 = (iChannelMap[1] * vec4(fTextureCoord, 0, 1)).xy;\nfloat maskAlpha = texture(iChannel[0], textureCoord0).a;\nmaskAlpha = inverted ? 1.0 - maskAlpha : maskAlpha;\nvec4 color = texture(iChannel[1], textureCoord1);\ncolor *= maskAlpha;\ncolor *= iOpacity;\nreturn color;\n}\nvoid main() {\nfragColor = getFragColor();\n}\n");

/***/ }),

/***/ "./src/aegl/shaders/effects/mask-blend.frag":
/*!**************************************************!*\
  !*** ./src/aegl/shaders/effects/mask-blend.frag ***!
  \**************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ("#version 300 es\n#ifdef GL_ES\nprecision mediump float;\n#endif\nin vec2 fTextureCoord;\nout vec4 fragColor;\nuniform vec2 iResolution;\nuniform vec2 iVideoResolution;\nuniform sampler2D iChannel[2];\nuniform mat4 iChannelMap[2];\nuniform float iOpacity;\nuniform bool inverted;\nuniform int maskMode;\nuniform bool isFirst;\nvec4 getFragColor() {\nvec2 textureCoord0 = (iChannelMap[0] * vec4(fTextureCoord, 0, 1)).xy;\nvec2 textureCoord1 = (iChannelMap[1] * vec4(fTextureCoord, 0, 1)).xy;\nvec4 source = texture(iChannel[0], textureCoord0);\nvec4 dest = texture(iChannel[1], textureCoord1);\nvec4 color;\nif (inverted) {\nsource = 1.0 - source;\n}\nif (maskMode == 3 && isFirst) {\nsource = vec4(1, 1, 1, 1);\n}\nswitch (maskMode) {\ncase 1:\ncolor = source;\nbreak;\ncase 2:\ncolor = source + dest;\nbreak;\ncase 3:\ncolor = source - dest;\nbreak;\ncase 4:\ncolor = max(source, dest);\nbreak;\ncase 5:\ncolor = min(source, dest);\nbreak;\ncase 6:\ncolor = abs(source - dest);\nbreak;\n}\ncolor *= iOpacity;\nreturn color;\n}\nvoid main() {\nfragColor = getFragColor();\n}\n");

/***/ }),

/***/ "./src/aegl/shaders/effects/mask-luminance.frag":
/*!******************************************************!*\
  !*** ./src/aegl/shaders/effects/mask-luminance.frag ***!
  \******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ("#version 300 es\n#ifdef GL_ES\nprecision mediump float;\n#endif\nin vec2 fTextureCoord;\nout vec4 fragColor;\nuniform vec2 iResolution;\nuniform vec2 iVideoResolution;\nuniform sampler2D iChannel[2];\nuniform mat4 iChannelMap[2];\nuniform float iOpacity;\nuniform bool inverted;\nvec4 getFragColor() {\nvec2 textureCoord0 = (iChannelMap[0] * vec4(fTextureCoord, 0, 1)).xy;\nvec2 textureCoord1 = (iChannelMap[1] * vec4(fTextureCoord, 0, 1)).xy;\nvec4 maskColor = texture(iChannel[0], textureCoord0);\nfloat luminance = 0.299 * maskColor.r + 0.587 * maskColor.g + 0.114 * maskColor.b;\nluminance = inverted ? 1.0 - luminance : luminance;\nvec4 color = texture(iChannel[1], textureCoord1);\ncolor *= luminance;\ncolor *= iOpacity;\nreturn color;\n}\nvoid main() {\nfragColor = getFragColor();\n}\n");

/***/ }),

/***/ "./src/aegl/shaders/effects/motion-blur.frag":
/*!***************************************************!*\
  !*** ./src/aegl/shaders/effects/motion-blur.frag ***!
  \***************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ("#version 300 es\n#ifdef GL_ES\nprecision mediump float;\n#endif\nin vec4 fRawCoord;\nin vec2 fTextureCoord;\nout vec4 fragColor;\nuniform vec2 iResolution;\nuniform vec2 iVideoResolution;\nuniform sampler2D iChannel[1];\nuniform mat4 iChannelMap[1];\nuniform float iOpacity;\nuniform mat4 iSamplingTransform;\nuniform mat4 motionMatrix;\nuniform int samplingCount;\nuniform bool repeatEdgePixels;\nfloat seedRandom2(vec2 v) {\nreturn fract(sin(dot(v, vec2(12.9898, 78.233))) * 43758.5453);\n}\nfloat noise2(vec2 v) {\nvec2 i = floor(v);\nvec2 f = fract(v);\nvec2 u = f * f * (3.0 - 2.0 * f);\nfloat a = seedRandom2(i);\nfloat b = seedRandom2(i + vec2(1, 0));\nfloat c = seedRandom2(i + vec2(0, 1));\nfloat d = seedRandom2(i + vec2(1, 1));\nreturn mix(a, b, u.x) +\n(c - a)* u.y * (1.0 - u.x) +\n(d - b) * u.x * u.y;\n}\nfloat stepRange(float value, float minValue, float maxValue) {\nfloat diffToCenter = abs(value - (minValue + maxValue) / 2.0);\nfloat halfRange = (maxValue - minValue) / 2.0;\nreturn 1.0 - step(halfRange, diffToCenter);\n}\nvec4 sampling(sampler2D sampler, vec2 textureCoord) {\nvec4 color = texture(sampler, textureCoord);\nif (!repeatEdgePixels) {\ncolor *= stepRange(textureCoord.x, 0.0, 1.0) * stepRange(textureCoord.y, 0.0, 1.0);\n}\nreturn color;\n}\nvec4 motionSampling(sampler2D sampler, vec2 textureCoord, vec2 motionV, int sampleCount, float frequency) {\nvec4 totalColor = vec4(0);\nfloat noiseValue = noise2(gl_FragCoord.xy * frequency);\nfor (int i = 0; i < sampleCount; i++) {\nfloat rate = (float(i) + noiseValue) / float(sampleCount);\nvec2 coord = textureCoord + rate * motionV;\nvec4 color = sampling(sampler, coord);\ntotalColor += color;\n}\nreturn totalColor / float(sampleCount);\n}\nvec4 getFragColor() {\nvec4 pixelMotionV = motionMatrix * fRawCoord;\nvec2 textureMotionV = pixelMotionV.xy / iVideoResolution;\ntextureMotionV.y = -textureMotionV.y;\ntextureMotionV = (iSamplingTransform * vec4(textureMotionV, 0, 0)).xy;\ntextureMotionV = (iChannelMap[0] * vec4(textureMotionV, 0, 0)).xy;\nvec2 textureCoord = (iChannelMap[0] * vec4(fTextureCoord, 0, 1)).xy;\nvec4 color = motionSampling(iChannel[0], textureCoord, textureMotionV, samplingCount, 2.0);\ncolor *= iOpacity;\nreturn color;\n}\nvoid main() {\nfragColor = getFragColor();\n}\n");

/***/ }),

/***/ "./src/aegl/shaders/effects/ramp.frag":
/*!********************************************!*\
  !*** ./src/aegl/shaders/effects/ramp.frag ***!
  \********************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ("#version 300 es\n#ifdef GL_ES\nprecision mediump float;\n#endif\nin vec2 fTextureCoord;\nin vec4 fRawCoord;\nout vec4 fragColor;\nuniform vec2 iResolution;\nuniform vec2 iVideoResolution;\nuniform sampler2D iChannel[1];\nuniform mat4 iChannelMap[1];\nuniform float iOpacity;\nuniform float effectOpacity;\nuniform vec2 startOfRamp;\nuniform vec4 startColor;\nuniform vec2 endOfRamp;\nuniform vec4 endColor;\nuniform int rampShape;\nuniform float blendWithOriginal;\nvec4 getFragColor() {\nvec2 startToEnd = endOfRamp - startOfRamp;\nvec2 startToCurrent = fRawCoord.xy - startOfRamp;\nfloat endRate;\nif (rampShape == 1) {\nendRate = dot(startToCurrent, startToEnd) / pow(length(startToEnd), 2.0);\n}\nelse {\nendRate = length(startToCurrent) / length(startToEnd);\n}\nendRate = clamp(endRate, 0.0, 1.0);\nvec4 color = mix(startColor, endColor, endRate);\nvec2 textureCoord = (iChannelMap[0] * vec4(fTextureCoord, 0, 1)).xy;\nvec4 inputColor = texture(iChannel[0], textureCoord);\ncolor = mix(inputColor, color, 1.0 - blendWithOriginal);\ncolor = mix(inputColor, color, effectOpacity);\ncolor *= iOpacity;\nreturn color;\n}\nvoid main() {\nfragColor = getFragColor();\n}\n");

/***/ }),

/***/ "./src/aegl/shaders/effects/tint.frag":
/*!********************************************!*\
  !*** ./src/aegl/shaders/effects/tint.frag ***!
  \********************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ("#version 300 es\n#ifdef GL_ES\nprecision mediump float;\n#endif\nin vec2 fTextureCoord;\nout vec4 fragColor;\nuniform vec2 iResolution;\nuniform vec2 iVideoResolution;\nuniform sampler2D iChannel[1];\nuniform mat4 iChannelMap[1];\nuniform float iOpacity;\nuniform float effectOpacity;\nuniform vec4 \t mapBlackTo;\nuniform vec4 \t mapWhiteTo;\nuniform float \t amountToTint;\nvec4 getFragColor() {\nvec2 textureCoord = (iChannelMap[0] * vec4(fTextureCoord, 0, 1)).xy;\nvec4 color = texture(iChannel[0], textureCoord);\nfloat luminance = 0.299 * color.r + 0.587 * color.g + 0.114 * color.b;\nvec4 tintColor = vec4(0);\ntintColor += mapBlackTo * (1.0 - luminance) * amountToTint;\ntintColor += mapWhiteTo * luminance * amountToTint;\ntintColor += color * (1.0 - amountToTint);\ntintColor *= iOpacity;\nvec4 inputColor = texture(iChannel[0], textureCoord);\ncolor = mix(inputColor, color, effectOpacity);\nreturn tintColor;\n}\nvoid main() {\nfragColor = getFragColor();\n}\n");

/***/ }),

/***/ "./src/aegl/shaders/layer/image-alpha.frag":
/*!*************************************************!*\
  !*** ./src/aegl/shaders/layer/image-alpha.frag ***!
  \*************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ("#version 300 es\n#ifdef GL_ES\nprecision mediump float;\n#endif\nin vec2 fTextureCoord;\nout vec4 fragColor;\nuniform vec2 iResolution;\nuniform vec2 iVideoResolution;\nuniform sampler2D iChannel[2];\nuniform mat4 iChannelMap[1];\nuniform float iOpacity;\nvec4 getFragColor() {\nvec2 textureCoord = (iChannelMap[0] * vec4(fTextureCoord, 0, 1)).xy;\nvec4 color = texture(iChannel[0], textureCoord);\nvec4 alphaColor = texture(iChannel[1], textureCoord);\nfloat alpha = (alphaColor.r + alphaColor.g + alphaColor.b) / 3.0;\ncolor *= alpha * iOpacity;\nreturn color;\n}\nvoid main() {\nfragColor = getFragColor();\n}\n");

/***/ }),

/***/ "./src/aegl/shaders/layer/solid-color.frag":
/*!*************************************************!*\
  !*** ./src/aegl/shaders/layer/solid-color.frag ***!
  \*************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ("#version 300 es\n#ifdef GL_ES\nprecision mediump float;\n#endif\nout vec4 fragColor;\nuniform vec4 solidColor;\nuniform float iOpacity;\nvec4 getFragColor() {\nreturn solidColor * iOpacity;\n}\nvoid main() {\nfragColor = getFragColor();\n}\n");

/***/ }),

/***/ "./src/aegl/shaders/layer/transform.frag":
/*!***********************************************!*\
  !*** ./src/aegl/shaders/layer/transform.frag ***!
  \***********************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ("#version 300 es\n#ifdef GL_ES\nprecision mediump float;\n#endif\nin vec2 fTextureCoord;\nout vec4 fragColor;\nuniform vec2 iResolution;\nuniform vec2 iVideoResolution;\nuniform sampler2D iChannel[1];\nuniform mat4 iChannelMap[1];\nuniform float iOpacity;\nvec4 getFragColor() {\nvec2 textureCoord = (iChannelMap[0] * vec4(fTextureCoord, 0, 1)).xy;\nvec4 color = texture(iChannel[0], textureCoord);\ncolor *= iOpacity;\nreturn color;\n}\nvoid main() {\nfragColor = getFragColor();\n}\n");

/***/ }),

/***/ "./src/aegl/shaders/shape/shape-fill.frag":
/*!************************************************!*\
  !*** ./src/aegl/shaders/shape/shape-fill.frag ***!
  \************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ("#version 300 es\n#ifdef GL_ES\nprecision mediump float;\n#endif\nin vec4 fProjectedCoord;\nout vec4 fragColor;\nuniform vec2 iResolution;\nuniform vec2 iVideoResolution;\nuniform sampler2D iChannel[1];\nuniform mat4 iChannelMap[1];\nuniform float effectOpacity;\nvec4 getFragColor() {\nvec2 fTextureCoord = fProjectedCoord.xy / iVideoResolution;\nfTextureCoord.y = 1.0 - fTextureCoord.y;\nvec2 textureCoord = (iChannelMap[0] * vec4(fTextureCoord, 0, 1)).xy;\nvec4 color = texture(iChannel[0], textureCoord);\nreturn color;\n}\nvoid main() {\nfragColor = getFragColor();\n}\n");

/***/ }),

/***/ "./src/aegl/shaders/shape/solid-fill.frag":
/*!************************************************!*\
  !*** ./src/aegl/shaders/shape/solid-fill.frag ***!
  \************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ("#version 300 es\n#ifdef GL_ES\nprecision mediump float;\n#endif\nout vec4 fragColor;\nuniform vec4 solidColor;\nuniform float iOpacity;\nvec4 getFragColor() {\nreturn solidColor * iOpacity;\n}\nvoid main() {\nfragColor = getFragColor();\n}\n");

/***/ }),

/***/ "./src/aegl/shaders/transform.vert":
/*!*****************************************!*\
  !*** ./src/aegl/shaders/transform.vert ***!
  \*****************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ("#version 300 es\n#ifdef GL_ES\nprecision mediump float;\n#endif\nin vec4 vPosition;\nin vec2 vTextureCoord;\nout vec2 fTextureCoord;\nout vec4 fRawCoord;\nout vec4 fProjectedCoord;\nuniform vec2 iResolution;\nuniform vec2 iVideoResolution;\nuniform mat4 iTransform;\nuniform mat4 iSamplingTransform;\nuniform mat4 iProjection;\nmat4 getPixelReflectionMatrix() {\nfloat w = iVideoResolution.x / 2.0;\nfloat h = iVideoResolution.y / 2.0;\nreturn mat4(\nw, 0, 0, 0,\n0, -h, 0, 0,\n0, 0, 0, 0,\nw, h, 0, 1\n);\n}\nvoid main() {\nvec4 openGLCoord = iProjection * iTransform * vPosition;;\nvec4 projectedCoord = getPixelReflectionMatrix() * openGLCoord;\ngl_Position = openGLCoord;\nfProjectedCoord = projectedCoord;\nfRawCoord = vPosition;\nfTextureCoord = (iSamplingTransform * vec4(vTextureCoord, 0, 1)).xy;\n}\n");

/***/ }),

/***/ "./src/bg-erase/bg-erase-preview.ts":
/*!******************************************!*\
  !*** ./src/bg-erase/bg-erase-preview.ts ***!
  \******************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.BackgroundErasePreview = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const color_correction_preview_1 = __webpack_require__(/*! ../color-correction/color-correction-preview */ "./src/color-correction/color-correction-preview.ts");
const todraw_1 = __webpack_require__(/*! ../libs/webgl/todraw */ "./src/libs/webgl/todraw.ts");
const preload_1 = __webpack_require__(/*! ../libs/util/preload */ "./src/libs/util/preload.ts");
const sampler_1 = __webpack_require__(/*! ../libs/webgl/sampler */ "./src/libs/webgl/sampler.ts");
const flit_ui_1 = __webpack_require__(/*! @pucelle/flit-ui */ "./node_modules/@pucelle/flit-ui/out/index.js");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
const file_1 = __webpack_require__(/*! ../libs/util/file */ "./src/libs/util/file.ts");
let BackgroundErasePreview = class BackgroundErasePreview extends color_correction_preview_1.ColorCorrectionPreview {
    name = 'bg-erase';
    imageStorageKey = 'bgErasePreviewImage';
    //protected toDrawForeground!: ToDraw
    toDrawBackground;
    toDrawBlend;
    toDrawBackgroundBlur;
    uniformSlides = [];
    imageDirectory = 'bg-erase';
    images = [
        'icon_2020_07-02_11-00-22.jpg',
        'icon_2020_07-02_14-26-40.jpg',
        'icon_2020_07-04_15-12-08.jpg',
        'icon_2020_07-02_11-40-10.jpg',
        'icon_2020_07-02_14-29-04.jpg',
        'icon_2020_07-04_15-19-37.jpg',
        'icon_2020_07-02_11-40-35.jpg',
        'icon_2020_07-02_14-29-23.jpg',
        'icon_2020_07-06_02-22-34.jpg',
        'icon_2020_07-02_11-40-56.jpg',
        'icon_2020_07-02_16-55-26.jpg',
        'icon_2020_07-06_03-53-09.jpg',
        'icon_2020_07-02_11-41-19.jpg',
        'icon_2020_07-03_04-25-59.jpg',
        'icon_2020_07-06_04-07-41.jpg',
        'icon_2020_07-02_11-41-28.jpg',
        'icon_2020_07-03_17-33-47.jpg',
        'icon_2020_07-06_07-58-31.jpg',
        'icon_2020_07-02_11-47-17.jpg',
        'icon_2020_07-03_22-11-24.jpg',
        'icon_2020_07-02_11-47-21.jpg',
        'icon_2020_07-04_08-06-32.jpg',
        'icon_2020_07-02_12-43-35.jpg',
        'icon_2020_07-04_10-15-31.jpg',
        'icon_2020_07-02_12-50-06.jpg',
        'icon_2020_07-04_13-37-20.jpg',
        'icon_2020_07-06_17-15-52.jpg',
        'icon3_0125.jpg',
        'icon3_0126.jpg',
        'icon3_0127.jpg',
        'icon3_0138.jpg',
        '499.jpg',
    ].sort();
    imageMaskMap = {};
    bgColors = ['#000000', '#ffffff', '#ff3333', '#33ff33', '#3333ff'];
    activeBGColor = ff_1.storage.get('bg_erase_active_bg_color', '#000000');
    render() {
        return (0, flit_1.html) `
		<template class="preview">
			${this.renderColors()}
			${this.renderImages()}
		</template>
		`;
    }
    renderColors() {
        return (0, flit_1.html) `
		<div class="preview-channels">
			<button @click=${() => this.setBgColor('original')} style="margin-top: 12px; margin-right: 4px;">原图</button>
			<button @click=${() => this.setBgColor('mask')} style="margin-top: 12px; margin-right: 4px;">蒙版</button>

			${this.bgColors.map((color) => (0, flit_1.html) `
				<div :style.background=${color}
					:class.active=${color === this.activeBGColor}
					@click=${() => this.setBgColor(color)}
				 />
			`)}

			<button @click=${this.addMoreImages} style="margin-top: 12px; margin-left: auto;">添加图片</button>
		</div>
		`;
    }
    async createToDraw() {
        this.updateSWClearColor();
        let vertCode = this.getVertexCode();
        //let foregroundFragCode = await (await fetch(`shaders/color-corrections/bg-erase-foreground-filter.frag`)).text()
        let backgroundFragCode = await (await fetch(`shaders/bg-erase/bg-erase-background-filter.frag`)).text();
        let blurFragCode = await (await fetch(`shaders/bg-erase/bg-erase-blur.frag`)).text();
        let blendFragCode = await (await fetch(`shaders/bg-erase/bg-erase-blend.frag`)).text();
        // 不需要再绘制前景, 但是代码仍保留, 因为未来将会对前景做平滑处理来改善局部的效果.
        // 提取前景颜色.
        // this.toDrawForeground = new ToDraw(this.sw, {
        // 	vertCode,
        // 	fragCode: foregroundFragCode,
        // 	vertices: {
        // 		data: this.getDefaultVerticesData(),
        // 		count: 4,
        // 	},
        // })
        // 提取背景颜色.
        this.toDrawBackground = new todraw_1.ToDraw(this.sw, {
            vertCode,
            fragCode: backgroundFragCode,
            vertices: {
                data: this.getDefaultVerticesData(),
                count: 4,
            },
        });
        // 模糊背景.
        this.toDrawBackgroundBlur = new todraw_1.ToDraw(this.sw, {
            vertCode,
            fragCode: blurFragCode,
            vertices: {
                data: this.getDefaultVerticesData(),
                count: 4,
            },
        });
        this.toDrawBlend = new todraw_1.ToDraw(this.sw, {
            vertCode,
            fragCode: blendFragCode,
            vertices: {
                data: this.getDefaultVerticesData(),
                count: 4,
            },
        });
        this.toDraw = new todraw_1.ToDraw(this.sw, {
            vertCode,
            fragCode: await this.getDefaultFragCode(),
            vertices: {
                data: this.getDefaultVerticesData(),
                count: 4,
            },
        });
        this.onGLReady();
    }
    async setImage(name) {
        this.activeImage = name;
        let imageURL = (0, file_1.isAbsolutePath)(name) ? name : `pictures/${this.imageDirectory}/${name}`;
        let maskURL = this.imageMaskMap[imageURL] || `pictures/${this.imageDirectory}/${name.replace(/\.(\w+)$/, '_v2_mask.png')}`;
        let image = await (0, preload_1.preloadImage)(imageURL);
        let maskImage = await (0, preload_1.preloadImage)(maskURL);
        this.imageNaturalSize = [image.naturalWidth, image.naturalHeight];
        this.adjustSize();
        let samplers = [new sampler_1.PixelSampler(this.sw, image), new sampler_1.PixelSampler(this.sw, maskImage)];
        this.toDrawBackground.useSampler('iChannel', ...samplers);
        //this.toDrawForeground.useSampler('iChannel', ...samplers)
        this.toDrawBlend.useSampler('iChannel', ...samplers);
        this.drawAll();
    }
    setBgColor(color) {
        this.activeBGColor = color;
        ff_1.storage.set('bg_erase_active_bg_color', color);
        this.updateSWClearColor();
        this.drawAll();
    }
    async addMoreImages() {
        let files = await (0, ff_1.selectMultipleFile)('image/*');
        if (!files) {
            return;
        }
        if (files.length !== 2) {
            flit_ui_1.notification.error(`请选择两个文件, 其中之一为原图, 另一个为名称中包含 "mask" 的蒙版图.`);
            return;
        }
        let maskFile = files.find(file => file.name.includes('mask'));
        if (!maskFile) {
            flit_ui_1.notification.error(`请选择两个文件, 其中之一为原图, 另一个为名称中包含 "mask" 的蒙版图.`);
            return;
        }
        let originalFile = files.find(file => file !== maskFile);
        let imageURL = URL.createObjectURL(originalFile);
        let maskURL = URL.createObjectURL(maskFile);
        this.images.push(imageURL);
        this.imageMaskMap[imageURL] = maskURL;
        this.setImage(imageURL);
    }
    updateSWClearColor() {
        if (this.activeBGColor.startsWith('#')) {
            this.sw.setClearColor(new flit_ui_1.Color(this.activeBGColor).getRGBA());
        }
    }
    drawAll() {
        this.sw.clear();
        if (this.activeBGColor === 'original') {
            this.toDraw.useSampler('iChannel', this.toDrawBlend.getSampler('iChannel')[0]);
            this.toDraw.draw();
            this.toDraw.unuseSampler('iChannel');
        }
        else if (this.activeBGColor === 'mask') {
            this.toDraw.useSampler('iChannel', this.toDrawBlend.getSampler('iChannel')[1]);
            this.toDraw.draw();
            this.toDraw.unuseSampler('iChannel');
        }
        else {
            // 绘制背景.
            let backgroundSampler = this.drawBackgroundBlur();
            //this.toDrawForeground.useSubSampler('iChannel', 2, backgroundSampler)
            this.toDrawBlend.useSubSampler('iChannel', 2, backgroundSampler);
            // 绘制前景.
            //let foregroundSampler = this.drawForeground()
            //this.toDrawBlend.useSubSampler('iChannel', 3, foregroundSampler)
            this.drawBlend();
        }
    }
    drawBackgroundBlur(blurRadius = 50, iterateCount = 2, maxMaskErrorPixels = 2) {
        let outputSampler;
        // 拆解为 iterateCount / 2 个半径, 其平方和等于原始半径的平方.
        let subRadius = blurRadius * Math.sqrt(1 / iterateCount);
        // 提取背景.
        let textureFrame = this.sw.textureFrameManager.requestFull();
        textureFrame.active();
        this.toDrawBackground.draw();
        textureFrame.deactive();
        this.toDrawBackgroundBlur.useSampler('iChannel', textureFrame.getSampler());
        this.toDrawBackgroundBlur.setUniform('maxMaskErrorPixels', maxMaskErrorPixels);
        // 横竖来回进行绘制.
        for (let i = 0; i < iterateCount * 2; i++) {
            if (i % 2 === 0) {
                this.toDrawBackgroundBlur.setUniform('samplingRadius', [subRadius, 0]);
            }
            else {
                this.toDrawBackgroundBlur.setUniform('samplingRadius', [0, subRadius]);
            }
            let textureFrame = this.sw.textureFrameManager.requestFull();
            textureFrame.active();
            this.toDrawBackgroundBlur.draw();
            textureFrame.deactive();
            this.toDrawBackgroundBlur.unuseSampler('iChannel');
            // 前面的绘制完成后再度作为绘制的输入.
            if (i < iterateCount * 2 - 1) {
                this.toDrawBackgroundBlur.useSampler('iChannel', textureFrame.getSampler());
            }
            else {
                outputSampler = textureFrame.getSampler();
            }
        }
        return outputSampler;
    }
    drawBlend(maxSearchingFgRadius = 5, maxMaskErrorPixels = 2) {
        this.toDrawBlend.setUniform('maxSearchingFgRadius', maxSearchingFgRadius);
        this.toDrawBlend.setUniform('maxMaskErrorPixels', maxMaskErrorPixels);
        this.toDrawBlend.draw();
    }
};
exports.BackgroundErasePreview = BackgroundErasePreview;
exports.BackgroundErasePreview = BackgroundErasePreview = __decorate([
    (0, flit_1.define)('bg-erase-preview')
], BackgroundErasePreview);


/***/ }),

/***/ "./src/bg-erase/green-screen-preview.ts":
/*!**********************************************!*\
  !*** ./src/bg-erase/green-screen-preview.ts ***!
  \**********************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.GreenScreenPreview = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const color_correction_preview_1 = __webpack_require__(/*! ../color-correction/color-correction-preview */ "./src/color-correction/color-correction-preview.ts");
const flit_ui_1 = __webpack_require__(/*! @pucelle/flit-ui */ "./node_modules/@pucelle/flit-ui/out/index.js");
const todraw_1 = __webpack_require__(/*! ../libs/webgl/todraw */ "./src/libs/webgl/todraw.ts");
const simple_webgl_1 = __webpack_require__(/*! ../libs/webgl/simple-webgl */ "./src/libs/webgl/simple-webgl.ts");
let GreenScreenPreview = class GreenScreenPreview extends color_correction_preview_1.ColorCorrectionPreview {
    name = 'green-screen';
    imageStorageKey = 'greenScreenPreviewImage';
    toDrawBlur;
    toDrawBlend;
    uniformSlides = [
        {
            name: 'tolerance',
            desc: 'Tolerance',
            min: 0,
            max: 1.5,
            step: 0.01,
            value: 0.7,
        },
        {
            name: 'kernalRadius',
            desc: 'KernalRadius',
            min: 0,
            max: 4,
            step: 1,
            value: 1,
        },
        {
            name: 'alphaBlurRadius',
            desc: 'AlphaBlurRadius',
            min: 0,
            max: 50,
            step: 1,
            value: 0,
        },
    ];
    imageDirectory = 'green-screen';
    images = [
        '85,220,90.jpg',
        '0,220,114.jpg',
        '6,253,0.jpg',
        '35,255,55.jpg',
        '48,116,239.jpg',
        '14,159,107.png',
        '14,159,108.png',
    ];
    async setImage(name) {
        let backgroundColor = flit_ui_1.Color.fromRGB(...name.match(/\d+,\d+,\d+/)[0].split(',').map(v => Number(v) / 255));
        this.sw.setUniform('backgroundColor', backgroundColor.getRGB());
        super.setImage(name);
    }
    initGL() {
        let canvas = this.refs.canvas;
        this.sw = new simple_webgl_1.SimpleWebGL(canvas, {
            clearColor: [1, 1, 1, 1],
        });
        this.onGLReady();
    }
    async createToDraw() {
        let vertCode = this.getVertexCode();
        let blurFragCode = await (await fetch(`shaders/bg-erase/feather-blur.frag`)).text();
        let blendFragCode = await (await fetch(`shaders/bg-erase/feather-blur-blend.frag`)).text();
        let eraseFragCode = await (await fetch(`shaders/bg-erase/green-screen.frag`)).text();
        this.toDrawBlur = new todraw_1.ToDraw(this.sw, {
            vertCode,
            fragCode: blurFragCode,
            vertices: {
                data: this.getDefaultVerticesData(),
                count: 4,
            },
        });
        this.toDrawBlend = new todraw_1.ToDraw(this.sw, {
            vertCode,
            fragCode: blendFragCode,
            vertices: {
                data: this.getDefaultVerticesData(),
                count: 4,
            },
        });
        this.toDraw = new todraw_1.ToDraw(this.sw, {
            vertCode,
            fragCode: eraseFragCode,
            vertices: {
                data: this.getDefaultVerticesData(),
                count: 4,
            },
        });
    }
    drawAll() {
        this.sw.clear();
        let iterateCount = 2;
        let blurRadius = this.uniformValues[2];
        // 拆解为 iterateCount / 2 个半径, 其平方和等于原始半径的平方.
        let subRadius = blurRadius * Math.sqrt(1 / iterateCount);
        if (blurRadius === 0) {
            this.toDraw.draw();
            return;
        }
        // 绘制在一个纹理上面, 然后作为模糊的输入.
        let textureFrame = this.sw.textureFrameManager.requestFull();
        textureFrame.active();
        this.toDraw.draw();
        textureFrame.deactive();
        this.toDrawBlur.useSampler('iChannel', textureFrame.getSampler());
        this.toDrawBlend.useSampler('iChannel', textureFrame.getSampler());
        // 横竖来回进行绘制.
        for (let i = 0; i < iterateCount * 2; i++) {
            if (i % 2 === 0) {
                this.toDrawBlur.setUniform('samplingRadius', [subRadius, 0]);
            }
            else {
                this.toDrawBlur.setUniform('samplingRadius', [0, subRadius]);
            }
            let textureFrame = this.sw.textureFrameManager.requestFull();
            textureFrame.active();
            this.toDrawBlur.draw();
            textureFrame.deactive();
            this.toDrawBlur.unuseSampler('iChannel');
            // 前面的绘制完成后再度作为绘制的输入.
            if (i < iterateCount * 2 - 1) {
                this.toDrawBlur.useSampler('iChannel', textureFrame.getSampler());
            }
            else {
                this.toDrawBlend.useSubSampler('iChannel', 1, textureFrame.getSampler());
            }
        }
        this.toDrawBlend.draw();
    }
};
exports.GreenScreenPreview = GreenScreenPreview;
exports.GreenScreenPreview = GreenScreenPreview = __decorate([
    (0, flit_1.define)('green-screen-preview')
], GreenScreenPreview);


/***/ }),

/***/ "./src/color-correction/color-correction-preview.ts":
/*!**********************************************************!*\
  !*** ./src/color-correction/color-correction-preview.ts ***!
  \**********************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ColorCorrectionForChannelPreview = exports.ColorCorrectionPreview = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
const preload_1 = __webpack_require__(/*! ../libs/util/preload */ "./src/libs/util/preload.ts");
const simple_webgl_1 = __webpack_require__(/*! ../libs/webgl/simple-webgl */ "./src/libs/webgl/simple-webgl.ts");
const flit_ui_1 = __webpack_require__(/*! @pucelle/flit-ui */ "./node_modules/@pucelle/flit-ui/out/index.js");
const color_correction_uniforms_1 = __webpack_require__(/*! ./color-correction-uniforms */ "./src/color-correction/color-correction-uniforms.ts");
const todraw_1 = __webpack_require__(/*! ../libs/webgl/todraw */ "./src/libs/webgl/todraw.ts");
const sampler_1 = __webpack_require__(/*! ../libs/webgl/sampler */ "./src/libs/webgl/sampler.ts");
const file_1 = __webpack_require__(/*! ../libs/util/file */ "./src/libs/util/file.ts");
let ColorCorrectionPreview = class ColorCorrectionPreview extends flit_1.Component {
    name = '';
    imageStorageKey = 'colorCorrectionPreviewImage';
    activeImage = '';
    uniformSlides = [{
            name: 'iPercent',
            desc: 'Percent',
            min: -100,
            max: 100,
            step: 1,
            value: 0,
        }];
    sw;
    uniformValues;
    imageNaturalSize = [0, 0];
    toDraw;
    imageDirectory = 'color-correction';
    images = [
        'allef-vinicius-pa0vicn6dwe-unsplash.jpg',
        'allef-vinicius-ttusgz8ulkk-unsplash.jpg',
        'allef-vinicius-_ugpeypqiuc-unsplash.jpg',
        'anastasia-dulgier-kokszzy9wsa-unsplash.jpg',
        'anita-austvika-c-cdpe9shi4-unsplash.jpg',
        'anthony-tran-mehojxixkdq-unsplash.jpg',
        'benjamin-wong-4-ka5rdcesi-unsplash.jpg',
        'deanna-alys-6lbbowkpzyq-unsplash.jpg',
        'erol-ahmed-aiyfr0vbadk-unsplash.jpg',
        'evie-s-vz3iqy0loaa-unsplash.jpg',
        'floriane-vita-fyd3owbuxny-unsplash.jpg',
        'icons8-team-7lnatqymzm4-unsplash.jpg',
        'jacob-postuma-pxztwi015zi-unsplash.jpg',
        'jake-peterson-vj4pn_psblo-unsplash.jpg',
        'jessica-weiller-so4efi-d1nc-unsplash.jpg',
        'joao-tzanno-g9_euqxpu4k-unsplash.jpg',
        'newborn-1328454.jpg',
        'quan-nguyen-sghnxezeo-q-unsplash.jpg',
        'rachit-tank-2cfz_fb08um-unsplash.jpg',
        'roksolana-zasiadko-3eaevlo2upi-unsplash.jpg',
        'scott-webb--udznjsczse-unsplash.jpg',
        'the-honest-company-aiade3prv90-unsplash.jpg',
        'wyron-a-gy38n9wkjqi-unsplash.jpg',
        'len_full.jpg',
    ];
    render() {
        return (0, flit_1.html) `
		<template class="preview">
			${this.renderToolbar()}
			${this.renderImages()}
		</template>
		`;
    }
    renderToolbar() {
        return (0, flit_1.html) `
		<table class="preview-toolbar">
		<tbody>
			${this.uniformSlides.map(({ name, desc, min, max, step, value: defaultValue }, index) => {
            let currentValue = this.uniformValues[index];
            return (0, flit_1.html) `
				<tr>
					<td>${desc}: <span class="preview-slide-value">${currentValue}</span></td>
					<td>
						<f-slider class="preview-slider" .min=${min} .max=${max} .step=${step} .value=${currentValue}
							@change=${(value) => this.changeSliderValue(name, index, value)}
						/>
						<button class="preview-slider-button" @click=${() => this.changeSliderValue(name, index, defaultValue)}>Reset</button>
					</td>
				</tr>
				`;
        })}
		</tbody>
		</table>
		`;
    }
    renderImages() {
        return (0, flit_1.html) `
			<div class="preview-nav">
			${this.images.map(name => (0, flit_1.html) `
				<div class="preview-nav-item"
					:class.active=${name === this.activeImage}
					@click=${() => this.onClickImageNav(name)}
				>
					<img src=${(0, file_1.isAbsolutePath)(name) ? name : `pictures/${this.imageDirectory}/${name}`}>
				</div>
			`)}
			</div>

			<div class="preview-canvas">
				<canvas :ref="canvas" />
			</div>
		`;
    }
    onCreated() {
        if (color_correction_uniforms_1.ColorCorrectionUniforms[this.name]) {
            this.uniformSlides = color_correction_uniforms_1.ColorCorrectionUniforms[this.name];
        }
        this.uniformValues = this.uniformSlides.map(uniform => uniform.value);
        this.activeImage = ff_1.storage.get(this.imageStorageKey, '');
    }
    async onReady() {
        this.initGL();
        for (let i = 0; i < this.uniformSlides.length; i++) {
            let { name, value } = this.uniformSlides[i];
            this.sw.setUniform(name, value);
        }
        await this.createToDraw();
        await this.setImage(ff_1.storage.get(this.imageStorageKey, this.images[0]));
    }
    onConnected() {
        (0, flit_1.on)(window, 'resize', this.onResize, this);
        this.once('disconnected', () => {
            (0, flit_1.off)(window, 'resize', this.onResize, this);
        });
    }
    onResize() {
        if (this.imageNaturalSize[0] > 0) {
            this.adjustSize();
            this.drawAll();
        }
    }
    drawAll() {
        this.sw.clear();
        this.sw.drawAll();
    }
    adjustSize() {
        let [iw, ih] = this.imageNaturalSize;
        let w = this.el.offsetWidth;
        let h = Math.round(ih / iw * w);
        if (w > iw) {
            w = iw;
            h = ih;
        }
        this.sw.setCanvasSize(w, h);
        this.sw.setUniform('iResolution', [w, h]);
    }
    onClickImageNav(name) {
        if (!(0, file_1.isAbsolutePath)(name)) {
            ff_1.storage.set(this.imageStorageKey, name);
        }
        this.setImage(name);
    }
    changeSliderValue(name, index, value) {
        this.sw.setUniform(name, value);
        this.uniformValues[index] = value;
        this.drawAll();
    }
    async setImage(name) {
        this.activeImage = name;
        let imageURL = `pictures/${this.imageDirectory}/${name}`;
        let image = await (0, preload_1.preloadImage)(imageURL);
        this.imageNaturalSize = [image.naturalWidth, image.naturalHeight];
        this.adjustSize();
        this.toDraw.useSampler('iChannel', new sampler_1.PixelSampler(this.sw, image));
        this.drawAll();
    }
    initGL() {
        let canvas = this.refs.canvas;
        this.sw = new simple_webgl_1.SimpleWebGL(canvas);
        this.onGLReady();
    }
    async createToDraw() {
        let vertCode = this.getVertexCode();
        let fragCode = await this.loadCurrentFragmentCode();
        this.toDraw = new todraw_1.ToDraw(this.sw, {
            vertCode,
            fragCode,
            vertices: {
                data: this.getDefaultVerticesData(),
                count: 4,
            },
        });
    }
    getVertexCode() {
        return `#version 300 es
		precision mediump float;
		in vec4 vPosition;
		out vec2 fTextureCoord;
		void main() {
			gl_Position = vPosition;
			fTextureCoord = vPosition.xy / 2.0 + 0.5;
		}
		`;
    }
    getDefaultVerticesData() {
        return {
            vPosition: [
                -1, 1,
                -1, -1,
                1, 1,
                1, -1,
            ]
        };
    }
    async getDefaultFragCode() {
        return `#version 300 es
		#ifdef GL_ES
		precision mediump float;
		#endif
		in vec2 fTextureCoord;
		out vec4 fragColor;
		uniform sampler2D iChannel[1];
		vec4 getFragColor() {
			return texture(iChannel[0], fTextureCoord);
		}
		void main() {
			fragColor = getFragColor(); 
		}
	`;
    }
    async loadCurrentFragmentCode() {
        return (await fetch(`shaders/color-corrections/out/${this.name}.frag`)).text();
    }
    onGLReady() { }
};
exports.ColorCorrectionPreview = ColorCorrectionPreview;
exports.ColorCorrectionPreview = ColorCorrectionPreview = __decorate([
    (0, flit_1.define)('color-correction-preview')
], ColorCorrectionPreview);
let ColorCorrectionForChannelPreview = class ColorCorrectionForChannelPreview extends ColorCorrectionPreview {
    colors = ['rgb(222, 56, 60)', 'rgb(222, 221, 60)', 'rgb(128, 217, 38)', 'rgb(60, 204, 225)', 'rgb(103, 103, 230)', 'rgb(221, 60, 221)'];
    activeColor = 'rgb(222, 56, 60)';
    render() {
        return (0, flit_1.html) `
		<template class="preview">
			${this.renderColors()}
			${this.renderToolbar()}
			${this.renderImages()}
		</template>
		`;
    }
    renderColors() {
        return (0, flit_1.html) `
		<div class="preview-channels">
			${this.colors.map((channel, index) => (0, flit_1.html) `
				<div :style.background=${channel}
					:class.active=${channel === this.activeColor}
					@click=${() => this.activeChannelInIndex(index)}
				 />
			`)}
		</div>
		`;
    }
    onGLReady() {
        this.sw.setUniform('colorToAdjust', new flit_ui_1.Color(this.activeColor).getRGB());
    }
    activeChannelInIndex(index) {
        this.activeColor = this.colors[index];
        this.sw.setUniform('colorToAdjust', new flit_ui_1.Color(this.activeColor).getRGB());
        this.drawAll();
    }
};
exports.ColorCorrectionForChannelPreview = ColorCorrectionForChannelPreview;
exports.ColorCorrectionForChannelPreview = ColorCorrectionForChannelPreview = __decorate([
    (0, flit_1.define)('color-correction-preview-for-channel')
], ColorCorrectionForChannelPreview);


/***/ }),

/***/ "./src/color-correction/color-correction-uniforms.ts":
/*!***********************************************************!*\
  !*** ./src/color-correction/color-correction-uniforms.ts ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ColorCorrectionUniforms = void 0;
const Percent = {
    name: 'iPercent',
    desc: 'Percent',
    min: -100,
    max: 100,
    step: 1,
    value: 0,
};
exports.ColorCorrectionUniforms = {
    'color-balance': [
        {
            name: 'rPercent',
            desc: 'Red',
            min: -100,
            max: 100,
            step: 1,
            value: 0,
        },
        {
            name: 'gPercent',
            desc: 'Green',
            min: -100,
            max: 100,
            step: 1,
            value: 0,
        },
        {
            name: 'bPercent',
            desc: 'Blue',
            min: -100,
            max: 100,
            step: 1,
            value: 0,
        },
    ],
    'hue-by-color': [
        Percent,
        {
            name: 'tolerance',
            desc: 'Tolerance',
            min: 0.1,
            max: 8,
            step: 0.1,
            value: 0.5,
        },
    ],
    'saturation-by-color': [
        Percent,
        {
            name: 'tolerance',
            desc: 'Tolerance',
            min: 0.1,
            max: 8,
            step: 0.1,
            value: 0.5,
        },
    ],
    'lightness-by-color': [
        Percent,
        {
            name: 'tolerance',
            desc: 'Tolerance',
            min: 0.1,
            max: 8,
            step: 0.1,
            value: 0.5,
        },
    ]
};


/***/ }),

/***/ "./src/components/function-curve.ts":
/*!******************************************!*\
  !*** ./src/components/function-curve.ts ***!
  \******************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.BezierFunction = exports.FunctionCurve = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const sampling_1 = __webpack_require__(/*! ../libs/math/sampling */ "./src/libs/math/sampling.ts");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
let FunctionCurve = class FunctionCurve extends flit_1.Component {
    fn = (x) => x;
    compiled;
    xRange = [0, 1];
    width = 100;
    render() {
        let [minX, maxX] = this.xRange;
        let scale = Math.floor(this.width / (maxX - minX));
        let step = Math.max(1 / scale, 0.001);
        let coords = []; // in normal math axis
        for (let x = minX; x <= maxX; x += step) {
            x = (0, ff_1.toDecimal)(x, 4);
            let y = (0, ff_1.toDecimal)(this.compiled(x), 4);
            coords.push([x, y]);
        }
        let yValues = coords.map(coord => coord[1]);
        let minY = Math.min(...yValues);
        let maxY = Math.max(...yValues);
        if (minY > 0) {
            minY = 0;
        }
        else if (maxY < 0) {
            maxY = 0;
        }
        coords = (0, sampling_1.simpleSamplingCoords)(coords, 0.001);
        let d = joinCoordsToCurve(coords);
        let axisLines = this.createAxisLines(minX, maxX, minY, maxY);
        let w = this.width;
        let h = Math.ceil((maxY - minY) * scale);
        let transform = `matrix(${scale}, 0, 0, -${scale}, 0, ${Math.round((maxY + minY) * scale)})`; // to map math axis to SVG axis, so we can easily implement more fetures in future.
        let viewBoxLeft = Math.round(minX * scale) - 4.5;
        let viewBoxTop = Math.round(minY * scale) - 4.5;
        let axisArrowWidth = 6 * step;
        let axisArrowHeight = 6 * step;
        return (0, flit_1.html) `
		<template class="function-curve">
			<svg viewBox="${viewBoxLeft} ${viewBoxTop} ${w + 9} ${h + 9}" width="${w + 9}" height="${h + 9}">
				<g style="transform: ${transform}">
					${axisLines.map(([coord1, coord2]) => (0, flit_1.svg) `
						<line x1="${coord1[0]}" y1="${coord1[1]}" x2="${coord2[0]}" y2="${coord2[1]}"
							stroke-width=${step}
							style="stroke: #888; stroke-opacity: 0.5; stroke-dasharray: 0.05; stroke-dashoffset: 0.025"
						/>
					`)}

					<line x1="${minX}" y1="0" x2="${maxX}" y2="0" style="stroke: #888; stroke-width: ${step}; stroke-linecap: square;"/>
					<line x1="0" y1="${minY}" x2="0" y2="${maxY}" style="stroke: #888; stroke-width: ${step}; stroke-linecap: square;" />

					<path d="M${maxX + axisArrowWidth / 2} 0 l-${axisArrowWidth} ${axisArrowHeight / 2} l0 -${axisArrowHeight}Z" style="fill: #888;" />
					<path d="M0 ${maxY + axisArrowWidth / 2} l-${axisArrowWidth / 2} ${-axisArrowHeight} l${axisArrowWidth} 0Z" style="fill: #888;" />

					<path d=${d} style="stroke: currentColor; fill: none; stroke-width: ${step * 2};" />
				</g>
			</svg>
		</template>
		`;
    }
    onCreated() {
        this.watchImmediately(() => this.fn, (fn) => {
            if (typeof fn === 'string') {
                this.compiled = new Function('x', fn.replace(/^\s*y\s*=\s*/, 'return '));
            }
            else {
                this.compiled = fn;
            }
        });
    }
    createAxisLines(minX, maxX, minY, maxY) {
        let axisLines = [];
        for (let x = Math.ceil(minX); x <= maxX; x++) {
            if (x === 0) {
                continue;
            }
            axisLines.push([
                [x, minY],
                [x, maxY],
            ]);
        }
        for (let y = Math.ceil(minY); y <= maxY; y++) {
            if (y === 0) {
                continue;
            }
            axisLines.push([
                [minX, y],
                [maxX, y],
            ]);
        }
        return axisLines;
    }
};
exports.FunctionCurve = FunctionCurve;
exports.FunctionCurve = FunctionCurve = __decorate([
    (0, flit_1.define)('function-curve')
], FunctionCurve);
let BezierFunction = class BezierFunction extends FunctionCurve {
    name = 'linear';
    onCreated() {
        this.compiled = (0, ff_1.getEasingFunction)(this.name);
    }
};
exports.BezierFunction = BezierFunction;
exports.BezierFunction = BezierFunction = __decorate([
    (0, flit_1.define)('bezier-function')
], BezierFunction);
/** 输出连接多个点为直线的 SVG 代码. */
function joinCoordsToCurve(coords) {
    coords = coords.map(coord => [
        (0, ff_1.toDecimal)(coord[0], 3),
        (0, ff_1.toDecimal)(coord[1], 3),
    ]);
    let d = '';
    for (let i = 0; i < coords.length; i++) {
        let coord = coords[i];
        if (i === 0) {
            d += 'M' + coord[0] + ' ' + coord[1];
        }
        else {
            d += ' L' + coord[0] + ' ' + coord[1];
        }
    }
    return d;
}


/***/ }),

/***/ "./src/components/function-generator.ts":
/*!**********************************************!*\
  !*** ./src/components/function-generator.ts ***!
  \**********************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.FunctionGenerator = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const matrix_1 = __webpack_require__(/*! ../libs/math/matrix */ "./src/libs/math/matrix.ts");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
let FunctionGenerator = class FunctionGenerator extends flit_1.Component {
    coords = ff_1.storage.get('functionCoords', []);
    generatedFn = x => x;
    generatedFnDesc = 'y = x';
    xRange = [0, 1];
    preferQuadratic = ff_1.storage.get('preferQuadratic', false);
    unEmptyCoordsCount = 0;
    render() {
        return (0, flit_1.html) `
		<template class="function-generator">
			${[0, 1, 2, 3, 4].map(index => {
            let coord = this.coords[index];
            let x = coord && coord[0] !== null && coord[0] !== undefined ? String(coord[0]) : '';
            let y = coord && coord[1] !== null && coord[1] !== undefined ? String(coord[1]) : '';
            return (0, flit_1.html) `
				<f-row .gutter="24">
					<f-col .span="6">
						<span>x${index + 1}:</span>
						<f-input .value=${x} @change=${(value) => this.onInputChange(index, 0, value ? Number(value) : null)} />
					</f-col>
					<f-col .span="6">
						<span>y${index + 1}:</span>
						<f-input .value=${y} @change=${(value) => this.onInputChange(index, 1, value ? Number(value) : null)} />
					</f-col>
				</f-row>
				`;
        })}

			<div class="function-generator-switch-container">
				<f-switch class="function-generator-switch"
					:enable=${[3, 4].includes(this.unEmptyCoordsCount)}
					.checked=${this.preferQuadratic}
					@change=${this.onChangePreferQuadratic} />
				优先使用一般二次曲线 (穿过 3 个或者 4 个点时有效)
			</div>

			<code class="function-generator-desc">${this.generatedFnDesc}</code>
			<function-curve .fn=${this.generatedFn} .xRange=${this.xRange} .width="200"></function-curve>
		</template>
		`;
    }
    onCreated() {
        this.generateFn();
    }
    onInputChange(coordIndex, axisIndex, value) {
        this.coords[coordIndex] = this.coords[coordIndex] || [];
        this.coords[coordIndex][axisIndex] = value;
        this.generateFn();
        ff_1.storage.set('functionCoords', this.coords);
    }
    onChangePreferQuadratic(value) {
        ff_1.storage.set('preferQuadratic', value);
        this.preferQuadratic = value;
        this.generateFn();
    }
    generateFn() {
        let coords = [];
        for (let coord of this.coords) {
            if (coord[0] !== null && coord[0] > -Infinity && coord[1] !== null && coord[1] > -Infinity) {
                coords.push(coord);
            }
        }
        if (coords.length >= 2) {
            let xRange = [
                Math.min(...coords.map(coord => coord[0])),
                Math.max(...coords.map(coord => coord[0]))
            ];
            if (xRange[1] - xRange[0] === 0) {
                return;
            }
            this.xRange = xRange;
            this.unEmptyCoordsCount = coords.length;
            if (this.preferQuadratic && (coords.length === 3 || coords.length === 4)) {
                this.generateQuadraticFn(coords);
            }
            else {
                this.generatePolynomialFn(coords);
            }
        }
    }
    // y = ax^n + bx^n-1 + ...
    generatePolynomialFn(coords) {
        // [[x^3, x^2, x^1, 1], [x2...]]
        let matrixData = coords.map(([x]) => {
            let a = [];
            for (let i = coords.length - 1; i >= 0; i--) {
                a.push(Math.pow(x, i));
            }
            return a;
        });
        let xMatrix = new matrix_1.Matrix(matrixData);
        // [[y1], [y2], ...]
        let ys = new matrix_1.Matrix(coords.map(coord => [coord[1]]));
        // [a, b, c, d, ...]
        let factors = xMatrix.inverse().multiply(ys).fix().data.map(v => v[0]);
        this.generatedFn = (x) => {
            let sum = 0;
            let factorIndex = 0;
            for (let exp = coords.length - 1; exp >= 0; exp--, factorIndex++) {
                let factor = factors[factorIndex];
                sum += factor * Math.pow(x, exp);
            }
            return sum;
        };
        let desc = 'y = ';
        let factorIndex = 0;
        for (let exp = coords.length - 1; exp >= 0; exp--, factorIndex++) {
            let factor = factors[factorIndex];
            if (exp > 1) {
                desc += `${factor} * x^${exp} + `;
            }
            else if (exp > 0) {
                desc += `${factor} * x + `;
            }
            else {
                desc += `${factor}`;
            }
        }
        this.generatedFnDesc = desc.replace(/\+ -/g, '-');
    }
    generateQuadraticFn(coords) {
        if (coords.length === 3) {
            this.generateQuadraticFnFor3Coords(coords);
        }
        else {
            this.generateQuadraticFnFor4Coords(coords);
        }
    }
    // y = axy + bx + cy + d
    generateQuadraticFnFor3Coords(coords) {
        let [[x1, y1], [x2, y2], [x3, y3]] = coords;
        let matrixData = [
            [x1 * y1, x1, y1, 1],
            [x2 * y2, x2, y2, 1],
            [x3 * y3, x3, y3, 1],
        ];
        let matrix = new matrix_1.Matrix(matrixData);
        // [a, b, c, d]
        let factors = matrix.solveHomogeneous().fix().data[0];
        if (!factors) {
            return;
        }
        let [a, b, c, d] = factors;
        this.generatedFn = (x) => {
            return -(b * x + d) / (a * x + c);
        };
        this.generatedFnDesc = `y = (${-b} * x + ${-d}) / (${a} * x + ${c})`.replace(/\+ -/g, '- ');
    }
    // y = ax^2 + bxy + cx + dy + e
    generateQuadraticFnFor4Coords(coords) {
        let [[x1, y1], [x2, y2], [x3, y3], [x4, y4]] = coords;
        let matrixData = [
            [x1 * x1, x1 * y1, x1, y1, 1],
            [x2 * x2, x2 * y2, x2, y2, 1],
            [x3 * x3, x3 * y3, x3, y3, 1],
            [x4 * x4, x4 * y4, x4, y4, 1],
        ];
        let matrix = new matrix_1.Matrix(matrixData);
        // [a, b, c, d, e]
        let factors = matrix.solveHomogeneous().fix().data[0];
        if (!factors) {
            return;
        }
        let [a, b, c, d, e] = factors;
        this.generatedFn = (x) => {
            return -(a * x * x + c * x + e) / (b * x + d);
        };
        this.generatedFnDesc = `y = (${-a} * x^2 + ${-c} * x + ${-e}) / (${b} * x + ${d})`.replace(/\+ -/g, '- ');
    }
};
exports.FunctionGenerator = FunctionGenerator;
exports.FunctionGenerator = FunctionGenerator = __decorate([
    (0, flit_1.define)('function-generator')
], FunctionGenerator);


/***/ }),

/***/ "./src/components/gauss-blur-generator.ts":
/*!************************************************!*\
  !*** ./src/components/gauss-blur-generator.ts ***!
  \************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.GaussBlur2DGenerator = exports.GaussBlur1DGenerator = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
const gauss_blur_1 = __webpack_require__(/*! ../libs/math/gauss-blur */ "./src/libs/math/gauss-blur.ts");
let GaussBlur1DGenerator = class GaussBlur1DGenerator extends flit_1.Component {
    radius = ff_1.storage.get('gauss_blur_1d_radius', 4);
    template = ff_1.storage.get('gauss_blur_1d_template', '	color += texture(iChannel[0], fTextureCoord + {x}.0 * d) * {p};');
    output = '';
    render() {
        return (0, flit_1.html) `
		<template class="gauss-blur">
			<f-input .value=${this.radius} :tooltip="半径像素" @change=${this.onChangeRadius} />
			<f-input .value=${this.template} :tooltip="代码模板" @change=${this.onChangeTemplate}" />
			<button @click=${this.generate} :enable=${this.radius}>生成高斯模糊权重代码</button>
			<f-textarea .value=${this.output} .placeholder="点击上面的按钮然后在此拷贝" />
		</template>
		`;
    }
    onChangeRadius(radius) {
        this.radius = radius;
        ff_1.storage.set('gauss_blur_1d_radius', radius);
    }
    onChangeTemplate(template) {
        this.template = template;
        ff_1.storage.set('gauss_blur_1d_template', template);
    }
    generate() {
        let priorities = (0, gauss_blur_1.generate1DGaussBlurPriorities)(this.radius);
        priorities.forEach(v => v.p = (0, ff_1.toDecimal)(v.p, 4));
        this.output = priorities.map(({ x, p }) => {
            return (0, ff_1.format)(this.template, { x, p });
        }).join('\n').replace(/\+(\s*)-/g, '-$1');
    }
};
exports.GaussBlur1DGenerator = GaussBlur1DGenerator;
exports.GaussBlur1DGenerator = GaussBlur1DGenerator = __decorate([
    (0, flit_1.define)('gauss-blur-1d-generator')
], GaussBlur1DGenerator);
let GaussBlur2DGenerator = class GaussBlur2DGenerator extends flit_1.Component {
    radius = ff_1.storage.get('gauss_blur_2d_radius', 4);
    template = ff_1.storage.get('gauss_blur_2d_template', '	color += texture(iChannel[0], fTextureCoord + vec2({x}.0, {y}.0) * d) * {p};');
    output = '';
    render() {
        return (0, flit_1.html) `
		<template class="gauss-blur">
			<f-input .value=${this.radius} :tooltip="半径像素" @change=${this.onChangeRadius} />
			<f-input .value=${this.template} :tooltip="代码模板" @change=${this.onChangeTemplate}" />
			<button @click=${this.generate} :enable=${this.radius}>生成高斯模糊权重代码</button>
			<f-textarea .value=${this.output} .placeholder="点击上面的按钮然后在此拷贝" />
		</template>
		`;
    }
    onChangeRadius(radius) {
        this.radius = radius;
        ff_1.storage.set('gauss_blur_2d_radius', radius);
    }
    onChangeTemplate(template) {
        this.template = template;
        ff_1.storage.set('gauss_blur_2d_template', template);
    }
    generate() {
        let priorities = (0, gauss_blur_1.generate2DGaussBlurPriorities)(this.radius);
        priorities.forEach(v => v.p = (0, ff_1.toDecimal)(v.p, 4));
        this.output = priorities.map(({ x, y, p }) => {
            return (0, ff_1.format)(this.template, { x, y, p });
        }).join('\n').replace(/\+(\s*)-/g, '-$1');
    }
};
exports.GaussBlur2DGenerator = GaussBlur2DGenerator;
exports.GaussBlur2DGenerator = GaussBlur2DGenerator = __decorate([
    (0, flit_1.define)('gauss-blur-2d-generator')
], GaussBlur2DGenerator);


/***/ }),

/***/ "./src/components/svg-polar-sampling.ts":
/*!**********************************************!*\
  !*** ./src/components/svg-polar-sampling.ts ***!
  \**********************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SVGPolarSampling = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const flit_ui_1 = __webpack_require__(/*! @pucelle/flit-ui */ "./node_modules/@pucelle/flit-ui/out/index.js");
const vector4_1 = __webpack_require__(/*! ../libs/math/vector4 */ "./src/libs/math/vector4.ts");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
let SVGPolarSampling = class SVGPolarSampling extends flit_1.Component {
    code = '';
    output = '';
    polarRadius = new Array(360);
    svgRect;
    svgCenter;
    render() {
        return (0, flit_1.html) `
		<template class="polar-sampling">
			<f-textarea @change=${this.onTextareaChange} .placeholder="在这里黏贴 SVG 代码, 请确保你的代码使用 stroke 描边路径" />
			<button @click=${this.generate} :enable=${this.code}>生成极坐标采样数据</button>
			<f-input .value=${this.output} .placeholder="点击上面的按钮然后在此拷贝" />
		</template>
		`;
    }
    onTextareaChange(code) {
        this.code = code;
    }
    generate() {
        let div = document.createElement('div');
        div.style.cssText = 'dispaly: fixed; left: 0; top: 0; visibility: hidden;';
        div.innerHTML = this.code;
        let svg = div.querySelector('svg');
        if (!svg) {
            flit_ui_1.notification.error(`未包含任何 "<svg>".`);
            throw '';
        }
        document.body.append(div);
        let paths = div.querySelectorAll('path');
        if (!paths.length) {
            flit_ui_1.notification.error(`未包含任何 "<path>".`);
            throw '';
        }
        this.svgRect = svg.getBBox();
        this.svgCenter = new vector4_1.Vector2(this.svgRect.x + this.svgRect.width / 2, this.svgRect.y + this.svgRect.height / 2);
        for (let path of paths) {
            this.processPath(path);
        }
        this.makesureAllRadiusFilled();
        let diagonalLength = new vector4_1.Vector2(this.svgRect.width, this.svgRect.height).length() / 2;
        let relativePolarRadius = this.polarRadius.map(v => (0, ff_1.toDecimal)(v / diagonalLength, 4));
        this.output = JSON.stringify(relativePolarRadius);
    }
    processPath(path) {
        let totalLength = path.getTotalLength();
        let step = Math.min(this.svgRect.width, this.svgRect.height) / 2 * Math.PI / 180; // 大约 1° 对应的弧长.
        let lastAngle = null;
        let lastLength = 0;
        for (let l = 0; l < totalLength; l += step) {
            [lastAngle, lastLength] = this.processLengthAtPath(path, l, lastAngle, lastLength);
        }
        this.processLengthAtPath(path, totalLength, lastAngle, lastLength);
    }
    processLengthAtPath(path, length, lastAngle, lastLength) {
        let coord = path.getPointAtLength(length);
        let vector = new vector4_1.Vector2(coord.x - this.svgCenter.x, -(coord.y - this.svgCenter.y)); // 注意由于坐标轴 Y 轴相反, 我们把 Y 取负值.
        let angle = Math.atan2(vector.y, vector.x) / Math.PI * 180;
        if (lastAngle !== null) {
            lastAngle = this.fixAngleFrom(lastAngle, angle);
            if (Math.abs(angle - lastAngle) > 5) {
                flit_ui_1.notification.error(`过大的采样跨度, 请确保你的 SVG 路径为单一的 stroke 描边路径, 您可以使用 Adobe Illustrator 进行编辑`);
                throw '';
            }
            this.markRadiusAtIntegarAngle(path, lastAngle, lastLength, angle, length);
        }
        return [angle, length];
    }
    fixAngleFrom(angle, fromAngle) {
        if (Math.abs(fromAngle - angle) > 180) {
            angle = fromAngle < 0 ? angle - 360 : angle + 360;
        }
        return angle;
    }
    markRadiusAtIntegarAngle(path, startAngle, startLength, endAngle, endLength) {
        // 确保角度增长, 则长度是否增长不确定.
        if (startAngle > endAngle) {
            [startAngle, endAngle] = [endAngle, startAngle];
            [startLength, endLength] = [endLength, startLength];
        }
        let startIntAngle = Math.ceil(startAngle);
        let endIntAngle = Math.floor(endAngle);
        for (let i = startIntAngle; i <= endIntAngle; i++) {
            let positiveIndex = (i + 360) % 360;
            this.polarRadius[positiveIndex] = this.binarySearchRadius(path, i, startLength, endLength);
        }
    }
    binarySearchRadius(path, intAngle, startLength, endLength) {
        let vector;
        // 此时角度增长, 长度是否增长不确定.
        // 需要达到小数点 4 位精度.
        for (let i = 0; i < 20; i++) {
            let centerLength = (startLength + endLength) / 2;
            let coord = path.getPointAtLength(centerLength);
            vector = new vector4_1.Vector2(coord.x - this.svgCenter.x, -(coord.y - this.svgCenter.y));
            let angle = Math.atan2(vector.y, vector.x) / Math.PI * 180;
            angle = this.fixAngleFrom(angle, intAngle);
            if (angle > intAngle) {
                endLength = centerLength;
            }
            else if (angle < intAngle) {
                startLength = centerLength;
            }
            else {
                break;
            }
        }
        return vector.length();
    }
    makesureAllRadiusFilled() {
        let filledCount = this.polarRadius.filter(v => v !== undefined).length;
        if (filledCount < 2) {
            flit_ui_1.notification.error(`采样到的数据少于两个.`);
            throw '';
        }
        for (let i = 0; i < this.polarRadius.length; i++) {
            if (this.polarRadius[i] === undefined) {
                this.makesureRadiusFilled(i);
            }
        }
    }
    makesureRadiusFilled(index) {
        let prevIndex = index;
        let nextIndex = index;
        let prevValue = 0;
        let nextValue = 0;
        while (prevIndex-- > -360) {
            let prevValue = this.polarRadius[(prevIndex + 360) % 360];
            if (prevValue !== undefined) {
                break;
            }
        }
        while (nextIndex++ < 720) {
            let nextValue = this.polarRadius[(nextIndex + 360) % 360];
            if (nextValue !== undefined) {
                break;
            }
        }
        this.polarRadius[index] = (prevValue * (nextIndex - index) + nextValue * (index - prevIndex)) / (nextIndex - prevIndex);
    }
};
exports.SVGPolarSampling = SVGPolarSampling;
exports.SVGPolarSampling = SVGPolarSampling = __decorate([
    (0, flit_1.define)('svg-polar-sampling')
], SVGPolarSampling);


/***/ }),

/***/ "./src/components/theme.ts":
/*!*********************************!*\
  !*** ./src/components/theme.ts ***!
  \*********************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ThemeSelect = void 0;
const flit_ui_1 = __webpack_require__(/*! @pucelle/flit-ui */ "./node_modules/@pucelle/flit-ui/out/index.js");
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
let ThemeSelect = class ThemeSelect extends flit_1.Component {
    theme = ff_1.storage.get('theme', 'light');
    render() {
        return (0, flit_1.html) `
		<template class="theme">
			<div class="theme-light-btn" @click=${() => this.setTheme('light')} :tooltip="白色主题"></div>
			<div class="theme-dark-btn" @click=${() => this.setTheme('dark')} :tooltip="黑色主题"></div>
		</template>
		`;
    }
    onCreated() {
        if (this.theme === 'dark') {
            flit_ui_1.theme.changeTheme('dark');
        }
        this.watchImmediately(() => flit_ui_1.theme.mode, (mode) => {
            document.body.classList.remove('theme-light', 'theme-dark');
            document.body.classList.add('theme-' + mode);
        });
    }
    setTheme(name) {
        flit_ui_1.theme.changeTheme(name);
        ff_1.storage.set('theme', name);
    }
};
exports.ThemeSelect = ThemeSelect;
exports.ThemeSelect = ThemeSelect = __decorate([
    (0, flit_1.define)('theme-select')
], ThemeSelect);


/***/ }),

/***/ "./src/docs.ts":
/*!*********************!*\
  !*** ./src/docs.ts ***!
  \*********************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.GLDocs = void 0;
const flit_ui_1 = __webpack_require__(/*! @pucelle/flit-ui */ "./node_modules/@pucelle/flit-ui/out/index.js");
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const flit = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
const aegl_1 = __webpack_require__(/*! ./aegl */ "./src/aegl/index.ts");
window.flit = flit;
flit_ui_1.theme.changeTheme('large');
let GLDocs = class GLDocs extends flit_1.Component {
    pageName = location.hash.slice(1) || 'about';
    navData = [
        { value: 'about', text: '关于 (About)' },
        // {value: 'environment', text: '环境'},
        // {value: 'code-standard', text: '代码规范'},
        { value: 'references/', text: '参考 (References)', children: [
                { value: 'references/computer-graphics', text: '计算机图形学 (Computer Graphics)' },
                { value: 'references/computational-geometry', text: '计算几何 (Computational Geometry)' },
            ] },
        { value: 'math/', text: '数学 (Math)', children: [
                { value: 'math/function-fitting', text: '函数拟合 (Function Fitting)' },
                { value: 'math/continuous', text: '连续 (Continous)' },
                { value: 'math/vector-modeling', text: '向量建模 (Vector Modeling)' },
                { value: 'math/filtering', text: '滤波 (Filtering)' },
                { value: 'math/gradient-sampling', text: '梯度采样 (Gradient Sampling)' },
                { value: 'math/transform', text: '变换的数学原理 (Transform)' },
            ] },
        { value: 'algorithms/', text: '算法 (Algorithms)', children: [
                { value: 'algorithms/easing', text: '缓动 (Easing)' },
                { value: 'algorithms/blur', text: '模糊 (Blur)' },
            ] },
        { value: 'opengl/', text: 'OpenGL', children: [
                { value: 'opengl/architecture', text: '架构 (Architecture)' },
                { value: 'opengl/shader-program', text: '着色程序 (Shader Program)' },
                { value: 'opengl/vertex', text: '顶点数据 (Vertex Data)' },
                { value: 'opengl/texture-units', text: '纹理单元 (Texture Units)' },
                { value: 'opengl/sampling', text: '采样 (Sampling)' },
                { value: 'opengl/glsl', text: 'GLSL' },
                { value: 'opengl/performance', text: '性能 (Performance)' },
                { value: 'opengl/blending', text: '混合 (blending)' },
            ] },
        { value: 'color-correction/', text: '调色 (Color Grading)', children: [
                { value: 'color-correction/color-balance', text: '色彩平衡 (Color Balance)' },
                { value: 'color-correction/lightness', text: '亮度 (Lightness)' },
                { value: 'color-correction/exposure', text: '曝光度 (Exposure)' },
                { value: 'color-correction/contrast', text: '对比度 (Contrast)' },
                { value: 'color-correction/saturation', text: '饱和度 (Saturation)' },
                { value: 'color-correction/vibrance', text: '自然饱和度 (Vibrance)' },
                { value: 'color-correction/hue', text: '色相 (Hue)' },
                { value: 'color-correction/hue-by-color', text: '单色色相 (Hue)' },
                { value: 'color-correction/saturation-by-color', text: '单色饱和度 (Saturation)' },
                { value: 'color-correction/lightness-by-color', text: '单色亮度 (Lightness)' },
                { value: 'color-correction/shadows', text: '阴影 (Shadows)' },
                { value: 'color-correction/highlights', text: '高光 (Highlights)' },
            ] },
        // {value: 'bg-erase', text: '抠图', children: [
        // 	{value: 'bg-erase/green-screen', text: '绿幕抠图 (Erase Green Screen)'},
        // 	{value: 'bg-erase/erase-by-mask', text: '蒙版抠图 (Erase by Mask)'},
        // ]},
        { value: 'transitions/', text: '转场 (Transitions)', children: [
                { value: 'transitions/geometry', text: '几何 (Geometry)', children: [
                        { value: 'transitions/geometry/push', text: '滑动 (Push)' },
                        { value: 'transitions/geometry/wipe', text: '擦除 (Wipe)' },
                        { value: 'transitions/geometry/slant-wipe', text: '斜线擦除 (Slant-Wipe)' },
                        { value: 'transitions/geometry/radar', text: '雷达 (Radar)' },
                        { value: 'transitions/geometry/rays', text: '射线 (Rays)' },
                        { value: 'transitions/geometry/enlarge', text: '放大 (Enlarge)' },
                        { value: 'transitions/geometry/alternate', text: '轮换 (Alternate)' },
                        { value: 'transitions/geometry/shuffle', text: '洗牌 (Shuffle)' },
                        { value: 'transitions/geometry/split', text: '分割 (Split)' },
                        { value: 'transitions/geometry/face-transform', text: '脸部变换 (Face Transform)' },
                    ] },
                { value: 'transitions/pixelate', text: '像素化 (Pixelate)', children: [
                        { value: 'transitions/pixelate/cube-pixelate', text: '方格像素化 (Cube Pixelate)' },
                        { value: 'transitions/pixelate/hexagon-pixelate', text: '六边形像素化 (Hexagon Pixelate)' },
                    ] },
                { value: 'transitions/dissolve', text: '溶解 (Dissolve)', children: [
                        { value: 'transitions/dissolve/fade', text: '淡入淡出 (Fade)' },
                        { value: 'transitions/dissolve/flash', text: '闪烁 (Flash)' },
                        { value: 'transitions/dissolve/mask', text: '蒙版 (Mask)' },
                        { value: 'transitions/dissolve/mask-fade', text: '渐变蒙版 (Mask Fade)' },
                        { value: 'transitions/dissolve/mask-of-shape', text: '形状蒙版 (Mask of Shape)' },
                        { value: 'transitions/dissolve/mask-of-polar-sampling', text: '极坐标采样蒙版 (Mask of Polar Sampling)' },
                    ] },
                { value: 'transitions/distortion', text: '扭曲 (Distortion)', children: [
                        { value: 'transitions/distortion/morph', text: '变形 (Morph)' },
                        { value: 'transitions/distortion/color-offset', text: '颜色偏离 (Color Offset)' },
                        { value: 'transitions/distortion/fly-eye', text: '蝇眼 (Fly Eye)' },
                        { value: 'transitions/wave', text: '波浪 (Wave)' },
                    ] },
                { value: 'transitions/blur', text: '模糊 (Blur)', children: [
                        { value: 'transitions/blur/zoom-blur', text: '缩放模糊 (Zoom Blur)' },
                        { value: 'transitions/blur/motion-blur', text: '运动模糊 (Motion Blur)' },
                    ] },
                { value: 'transitions/stripe-or-grid', text: '条纹和网格 (Stripe or Grid)', children: [
                        { value: 'transitions/stripe-or-grid/stripe-merge', text: '条纹合并 (Stripe-Merge)' },
                        { value: 'transitions/stripe-or-grid/grid-zoom', text: '网格缩放 (Grid Zoom)' },
                        { value: 'transitions/stripe-or-grid/shutter', text: '百叶窗 (Shutter)' },
                    ] },
                { value: 'transitions/3d', text: '3D', children: [
                        { value: 'transitions/3d/page-curl', text: '卷页 (Page Curl)' },
                        { value: 'transitions/3d/cube', text: '立方体 (Cube)' },
                    ] },
                // {value: 'transitions/analysis', text: '逆向分析', children: [
                // 	{value: 'transitions/analysis/video-editor', text: 'Video Editor'},
                // 	{value: 'transitions/analysis/filmora', text: 'Filmora'},
                // 	{value: 'transitions/analysis/gl-transitions', text: 'GLTransitions'},
                // 	{value: 'transitions/analysis/shadertoy', text: 'ShaderToy'},
                // ]},
            ] },
        { value: 'aegl/', text: 'AEGL', children: [
            // {value: 'aegl/compare-to-ae', text: '和 AE 的渲染区别'},
            // {value: 'aegl/architecture', text: 'AEGL 架构'},
            ] },
        // {value: 'tools', text: '工具', children: [
        // 	{value: 'tools/fix-video-black-surrounding', text: '修正视频半透明黑边'},
        // ]}
    ];
    aeglTemplateList;
    render() {
        return (0, flit_1.html) `
		<template class="docs">
			<div class="wrapper docs-wrapper">
				<f-navigation :ref="navigation" class="navigation" @navigate=${this.navigateTo} .data=${this.navData} .active=${this.pageName} />
				<div class="content" :ref="content"></div>
			</div>
		</template>
		`;
    }
    onCreated() {
        this.watchImmediately(() => flit_ui_1.theme.mode, (mode) => {
            document.body.classList.remove('theme-light', 'theme-dark');
            document.body.classList.add('theme-' + mode);
        });
    }
    async onReady() {
        await this.loadAEGLTemplateList();
        await this.load(this.pageName);
        window.onhashchange = () => {
            this.navigateTo(location.hash.slice(1));
        };
    }
    async loadAEGLTemplateList() {
        this.aeglTemplateList = await aegl_1.TemplateList.get();
        let navMenu = this.navData.find(v => v.value === 'aegl/');
        let listItems = this.aeglTemplateList.map(({ id, name }) => {
            return { value: `aegl/${id}`, text: `${name}` };
        });
        navMenu.children.push(...listItems);
    }
    async navigateTo(value) {
        if (this.pageName !== value) {
            this.pageName = value;
            location.hash = '#' + value;
            this.load(value);
        }
    }
    async load(value) {
        if (/^aegl\/(\d+)$/.test(value)) {
            let id = Number((0, ff_1.firstMatch)(value, /^aegl\/(\d+)$/));
            let { name } = this.aeglTemplateList.find(v => v.id === id);
            let code = `
# ${id} - ${name}
<aegl-preview .id="${id}"></aegl-preview>
`;
            this.loadHTML(marked(code));
        }
        else {
            let url = 'md/' + value.replace(/\/$/, '/index') + '.md';
            let res = await fetch(url, { credentials: 'include' });
            let code = await res.text();
            this.loadHTML(marked(code));
        }
    }
    async loadHTML(html) {
        let result = new flit_1.TemplateResult('html', [html], []);
        this.refs.content.innerHTML = '';
        this.refs.content.append((0, flit_1.render)(result, this).fragment);
        this.refs.content.querySelectorAll('pre[class^="language-"]').forEach((pre) => {
            Prism.highlightElement(pre);
        });
        MathJax.typeset();
    }
};
exports.GLDocs = GLDocs;
exports.GLDocs = GLDocs = __decorate([
    (0, flit_1.define)('gl-docs')
], GLDocs);


/***/ }),

/***/ "./src/index.ts":
/*!**********************!*\
  !*** ./src/index.ts ***!
  \**********************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __exportStar = (this && this.__exportStar) || function(m, exports) {
    for (var p in m) if (p !== "default" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
__exportStar(__webpack_require__(/*! ./docs */ "./src/docs.ts"), exports);
__exportStar(__webpack_require__(/*! ./components/theme */ "./src/components/theme.ts"), exports);
__exportStar(__webpack_require__(/*! ./components/function-curve */ "./src/components/function-curve.ts"), exports);
__exportStar(__webpack_require__(/*! ./components/function-generator */ "./src/components/function-generator.ts"), exports);
__exportStar(__webpack_require__(/*! ./components/svg-polar-sampling */ "./src/components/svg-polar-sampling.ts"), exports);
__exportStar(__webpack_require__(/*! ./components/gauss-blur-generator */ "./src/components/gauss-blur-generator.ts"), exports);
__exportStar(__webpack_require__(/*! ./tools/fix-video-black-surrounding */ "./src/tools/fix-video-black-surrounding.ts"), exports);
__exportStar(__webpack_require__(/*! ./color-correction/color-correction-preview */ "./src/color-correction/color-correction-preview.ts"), exports);
__exportStar(__webpack_require__(/*! ./bg-erase/green-screen-preview */ "./src/bg-erase/green-screen-preview.ts"), exports);
__exportStar(__webpack_require__(/*! ./bg-erase/bg-erase-preview */ "./src/bg-erase/bg-erase-preview.ts"), exports);
__exportStar(__webpack_require__(/*! ./transitions/transition-preview */ "./src/transitions/transition-preview.ts"), exports);
__exportStar(__webpack_require__(/*! ./transitions/face-transform-preview */ "./src/transitions/face-transform-preview.ts"), exports);
__webpack_require__(/*! ./transition-samples */ "./src/transition-samples/index.ts");
__exportStar(__webpack_require__(/*! ./aegl-ui/aegl-preview */ "./src/aegl-ui/aegl-preview.ts"), exports);


/***/ }),

/***/ "./src/libs/area/paint-area.ts":
/*!*************************************!*\
  !*** ./src/libs/area/paint-area.ts ***!
  \*************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.PaintArea = void 0;
const rect_area_1 = __webpack_require__(/*! ./rect-area */ "./src/libs/area/rect-area.ts");
/**
 * 将绘制区域和 RectArea 分离是为了方便更换矩形或者凸多边形区域.
 * 此外可以更方便处理空绘制区域.
 */
var PaintArea;
(function (PaintArea) {
    /** 从多个坐标获得包含他们的最小绘制区域. */
    function fromCoords(coords) {
        return rect_area_1.RectArea.fromCoords(coords);
    }
    PaintArea.fromCoords = fromCoords;
    /** 合并多个区域为到第一个区域. */
    function union(areas) {
        let availableAreas = areas.filter(area => area);
        return rect_area_1.RectArea.union(availableAreas);
    }
    PaintArea.union = union;
    /** 求交多个区域到第一个区域. 如果没有相交则返回 null. */
    function cross(areas) {
        let availableAreas = areas.filter(area => area);
        return rect_area_1.RectArea.cross(availableAreas);
    }
    PaintArea.cross = cross;
})(PaintArea || (exports.PaintArea = PaintArea = {}));


/***/ }),

/***/ "./src/libs/area/rect-area.ts":
/*!************************************!*\
  !*** ./src/libs/area/rect-area.ts ***!
  \************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.RectArea = void 0;
const vector4_1 = __webpack_require__(/*! ../math/vector4 */ "./src/libs/math/vector4.ts");
/**
 * 用于存储某个绘制的顶点范围, 坐标轴为左上角开始的视频分辨率坐标.
 * 由于渲染包含大量的后期着色, 总是全屏着色会让 GPU 不堪重负, 尤其是文字.
 * 所以使用渲染区域检测会大大减少像素着色数量.
 * 此类未来将会升级为凸包检测.
 */
class RectArea {
    /** 合并多个矩形区域. */
    static union(areas) {
        if (areas.length === 0) {
            return null;
        }
        let area = areas[0].clone();
        for (let i = 1; i < areas.length; i++) {
            area.unionWith(areas[i]);
        }
        return area;
    }
    /** 求交多个矩形区域. 如果没有相交则返回 null. */
    static cross(areas) {
        if (areas.length === 0) {
            return null;
        }
        let area = areas[0].clone();
        for (let i = 1; i < areas.length; i++) {
            area.crossWith(areas[i]);
        }
        if (!area.isAvailable()) {
            return null;
        }
        return area;
    }
    /** 从多个坐标获得包含他们的最小矩形区域. */
    static fromCoords(coords) {
        if (coords.length === 0) {
            return null;
        }
        let x1 = Infinity;
        let x2 = -Infinity;
        let y1 = Infinity;
        let y2 = -Infinity;
        for (let i = 0; i < coords.length; i++) {
            let { x, y } = coords[i];
            x1 = Math.min(x1, x);
            x2 = Math.max(x2, x);
            y1 = Math.min(y1, y);
            y2 = Math.max(y2, y);
        }
        return new RectArea(x1, y1, x2, y2);
    }
    x1;
    y1;
    x2;
    y2;
    constructor(x1, y1, x2, y2) {
        this.x1 = x1;
        this.y1 = y1;
        this.x2 = x2;
        this.y2 = y2;
    }
    /** 获得区域宽度. */
    get width() {
        return this.x2 - this.x1;
    }
    /** 获得区域高度. */
    get height() {
        return this.y2 - this.y1;
    }
    /** 返回当前区域是否实际占据空间. */
    isAvailable() {
        return this.x1 < this.x2 && this.y1 < this.y2;
    }
    /** 复制一份. */
    clone() {
        let { x1, y1, x2, y2 } = this;
        return new RectArea(x1, y1, x2, y2);
    }
    /** 在当前对象上进行缩放. */
    scaleSelf(scaleX, scaleY = scaleX) {
        this.x1 *= scaleX;
        this.y1 *= scaleY;
        this.x2 *= scaleX;
        this.y2 *= scaleY;
        return this;
    }
    /** 复制一份并且进行缩放. */
    scale(scaleX, scaleY = scaleX) {
        return this.clone().scaleSelf(scaleX, scaleY);
    }
    /** 扩展半径范围, 作用于自己身上. */
    extendSelf(x, y = x) {
        this.x1 -= x;
        this.y1 -= y;
        this.x2 += x;
        this.y2 += y;
        return this;
    }
    /** 复制一份并且进行扩展. */
    extend(x, y = x) {
        return this.clone().extendSelf(x, y);
    }
    /** 将四角的坐标都乘以一个矩阵, 返回一个新的矩形区域.. */
    multiplyBy(matrix) {
        let coords = this.getCoords();
        let newCoords = coords.map(coord => matrix.transfer2(coord));
        return RectArea.fromCoords(newCoords);
    }
    /** 移动矩形区域, 作用于自己身上. */
    translateSelf(x, y) {
        this.x1 += x;
        this.y1 += y;
        this.x2 += x;
        this.y2 += y;
        return this;
    }
    /** 移动矩形区域. */
    translate(x, y) {
        return this.clone().translateSelf(x, y);
    }
    /** 将所有的参数向外取整. */
    roundSelf() {
        this.x1 = Math.floor(this.x1);
        this.y1 = Math.floor(this.y1);
        this.x2 = Math.ceil(this.x2);
        this.y2 = Math.ceil(this.y2);
        return this;
    }
    /** 将所有的参数向外取整. */
    round() {
        return this.clone().roundSelf();
    }
    /** 合并另一个区域. */
    unionWith(area) {
        this.x1 = Math.min(this.x1, area.x1);
        this.y1 = Math.min(this.y1, area.y1);
        this.x2 = Math.max(this.x2, area.x2);
        this.y2 = Math.max(this.y2, area.y2);
        return this;
    }
    /** 和另一个区域求交. */
    crossWith(area) {
        this.x1 = Math.max(this.x1, area.x1);
        this.y1 = Math.max(this.y1, area.y1);
        this.x2 = Math.max(Math.min(this.x2, area.x2), this.x1);
        this.y2 = Math.max(Math.min(this.y2, area.y2), this.y1);
        return this;
    }
    /** 获得四角坐标构成的矢量. */
    getCoords() {
        let { x1, y1, x2, y2 } = this;
        return [
            new vector4_1.Vector2(x1, y1),
            new vector4_1.Vector2(x1, y2),
            new vector4_1.Vector2(x2, y1),
            new vector4_1.Vector2(x2, y2),
        ];
    }
    /** 获得四角坐标对应的数字. */
    getNumCoords() {
        let { x1, y1, x2, y2 } = this;
        return [
            [x1, y1],
            [x1, y2],
            [x2, y1],
            [x2, y2],
        ];
    }
}
exports.RectArea = RectArea;


/***/ }),

/***/ "./src/libs/curves/polygon-line.ts":
/*!*****************************************!*\
  !*** ./src/libs/curves/polygon-line.ts ***!
  \*****************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.triangulatePolygonLine = void 0;
const vector4_1 = __webpack_require__(/*! ../math/vector4 */ "./src/libs/math/vector4.ts");
/** 计算结果的误差范围. */
const EPSILON = 1.0e-9;
/**
 * 将多边形的描边带进行三角化剖分.
 * close 指定是否闭合, 指定为 true 时将顶点首尾连接.
 * 注意这只是一个最简单的情况, 它假设了任意的两个线段都不会发生重叠.
 */
function triangulatePolygonLine(numCoords, strokeWidth, close) {
    if (numCoords.length < 2) {
        return [];
    }
    let coords = numCoords.map(v => new vector4_1.Vector2(v[0], v[1]));
    // 顺时针和逆时针方向的线段交点.
    let corssCoords = [];
    for (let i = 0; i < coords.length; i++) {
        let prev = i === 0 ? close ? coords[coords.length - 1] : null : coords[i - 1];
        let current = coords[i];
        let next = i === coords.length - 1 ? close ? coords[0] : null : coords[i + 1];
        // 0~1 之间的线性, 起点位置向两边延伸.
        if (!prev) {
            corssCoords.push(getSegmentEndCoords(next, current, strokeWidth).reverse());
        }
        // 终点位置向两边延伸.
        else if (!next) {
            corssCoords.push(getSegmentEndCoords(prev, current, strokeWidth));
        }
        // 两个线段的中间交点.
        else {
            corssCoords.push(getTwoSegmentsCrossCoords(prev, current, next, strokeWidth));
        }
    }
    // 输出条带类型坐标, 三角形为顺时针方向组织, 适用于左上角为原点的坐标系.
    let stripeCoords = [];
    for (let i = 0; i < corssCoords.length; i++) {
        let [clockwiseCoord, antiClockwiseCoord] = corssCoords[i];
        stripeCoords.push(clockwiseCoord.xy, antiClockwiseCoord.xy);
    }
    // 如果封闭, 将第一个顶点再写入.
    if (close) {
        stripeCoords.push(corssCoords[0][0].xy, corssCoords[0][1].xy);
    }
    return stripeCoords;
}
exports.triangulatePolygonLine = triangulatePolygonLine;
/** 从顺序的两个点获得指定的宽度线段的顺时针和逆时针方向的两个结束点. */
function getSegmentEndCoords(coord1, coord2, strokeWidth) {
    // 坐标 1 到 2 的向量.
    let v = coord2.minus(coord1);
    v.normalizeSelf().multiplyScalarSelf(strokeWidth / 2);
    let clockwiseCoord = coord2.add(v.rotate(Math.PI / 2));
    let antiClockwiseCoord = coord2.add(v.rotate(-Math.PI / 2));
    return [clockwiseCoord, antiClockwiseCoord];
}
/** 从顺序的三个点获得两个指定宽度线段的顺时针和逆时针方向的交点. */
function getTwoSegmentsCrossCoords(coord1, coord2, coord3, strokeWidth) {
    let v1 = coord1.minus(coord2).normalizeSelf();
    let v2 = coord3.minus(coord2).normalizeSelf();
    // 计算角平分线向量, 其长度等于 2cos(θ), θ 为一半夹角.
    let halvingV = v1.add(v2);
    let halvingVLength = halvingV.length();
    // 如果两个线段基本平行.
    if (halvingVLength < EPSILON) {
        return getSegmentEndCoords(coord1, coord2, strokeWidth);
    }
    else {
        // 计算 1 / sin(θ).
        let lengthToBe = 1 / Math.sqrt(1 - halvingVLength * halvingVLength / 4);
        // 缩放角平分线向量以刚好和线段中间外侧交点对齐.
        halvingV.multiplyScalarSelf(strokeWidth / 2 * lengthToBe / halvingVLength);
        // 如果 v 到 v1 的旋转角小于 180°, 则 c2 + v 为顺时针交点.
        if (halvingV.cross(v1) > 0) {
            return [
                coord2.add(halvingV),
                coord2.minus(halvingV),
            ];
        }
        else {
            return [
                coord2.minus(halvingV),
                coord2.add(halvingV),
            ];
        }
    }
}


/***/ }),

/***/ "./src/libs/ffmpeg/ffmpeg.ts":
/*!***********************************!*\
  !*** ./src/libs/ffmpeg/ffmpeg.ts ***!
  \***********************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ffmpeg = void 0;
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
const debug_1 = __webpack_require__(/*! ../util/debug */ "./src/libs/util/debug.ts");
const file_1 = __webpack_require__(/*! ../util/file */ "./src/libs/util/file.ts");
const work_queue_1 = __webpack_require__(/*! ./work-queue */ "./src/libs/ffmpeg/work-queue.ts");
const timestamp_1 = __webpack_require__(/*! ../util/timestamp */ "./src/libs/util/timestamp.ts");
// 使用的 ffmpeg 工程: https://github.com/purhya/ffmpeg.js
// 参考 Makefile 可以获得其对应的编解码器以及格式列表.
// 支持的格式: MP4, JPEG, PNG 编码; 以及 MP4, VP9, 图片解码.
var ffmpeg;
(function (ffmpeg) {
    /** Worker 路径. */
    let ffmpegWorkerPath = document.currentScript instanceof HTMLScriptElement
        ? (0, file_1.getPathParent)((0, file_1.getPathParent)(document.currentScript.src)) + '/libs/ffmpeg-worker.js'
        : 'libs/ffmpeg-worker.js';
    /** 设置 Worker 路径. */
    function configWorkerPath(workerPath) {
        ffmpegWorkerPath = workerPath;
    }
    ffmpeg.configWorkerPath = configWorkerPath;
    /**
     * 对应着一个 ffmpeg Worker, 它可以被复用.
     * Worker 首次启动大约耗时 300ms, 之后只耗时大约 50ms, 所以用不着重用.
     */
    class FFWorker {
        /** 内部使用的 Worker. */
        worker = null;
        /** 当中止时调用的函数. */
        onAbort = null;
        /** 等待 Worker 结束的 Promise. */
        terminatePromise = null;
        /** 等待 Worker 结束的 Promise 对应的 resolve. */
        terminateResolve = null;
        /** 运行 ffmpeg 指令. */
        async exec(files, args, onMessage) {
            // 必须转为字符串, 否则会出错.
            args = [
                '-hide_banner',
                ...args.map(v => String(v))
            ];
            let promise = new Promise(async (resolve, reject) => {
                let workerPath = await this.getWorkerJSURL();
                let worker = this.worker = new Worker(workerPath);
                // 中止 Worker 时.
                this.onAbort = () => {
                    onEnd();
                    reject('Terminated');
                };
                // 结束任务时清理.
                let onEnd = () => {
                    this.onAbort = null;
                    this.close();
                };
                // 出现错误时.
                worker.onerror = (err) => {
                    onEnd();
                    reject(err);
                };
                worker.onmessage = async (event) => {
                    let msg = event.data;
                    switch (msg.type) {
                        case "ready":
                            if (this.isWorkerFilesCrossedDomain()) {
                                worker.postMessage({
                                    type: 'set_wasm_url',
                                    url: await this.getWorkerWasmURL(),
                                });
                            }
                            worker.postMessage({
                                type: 'run',
                                MEMFS: files,
                                arguments: args.map(v => String(v)),
                            });
                            break;
                        case "stdout":
                        case "stderr":
                            // 在 wasm 的 build 中总是遇到这个错误,
                            // 它可能和代码块无法被运行到有关, 也有可能和异步有关.
                            // 不影响实际功能, 这里暂时将其屏蔽.
                            if (!msg.data.includes('RuntimeError: unreachable')) {
                                debug_1.debug.veryVerbose(msg.data);
                                onMessage(msg.data);
                            }
                            break;
                        case "exit":
                            // 目前 exit 会在 done 之前触发,
                            // 所以我们不处理它.
                            break;
                        case "abort":
                            onEnd();
                            reject(msg.data);
                            break;
                        case "done":
                            onEnd();
                            resolve(msg.data.MEMFS);
                            break;
                    }
                };
            });
            return promise;
        }
        /** 获取 Worker 脚本的可用地址. */
        async getWorkerJSURL() {
            if (this.isWorkerFilesCrossedDomain()) {
                let workerPath = (0, timestamp_1.addTimestamp)(ffmpegWorkerPath);
                let code = await (await fetch(workerPath)).text();
                let codeBlob = window.URL.createObjectURL(new Blob([code], {
                    type: 'application/javascript'
                }));
                return codeBlob;
            }
            else {
                return (0, timestamp_1.addTimestamp)(ffmpegWorkerPath);
            }
        }
        /** 检查 worker 脚本是否存放为跨域资源. */
        isWorkerFilesCrossedDomain() {
            let hostOfWorker = new URL(ffmpegWorkerPath).host;
            let crossedDomain = hostOfWorker !== location.host;
            return crossedDomain;
        }
        /** 获取 Worker wasm 文件的可用地址. */
        async getWorkerWasmURL() {
            return (0, timestamp_1.addTimestamp)(ffmpegWorkerPath.replace(/\.js($|\?.+)/, '.wasm$1'));
        }
        /** 运行 ffmpeg 指令以获取信息. */
        async info(args) {
            let messages = [];
            await this.exec([], args, (message) => {
                messages.push(message);
            });
            return messages;
        }
        /** 运行 ffmpeg 指令, 并且通报进度信息. */
        async execWithProgress(files, args, onProgress) {
            let onMessage = (message) => {
                let frameIndex = (0, ff_1.firstMatch)(message, /^frame=\s*(\d+) /);
                if (frameIndex) {
                    onProgress(Number(frameIndex));
                }
            };
            return this.exec(files, args, onMessage);
        }
        /** 运行 ffmpeg 指令, 并且通报进度信息. */
        async getExecMessages(files, args) {
            let messages = [];
            let onMessage = (message) => {
                messages.push(message);
            };
            await this.exec(files, args, onMessage);
            return messages;
        }
        /** 正常关闭 Worker. */
        close() {
            if (this.worker) {
                this.worker.terminate();
            }
            if (this.terminateResolve) {
                this.terminateResolve();
            }
        }
        /** 中止 Worker, 如果有正在运行的任务则会被中止. */
        abort() {
            if (this.onAbort) {
                this.onAbort();
            }
            if (this.worker) {
                this.worker.terminate();
            }
        }
        /**
         * 等待任务运行结束, 即便当前无任务运行, 它也会等待下一个任务运行结束.
         * 如果 worker 被 abort, 那么此 promise 不会被 resolve.
         */
        async waitForClose() {
            if (!this.terminatePromise) {
                this.terminatePromise = new Promise((resolve) => {
                    this.terminateResolve = resolve;
                });
            }
            await this.terminatePromise;
        }
    }
    ffmpeg.FFWorker = FFWorker;
    /** 用于启用多个 Worker 同时处理任务, 例如编码. */
    class WorkerGroup extends work_queue_1.WorkQueue {
        /** 创建一个 Worker. */
        create() {
            let worker = new FFWorker();
            worker.waitForClose().then(() => {
                this.delete(worker);
            });
            return worker;
        }
        /** 关闭所有的 Worker, 如果有正在运行的任务则中止. */
        abort() {
            for (let worker of this.workers) {
                worker.abort();
            }
            this.workers = [];
        }
    }
    ffmpeg.WorkerGroup = WorkerGroup;
    /** 默认的工作线程, 使用核心数默认为总核心数目 - 2. */
    ffmpeg.defaultWorkerGroup = new WorkerGroup(Math.max(navigator.hardwareConcurrency - 2, 1));
    /** 运行 ffmpeg 指令以获取信息. */
    async function info(args) {
        let worker = new FFWorker();
        let results = await worker.info(args);
        return results;
    }
    ffmpeg.info = info;
    /** 运行 ffmpeg 指令. */
    async function exec(files, args, onMessage) {
        let worker = new FFWorker();
        let results = await worker.exec(files, args, onMessage);
        return results;
    }
    ffmpeg.exec = exec;
    /** 运行 ffmpeg 指令, 并且通报进度信息. */
    async function execWithProgress(files, args, onProgress) {
        let worker = new FFWorker();
        let results = await worker.execWithProgress(files, args, onProgress);
        return results;
    }
    ffmpeg.execWithProgress = execWithProgress;
    /** 运行 ffmpeg 指令, 并且通报进度信息. */
    async function getExecMessages(files, args) {
        let worker = new FFWorker();
        let results = await worker.getExecMessages(files, args);
        return results;
    }
    ffmpeg.getExecMessages = getExecMessages;
    /** 将文件加入到一个 list.txt, 再将此文件加入到文件列表. */
    function listInputFiles(files) {
        let text = '';
        for (let file of files) {
            text += `file '${file.name}'\n`;
        }
        let listFile = {
            name: 'list.txt',
            data: stringToUint8Array(text.slice(0, -1)),
        };
        return [...files, listFile];
    }
    ffmpeg.listInputFiles = listInputFiles;
    /** 将 ASCII 字符串转为 UTF8 Bite Array. */
    function stringToUint8Array(string) {
        let ua = new Uint8Array(string.length);
        for (let i = 0; i < string.length; i++) {
            ua[i] = string.charCodeAt(i);
        }
        return ua;
    }
    /** 从路径加载数据以获得文件. */
    async function getFFFileFromPath(path) {
        let name = (0, file_1.getPathName)(path);
        let response = await fetch(path);
        if (!response.ok) {
            return Promise.reject(response.status);
        }
        let data = await response.arrayBuffer();
        return { name, data };
    }
    ffmpeg.getFFFileFromPath = getFFFileFromPath;
    /** 从路径加载数据以获得文件. */
    async function getFFFileFromFile(file) {
        let name = (0, file_1.getPathName)(file.name);
        let data = await (0, file_1.readBlobAsArrayBuffer)(file);
        return { name, data };
    }
    ffmpeg.getFFFileFromFile = getFFFileFromFile;
    /** 获得音视频信息, 仅适用于单通道音频. */
    async function getMediaInfo(file) {
        let messages = (await getExecMessages([file], [
            '-i', file.name
        ])).join('\n');
        let match = messages.match(/^  Duration: (.+?), .+?, bitrate: (\d+) kb\/s/m);
        let duration = match ? (0, ff_1.parseDurationToSeconds)(match[1]) : 0;
        let bitrate = match ? Number(match[2]) : 0;
        let metadata = parseMetadata((0, ff_1.firstMatch)(messages, /^ {2}Metadata:\n((?: {4}[\S].+\n)+)/m));
        let mediaInfo = {
            duration,
            bitrate,
            metadata,
        };
        let videoInfo = (0, ff_1.firstMatch)(messages, /^\s*Stream #0:\d.+?Video:(.+)/m).replace(/\(.+?\)/g, '');
        if (videoInfo) {
            let parts = videoInfo.split(',');
            let codec = parts[0].trim();
            let pixelFormat = parts[1].trim();
            let [width, height] = parts[2].match(/(\d+)x(\d+)/).map(v => Number(v)).slice(1);
            let bitrate = Number((0, ff_1.firstMatch)(videoInfo, /(\d+) kb\/s/)) || 0;
            let frameRate = Number((0, ff_1.firstMatch)(videoInfo, /([\d.]+) fps/)) || 0;
            let metadata = parseMetadata((0, ff_1.firstMatch)(messages, /^\s*Stream #0:\d.+?Video:.+\n {4}Metadata:\n((?: {6}[\S].+\n))+/m));
            mediaInfo.video = {
                codec,
                pixelFormat,
                width,
                height,
                bitrate,
                frameRate,
                metadata,
            };
        }
        let audioInfo = (0, ff_1.firstMatch)(messages, /^\s*Stream #0:\d.+?Audio:(.+)/).replace(/\(.+?\)/g, '');
        if (audioInfo) {
            let parts = audioInfo.split(',');
            let codec = parts[0].trim();
            let samplingRate = Number(parts[1].replace(/Hz/, ''));
            let mode = parts[2].trim();
            let bitrate = Number(parts[4].replace(/kb\/s/, ''));
            let metadata = parseMetadata((0, ff_1.firstMatch)(messages, /^\s*Stream #0:\d.+?Audio:.+\n {4}Metadata:\n((?: {6}[\S].+\n))+/m));
            mediaInfo.audio = {
                codec,
                samplingRate,
                mode,
                bitrate,
                metadata,
            };
        }
        return mediaInfo;
    }
    ffmpeg.getMediaInfo = getMediaInfo;
    /** 解析元数据. */
    function parseMetadata(string) {
        let matches = (0, ff_1.subMatches)(string, /^\s*(.+?)\s*:\s*(.+)/m);
        return (0, ff_1.indexBy)(matches, match => [match[0], match[1]]);
    }
    /** 下载 ffmpeg 文件. */
    function downloadFile(file) {
        let blob = new Blob([file.data]);
        let a = document.createElement('a');
        let url = URL.createObjectURL(blob);
        a.textContent = file.name;
        a.setAttribute('href', url);
        a.setAttribute('download', file.name);
        a.click();
    }
    ffmpeg.downloadFile = downloadFile;
})(ffmpeg || (exports.ffmpeg = ffmpeg = {}));


/***/ }),

/***/ "./src/libs/ffmpeg/work-queue.ts":
/*!***************************************!*\
  !*** ./src/libs/ffmpeg/work-queue.ts ***!
  \***************************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.WorkQueue = void 0;
/** 用于请求资源并且并行执行任务. */
class WorkQueue {
    /** 线程数目. */
    threadCount = 1;
    /** 用于存储正在运行的任务. */
    workers = [];
    /** 申请任务 的 Promise 对应的 resolve 队列. */
    requestResolves = [];
    /** 当至少一个线程闲置时被 resolve. */
    untilIdlePromise = null;
    /** 当至少一个线程闲置时触发的 Promise 对应的 resolve. */
    idleResolve = null;
    constructor(threadCount = 1) {
        this.threadCount = threadCount;
    }
    /** 配置核心数目. */
    configThreadCount(threadCount) {
        this.threadCount = Math.max(threadCount, 1);
    }
    /**
     * 申请一个闲置的 Worker.
     * 申请之后需要很快被使用, 否则将会拖慢或者阻塞任务运行.
     * 如果其申请后可能不被使用, 那么应当增加一个倒计时,
     * 例如在 5s 之后仍未被使用则抛出错误或者警告.
     */
    async request() {
        // 新建 Worker.
        if (this.workers.length < this.threadCount) {
            return this.createWorker();
        }
        // 进入等待序列以等待 Worker 闲置.
        else {
            return new Promise((resolve) => {
                this.requestResolves.push(resolve);
            });
        }
    }
    /** 创建 Worker. */
    createWorker() {
        let worker = this.create();
        this.workers.push(worker);
        if (!worker) {
            throw new Error(`Ensure each worker to be a meaningful and special value`);
        }
        return worker;
    }
    /** 移除 Worker. */
    delete(worker) {
        this.workers = this.workers.filter(w => w !== worker);
        this.checkReuqests();
    }
    /** 检查 Worker 请求是否可被满足, 如果可以的话则启动新的 worker. */
    checkReuqests() {
        while (this.requestResolves.length > 0) {
            let worker = this.createWorker();
            let resolve = this.requestResolves.shift();
            resolve(worker);
        }
        // 触发闲置 promise.
        if (this.workers.length < this.threadCount && this.idleResolve) {
            this.idleResolve();
            this.idleResolve = null;
            this.untilIdlePromise = null;
        }
    }
    /** 是否处于闲置状态. */
    isIdle() {
        // 不用检查 requestResolves 等待序列, 因为从闲置到处理等待系列之间没有停留.
        return this.workers.length < this.threadCount;
    }
    /** 等待直到至少一个线程闲置. */
    async untilIdle() {
        if (this.workers.length < this.threadCount) {
            return;
        }
        else if (this.untilIdlePromise) {
            return this.untilIdlePromise;
        }
        else {
            return this.untilIdlePromise = new Promise((resolve) => {
                this.idleResolve = resolve;
            });
        }
    }
}
exports.WorkQueue = WorkQueue;


/***/ }),

/***/ "./src/libs/math/bezier.ts":
/*!*********************************!*\
  !*** ./src/libs/math/bezier.ts ***!
  \*********************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.getCubicBezierEasingFunction = void 0;
/*
F(t)  = (1-t)^3 * P0 + 3t(1-t)^2 * P1 + 3t^2(1-t)^2 * P2 + t^3 * P3, t in [0, 1]

Get the x axis projecting function, and knows x0 = 0, x3 = 1, got:
Cx(t) = 3t(1-t)^2 * x1 + 3t^2(1-t) * x2 + t^3
      = (3x1 - 3x2 + 1) * t^3 + (-6x1 + 3x2) * t^2 + 3x1 * t

From Cx(t) = x, got t by binary iteration algorithm, then pass it to y axis projecting function:
Cy(t) = (3y1 - 3y2 + 1) * t^3 + (-6y1 + 3y2) * t^2 + 3y1 * t
*/
/**
 * 用于执行 0~1 范围的贝塞尔曲线计算.
 * 由于贝塞尔曲线具有仿射不变性, 所以其他范围的曲线可以映射为 0~1 的.
 */
function getCubicBezierEasingFunction(x1, y1, x2, y2) {
    let a = 3 * x1 - 3 * x2 + 1;
    let b = -6 * x1 + 3 * x2;
    let c = 3 * x1;
    let ay = 3 * y1 - 3 * y2 + 1;
    let by = -6 * y1 + 3 * y2;
    let cy = 3 * y1;
    function calcX(t) {
        return ((a * t + b) * t + c) * t;
    }
    return function (x) {
        if (x === 0) {
            return 0;
        }
        else if (x === 1) {
            return 1;
        }
        // 这用这两个参数, 大约会经历 15 次左右的迭代.
        let t1 = 0;
        let t2 = 1;
        let t = 0.5;
        while (t2 - t1 > 0.0001) {
            let v = calcX(t) - x;
            if (v < 0) {
                t1 = t;
            }
            else {
                t2 = t;
            }
            t = (t1 + t2) / 2;
        }
        return ((ay * t + by) * t + cy) * t;
    };
}
exports.getCubicBezierEasingFunction = getCubicBezierEasingFunction;


/***/ }),

/***/ "./src/libs/math/gauss-blur.ts":
/*!*************************************!*\
  !*** ./src/libs/math/gauss-blur.ts ***!
  \*************************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.generate2DGaussBlurPriorities = exports.generate1DGaussBlurPriorities = void 0;
// 高斯模糊在方差超过 3 之后几乎固定为 0, 而在 1.5 附近快速下降, 超过此范围的权重值因为太小而显得意义不大.
/** 生成高斯模糊的权重值. 它只返回从中心为 0 处到正半区 1.5 范围, 返回的值格式类似 [[-1, ?], [0, ?], [1, ?]]. */
function generate1DGaussBlurPriorities(radius) {
    let v = radius / 2 / 1.5;
    let total = 0;
    let values = [];
    for (let x = -radius / 2; x <= radius / 2; x++) {
        let priority = calc1DGaussValue(x, v);
        total += priority;
        values.push({
            x,
            p: priority
        });
    }
    values.forEach(v => v.p /= total);
    return values;
}
exports.generate1DGaussBlurPriorities = generate1DGaussBlurPriorities;
/** 计算高斯函数值. */
function calc1DGaussValue(x, v) {
    let exp = -x * x / (2 * v * v);
    return Math.pow(Math.E, exp) / (Math.sqrt(2 * Math.PI) * v);
}
// 高斯模糊在方差超过 3 之后几乎固定为 0, 而在 1.5 附近快速下降, 超过此范围的权重值因为太小而显得意义不大.
/** 生成二维高斯模糊的权重值. 它只返回从中心为 0 处到正半区 1.5 范围, 返回的值格式类似 [[-1, ?], [0, ?], [1, ?]]. */
function generate2DGaussBlurPriorities(radius) {
    let v = radius / 2 / 1.5;
    let total = 0;
    let values = [];
    for (let x = -radius / 2; x <= radius / 2; x++) {
        for (let y = -radius / 2; y <= radius / 2; y++) {
            let priority = calc2DGaussValue(x, y, v);
            total += priority;
            values.push({
                x,
                y,
                p: priority,
            });
        }
    }
    values.forEach(v => v.p /= total);
    return values;
}
exports.generate2DGaussBlurPriorities = generate2DGaussBlurPriorities;
/** 计算高斯函数值, 注意它移除了常量部分. */
function calc2DGaussValue(x, y, v) {
    let exp = -(x * x + y * y) / (2 * v * v);
    return Math.pow(Math.E, exp);
}


/***/ }),

/***/ "./src/libs/math/matrix.ts":
/*!*********************************!*\
  !*** ./src/libs/math/matrix.ts ***!
  \*********************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Matrix = void 0;
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
/**
 * 注意这里的所有数据格式是基于行主序的形式, 和线性代数中的矩阵结构保持一致.
 * 这个类是为处理线性代数问题设计的, 而不是为三维坐标的变换设计的.
 * 当进行 4 阶变换矩阵处理时, 应当使用 Matrix4, 它的效率会明显更高.
 */
class Matrix {
    /** 返回一个 rank 阶零矩阵. */
    static zero(rank) {
        let data = [];
        for (let i = 0; i < rank; i++) {
            data[i] = [];
            for (let j = 0; j < rank; j++) {
                data[i][j] = 0;
            }
        }
        return new Matrix(data);
    }
    /** 返回一个 rank 阶的单位矩阵. */
    static I(rank) {
        let data = [];
        for (let i = 0; i < rank; i++) {
            data[i] = [];
            for (let j = 0; j < rank; j++) {
                data[i][j] = i === j ? 1 : 0;
            }
        }
        return new Matrix(data);
    }
    /** 从列向量生成矩阵. */
    static fromVector(vector) {
        return Matrix.fromFlat(vector.values, 1);
    }
    /** 从多个列向量生成矩阵. */
    static fromVectors(...vectors) {
        return new Matrix(vectors.map(v => v.values)).transpose();
    }
    /** 从扁平的数据生成矩阵. */
    static fromFlat(flatData, colCount) {
        let data = [];
        let rowCount = flatData.length / colCount;
        for (let i = 0; i < rowCount; i++) {
            let row = [];
            data.push(row);
            for (let j = 0; j < colCount; j++) {
                row[j] = flatData[i * colCount + j];
            }
        }
        return new Matrix(data);
    }
    /** 矩阵数据, 二维数组格式, 每一个子数组都对应着一个矩阵的行. */
    data;
    constructor(data) {
        this.data = data;
    }
    /** 检查矩阵的数据格式是否正确. */
    validate() {
        let firstColCount = this.data[0].length;
        for (let line of this.data) {
            if (line.length !== firstColCount) {
                throw new Error('Matrix line data have different length');
            }
        }
    }
    /** 获得矩阵的行数. */
    get rowCount() {
        return this.data.length;
    }
    /** 获得矩阵的列数. */
    get columnCount() {
        return this.data[0] ? this.data[0].length : 0;
    }
    /** 打印矩阵. */
    print() {
        console.table(this.data);
    }
    /** 克隆矩阵. */
    clone() {
        return new Matrix(this.copyData());
    }
    /** 拷贝矩阵的 data. */
    copyData() {
        let data = this.data;
        let newData = [];
        let rows = this.rowCount;
        for (let i = 0; i < rows; i++) {
            newData[i] = data[i].concat();
        }
        return newData;
    }
    /** 获得矩阵的转置矩阵. */
    transpose() {
        let data = this.data;
        let rows = this.rowCount;
        let cols = this.columnCount;
        let newData = [];
        for (let i = 0; i < cols; i++) {
            newData[i] = [];
            for (let j = 0; j < rows; j++) {
                newData[i][j] = data[j][i];
            }
        }
        return new Matrix(newData);
    }
    /** 获得矩阵和另一个矩阵逐项求和的结果. */
    add(matrix) {
        if (this.rowCount !== matrix.rowCount) {
            throw 'Matrixs has different row count and cant add';
        }
        if (this.columnCount !== matrix.columnCount) {
            throw 'Matrixs has different column count and cant add';
        }
        let dl = this.data;
        let dr = matrix.data;
        let rows = this.rowCount;
        let cols = this.columnCount;
        let newData = [];
        for (let i = 0; i < rows; i++) {
            let rl = dl[i];
            let rr = dr[i];
            newData[i] = [];
            for (let j = 0; j < cols; j++) {
                newData[i][j] = rl[j] + rr[j];
            }
        }
        return new Matrix(newData);
    }
    /** 获得矩阵和另一个矩阵逐项相减的结果. */
    minus(matrix) {
        return this.add(matrix.multiplyScalar(-1));
    }
    /** 获得矩阵中的每一个元素和数字相乘的结果. */
    multiplyScalar(number) {
        let rows = this.rowCount;
        let cols = this.columnCount;
        let dl = this.data;
        let newData = [];
        for (let i = 0; i < rows; i++) {
            newData[i] = [];
            for (let j = 0; j < cols; j++) {
                newData[i][j] = dl[i][j] * number;
            }
        }
        return new Matrix(newData);
    }
    /** 获得矩阵作为左矩阵和另一个矩阵相乘的结果. */
    multiply(matrix) {
        let rows = this.rowCount;
        let cols = this.columnCount;
        let dl = this.data;
        let rRows = matrix.rowCount;
        let rCols = matrix.columnCount;
        let dr = matrix.data;
        if (cols !== rRows) {
            throw 'Matrixs cant multiple since the column count of first matrix does not match the row count of the second matrix';
        }
        let newData = [];
        for (let i = 0; i < rows; i++) {
            newData[i] = [];
            for (let j = 0; j < rCols; j++) {
                let value = 0;
                for (let k = 0; k < rRows; k++) {
                    value += dl[i][k] * dr[k][j];
                }
                newData[i][j] = value;
            }
        }
        return new Matrix(newData);
    }
    transferWithFollowedMatrix(I) {
        let rows = this.rowCount;
        let cols = this.columnCount;
        if (I && rows !== I.rowCount) {
            throw 'Matrix cant transfer since its followed data has different row count';
        }
        let dl = this.copyData();
        let dr = I ? I.data : null;
        let minRowCol = Math.min(rows, cols);
        let colsI = I ? I.columnCount : 0;
        let rank = 0;
        for (let i = 0; i < minRowCol; i++) {
            if (dl[i][i] === 0) {
                //find another row which the value of current column is nonzero, then swap two rows
                for (let j = i + 1; j < rows; j++) {
                    if (dl[j][i] !== 0) {
                        let temp = dl[i];
                        dl[i] = dl[j];
                        dl[j] = temp;
                        if (dr) {
                            temp = dr[i];
                            dr[i] = dr[j];
                            dr[j] = temp;
                        }
                        break;
                    }
                }
            }
            let midValue = dl[i][i];
            if (midValue === 0) {
                continue;
            }
            rank++;
            let rFactor = dl[i];
            let rFactorI = dr ? dr[i] : null;
            //all lower lines minus current line
            for (let j = i + 1; j < rows; j++) {
                let r = dl[j];
                let rI = dr ? dr[j] : null;
                let value = r[i];
                if (value !== 0) {
                    r[i] = 0;
                    let factor = -value / midValue;
                    for (let k = i + 1; k < cols; k++) {
                        r[k] = r[k] + factor * rFactor[k];
                    }
                    if (dr && rI && rFactorI) {
                        for (let k = 0; k < colsI; k++) {
                            rI[k] = rI[k] + factor * rFactorI[k];
                        }
                    }
                }
            }
        }
        for (let i = rank - 1; i >= 0; i--) {
            let rFactor = dl[i];
            let rFactorI = dr ? dr[i] : null;
            let midValue = rFactor[i];
            //all upper lines minus current line
            for (let j = i - 1; j >= 0; j--) {
                let r = dl[j];
                let rI = dr ? dr[j] : null;
                let value = r[i];
                r[i] = 0;
                if (value !== 0) {
                    let factor = -value / midValue;
                    for (let k = rank; k < cols; k++) {
                        r[k] = r[k] + factor * rFactor[k];
                    }
                    if (dr && rI && rFactorI) {
                        for (let k = 0; k < colsI; k++) {
                            rI[k] = rI[k] + factor * rFactorI[k];
                        }
                    }
                }
            }
            rFactor[i] = 1;
            for (let k = rank; k < cols; k++) {
                rFactor[k] = rFactor[k] / midValue;
            }
            if (dr && rFactorI) {
                for (let k = 0; k < colsI; k++) {
                    rFactorI[k] = rFactorI[k] / midValue;
                }
            }
        }
        return {
            transfer: dl,
            follower: dr,
            rank: rank
        };
    }
    /** 获得矩阵的秩. */
    rank() {
        return this.transferWithFollowedMatrix().rank;
    }
    /** 获得矩阵的逆矩阵. */
    inverse() {
        let rows = this.rowCount;
        let cols = this.columnCount;
        if (rows != cols) {
            throw 'Matrix cant generate reverse matrix since its row count not equals to column count';
        }
        let I = Matrix.I(rows);
        return new Matrix(this.transferWithFollowedMatrix(I).follower);
    }
    /** 解非齐次线性方程组 Ax = b, 获得解空间组成的矩阵. */
    solveNonHomogeneous(valueMatrix) {
        let rows = this.rowCount;
        let cols = this.columnCount;
        if (rows > cols) {
            throw 'Equation cant be solved since its row count less than column count';
        }
        if (valueMatrix.rowCount !== rows) {
            throw 'Equation cant be solved since the row count of value matrix not equals to row count of current matrix';
        }
        if (valueMatrix.columnCount !== 1) {
            throw 'Equation cant be solved since the column count of value matrix not equals to 1';
        }
        let o = this.transferWithFollowedMatrix(valueMatrix);
        if (o.rank !== rows) {
            for (let i = o.rank; i < rows; i++) {
                if ((0, ff_1.toDecimal)(o.follower[i][0], 8) !== 0) {
                    throw 'Equation has no solution';
                }
            }
        }
        let solutionData = o.follower;
        if (solutionData.length < cols) {
            for (let i = solutionData.length; i < cols; i++) {
                solutionData[i] = [0];
            }
        }
        return new Matrix(solutionData).transpose();
    }
    /** 解齐次线性方程组 Ax = 0, 获得解空间组成的矩阵. */
    solveHomogeneous() {
        let rows = this.rowCount;
        let cols = this.columnCount;
        if (rows > cols) {
            throw 'Equation cant be solved since its row count less than column count';
        }
        let o = this.transferWithFollowedMatrix();
        let data = o.transfer;
        let rank = o.rank;
        if (rank !== rows) {
            data = data.slice(0, o.rank);
        }
        // Solution list
        let solutions = [];
        for (let i = rank; i < cols; i++) {
            let solution = [];
            for (let j = 0; j < rank; j++) {
                solution[j] = -data[j][i];
            }
            for (let j = rank; j < cols; j++) {
                solution[j] = j === i ? 1 : 0;
            }
            solutions.push(solution);
        }
        return new Matrix(solutions);
    }
    /** 尝试修正数值计算的微小误差, 将数字和指定的小数位对齐. */
    fix(decimalCount = 8) {
        let data = this.data;
        let rows = this.rowCount;
        let cols = this.columnCount;
        for (let i = 0; i < rows; i++) {
            for (let j = 0; j < cols; j++) {
                data[i][j] = (0, ff_1.toDecimal)(data[i][j], decimalCount);
            }
        }
        return this;
    }
    /** 输出扁平化的行主序的格式. */
    rowMajorFlatten() {
        return this.data.flat();
    }
    /** 输出扁平化的列主序的格式. */
    columnMajorFlatten() {
        return this.transpose().data.flat();
    }
}
exports.Matrix = Matrix;


/***/ }),

/***/ "./src/libs/math/matrix4.ts":
/*!**********************************!*\
  !*** ./src/libs/math/matrix4.ts ***!
  \**********************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Matrix4 = exports.Matrix3 = exports.Matrix2 = void 0;
const vector4_1 = __webpack_require__(/*! ./vector4 */ "./src/libs/math/vector4.ts");
/*
以下矩阵类参考了 Three.js 的实现.
在开始的时候是一个通用矩阵类来实现的,
但是后来发现相比实现一个通用类来支持任意阶的 Matrix 运算,
这样的实现会带来至少 5 倍的运算效率提升.

什么时候选择 Self 方法:
注意这个方法并不是为了提升性能, 因为它对于性能的影响微乎其微,
使用这个方法时基于其语义, 例如一个变换对象, 它需要累积多个变换到自己身上,
那么此时应当使用 Self 方法.
*/
class Matrix2 {
    /** 返回默认单位矩阵, 其不可更改. */
    static I = Object.seal(new Matrix2());
    /** 返回一个零矩阵. */
    static zero() {
        return new Matrix2(0, 0, 0, 0);
    }
    /** 从多个向量创建矩阵. */
    static fromVectors(vector1, vector2) {
        return new Matrix2(vector1.x, vector2.x, vector1.y, vector2.y);
    }
    /** 内部计算使用列主序排列, 这样可以不用调整直接输出. */
    data;
    /** 传入的参数为行主序格式. */
    constructor(n11 = 1, n12 = 0, n21 = 0, n22 = 1) {
        this.set(n11, n12, n21, n22);
    }
    /** 基于行主序设置值. */
    set(n11, n12, n21, n22) {
        this.data = [
            n11, n21,
            n12, n22,
        ];
    }
    /** 克隆矩阵. */
    clone() {
        let [n11, n21, n12, n22,] = this.data;
        return new Matrix2(n11, n12, n21, n22);
    }
    /** 返回行主序的扁平数据格式. */
    flatten() {
        let [n11, n21, n12, n22,] = this.data;
        return [
            n11, n12,
            n21, n22,
        ];
    }
    /** 输出扁平化的列主序的格式. */
    toFloat32Array() {
        return new Float32Array(this.data);
    }
    /** 获得矩阵的转置矩阵. */
    transpose() {
        return this.clone().transposeSelf();
    }
    /** 转换为转置矩阵. */
    transposeSelf() {
        let [n11, n21, n12, n22,] = this.data;
        this.set(n11, n21, n12, n22);
        return this;
    }
    /** 获得矩阵和另一个矩阵逐项求和的结果. */
    add(matrix) {
        return this.clone().addSelf(matrix);
    }
    /** 加上另一个矩阵. */
    addSelf(matrix) {
        let [r11, r21, r12, r22,] = matrix.data;
        this.data[0] += r11;
        this.data[1] += r21;
        this.data[2] += r12;
        this.data[3] += r22;
        return this;
    }
    /** 获得矩阵和另一个矩阵逐项相减的结果. */
    minus(matrix) {
        return this.clone().minusSelf(matrix);
    }
    /** 减去另一个矩阵. */
    minusSelf(matrix) {
        let [r11, r21, r12, r22,] = matrix.data;
        this.data[0] -= r11;
        this.data[1] -= r12;
        this.data[2] -= r21;
        this.data[3] -= r22;
        return this;
    }
    /** 获得矩阵和标量相乘的结果. */
    multiplyScalar(scale) {
        return this.clone().multiplyScalarSelf(scale);
    }
    /** 矩阵中的每一个元素和数字相乘. */
    multiplyScalarSelf(scale) {
        this.data[0] *= scale;
        this.data[1] *= scale;
        this.data[2] *= scale;
        this.data[3] *= scale;
        return this;
    }
    /** 获得矩阵作为左矩阵右乘另一个矩阵的结果. */
    multiply(matrix) {
        return this.clone().multiplySelf(matrix);
    }
    /** 将当前矩阵作为左矩阵右乘另一个矩阵的结果. */
    multiplySelf(matrix) {
        let [l11, l21, l12, l22,] = this.data;
        let [r11, r21, r12, r22,] = matrix.data;
        this.set(l11 * r11 + l12 * r21, l11 * r12 + l12 * r22, l21 * r11 + l22 * r21, l21 * r12 + l22 * r22);
        return this;
    }
    /** 获得矩阵的逆矩阵. */
    inverse() {
        return this.clone().inverseSelf();
    }
    /** 将矩阵转为其逆矩阵. */
    inverseSelf() {
        let [n11, n21, n12, n22,] = this.data;
        let detValue = n11 * n22 - n12 * n21;
        if (detValue === 0) {
            this.set(0, 0, 0, 0);
        }
        else {
            let detValueInvert = 1 / detValue;
            // 代数余子式转置矩阵.
            this.set(n22 * detValueInvert, -n12 * detValueInvert, -n21 * detValueInvert, n11 * detValueInvert);
        }
        return this;
    }
    /** 获得矩阵的行列式值. */
    getDeterminant() {
        let [n11, n21, n12, n22,] = this.data;
        return n11 * n22 - n12 * n21;
    }
    /** 乘以二元矢量. */
    transfer(vector) {
        let [n11, n21, n12, n22,] = this.data;
        let { x, y } = vector;
        return new vector4_1.Vector2(n11 * x + n12 * y, n21 * x + n22 * y);
    }
    /** 打印矩阵. */
    print() {
        let [n11, n21, n12, n22,] = this.data;
        console.table([
            [n11, n12],
            [n21, n22],
        ]);
    }
}
exports.Matrix2 = Matrix2;
class Matrix3 {
    /** 返回默认单位矩阵, 其不可更改. */
    static I = Object.seal(new Matrix3());
    /** 返回一个零矩阵. */
    static zero() {
        return new Matrix3(0, 0, 0, 0, 0, 0, 0, 0, 0);
    }
    /** 从多个向量创建矩阵. */
    static fromVectors(v1, v2, v3) {
        return new Matrix3(v1.x, v2.x, v3.x, v1.y, v2.y, v3.y, v1.z, v2.z, v3.z);
    }
    /** 内部计算使用列主序排列, 这样可以不用调整直接输出. */
    data;
    /** 传入的参数为行主序格式. */
    constructor(n11 = 1, n12 = 0, n13 = 0, n21 = 0, n22 = 1, n23 = 0, n31 = 0, n32 = 0, n33 = 1) {
        this.set(n11, n12, n13, n21, n22, n23, n31, n32, n33);
    }
    /** 基于行主序设置值. */
    set(n11, n12, n13, n21, n22, n23, n31, n32, n33) {
        this.data = [
            n11, n21, n31,
            n12, n22, n32,
            n13, n23, n33,
        ];
    }
    /** 克隆矩阵. */
    clone() {
        let [n11, n21, n31, n12, n22, n32, n13, n23, n33,] = this.data;
        return new Matrix3(n11, n12, n13, n21, n22, n23, n31, n32, n33);
    }
    /** 返回行主序的扁平数据格式. */
    flatten() {
        let [n11, n21, n31, n12, n22, n32, n13, n23, n33,] = this.data;
        return [
            n11, n12, n13,
            n21, n22, n23,
            n31, n32, n33,
        ];
    }
    /** 输出扁平化的列主序的格式. */
    toFloat32Array() {
        return new Float32Array(this.data);
    }
    /** 获得矩阵的转置矩阵. */
    transpose() {
        return this.clone().transposeSelf();
    }
    /** 转换为转置矩阵. */
    transposeSelf() {
        let [n11, n21, n31, n12, n22, n32, n13, n23, n33,] = this.data;
        this.set(n11, n21, n31, n12, n22, n32, n13, n23, n33);
        return this;
    }
    /** 获得矩阵和另一个矩阵逐项求和的结果. */
    add(matrix) {
        return this.clone().addSelf(matrix);
    }
    /** 加上另一个矩阵. */
    addSelf(matrix) {
        let [r11, r21, r31, r12, r22, r32, r13, r23, r33,] = matrix.data;
        this.data[0] += r11;
        this.data[1] += r21;
        this.data[2] += r31;
        this.data[3] += r12;
        this.data[4] += r22;
        this.data[5] += r32;
        this.data[6] += r13;
        this.data[7] += r23;
        this.data[8] += r33;
        return this;
    }
    /** 获得矩阵和另一个矩阵逐项相减的结果. */
    minus(matrix) {
        return this.clone().minusSelf(matrix);
    }
    /** 减去另一个矩阵. */
    minusSelf(matrix) {
        let [r11, r21, r31, r12, r22, r32, r13, r23, r33,] = matrix.data;
        this.data[0] -= r11;
        this.data[1] -= r21;
        this.data[2] -= r31;
        this.data[3] -= r12;
        this.data[4] -= r22;
        this.data[5] -= r32;
        this.data[6] -= r13;
        this.data[7] -= r23;
        this.data[8] -= r33;
        return this;
    }
    /** 获得矩阵和标量相乘的结果. */
    multiplyScalar(scale) {
        return this.clone().multiplyScalarSelf(scale);
    }
    /** 矩阵中的每一个元素和数字相乘. */
    multiplyScalarSelf(scale) {
        this.data[0] *= scale;
        this.data[1] *= scale;
        this.data[2] *= scale;
        this.data[3] *= scale;
        this.data[4] *= scale;
        this.data[5] *= scale;
        this.data[6] *= scale;
        this.data[7] *= scale;
        this.data[8] *= scale;
        return this;
    }
    /** 获得矩阵作为左矩阵和另一个矩阵相乘的结果. */
    multiply(matrix) {
        return this.clone().multiplySelf(matrix);
    }
    /** 将当前矩阵作为左矩阵和另一个矩阵相乘. */
    multiplySelf(matrix) {
        let [l11, l21, l31, l12, l22, l32, l13, l23, l33,] = this.data;
        let [r11, r21, r31, r12, r22, r32, r13, r23, r33,] = matrix.data;
        this.set(l11 * r11 + l12 * r21 + l13 * r31, l11 * r12 + l12 * r22 + l13 * r32, l11 * r13 + l12 * r23 + l13 * r33, l21 * r11 + l22 * r21 + l23 * r31, l21 * r12 + l22 * r22 + l23 * r32, l21 * r13 + l22 * r23 + l23 * r33, l31 * r11 + l32 * r21 + l33 * r31, l31 * r12 + l32 * r22 + l33 * r32, l31 * r13 + l32 * r23 + l33 * r33);
        return this;
    }
    /** 将当前矩阵作为右矩阵左乘另一个矩阵的数据. */
    leftMultiplyDataToSelf(...data) {
        let [l11, l12, l13, l21, l22, l23, l31, l32, l33,] = data;
        let [r11, r21, r31, r12, r22, r32, r13, r23, r33,] = this.data;
        this.set(l11 * r11 + l12 * r21 + l13 * r31, l11 * r12 + l12 * r22 + l13 * r32, l11 * r13 + l12 * r23 + l13 * r33, l21 * r11 + l22 * r21 + l23 * r31, l21 * r12 + l22 * r22 + l23 * r32, l21 * r13 + l22 * r23 + l23 * r33, l31 * r11 + l32 * r21 + l33 * r31, l31 * r12 + l32 * r22 + l33 * r32, l31 * r13 + l32 * r23 + l33 * r33);
        return this;
    }
    /** 获得矩阵的逆矩阵. */
    inverse() {
        return this.clone().inverseSelf();
    }
    /** 将矩阵转为其逆矩阵. */
    inverseSelf() {
        let [n11, n21, n31, n12, n22, n32, n13, n23, n33,] = this.data;
        // 这三个代数余子式值是经过转置处理的, 所以需要乘以其首列以获得行列式值.
        let m11 = n22 * n33 - n23 * n32;
        let m12 = n32 * n13 - n33 * n12;
        let m13 = n12 * n23 - n13 * n22;
        let detValue = n11 * m11 + n21 * m12 + n31 * m13;
        if (detValue === 0) {
            this.set(0, 0, 0, 0, 0, 0, 0, 0, 0);
        }
        else {
            let detValueInvert = 1 / detValue;
            // 代数余子式转置矩阵.
            this.set(m11 * detValueInvert, m12 * detValueInvert, m13 * detValueInvert, (n23 * n31 - n21 * n33) * detValueInvert, (n33 * n11 - n31 * n13) * detValueInvert, (n13 * n21 - n11 * n23) * detValueInvert, (n21 * n32 - n22 * n31) * detValueInvert, (n31 * n12 - n32 * n11) * detValueInvert, (n11 * n22 - n12 * n21) * detValueInvert);
        }
        return this;
    }
    /** 获得矩阵的行列式值. */
    getDeterminant() {
        let [n11, n21, n31, n12, n22, n32, n13, n23, n33,] = this.data;
        return n11 * n22 * n33 - n13 * n22 * n31
            + n12 * n23 * n31 - n12 * n21 * n33
            + n13 * n21 * n32 - n11 * n23 * n32;
    }
    /** 乘以二元矢量. */
    transfer2(vector) {
        let vector3 = vector4_1.Vector3.fromVector2(vector);
        let transfered = this.transfer3(vector3);
        return new vector4_1.Vector2(...transfered.xy);
    }
    /** 乘以三元矢量. */
    transfer3(vector) {
        let [n11, n21, n31, n12, n22, n32, n13, n23, n33,] = this.data;
        let { x, y, z } = vector;
        return new vector4_1.Vector3(n11 * x + n12 * y + n13 * z, n21 * x + n22 * y + n23 * z, n31 * x + n32 * y + n33 * z);
    }
    /** 打印矩阵. */
    print() {
        let [n11, n21, n31, n12, n22, n32, n13, n23, n33,] = this.data;
        console.table([
            [n11, n12, n13],
            [n21, n22, n23],
            [n31, n32, n33],
        ]);
    }
    /** 执行位移并且返回一个新的矩阵. */
    translate(x = 0, y = 0) {
        return this.clone().translateSelf(x, y);
    }
    /** 执行位移. */
    translateSelf(x = 0, y = 0) {
        return this.leftMultiplyDataToSelf(1, 0, x, 0, 1, y, 0, 0, 1);
    }
    /** 执行缩放并且返回一个新的矩阵, 参数为各个方向的缩放比例, 默认为 1. */
    scale(sx = 1, sy = 1) {
        return this.clone().scaleSelf(sx, sy);
    }
    /** 执行缩放, 参数为各个方向的缩放比例, 默认为 1. */
    scaleSelf(sx = 1, sy = 1) {
        return this.leftMultiplyDataToSelf(sx, 0, 0, 0, sy, 0, 0, 0, 1);
    }
    /** 执行旋转并且返回一个新的矩阵, 参数为各个方向的旋转弧度. */
    rotate(radians = 0) {
        return this.clone().rotateSelf(radians);
    }
    /** 执行旋转, 参数为各个方向的旋转弧度. */
    rotateSelf(radians = 0) {
        let c = Math.cos(radians);
        let s = Math.sin(radians);
        return this.leftMultiplyDataToSelf(c, -s, 0, s, c, 0, 0, 0, 1);
    }
    /**
     * 执行斜切并且返回一个新的矩阵, 参数为 y 到 x 和 x 到 y 方向的斜切弧度.
     * 理论上看应该支持全部 6 个参数, 但是由于一般斜切用的很少, 所以如果确实需要的话, 可以使用矩阵来代替.
     */
    skew(yToX = 0, xToY = 0) {
        return this.clone().skewSelf(yToX, xToY);
    }
    /**
     * 执行斜切, 参数为 y 到 x 和 x 到 y 方向的斜切弧度.
     * 理论上看应该支持全部 6 个参数, 但是由于一般斜切用的很少, 所以如果确实需要的话, 可以使用矩阵来代替.
     */
    skewSelf(yToX = 0, xToY = 0) {
        let sx = Math.tan(yToX);
        let sy = Math.tan(xToY);
        return this.leftMultiplyDataToSelf(1, sx, 0, sy, 1, 0, 0, 0, 1);
    }
}
exports.Matrix3 = Matrix3;
class Matrix4 {
    /** 返回默认单位矩阵, 其不可更改. */
    static I = Object.seal(new Matrix4());
    /** 返回一个零矩阵. */
    static zero() {
        return new Matrix4(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);
    }
    /** 从多个向量创建矩阵. */
    static fromVectors(v1, v2, v3, v4) {
        return new Matrix4(v1.x, v2.x, v3.x, v4.x, v1.y, v2.y, v3.y, v4.y, v1.z, v2.z, v3.z, v4.z, v1.w, v2.w, v3.w, v4.w);
    }
    /** 将 3×3 的 2D 变换矩阵数据扩充为 4x4. */
    static fromMatrix3(matrix) {
        let [n11, n21, n31, n12, n22, n32, n13, n23, n33,] = matrix.data;
        return new Matrix4(n11, n12, 0, n13, n21, n22, 0, n23, 0, 0, 1, 0, n31, n32, 0, n33);
    }
    /**
     * 通过摄影机坐标和正在观察的点的坐标定义观察矩阵, 将原始坐标转为摄影机坐标系的坐标.
     * @param upVector 一个大致向上的向量, 用于定于摄影机的上朝向.
     */
    static lookAt(cameraCoord, watchCoord, upVector = new vector4_1.Vector3(0, 1, 0)) {
        // 代表摄影机朝向的反方向的向量, 即摄影机的 z 轴.
        let d = cameraCoord.minus(watchCoord).normalize();
        // 代表摄影机右侧的向量, 由代表 y 轴的上向量和代表 z 轴的向量叉积生成的摄影机 x 轴.
        let r = upVector.cross(d).normalize();
        // y 轴等于 z 和 x 的叉积.
        let u = d.cross(r);
        // 摄影极坐标.
        let c = cameraCoord;
        // r, u, d 组成了摄影机坐标系的正交基, 设为矩阵 Bc, 即 C = Bc * Cc.
        // 所以为了将原始坐标转为摄影机坐标, 需要左乘正交基矩阵的逆矩阵, 而单位正交矩阵的逆矩阵等于转置矩阵.
        let rotateMatrix = new Matrix4(r.x, r.y, r.z, 0, u.x, u.y, u.z, 0, d.x, d.y, d.z, 0, 0, 0, 0, 1);
        // 将坐标以摄影机坐标为原点进行移动.
        let moveMatrix = new Matrix4(1, 0, 0, -c.x, 0, 1, 0, -c.y, 0, 0, 1, -c.z, 0, 0, 0, 1);
        return rotateMatrix.multiplySelf(moveMatrix);
    }
    /**
     * 通过摄像机和投影屏幕的距离来生成透视投影矩阵.
     * deep 为投影屏幕到摄影机的距离, 即投影屏幕在摄影机坐标系内的 z 坐标的绝对值.
     * width, height 对应着投影之后的 |z| = deep 时的 xy 的可视坐标范围, 或者也可以理解为投影屏幕的宽高.
     * near 和 far 对应着近平面和远平面. 应当根据坐标的范围调整他们, 另外 far/near 不应过大, 例如超过 1000, 这样可以获得更好的精度.
     */
    static perspective(width, height, deep, near = 0.1, far = 100) {
        let r = width / 2;
        let t = height / 2;
        let a11 = deep / r;
        let a22 = deep / t;
        let a33 = -(far + near) / (far - near);
        let a34 = -2 * far * near / (far - near);
        // a43 = -1 是因为摄影机的观察方向为其坐标系的 z 轴负半轴, 所以我们为齐次坐标增加一个负值来让 xyz 坐标保持原先的正负.
        return new Matrix4(a11, 0, 0, 0, 0, a22, 0, 0, 0, 0, a33, a34, 0, 0, -1, 0);
    }
    /** 内部计算使用列主序排列, 这样可以不用调整直接输出. */
    data;
    /** 传入的参数为行主序格式. */
    constructor(n11 = 1, n12 = 0, n13 = 0, n14 = 0, n21 = 0, n22 = 1, n23 = 0, n24 = 0, n31 = 0, n32 = 0, n33 = 1, n34 = 0, n41 = 0, n42 = 0, n43 = 0, n44 = 1) {
        this.set(n11, n12, n13, n14, n21, n22, n23, n24, n31, n32, n33, n34, n41, n42, n43, n44);
    }
    /** 基于行主序设置值. */
    set(n11, n12, n13, n14, n21, n22, n23, n24, n31, n32, n33, n34, n41, n42, n43, n44) {
        this.data = [
            n11, n21, n31, n41,
            n12, n22, n32, n42,
            n13, n23, n33, n43,
            n14, n24, n34, n44,
        ];
    }
    /** 克隆矩阵. */
    clone() {
        let [n11, n21, n31, n41, n12, n22, n32, n42, n13, n23, n33, n43, n14, n24, n34, n44,] = this.data;
        return new Matrix4(n11, n12, n13, n14, n21, n22, n23, n24, n31, n32, n33, n34, n41, n42, n43, n44);
    }
    /** 返回行主序的扁平数据格式. */
    flatten() {
        let [n11, n21, n31, n41, n12, n22, n32, n42, n13, n23, n33, n43, n14, n24, n34, n44,] = this.data;
        return [
            n11, n12, n13, n14,
            n21, n22, n23, n24,
            n31, n32, n33, n34,
            n41, n42, n43, n44,
        ];
    }
    /** 输出扁平化的列主序的格式. */
    toFloat32Array() {
        return new Float32Array(this.data);
    }
    /** 获得矩阵的转置矩阵. */
    transpose() {
        return this.clone().transposeSelf();
    }
    /** 转换为转置矩阵. */
    transposeSelf() {
        let [n11, n21, n31, n41, n12, n22, n32, n42, n13, n23, n33, n43, n14, n24, n34, n44,] = this.data;
        this.set(n11, n21, n31, n41, n12, n22, n32, n42, n13, n23, n33, n43, n14, n24, n34, n44);
        return this;
    }
    /** 获得矩阵和另一个矩阵逐项求和的结果. */
    add(matrix) {
        return this.clone().addSelf(matrix);
    }
    /** 加上另一个矩阵. */
    addSelf(matrix) {
        let [r11, r21, r31, r41, r12, r22, r32, r42, r13, r23, r33, r43, r14, r24, r34, r44,] = matrix.data;
        this.data[0] += r11;
        this.data[1] += r21;
        this.data[2] += r31;
        this.data[3] += r41;
        this.data[4] += r12;
        this.data[5] += r22;
        this.data[6] += r32;
        this.data[7] += r42;
        this.data[8] += r13;
        this.data[9] += r23;
        this.data[10] += r33;
        this.data[11] += r43;
        this.data[12] += r14;
        this.data[13] += r24;
        this.data[14] += r34;
        this.data[15] += r44;
        return this;
    }
    /** 获得矩阵和另一个矩阵逐项相减的结果. */
    minus(matrix) {
        return this.clone().minusSelf(matrix);
    }
    /** 减去另一个矩阵. */
    minusSelf(matrix) {
        let [r11, r21, r31, r41, r12, r22, r32, r42, r13, r23, r33, r43, r14, r24, r34, r44,] = matrix.data;
        this.data[0] -= r11;
        this.data[1] -= r21;
        this.data[2] -= r31;
        this.data[3] -= r41;
        this.data[4] -= r12;
        this.data[5] -= r22;
        this.data[6] -= r32;
        this.data[7] -= r42;
        this.data[8] -= r13;
        this.data[9] -= r23;
        this.data[10] -= r33;
        this.data[11] -= r43;
        this.data[12] -= r14;
        this.data[13] -= r24;
        this.data[14] -= r34;
        this.data[15] -= r44;
        return this;
    }
    /** 获得矩阵和标量相乘的结果. */
    multiplyScalar(scale) {
        return this.clone().multiplyScalarSelf(scale);
    }
    /** 矩阵中的每一个元素和数字相乘. */
    multiplyScalarSelf(scale) {
        this.data[0] *= scale;
        this.data[1] *= scale;
        this.data[2] *= scale;
        this.data[3] *= scale;
        this.data[4] *= scale;
        this.data[5] *= scale;
        this.data[6] *= scale;
        this.data[7] *= scale;
        this.data[8] *= scale;
        this.data[9] *= scale;
        this.data[10] *= scale;
        this.data[11] *= scale;
        this.data[12] *= scale;
        this.data[13] *= scale;
        this.data[14] *= scale;
        this.data[15] *= scale;
        return this;
    }
    /** 获得矩阵作为左矩阵和另一个矩阵相乘的结果. */
    multiply(matrix) {
        return this.clone().multiplySelf(matrix);
    }
    /** 将当前矩阵作为左矩阵和另一个矩阵相乘. */
    multiplySelf(matrix) {
        let [l11, l21, l31, l41, l12, l22, l32, l42, l13, l23, l33, l43, l14, l24, l34, l44,] = this.data;
        let [r11, r21, r31, r41, r12, r22, r32, r42, r13, r23, r33, r43, r14, r24, r34, r44,] = matrix.data;
        this.set(l11 * r11 + l12 * r21 + l13 * r31 + l14 * r41, l11 * r12 + l12 * r22 + l13 * r32 + l14 * r42, l11 * r13 + l12 * r23 + l13 * r33 + l14 * r43, l11 * r14 + l12 * r24 + l13 * r34 + l14 * r44, l21 * r11 + l22 * r21 + l23 * r31 + l24 * r41, l21 * r12 + l22 * r22 + l23 * r32 + l24 * r42, l21 * r13 + l22 * r23 + l23 * r33 + l24 * r43, l21 * r14 + l22 * r24 + l23 * r34 + l24 * r44, l31 * r11 + l32 * r21 + l33 * r31 + l34 * r41, l31 * r12 + l32 * r22 + l33 * r32 + l34 * r42, l31 * r13 + l32 * r23 + l33 * r33 + l34 * r43, l31 * r14 + l32 * r24 + l33 * r34 + l34 * r44, l41 * r11 + l42 * r21 + l43 * r31 + l44 * r41, l41 * r12 + l42 * r22 + l43 * r32 + l44 * r42, l41 * r13 + l42 * r23 + l43 * r33 + l44 * r43, l41 * r14 + l42 * r24 + l43 * r34 + l44 * r44);
        return this;
    }
    /** 将当前矩阵作为右矩阵左乘另一个矩阵. */
    leftMultiply(matrix) {
        return matrix.multiply(this);
    }
    /** 将当前矩阵作为右矩阵左乘另一个矩阵. */
    leftMultiplySelf(matrix) {
        return this.leftMultiplyDataToSelf(...matrix.flatten());
    }
    /** 将当前矩阵作为右矩阵左乘另一个矩阵行主序的数据. */
    leftMultiplyDataToSelf(...data) {
        let [l11, l12, l13, l14, l21, l22, l23, l24, l31, l32, l33, l34, l41, l42, l43, l44,] = data;
        let [r11, r21, r31, r41, r12, r22, r32, r42, r13, r23, r33, r43, r14, r24, r34, r44,] = this.data;
        this.set(l11 * r11 + l12 * r21 + l13 * r31 + l14 * r41, l11 * r12 + l12 * r22 + l13 * r32 + l14 * r42, l11 * r13 + l12 * r23 + l13 * r33 + l14 * r43, l11 * r14 + l12 * r24 + l13 * r34 + l14 * r44, l21 * r11 + l22 * r21 + l23 * r31 + l24 * r41, l21 * r12 + l22 * r22 + l23 * r32 + l24 * r42, l21 * r13 + l22 * r23 + l23 * r33 + l24 * r43, l21 * r14 + l22 * r24 + l23 * r34 + l24 * r44, l31 * r11 + l32 * r21 + l33 * r31 + l34 * r41, l31 * r12 + l32 * r22 + l33 * r32 + l34 * r42, l31 * r13 + l32 * r23 + l33 * r33 + l34 * r43, l31 * r14 + l32 * r24 + l33 * r34 + l34 * r44, l41 * r11 + l42 * r21 + l43 * r31 + l44 * r41, l41 * r12 + l42 * r22 + l43 * r32 + l44 * r42, l41 * r13 + l42 * r23 + l43 * r33 + l44 * r43, l41 * r14 + l42 * r24 + l43 * r34 + l44 * r44);
        return this;
    }
    /** 获得矩阵的逆矩阵. */
    inverse() {
        return this.clone().inverseSelf();
    }
    /** 将矩阵转为其逆矩阵. */
    inverseSelf() {
        let [n11, n21, n31, n41, n12, n22, n32, n42, n13, n23, n33, n43, n14, n24, n34, n44,] = this.data;
        // 这四个代数余子式值是经过转置处理的, 所以需要乘以其首列以获得行列式值.
        let m11 = n23 * n34 * n42 - n24 * n33 * n42 + n24 * n32 * n43 - n22 * n34 * n43 - n23 * n32 * n44 + n22 * n33 * n44;
        let m12 = n14 * n33 * n42 - n13 * n34 * n42 - n14 * n32 * n43 + n12 * n34 * n43 + n13 * n32 * n44 - n12 * n33 * n44;
        let m13 = n13 * n24 * n42 - n14 * n23 * n42 + n14 * n22 * n43 - n12 * n24 * n43 - n13 * n22 * n44 + n12 * n23 * n44;
        let m14 = n14 * n23 * n32 - n13 * n24 * n32 - n14 * n22 * n33 + n12 * n24 * n33 + n13 * n22 * n34 - n12 * n23 * n34;
        let detValue = n11 * m11 + n21 * m12 + n31 * m13 + n41 * m14;
        let detValueInvert = detValue === 0 ? 0 : 1 / detValue;
        // 代数余子式转置矩阵.
        // 由于手工计算这么多的数字太容易出错了, 所以以下代码直接拷贝自:
        // https://github.com/mrdoob/three.js/blob/master/src/math/Matrix4.js
        // 实际上这些代码中的数字编号也可以进行比较精确的对齐和循环.
        this.set(m11 * detValueInvert, m12 * detValueInvert, m13 * detValueInvert, m14 * detValueInvert, (n24 * n33 * n41 - n23 * n34 * n41 - n24 * n31 * n43 + n21 * n34 * n43 + n23 * n31 * n44 - n21 * n33 * n44) * detValueInvert, (n13 * n34 * n41 - n14 * n33 * n41 + n14 * n31 * n43 - n11 * n34 * n43 - n13 * n31 * n44 + n11 * n33 * n44) * detValueInvert, (n14 * n23 * n41 - n13 * n24 * n41 - n14 * n21 * n43 + n11 * n24 * n43 + n13 * n21 * n44 - n11 * n23 * n44) * detValueInvert, (n13 * n24 * n31 - n14 * n23 * n31 + n14 * n21 * n33 - n11 * n24 * n33 - n13 * n21 * n34 + n11 * n23 * n34) * detValueInvert, (n22 * n34 * n41 - n24 * n32 * n41 + n24 * n31 * n42 - n21 * n34 * n42 - n22 * n31 * n44 + n21 * n32 * n44) * detValueInvert, (n14 * n32 * n41 - n12 * n34 * n41 - n14 * n31 * n42 + n11 * n34 * n42 + n12 * n31 * n44 - n11 * n32 * n44) * detValueInvert, (n12 * n24 * n41 - n14 * n22 * n41 + n14 * n21 * n42 - n11 * n24 * n42 - n12 * n21 * n44 + n11 * n22 * n44) * detValueInvert, (n14 * n22 * n31 - n12 * n24 * n31 - n14 * n21 * n32 + n11 * n24 * n32 + n12 * n21 * n34 - n11 * n22 * n34) * detValueInvert, (n23 * n32 * n41 - n22 * n33 * n41 - n23 * n31 * n42 + n21 * n33 * n42 + n22 * n31 * n43 - n21 * n32 * n43) * detValueInvert, (n12 * n33 * n41 - n13 * n32 * n41 + n13 * n31 * n42 - n11 * n33 * n42 - n12 * n31 * n43 + n11 * n32 * n43) * detValueInvert, (n13 * n22 * n41 - n12 * n23 * n41 - n13 * n21 * n42 + n11 * n23 * n42 + n12 * n21 * n43 - n11 * n22 * n43) * detValueInvert, (n12 * n23 * n31 - n13 * n22 * n31 + n13 * n21 * n32 - n11 * n23 * n32 - n12 * n21 * n33 + n11 * n22 * n33) * detValueInvert);
        return this;
    }
    /** 获得矩阵的行列式值. */
    getDeterminant() {
        let [n11, n21, n31, n41, n12, n22, n32, n42, n13, n23, n33, n43, n14, n24, n34, n44,] = this.data;
        return n11 * n22 * n33 * n44 - n14 * n23 * n32 * n41
            + n12 * n23 * n34 * n41 - n13 * n22 * n31 * n44
            + n13 * n24 * n31 * n42 - n12 * n21 * n34 * n43
            + n14 * n21 * n32 * n43 - n11 * n24 * n33 * n42;
    }
    /** 乘以二元矢量. */
    transfer2(vector) {
        let vector4 = vector4_1.Vector4.fromVector2(vector);
        let transfered = this.transfer4(vector4);
        return new vector4_1.Vector2(...transfered.xy);
    }
    /** 乘以三元矢量. */
    transfer3(vector) {
        let vector4 = vector4_1.Vector4.fromVector3(vector);
        let transfered = this.transfer4(vector4);
        return new vector4_1.Vector3(...transfered.xyz);
    }
    /** 乘以四元矢量. */
    transfer4(vector) {
        let [n11, n21, n31, n41, n12, n22, n32, n42, n13, n23, n33, n43, n14, n24, n34, n44,] = this.data;
        let { x, y, z, w } = vector;
        return new vector4_1.Vector4(n11 * x + n12 * y + n13 * z + n14 * w, n21 * x + n22 * y + n23 * z + n24 * w, n31 * x + n32 * y + n33 * z + n34 * w, n41 * x + n42 * y + n43 * z + n44 * w);
    }
    /** 打印矩阵. */
    print() {
        let [n11, n21, n31, n41, n12, n22, n32, n42, n13, n23, n33, n43, n14, n24, n34, n44,] = this.data;
        console.table([
            [n11, n12, n13, n14],
            [n21, n22, n23, n24],
            [n31, n32, n33, n34],
            [n41, n42, n43, n44],
        ]);
    }
    /** 执行位移并且返回一个新的矩阵. */
    translate(x = 0, y = 0, z = 0) {
        return this.clone().translateSelf(x, y, z);
    }
    /** 执行位移. */
    translateSelf(x = 0, y = 0, z = 0) {
        return this.leftMultiplyDataToSelf(1, 0, 0, x, 0, 1, 0, y, 0, 0, 1, z, 0, 0, 0, 1);
    }
    /** 执行缩放并且返回一个新的矩阵, 参数为各个方向的缩放比例, 默认为 1. */
    scale(sx = 1, sy = 1, sz = 1) {
        return this.clone().scaleSelf(sx, sy, sz);
    }
    /** 执行缩放, 参数为各个方向的缩放比例, 默认为 1. */
    scaleSelf(sx = 1, sy = 1, sz = 1) {
        return this.leftMultiplyDataToSelf(sx, 0, 0, 0, 0, sy, 0, 0, 0, 0, sz, 0, 0, 0, 0, 1);
    }
    /** 执行旋转并且返回一个新的矩阵, 参数为沿各个轴旋转的弧度. */
    rotate(radians = 0) {
        return this.clone().rotateSelf(radians);
    }
    /** 执行旋转, 参数为沿各个轴旋转的弧度. */
    rotateSelf(radians = 0) {
        let c = Math.cos(radians);
        let s = Math.sin(radians);
        this.leftMultiplyDataToSelf(c, -s, 0, 0, s, c, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1);
        return this;
    }
    /** 执行三维旋转并且返回一个新的矩阵, 参数为沿各个轴旋转的弧度. */
    rotate3D(acrossX = 0, acrossY = 0, acrossZ = 0) {
        return this.clone().rotate3DSelf(acrossX, acrossY, acrossZ);
    }
    /** 执行三维旋转, 参数为沿各个轴旋转的弧度. */
    rotate3DSelf(acrossX = 0, acrossY = 0, acrossZ = 0) {
        if (acrossX !== 0) {
            let c = Math.cos(acrossX);
            let s = Math.sin(acrossX);
            this.leftMultiplyDataToSelf(1, 0, 0, 0, 0, c, -s, 0, 0, s, c, 0, 0, 0, 0, 1);
        }
        if (acrossY !== 0) {
            let c = Math.cos(acrossY);
            let s = Math.sin(acrossY);
            this.leftMultiplyDataToSelf(c, 0, s, 0, 0, 1, 0, 0, -s, 0, c, 0, 0, 0, 0, 1);
        }
        if (acrossZ !== 0) {
            let c = Math.cos(acrossZ);
            let s = Math.sin(acrossZ);
            this.leftMultiplyDataToSelf(c, -s, 0, 0, s, c, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1);
        }
        return this;
    }
    /** 执行旋转并且返回一个新的矩阵, 参数为沿各个轴旋转的弧度. */
    skew(yToX = 0, xToY = 0) {
        return this.clone().skewSelf(yToX, xToY);
    }
    /**
     * 执行斜切, 参数为 y 到 x 和 x 到 y 方向的斜切角度.
     * 理论上看应该支持全部 6 个参数, 但是由于一般斜切用的很少, 所以如果确实需要的话, 可以使用矩阵来代替.
     */
    skewSelf(yToX = 0, xToY = 0) {
        let sx = Math.tan(yToX);
        let sy = Math.tan(xToY);
        return this.leftMultiplyDataToSelf(1, sx, 0, 0, sy, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1);
    }
}
exports.Matrix4 = Matrix4;


/***/ }),

/***/ "./src/libs/math/random.ts":
/*!*********************************!*\
  !*** ./src/libs/math/random.ts ***!
  \*********************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.random = exports.seedRandom = void 0;
/** 根据种子生成伪随机整数, 种子相同时生成的结果相同. */
function seedRandom(min, max, seed) {
    // 需要加上一个值, 否则 seed = 0 时固定返回 0.
    let n = Math.sin(seed * 12.9898 + 78.233) * 43758.5453;
    let rate = n - Math.floor(n);
    return min + rate * (max - min);
}
exports.seedRandom = seedRandom;
/** 生成两个数字指定的范围内的随机数. */
function random(min, max = 0) {
    return Math.random() * (max - min) + min;
}
exports.random = random;


/***/ }),

/***/ "./src/libs/math/sampling.ts":
/*!***********************************!*\
  !*** ./src/libs/math/sampling.ts ***!
  \***********************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.simpleSamplingCoords = void 0;
/** Simple sampling coordinates, when using linears to approach curve. */
function simpleSamplingCoords(coords, tolerance) {
    if (coords.length <= 2) {
        return coords;
    }
    let startIndex = 0;
    let lastWorkedIndex = 1;
    let endIndex = 2;
    let simpleCoords = [coords[0]];
    while (true) {
        // If works, double current range.
        if (isEndIndexWorks(coords, startIndex, endIndex, tolerance)) {
            lastWorkedIndex = endIndex;
            if (endIndex < coords.length - 1) {
                endIndex = startIndex + (endIndex - startIndex) * 2;
                endIndex = Math.min(endIndex, coords.length - 1);
            }
            else {
                break;
            }
        }
        else {
            lastWorkedIndex = binaryFindLastWorkedIndex(coords, lastWorkedIndex, endIndex, tolerance);
            if (lastWorkedIndex < coords.length - 1) {
                simpleCoords.push(coords[lastWorkedIndex]);
                startIndex = lastWorkedIndex;
                lastWorkedIndex = startIndex + 1;
                endIndex = startIndex + 2;
                if (endIndex > coords.length - 1) {
                    break;
                }
            }
            else {
                break;
            }
        }
    }
    simpleCoords.push(coords[coords.length - 1]);
    return simpleCoords;
}
exports.simpleSamplingCoords = simpleSamplingCoords;
/** 检查结束的索引位置是否可行. */
function isEndIndexWorks(coords, startIndex, endIndex, tolerance) {
    let [startX, startY] = coords[startIndex];
    let [endX, endY] = coords[endIndex];
    let xRange = endX - startX;
    for (let i = startIndex + 1; i < endIndex; i++) {
        let [x, y] = coords[i];
        let rightRate = (x - startX) / xRange;
        let leftRate = 1 - rightRate;
        let linearY = leftRate * startY + rightRate * endY;
        if (Math.abs(y - linearY) > tolerance) {
            return false;
        }
    }
    return true;
}
/** 二分检查合适的结束索引位置. */
function binaryFindLastWorkedIndex(coords, startIndex, endIndex, tolerance) {
    let from = startIndex;
    let to = endIndex;
    while (to - from > 1) {
        let center = Math.round((from + to) / 2);
        if (isEndIndexWorks(coords, startIndex, center, tolerance)) {
            from = center;
        }
        else {
            to = center;
        }
    }
    return from;
}


/***/ }),

/***/ "./src/libs/math/stat.ts":
/*!*******************************!*\
  !*** ./src/libs/math/stat.ts ***!
  \*******************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Stat = void 0;
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
/** 计算一组数值的统计信息. */
var Stat;
(function (Stat) {
    /** 获得平均值. */
    function getAverageValue(values) {
        return (0, ff_1.avg)(values);
    }
    Stat.getAverageValue = getAverageValue;
    /** 获得标准差. */
    function getStandardDeviation(values) {
        let averageValue = getAverageValue(values);
        let squareDeviation = 0;
        for (let value of values) {
            squareDeviation += Math.pow(value - averageValue, 2);
        }
        return Math.sqrt(squareDeviation / values.length);
    }
    Stat.getStandardDeviation = getStandardDeviation;
    /** 获得中心均值, 要求和均值的误差不超过标准差的 delta 倍. */
    function getCoreAverageValues(values, delta) {
        let averageValue = getAverageValue(values);
        let standardDeviation = getStandardDeviation(values);
        let coreValues = values.filter(value => Math.abs(value - averageValue) <= standardDeviation * delta);
        return getAverageValue(coreValues);
    }
    Stat.getCoreAverageValues = getCoreAverageValues;
})(Stat || (exports.Stat = Stat = {}));


/***/ }),

/***/ "./src/libs/math/vector4.ts":
/*!**********************************!*\
  !*** ./src/libs/math/vector4.ts ***!
  \**********************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Vector4 = exports.Vector3 = exports.Vector2 = void 0;
// 由于数学计算对于性能很敏感, 出于此考虑, VectorX 不使用一个通用的 Vector 类.
// 这样它可以充分利用 V8 的 Hidden Class.
// 此外 VectorX 的方法大多仅和自身类有关, 不适合继承 Vector.
class Vector2 {
    static fromRadians(radians) {
        return new Vector2(Math.cos(radians), Math.sin(radians));
    }
    static fromAngle(angle) {
        return Vector2.fromRadians(angle / 180 * Math.PI);
    }
    x;
    y;
    constructor(x = 0, y = 0) {
        this.x = x;
        this.y = y;
    }
    add(vector) {
        return this.clone().addSelf(vector);
    }
    addSelf(vector) {
        this.x += vector.x;
        this.y += vector.y;
        return this;
    }
    minus(vector) {
        return this.clone().minusSelf(vector);
    }
    minusSelf(vector) {
        this.x -= vector.x;
        this.y -= vector.y;
        return this;
    }
    multiply(vector) {
        return this.clone().multiplySelf(vector);
    }
    multiplySelf(vector) {
        this.x *= vector.x;
        this.y *= vector.y;
        return this;
    }
    multiplyScalar(scale) {
        return this.clone().multiplyScalarSelf(scale);
    }
    multiplyScalarSelf(scale) {
        this.x *= scale;
        this.y *= scale;
        return this;
    }
    divide(vector) {
        return this.clone().divideSelf(vector);
    }
    divideSelf(vector) {
        this.x /= vector.x;
        this.y /= vector.y;
        return this;
    }
    divideScalar(scale) {
        return this.clone().divideScalarSelf(scale);
    }
    divideScalarSelf(scale) {
        this.x /= scale;
        this.y /= scale;
        return this;
    }
    normalize() {
        return this.clone().normalizeSelf();
    }
    normalizeSelf() {
        let scale = 1 / this.length();
        this.x *= scale;
        this.y *= scale;
        return this;
    }
    clone() {
        return new Vector2(this.x, this.y);
    }
    rotate(radians) {
        return this.clone().rotateSelf(radians);
    }
    rotateSelf(radians) {
        let cos = Math.cos(radians);
        let sin = Math.sin(radians);
        let { x, y } = this;
        this.x = x * cos - y * sin;
        this.y = x * sin + y * cos;
        return this;
    }
    dot(vector) {
        return this.x * vector.x
            + this.y * vector.y;
    }
    length() {
        return Math.sqrt(this.x * this.x + this.y * this.y);
    }
    /**
     * 计算向量叉积的值.
     * 它相当于围成的平行四边形面积, 并且当前向量到 vector 的旋转角小于 180° 时为正.
     * 二维向量的叉积本身没有意义, 这里的计算相当于 z 取 0 在三维空间计算, 然后只取 z 值.
     */
    cross(vector) {
        return this.x * vector.y - this.y * vector.x;
    }
    get values() {
        return this.xy;
    }
    get xy() {
        return [this.x, this.y];
    }
}
exports.Vector2 = Vector2;
class Vector3 {
    x;
    y;
    z;
    static fromVector2(vector) {
        return new Vector3(vector.x, vector.y, 1);
    }
    constructor(x = 0, y = 0, z = 0) {
        this.x = x;
        this.y = y;
        this.z = z;
    }
    add(vector) {
        return this.clone().addSelf(vector);
    }
    addSelf(vector) {
        this.x += vector.x;
        this.y += vector.y;
        this.z += vector.z;
        return this;
    }
    minus(vector) {
        return this.clone().minusSelf(vector);
    }
    minusSelf(vector) {
        this.x -= vector.x;
        this.y -= vector.y;
        this.z -= vector.z;
        return this;
    }
    multiply(vector) {
        return this.clone().multiplySelf(vector);
    }
    multiplySelf(vector) {
        this.x *= vector.x;
        this.y *= vector.y;
        this.z *= vector.z;
        return this;
    }
    multiplyScalar(vector) {
        return this.clone().minusSelf(vector);
    }
    multiplyScalarSelf(number) {
        this.x *= number;
        this.y *= number;
        this.z *= number;
        return this;
    }
    divide(vector) {
        return this.clone().divideSelf(vector);
    }
    divideSelf(vector) {
        this.x /= vector.x;
        this.y /= vector.y;
        this.z /= vector.z;
        return this;
    }
    divideScalar(scale) {
        return this.clone().divideScalarSelf(scale);
    }
    divideScalarSelf(scale) {
        this.x /= scale;
        this.y /= scale;
        this.z /= scale;
        return this;
    }
    normalize() {
        return this.clone().normalizeSelf();
    }
    normalizeSelf() {
        let scale = 1 / this.length();
        this.x *= scale;
        this.y *= scale;
        this.z *= scale;
        return this;
    }
    clone() {
        return new Vector3(this.x, this.y, this.z);
    }
    dot(vector) {
        return this.x * vector.x
            + this.y * vector.y
            + this.z * vector.z;
    }
    length() {
        return Math.sqrt(this.x * this.x + this.y * this.y + this.z * this.z);
    }
    cross(vector) {
        let { x: x1, y: y1, z: z1 } = this;
        let { x: x2, y: y2, z: z2 } = vector;
        return new Vector3(y1 * z2 - y2 * z1, z1 * x2 - z2 * x1, x1 * y2 - x2 * y1);
    }
    get values() {
        return this.xyz;
    }
    get xy() {
        return [this.x, this.y];
    }
    get xyz() {
        return [this.x, this.y, this.z];
    }
}
exports.Vector3 = Vector3;
class Vector4 {
    x;
    y;
    z;
    w;
    static fromVector2(vector) {
        return new Vector4(vector.x, vector.y, 0, 1);
    }
    static fromVector3(vector) {
        return new Vector4(vector.x, vector.y, vector.z, 1);
    }
    constructor(x = 0, y = 0, z = 0, w = 1) {
        this.x = x;
        this.y = y;
        this.z = z;
        this.w = w;
    }
    add(vector) {
        return this.clone().addSelf(vector);
    }
    addSelf(vector) {
        this.x += vector.x;
        this.y += vector.y;
        this.z += vector.z;
        this.w += vector.w;
        return this;
    }
    minus(vector) {
        return this.clone().minusSelf(vector);
    }
    minusSelf(vector) {
        this.x -= vector.x;
        this.y -= vector.y;
        this.z -= vector.z;
        this.w -= vector.w;
        return this;
    }
    multiply(vector) {
        return this.clone().multiplySelf(vector);
    }
    multiplySelf(vector) {
        this.x *= vector.x;
        this.y *= vector.y;
        this.z *= vector.z;
        this.w *= vector.w;
        return this;
    }
    multiplyScalar(vector) {
        return this.clone().multiplySelf(vector);
    }
    multiplyScalarSelf(number) {
        this.x *= number;
        this.y *= number;
        this.z *= number;
        this.w *= number;
        return this;
    }
    divide(vector) {
        return this.clone().divideSelf(vector);
    }
    divideSelf(vector) {
        this.x /= vector.x;
        this.y /= vector.y;
        this.z /= vector.z;
        this.w /= vector.w;
        return this;
    }
    divideScalar(scale) {
        return this.clone().divideScalarSelf(scale);
    }
    divideScalarSelf(scale) {
        this.x /= scale;
        this.y /= scale;
        this.z /= scale;
        this.w /= scale;
        return this;
    }
    normalize() {
        return this.clone().normalizeSelf();
    }
    normalizeSelf() {
        let scale = 1 / this.length();
        this.x *= scale;
        this.y *= scale;
        this.z *= scale;
        this.w *= scale;
        return this;
    }
    clone() {
        return new Vector4(this.x, this.y, this.z, this.w);
    }
    dot(vector) {
        return this.x * vector.x
            + this.y * vector.y
            + this.z * vector.z
            + this.w * vector.w;
    }
    length() {
        return Math.sqrt(this.x * this.x + this.y * this.y + this.z * this.z + this.w * this.w);
    }
    /** 4 维向量叉积需要三个向量, 但是完全没啥用. */
    //cross() {}
    get values() {
        return this.xyzw;
    }
    get xy() {
        return [this.x, this.y];
    }
    get xyz() {
        return [this.x, this.y, this.z];
    }
    get xyzw() {
        return [this.x, this.y, this.z, this.w];
    }
}
exports.Vector4 = Vector4;


/***/ }),

/***/ "./src/libs/pico-face.ts":
/*!*******************************!*\
  !*** ./src/libs/pico-face.ts ***!
  \*******************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.PicoFace = void 0;
const preload_1 = __webpack_require__(/*! ./util/preload */ "./src/libs/util/preload.ts");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
const file_1 = __webpack_require__(/*! ./util/file */ "./src/libs/util/file.ts");
/** 检查图片中的人脸. */
var PicoFace;
(function (PicoFace) {
    /** 脚本文件和数据集文件存放的目录. */
    let libsDirectoryWithEndSlash = document.currentScript instanceof HTMLScriptElement
        ? (0, file_1.getPathParent)((0, file_1.getPathParent)(document.currentScript.src)) + '/'
        : '';
    /** 脚本路径. */
    let pinoJSPath = libsDirectoryWithEndSlash + 'libs/pico.js';
    /**
     * 人脸数据集的路径, 原始地址为
     * https://raw.githubusercontent.com/nenadmarkus/pico/c2e81f9d23cc11d1a612fd21e4f9de0921a5d0d9/rnt/cascades/facefinder.
     */
    let cascadeFaceFinderPath = libsDirectoryWithEndSlash + 'libs/pico-cascade-facefinder.dat';
    /** 初始化的 promise. */
    let initializePromise;
    /** 数据集解析结果. */
    let facefinderClassifyRegion;
    /** 图片缩放到的最大像素尺寸. */
    let minScalingSize = 320;
    /** 设置脚本地址. */
    function configPinoJSPath(path) {
        pinoJSPath = path;
    }
    PicoFace.configPinoJSPath = configPinoJSPath;
    /** 设置人脸数据集的地址. */
    function configCascadeFaceFinderPath(path) {
        cascadeFaceFinderPath = path;
    }
    PicoFace.configCascadeFaceFinderPath = configCascadeFaceFinderPath;
    /** 设置图片缩放到的最大尺寸. */
    function configMinMaxScalingToSize(minSize) {
        minScalingSize = minSize;
    }
    PicoFace.configMinMaxScalingToSize = configMinMaxScalingToSize;
    /** 如果没有初始化, 则进行初始化. */
    async function initialize() {
        if (!initializePromise) {
            initializePromise = (async () => {
                await initializeJS();
                await initializeCascadeData();
            })();
        }
        await initializePromise;
    }
    /** 初始化脚本. */
    async function initializeJS() {
        await (0, preload_1.loadScript)(pinoJSPath);
    }
    /** 初始化数据集. */
    async function initializeCascadeData() {
        let response = await fetch(cascadeFaceFinderPath);
        let buffer = await response.arrayBuffer();
        let bytes = new Uint8Array(buffer);
        facefinderClassifyRegion = pico.unpack_cascade(bytes);
    }
    /** 获取所有脸部加权构成的中心点, 类似于重心. */
    function getTotalFaceCenter(results) {
        if (!results.length) {
            return null;
        }
        let totalX = 0;
        let totalY = 0;
        let totalR = 0;
        let totalP = 0;
        for (let result of results) {
            // 权重等于脸部相似度乘以面积.
            let p = result.p * result.r * result.r;
            totalX += result.x * p;
            totalY += result.y * p;
            totalR += result.r * p;
            totalP += p;
        }
        return {
            x: totalX / totalP,
            y: totalY / totalP,
            d: totalR / totalP,
        };
    }
    PicoFace.getTotalFaceCenter = getTotalFaceCenter;
    /** 获取所有脸部加权构成的对齐点, 例如脸偏上时, 这个对齐位置会更加偏上. */
    function getTotalFaceAlignPosition(results) {
        if (!results.length) {
            return null;
        }
        let { x, y, d } = getTotalFaceCenter(results);
        // 实际的对齐位置在内部外部拥有完全一样的比例, 例如:
        // 设置其百分比位置为 p
        // 则脸部上边沿为: p - dp = y - d/2
        // p = (y - d/2) / (1 - d)
        let px = (x - d / 2) / (1 - d);
        let py = (y - d / 2) / (1 - d);
        px = (0, ff_1.constrain)(px, 0, 1);
        py = (0, ff_1.constrain)(py, 0, 1);
        return {
            x: px,
            y: py,
        };
    }
    PicoFace.getTotalFaceAlignPosition = getTotalFaceAlignPosition;
    /**
     * 获取图片中的所有的脸部.
     * threshold 决定了相似度的阈值.
     */
    async function getFaces(image, threshold = 50) {
        await initialize();
        let smallImageData = scaleImage(image);
        let grayData = rgba2grayScale(smallImageData.data, smallImageData.width, smallImageData.height);
        let xScaleBack = 1 / smallImageData.width;
        let yScaleBack = 1 / smallImageData.height;
        let rScaleBack = Math.sqrt(xScaleBack * yScaleBack);
        let imageConfig = {
            pixels: grayData,
            nrows: smallImageData.height,
            ncols: smallImageData.width,
            ldim: smallImageData.width,
        };
        let params = {
            shiftfactor: 0.1,
            minsize: 20,
            maxsize: minScalingSize,
            scalefactor: 1.1,
        };
        let results = pico.run_cascade(imageConfig, facefinderClassifyRegion, params);
        // 合并检测结果.
        results = pico.cluster_detections(results, 0.2);
        // 挑选出阈值超过 threshold 的结果.
        results = results.filter(result => {
            return result[3] > threshold;
        });
        return results.map(result => {
            return {
                x: result[1] * xScaleBack,
                y: result[0] * yScaleBack,
                r: result[2] * rScaleBack,
                p: result[3],
            };
        });
    }
    PicoFace.getFaces = getFaces;
    /** 缩放图像到一个合适的尺寸. */
    function scaleImage(image) {
        let rawWidth = image instanceof HTMLImageElement ? image.naturalWidth : image.videoWidth;
        let rawHeight = image instanceof HTMLImageElement ? image.naturalHeight : image.videoHeight;
        let scaling;
        // 缩放到某个尺寸, 保持较小的一侧和 minScalingSize 相等.
        if (rawWidth > rawHeight) {
            scaling = minScalingSize / rawHeight;
        }
        else {
            scaling = minScalingSize / rawWidth;
        }
        let w = Math.round(rawWidth * scaling);
        let h = Math.round(rawHeight * scaling);
        let canvas = document.createElement('canvas');
        canvas.width = w;
        canvas.height = h;
        let context = canvas.getContext('2d');
        context.drawImage(image, 0, 0, w, h);
        let data = context.getImageData(0, 0, w, h);
        return data;
    }
    /** 将原始图像转为灰度图. */
    function rgba2grayScale(rgba, width, height) {
        let grayPixels = new Uint8Array(width * height);
        for (let r = 0; r < width; r++) {
            for (let c = 0; c < height; c++) {
                // gray = 0.2 * red + 0.7 * green + 0.1 * blue
                grayPixels[r * height + c] = (2 * rgba[4 * r * height + 4 * c + 0] // +0 是为了对齐, 不用在意因为它会被 V8 编译过程优化掉.
                    + 7 * rgba[4 * r * height + 4 * c + 1]
                    + 1 * rgba[4 * r * height + 4 * c + 2]) / 10;
            }
        }
        return grayPixels;
    }
})(PicoFace || (exports.PicoFace = PicoFace = {}));


/***/ }),

/***/ "./src/libs/util/color.ts":
/*!********************************!*\
  !*** ./src/libs/util/color.ts ***!
  \********************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Color = void 0;
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
/**
 * 用于处理颜色.
 * 其中的百分比实际使用的值为 0~100, 而不是 0~1, 这是为了和早已 Sass 保持一致.
 */
class Color {
    /** 从 RGBA 数据生成颜色. */
    static fromRGBA(r, g, b, a) {
        r = Math.max(Math.min(r, 1), 0);
        g = Math.max(Math.min(g, 1), 0);
        b = Math.max(Math.min(b, 1), 0);
        a = Math.max(Math.min(a, 1), 0);
        if (a === 1) {
            return new Color('#'
                + (Math.round(255 * r)).toString(16).padStart(2, '0')
                + (Math.round(255 * g)).toString(16).padStart(2, '0')
                + (Math.round(255 * b)).toString(16).padStart(2, '0'));
        }
        else {
            return new Color('rgba('
                + (Math.round(255 * r)).toString() + ', '
                + (Math.round(255 * g)).toString() + ', '
                + (Math.round(255 * b)).toString() + ', '
                + (0, ff_1.toPower)(a, -2) + ')');
        }
    }
    /** 从 RGB 数据生成颜色. */
    static fromRGB(r, g, b) {
        return Color.fromRGBA(r, g, b, 1);
    }
    value;
    constructor(value) {
        this.value = value.trim();
    }
    /** 转为 #xxxxxx. */
    toString() {
        return this.value;
    }
    /** 获取 [r, g, b, a], 返回值介于 0 ~ 1. */
    getRGBA() {
        if (/^#[0-9a-fA-F]{3,6}$/.test(this.value)) {
            return [...this.parseNormalColor(this.value), 1];
        }
        let match = this.value.match(/^rgb\(\s*(\d+)\s*,\s*(\d+)\s*,\s*(\d+)\s*\)$/);
        if (match) {
            return [
                Number(match[1]) / 255,
                Number(match[2]) / 255,
                Number(match[3]) / 255,
                1
            ];
        }
        match = this.value.match(/^rgba\(\s*(\d+)\s*,\s*(\d+)\s*,\s*(\d+)\s*,\s*([\d.]+)\s*\)$/);
        if (match) {
            return [
                Number(match[1]) / 255,
                Number(match[2]) / 255,
                Number(match[3]) / 255,
                Number(match[4]),
            ];
        }
        match = this.value.match(/^rgba\(\s*(#[0-9a-fA-F]{3,6})\s*,\s*([\d.]+)\s*\)$/);
        if (match) {
            return [...this.parseNormalColor(match[1]), Number(match[2])];
        }
        throw new Error(`"${this.value}" is not a valid RGB color`);
    }
    /** 获取 [r, g, b], 返回值介于 0 ~ 1. */
    getRGB() {
        return this.getRGBA().slice(0, 3);
    }
    /** 解析颜色数据为 RGB 数组. */
    parseNormalColor(color) {
        if (color.length === 4) {
            return [
                parseInt(color[1], 16) * 17 / 255,
                parseInt(color[2], 16) * 17 / 255,
                parseInt(color[3], 16) * 17 / 255
            ];
        }
        else {
            return [
                parseInt(color.slice(1, 3), 16) / 255,
                parseInt(color.slice(3, 5), 16) / 255,
                parseInt(color.slice(5, 7), 16) / 255
            ];
        }
    }
    /** 使用介于 0-100 的强度来使得当前颜色变得更暗. */
    darken(percentage) {
        return this.lighten(-percentage);
    }
    /** 使用介于 0-100 的强度来使得当前颜色变得更亮. */
    lighten(percentage) {
        let [r, g, b, a] = this.getRGBA();
        let p = percentage / 100;
        r += p;
        g += p;
        b += p;
        return Color.fromRGBA(r, g, b, a);
    }
    /** 使用介于 0-100 的强度来使得当前颜色向中间色移动. */
    toMiddle(percentage) {
        if (this.getLightness() < 0.5) {
            return this.lighten(percentage);
        }
        else {
            return this.darken(percentage);
        }
    }
    /** 获得颜色的亮度, 返回值介于 0 ~ 1. */
    getLightness() {
        let [r, g, b] = this.getRGBA();
        return r * 0.299 + g * 0.587 + b * 0.114;
    }
    /** 修改 alpha 值, 然后返回一个新的颜色. alpha 的值介于 0-1. */
    alpha(a) {
        let [r, g, b] = this.getRGBA();
        return Color.fromRGBA(r, g, b, a);
    }
    /** 混合入另外一个颜色, 其比例通过 percentage 参数指定, 值介于 0-100. */
    mix(color, percentage) {
        let [r, g, b, a] = this.getRGBA();
        if (typeof color === 'string') {
            color = new Color(color);
        }
        let [r2, g2, b2, a2] = color.getRGBA();
        let p = percentage / 100;
        r = r * (1 - p) + r2 * p;
        g = g * (1 - p) + g2 * p;
        b = b * (1 - p) + b2 * p;
        a = a * (1 - p) + a2 * p;
        return Color.fromRGBA(r, g, b, a);
    }
}
exports.Color = Color;


/***/ }),

/***/ "./src/libs/util/debug.ts":
/*!********************************!*\
  !*** ./src/libs/util/debug.ts ***!
  \********************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.debug = void 0;
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
/** 消息级别. */
var Level;
(function (Level) {
    Level[Level["No"] = 0] = "No";
    Level[Level["Log"] = 1] = "Log";
    Level[Level["Verbose"] = 2] = "Verbose";
    Level[Level["VeryVerbose"] = 3] = "VeryVerbose";
})(Level || (Level = {}));
var debug;
(function (debug) {
    // 开发模式下默认级别.
    debug.development = location.hostname === 'localhost' || location.hostname === '127.0.0.1';
    debug.logLevel = debug.development ? Level.Verbose : 0;
    // 可以通过 URL 重设级别.
    let levelFromPath = (0, ff_1.firstMatch)(location.search, /loglevel=(\d+)/);
    if (levelFromPath) {
        debug.logLevel = Number(levelFromPath);
    }
    /** 仅在开发环境中打印调试信息. */
    function verbose(message) {
        if (debug.logLevel >= Level.Verbose) {
            console.log('%c' + message, 'color: #999');
        }
    }
    debug.verbose = verbose;
    /** 仅在开发环境中打印调试信息. */
    function veryVerbose(message) {
        if (debug.logLevel >= Level.VeryVerbose) {
            console.log('%c' + message, 'color: #bbb');
        }
    }
    debug.veryVerbose = veryVerbose;
    /** 仅在开发环境中打印调试信息. */
    function log(message) {
        if (debug.logLevel >= Level.Log) {
            console.log(message);
        }
    }
    debug.log = log;
    /** 仅在开发环境中打印警告信息. */
    function warn(message) {
        if (debug.logLevel >= Level.Log) {
            console.warn(message);
        }
    }
    debug.warn = warn;
    /** 开始计时. */
    function timeStart(name) {
        let startTime = 0;
        if (debug.logLevel >= Level.Log) {
            startTime = performance.now();
        }
        return () => {
            if (debug.logLevel >= Level.Log) {
                let endTime = performance.now();
                let costTime = (0, ff_1.toDecimal)(endTime - startTime, 2);
                let message = `${name} cost ${costTime} ms`;
                if (costTime > 10) {
                    console.log('%c' + message, 'color: #c80');
                }
                else {
                    log(message);
                }
            }
        };
    }
    debug.timeStart = timeStart;
    /** 用于记录已经做过提示的对象. */
    const ForWhichMap = new WeakSet();
    /** 仅在开发环境中打印调试信息. */
    function logOnce(message, forWhich) {
        if (debug.development && !ForWhichMap.has(forWhich)) {
            console.log(message);
            ForWhichMap.add(forWhich);
        }
    }
    debug.logOnce = logOnce;
    /** 仅在开发环境中打印警告信息. */
    function warnOnce(message, forWhich) {
        if (debug.development && !ForWhichMap.has(forWhich)) {
            console.warn(message);
            ForWhichMap.add(forWhich);
        }
    }
    debug.warnOnce = warnOnce;
})(debug || (exports.debug = debug = {}));


/***/ }),

/***/ "./src/libs/util/file.ts":
/*!*******************************!*\
  !*** ./src/libs/util/file.ts ***!
  \*******************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.isBlobURL = exports.isRelativePath = exports.isAbsolutePath = exports.getPathExtension = exports.getPathParent = exports.getPathBaseName = exports.getPathName = exports.getFilefromURL = exports.readBlobAsArrayBuffer = void 0;
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
/** 读取 Blob 为 ArrayBuffer. */
function readBlobAsArrayBuffer(blob) {
    return new Promise((resolve, reject) => {
        var fileReader = new FileReader();
        fileReader.onload = () => {
            resolve(fileReader.result);
        };
        fileReader.onerror = () => {
            reject(fileReader.error);
        };
        fileReader.readAsArrayBuffer(blob);
    });
}
exports.readBlobAsArrayBuffer = readBlobAsArrayBuffer;
/** 从 URL 获取一个 File 对象. */
async function getFilefromURL(url) {
    let blob = await (await fetch(url)).blob();
    let name = getPathName(url) || 'unknown';
    return new File([blob], name);
}
exports.getFilefromURL = getFilefromURL;
/** 获得文件路径中的名称部分. */
function getPathName(path) {
    return (0, ff_1.firstMatch)(path, /([^\\\/]+)$/);
}
exports.getPathName = getPathName;
/** 获得文件路径中的名称部分. */
function getPathBaseName(path) {
    return getPathName(path).replace(/\.(\w+)$/, '');
}
exports.getPathBaseName = getPathBaseName;
/** 获得文件路径中的名称部分. */
function getPathParent(path) {
    return path.replace(/[\\\/]([^\\\/]+)$/, '');
}
exports.getPathParent = getPathParent;
/** 获得文件路径中的后缀部分, 并且转换为小写. */
function getPathExtension(path) {
    return (0, ff_1.firstMatch)(path, /\.(\w+)$/).toLowerCase();
}
exports.getPathExtension = getPathExtension;
/** 检查路径是否为绝对路径. */
function isAbsolutePath(path) {
    return /^\w+:|^\/\//.test(path);
}
exports.isAbsolutePath = isAbsolutePath;
/** 检查路径是否为相对路径. */
function isRelativePath(path) {
    return !isAbsolutePath(path);
}
exports.isRelativePath = isRelativePath;
/** 检查路径是否为 Blob 路径. */
function isBlobURL(url) {
    return /^blob:/.test(url);
}
exports.isBlobURL = isBlobURL;


/***/ }),

/***/ "./src/libs/util/image-worker-decoder.ts":
/*!***********************************************!*\
  !*** ./src/libs/util/image-worker-decoder.ts ***!
  \***********************************************/
/***/ ((__unused_webpack_module, exports) => {


// 参考 https://stackoverflow.com/questions/58856403/decode-images-in-web-worker
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.decodeImageInWorker = exports.supportsDecodeImageInWorker = void 0;
let workerScript = `
let ctx = new OffscreenCanvas(1, 1).getContext('2d')

onmessage = async function (e) {
	let url = e.data.url
	let response = await fetch(url, {mode: 'cors'})
	let blob = await response.blob()

	let bitmap = await createImageBitmap(blob, {
		imageOrientation: 'none',
		premultiplyAlpha: 'premultiply',
		colorSpaceConversion: 'none',
	})

	ctx.canvas.width = bitmap.width
	ctx.canvas.height = bitmap.height
	ctx.drawImage(bitmap, 0, 0)

	let imgData = ctx.getImageData(0, 0, ctx.canvas.width, ctx.canvas.height)
	let data = new Uint8Array(imgData.data)

	postMessage({
		width: imgData.width,
		height: imgData.height,
		data: data.buffer,
	}, [data.buffer])
}
`;
/** 是否支持使用 Worker 解码图片. */
function supportsDecodeImageInWorker() {
    return !!window.OffscreenCanvas;
}
exports.supportsDecodeImageInWorker = supportsDecodeImageInWorker;
/** 使用 Worker 解码图片. */
function decodeImageInWorker(url) {
    return new Promise((resolve, reject) => {
        let blob = new Blob([workerScript], { type: 'application/javascript' });
        let worker = new Worker(URL.createObjectURL(blob));
        worker.onmessage = async (e) => {
            let { width, height, data: arrayBuffer } = e.data;
            let data = new Uint8Array(arrayBuffer);
            resolve({ width, height, data });
        };
        worker.onerror = reject;
        worker.postMessage({ url });
    });
}
exports.decodeImageInWorker = decodeImageInWorker;


/***/ }),

/***/ "./src/libs/util/jpeg-orientation.ts":
/*!*******************************************!*\
  !*** ./src/libs/util/jpeg-orientation.ts ***!
  \*******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.fixJPEGOrientation = void 0;
const preload_1 = __webpack_require__(/*! ./preload */ "./src/libs/util/preload.ts");
/** 修复 JPEG 图片的旋转. */
async function fixJPEGOrientation(file) {
    if (file.type !== 'image/jpeg') {
        return file;
    }
    let orientation = await getJPEGOrientation(file);
    if (orientation <= 1) {
        return file;
    }
    let url = URL.createObjectURL(file);
    let image = await (0, preload_1.preloadImage)(url);
    let canvas = document.createElement('canvas');
    let width = image.naturalWidth;
    let height = image.naturalHeight;
    canvas.width = width;
    canvas.height = height;
    // 绘制 Canvas 时会自动纠正 orientation.
    let context = canvas.getContext('2d');
    context.drawImage(image, 0, 0);
    return new Promise((resolve) => {
        canvas.toBlob((blob) => {
            let newFile = new File([blob], file.name);
            resolve(newFile);
        }, `image/$jpeg`, 1);
    });
}
exports.fixJPEGOrientation = fixJPEGOrientation;
/**
 * 获取 JPEG 的旋转信息. 来源于:
 * https://stackoverflow.com/questions/7584794/accessing-jpeg-exif-rotation-data-in-javascript-on-the-client-side/20600869
 */
async function getJPEGOrientation(file) {
    return new Promise(resolve => {
        let reader = new FileReader();
        reader.onload = (event) => {
            if (!event.target) {
                return;
            }
            let file = event.target;
            let view = new DataView(file.result);
            if (view.getUint16(0, false) != 0xFFD8) {
                return resolve(-2);
            }
            let length = view.byteLength;
            let offset = 2;
            while (offset < length) {
                if (view.getUint16(offset + 2, false) <= 8) {
                    return resolve(-1);
                }
                let marker = view.getUint16(offset, false);
                offset += 2;
                if (marker == 0xFFE1) {
                    if (view.getUint32(offset += 2, false) != 0x45786966) {
                        return resolve(-1);
                    }
                    let little = view.getUint16(offset += 6, false) == 0x4949;
                    offset += view.getUint32(offset + 4, little);
                    let tags = view.getUint16(offset, little);
                    offset += 2;
                    for (let i = 0; i < tags; i++) {
                        if (view.getUint16(offset + (i * 12), little) == 0x0112) {
                            return resolve(view.getUint16(offset + (i * 12) + 8, little));
                        }
                    }
                }
                else if ((marker & 0xFF00) != 0xFF00) {
                    break;
                }
                else {
                    offset += view.getUint16(offset, false);
                }
            }
            resolve(-1);
        };
        reader.readAsArrayBuffer(file);
    });
}


/***/ }),

/***/ "./src/libs/util/preload.ts":
/*!**********************************!*\
  !*** ./src/libs/util/preload.ts ***!
  \**********************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.loadStyle = exports.loadScript = exports.preloadAudio = exports.preloadVideo = exports.preloadImage = void 0;
/** 预加载图片. */
async function preloadImage(url) {
    return new Promise(async (resolve, reject) => {
        let blob = await preloadAsBlob(url);
        let img = new Image();
        img.src = URL.createObjectURL(blob);
        img.onload = () => resolve(img);
        img.onerror = (err) => reject(err);
    });
}
exports.preloadImage = preloadImage;
/** 预加载为 Blob. */
async function preloadAsBlob(url) {
    return await (await fetch(url, { mode: 'cors' })).blob();
}
/** 预加载视频的内容. */
function preloadVideo(url) {
    return new Promise(async (resolve, reject) => {
        let blob = await preloadAsBlob(url);
        let video = document.createElement('video');
        video.preload = 'auto';
        video.oncanplaythrough = () => resolve(video);
        video.onerror = (err) => reject(err);
        video.src = URL.createObjectURL(blob);
        // 等待最多 1s. 以预防一些永远不触发事件的问题.
        setTimeout(() => {
            resolve(video);
        }, 1000);
    });
}
exports.preloadVideo = preloadVideo;
/** 预加载音频的内容. */
function preloadAudio(url) {
    return new Promise(async (resolve, reject) => {
        let blob = await preloadAsBlob(url);
        let audio = document.createElement('audio');
        audio.preload = 'auto';
        audio.oncanplaythrough = () => resolve(audio);
        audio.onerror = (err) => reject(err);
        audio.src = URL.createObjectURL(blob);
        // 等待最多 1s. 以预防一些永远不触发事件的问题.
        setTimeout(() => {
            resolve(audio);
        }, 1000);
    });
}
exports.preloadAudio = preloadAudio;
/** 加载脚本. */
function loadScript(url) {
    return new Promise((resolve, reject) => {
        let script = document.createElement('script');
        script.async = false;
        script.src = url;
        document.head.append(script);
        script.addEventListener('load', () => resolve());
        script.addEventListener('error', () => reject());
    });
}
exports.loadScript = loadScript;
/** 加载 CSS 文件. */
function loadStyle(url) {
    return new Promise((resolve, reject) => {
        let link = document.createElement('link');
        link.rel = 'stylesheet';
        link.href = url;
        document.head.append(link);
        link.addEventListener('load', () => resolve());
        link.addEventListener('error', () => reject());
    });
}
exports.loadStyle = loadStyle;


/***/ }),

/***/ "./src/libs/util/timestamp.ts":
/*!************************************!*\
  !*** ./src/libs/util/timestamp.ts ***!
  \************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.addTimestamp = void 0;
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
const file_1 = __webpack_require__(/*! ./file */ "./src/libs/util/file.ts");
// 当前脚本的时间戳.
const timestamp = document.currentScript instanceof HTMLScriptElement ? (0, ff_1.firstMatch)(document.currentScript.src, /\?(\d+|\w+=\d+)/) : '';
/** 为 URL 增加时间戳. */
function addTimestamp(url) {
    if (!timestamp || (0, file_1.isBlobURL)(url)) {
        return url;
    }
    if (url.includes('?')) {
        return url + '&' + timestamp;
    }
    else {
        return url + '?' + timestamp;
    }
}
exports.addTimestamp = addTimestamp;


/***/ }),

/***/ "./src/libs/webgl/mapped-sampler.ts":
/*!******************************************!*\
  !*** ./src/libs/webgl/mapped-sampler.ts ***!
  \******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.MappedSampler = void 0;
const matrix4_1 = __webpack_require__(/*! ../math/matrix4 */ "./src/libs/math/matrix4.ts");
/**
 * 映射纹理, 包含纹理采样器以及其对应的采样变换 (映射) 矩阵.
 * 它的采样变换映射矩阵将物体的运动矩阵转为采样矩阵,
 * 从而直接计算最终采样坐标而不用再绘制运动矩阵的效果.
 *
 * 起初它还包含一个不可叠加的裁剪矩阵, 用于当纹理对应到整个画布一小块,
 * 具体方法是在 GLSL 端使用裁剪矩阵乘以采样坐标, 然后将数字 clamp 到 0~1 范围.
 * 但是实测这样会带来一个很大的问题, 即如果采样跨域了 0~1 范围, 线性采样所获得的结果会不连续.
 *
 * 尽管只有两个公开属性, 不过仍保留此类, 因为它非常通用.
 */
class MappedSampler {
    sampler;
    mapMatrix;
    constructor(sampler, mapMatrix = matrix4_1.Matrix4.I) {
        this.sampler = sampler;
        this.mapMatrix = mapMatrix;
    }
    /** 释放纹理对象, 通知不再使用它. */
    release() {
        this.sampler.release();
    }
}
exports.MappedSampler = MappedSampler;


/***/ }),

/***/ "./src/libs/webgl/reference-counter.ts":
/*!*********************************************!*\
  !*** ./src/libs/webgl/reference-counter.ts ***!
  \*********************************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ReferenceCounter = void 0;
/** 用于记录某类对象被使用的次数, 当不再使用时触发 callback. */
// 此类最初想设计为一个更加通用的类, 并且不需要做初始化即可进行零
// 散地添加引用并且做弱映射以不干扰内存回收.
// 不过后来由于其功能扩展后确实需要做配置, 所以需要初始化.
// 并且成为了 WebGL 库的专用类.
class ReferenceCounter {
    /** 如果无引用并且维持此段时间之后, 则触发回调. */
    noReferenceForSeconds = 5;
    /** 如果没有被引用过并且维持此段时间之后, 则触发回调. */
    noTouchForSeconds = 5;
    /** 用于记录数据被何对象引用, 以便于调试. */
    usedMap = new Map();
    /** 用于存储当前移除的倒计时. */
    deleteTimeoutMap = new Map();
    /** 用于存储当前新注册对象无任何引用的回调倒计时. */
    warnNoTouchTimeoutMap = new Map();
    constructor(options = {}) {
        if (options.noReferenceForSeconds !== undefined) {
            this.noReferenceForSeconds = options.noReferenceForSeconds;
        }
        if (options.noTouchForSeconds !== undefined) {
            this.noTouchForSeconds = options.noTouchForSeconds;
        }
    }
    /** 当新的对象生成时注册它, 如果它稍后超过某个时间仍未被引用过, 则触发一个回调. */
    register(item) {
        let timeoutId = setTimeout(() => this.warnNoTouch(item), this.noTouchForSeconds * 1000);
        this.warnNoTouchTimeoutMap.set(item.id, timeoutId);
    }
    warnNoTouch(item) {
        this.warnNoTouchTimeoutMap.delete(item.id);
        item.__onNoTouchForSeconds(this.noTouchForSeconds);
    }
    /** 新的引用产生. */
    use(item, by) {
        this.clearTimeouts(item.id);
        let usedSet = this.usedMap.get(item.id);
        if (!usedSet) {
            usedSet = new Set();
            this.usedMap.set(item.id, usedSet);
        }
        usedSet.add(by);
    }
    /** 取消回调倒计时. */
    clearTimeouts(id) {
        let deleteTimeoutId = this.deleteTimeoutMap.get(id);
        if (deleteTimeoutId !== undefined) {
            clearTimeout(deleteTimeoutId);
            this.deleteTimeoutMap.delete(id);
        }
        let warnTimeoutId = this.warnNoTouchTimeoutMap.get(id);
        if (warnTimeoutId !== undefined) {
            clearTimeout(warnTimeoutId);
            this.warnNoTouchTimeoutMap.delete(id);
        }
    }
    /** 当一个引用被移除时调用, 如果一定时间内未产生新的引用, 则触发 callback. */
    unuse(item, by) {
        if (!this.usedMap.has(item.id)) {
            return;
        }
        let usedSet = this.usedMap.get(item.id);
        usedSet.delete(by);
        // 略微延迟释放以应对释放后马上引用的情况.
        // 即使延迟时间为 0 也使用 setTimeout 是因为一些绘制任务可能会在 Micro Task 中创建, 所以需要保证比这些任务更靠后.
        // 这里有一个小问题: 如果无引用, 开始计时, 结束前引用再释放引用, 
        if (usedSet.size === 0) {
            let timeoutId = setTimeout(() => this.deleteReference(item), this.noReferenceForSeconds * 1000);
            this.deleteTimeoutMap.set(item.id, timeoutId);
            item.__onNoReference();
        }
    }
    /** 对象是否正在被使用. */
    isUsing(item) {
        let usedSet = this.usedMap.get(item.id);
        return !!usedSet && usedSet.size > 0;
    }
    /** 检查是否无引用, 如果是, 则调用 callback. */
    deleteReference(item) {
        this.deleteTimeoutMap.delete(item.id);
        this.usedMap.delete(item.id);
        item.__onNoReferenceForSeconds(this.noReferenceForSeconds);
    }
    /** 从外部移除所有引用, 但是不会调用 callback. */
    delete(item) {
        this.clearTimeouts(item.id);
        this.usedMap.delete(item.id);
    }
}
exports.ReferenceCounter = ReferenceCounter;


/***/ }),

/***/ "./src/libs/webgl/sampler-manager.ts":
/*!*******************************************!*\
  !*** ./src/libs/webgl/sampler-manager.ts ***!
  \*******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SamplerManager = exports.TextureUploadState = void 0;
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
var TextureUploadState;
(function (TextureUploadState) {
    /** 未有任何数据上传. */
    TextureUploadState[TextureUploadState["NotUploaded"] = 0] = "NotUploaded";
    /** 需要的数据已经上传. */
    TextureUploadState[TextureUploadState["Uploaded"] = 1] = "Uploaded";
})(TextureUploadState || (exports.TextureUploadState = TextureUploadState = {}));
/**
 * 用于自动管理采样器以及纹理单元的包括创建, 删除, 重用等等.
 * 由于我们可以上传一堆纹理数据并且设置采样器, 但是每次只能激活最多 16(可能更多) 个.
 * 所以这里将纹理单元以及对应采样器的管理进行自动化, 在每个对象绘制之前, 将其依赖的采样器链接到纹理单元上.
 * 此外, 如果多个绘制对象依赖的纹理数据有重复, 这里也会选择共享它, 而不会重复上传.
 * 此类负责写入 Sampler 的 index 和 texture.
 */
class SamplerManager extends ff_1.Emitter {
    context;
    /** 存储当前纹理单元的占用情况. */
    samplerUnits;
    /** 用于存储纹理数据所关联的采样器. Sampler 的类型指定为数组而不是 Set 是因为需要针对 sampler 的 id 做操作. */
    dataCacher = new Map();
    /** 用于存储纹理是否生成了 mipmap. */
    mipmapGenerated = new Set();
    constructor(context) {
        super();
        this.context = context;
        // 根据纹理单元数目设置当前激活的采样器数组.
        // 建议优先选择将纹理数据绑定到 ToDraw 对象上然后按照需要来动态设置.
        let maxTextureUnitCount = this.context.getParameter(this.context.MAX_TEXTURE_IMAGE_UNITS);
        this.samplerUnits = new Array(maxTextureUnitCount);
    }
    /** 为采样器申请纹理单元, 并且将其激活为当前纹理单元. */
    requestUnitIndex(sampler, toDraw = null) {
        sampler.unitIndex = this.requestAUnitIndex(toDraw);
        this.storeIntoUnits(sampler);
    }
    /**
     * 申请一个可用的纹理单元, 并且将其激活和设置为当前纹理单元.
     * 注意这里不负责清理之前该索引位置的采样器, 需要稍后通过调用 store 来清理和重新放置.
     */
    requestAUnitIndex(toDraw = null) {
        let index = -1;
        // 优先使用未被占用的单元.
        index = this.samplerUnits.findIndex(sampler => sampler === undefined);
        // 其次使用当前不被使用可以暂时取消激活的纹理单元.
        if (index === -1) {
            for (let i = 0; i < this.samplerUnits.length; i++) {
                let sampler = this.samplerUnits[i];
                let usingIt = toDraw && toDraw.__isUsingSampler(sampler);
                if (!toDraw || !usingIt) {
                    index = i;
                    break;
                }
            }
        }
        if (index === -1) {
            throw new Error(`All of the texture units are in use!`);
        }
        this.context.activeTexture(this.context.TEXTURE0 + index);
        return index;
    }
    /** 当采样器创建时将其记录到其关联的索引位置. */
    storeIntoUnits(sampler) {
        let index = sampler.unitIndex;
        let oldSampler = this.samplerUnits[index];
        if (oldSampler) {
            this.unstoreFromUnits(oldSampler);
        }
        this.samplerUnits[index] = sampler;
    }
    /** 释放采样器使用的纹理单元, 但是保持其数据待在 GPU, 待使用时会再申请纹理单元. */
    unstoreFromUnits(sampler) {
        if (sampler.unitIndex > -1) {
            this.samplerUnits[sampler.unitIndex] = undefined;
            sampler.unitIndex = -1;
        }
    }
    /**
     * 根据纹理数据创建或者重用一个纹理对象.
     * 所使用的当前纹理单元必须已被激活.
     * 返回是否已经纹理数据是否已被上传.
     */
    requestTexture(sampler) {
        let texture = this.findTextureForData(sampler.data);
        let state = TextureUploadState.Uploaded;
        if (!texture) {
            texture = this.context.createTexture();
            state = TextureUploadState.NotUploaded;
        }
        this.context.bindTexture(this.context.TEXTURE_2D, texture);
        sampler.texture = texture;
        // 保持纹理数据和对象之间的关联.
        this.cacheData(sampler);
        return state;
    }
    /** 是否存在已创建的纹理关联到纹理数据. */
    hasTextureForData(data) {
        return this.dataCacher.has(data);
    }
    /** 从纹理数据查询已创建的纹理. */
    findTextureForData(data) {
        if (!this.shouldCacheData(data)) {
            return null;
        }
        let samplers = this.dataCacher.get(data);
        if (samplers) {
            return [...samplers][0].texture;
        }
        else {
            return null;
        }
    }
    /** 确保 mipmap 已生成. */
    ensureMipmapIfNeeded(sampler) {
        let shouldGenerateAndNotYet = !this.mipmapGenerated.has(sampler.texture) && sampler.shouldGenerateMipmap();
        if (shouldGenerateAndNotYet) {
            this.generateMipmapIfNeeded(sampler);
        }
    }
    /** 如果有需要的话生成 mipmap. */
    generateMipmapIfNeeded(sampler) {
        if (sampler.shouldGenerateMipmap()) {
            sampler.activeAsCurrent();
            this.context.generateMipmap(this.context.TEXTURE_2D);
            this.mipmapGenerated.add(sampler.texture);
        }
        // 即使不需要生成, 之前生成的此时也已过期.
        else {
            this.mipmapGenerated.delete(sampler.texture);
        }
    }
    /** 当采样器创建或者重设数据时记录并且重用它的数据. */
    cacheData(sampler) {
        let data = sampler.data;
        if (this.shouldCacheData(data)) {
            let samplers = this.dataCacher.get(data);
            if (!samplers) {
                samplers = new Set();
                this.dataCacher.set(data, samplers);
            }
            samplers.add(sampler);
        }
    }
    /** 是否需要存储数据. */
    shouldCacheData(data) {
        return !!data;
    }
    /** 替换掉采样器纹理对象对应的数据, 会同时替换所有公用此数据的所有采样器. */
    replaceDataReference(sampler, newData) {
        // 由于更新数据, 之前的 mipmap 已经过期.
        this.mipmapGenerated.delete(sampler.texture);
        // 对于视频而言, 数据始终相同, 此时不用再更新数据引用.
        let oldData = sampler.data;
        if (oldData === newData) {
            return;
        }
        let samplersSharesData = null;
        if (this.shouldCacheData(oldData)) {
            samplersSharesData = this.dataCacher.get(oldData);
            this.dataCacher.delete(oldData);
            this.emit('deletedata', oldData);
        }
        if (this.shouldCacheData(newData)) {
            samplersSharesData = samplersSharesData || new Set();
            samplersSharesData.add(sampler);
            this.dataCacher.set(newData, samplersSharesData);
            for (let sampler of samplersSharesData) {
                sampler.data = newData;
            }
        }
    }
    /** 移除采样器的数据. */
    uncacheData(sampler) {
        // 数据是否有其他引用.
        let hasReference = false;
        let { data, texture } = sampler;
        if (this.shouldCacheData(data)) {
            let samplers = this.dataCacher.get(data);
            samplers.delete(sampler);
            hasReference = samplers.size > 0;
            // 不再有任何采样器依赖此纹理数据.
            if (!hasReference) {
                this.dataCacher.delete(data);
                this.emit('deletedata', data);
            }
        }
        // 只有其处于闲置状态时才移除.
        // 否则有可能它刚好被重用而移除旧的, 结果对象却被移除.
        if (!hasReference) {
            this.context.deleteTexture(texture);
            this.mipmapGenerated.delete(texture);
        }
    }
    /** 移除一个采样器, 返回是否移除了数据. */
    deleteUnitAndTexture(sampler) {
        this.unstoreFromUnits(sampler);
        this.uncacheData(sampler);
    }
}
exports.SamplerManager = SamplerManager;


/***/ }),

/***/ "./src/libs/webgl/sampler.ts":
/*!***********************************!*\
  !*** ./src/libs/webgl/sampler.ts ***!
  \***********************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.TextureFrameSampler = exports.FloatSampler = exports.PixelSampler = exports.Sampler = exports.SamplerWrapType = exports.SamplerFilter = void 0;
const util_1 = __webpack_require__(/*! ./util */ "./src/libs/webgl/util.ts");
const sampler_manager_1 = __webpack_require__(/*! ./sampler-manager */ "./src/libs/webgl/sampler-manager.ts");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
const debug_1 = __webpack_require__(/*! ../util/debug */ "./src/libs/util/debug.ts");
/**
 * 纹理的采样插值类型, 关系到采样的效率.
 * 必须分析场景类型并且熟悉采样插值的具体算法才能准确确定使用哪一个.
 */
var SamplerFilter;
(function (SamplerFilter) {
    /** 读取最近的 1 个像素. */
    SamplerFilter[SamplerFilter["Nearest"] = WebGL2RenderingContext.prototype.NEAREST] = "Nearest";
    /** 读取最近的 4 个像素. */
    SamplerFilter[SamplerFilter["Linear"] = WebGL2RenderingContext.prototype.LINEAR] = "Linear";
    /** 读取最近的层上的 1 个像素. */
    SamplerFilter[SamplerFilter["MipmapNearestStatic"] = WebGL2RenderingContext.prototype.NEAREST_MIPMAP_NEAREST] = "MipmapNearestStatic";
    /** 读取两个层上的各 1 个像素. */
    SamplerFilter[SamplerFilter["MipmapNearest"] = WebGL2RenderingContext.prototype.NEAREST_MIPMAP_LINEAR] = "MipmapNearest";
    /** 读取最近的层上的 4 个像素. */
    SamplerFilter[SamplerFilter["MipmapLinearStatic"] = WebGL2RenderingContext.prototype.LINEAR_MIPMAP_NEAREST] = "MipmapLinearStatic";
    /** 读取两个层上的各 4 个像素. */
    SamplerFilter[SamplerFilter["MipmapLinear"] = WebGL2RenderingContext.prototype.LINEAR_MIPMAP_LINEAR] = "MipmapLinear";
})(SamplerFilter || (exports.SamplerFilter = SamplerFilter = {}));
/** 纹理的重复类型. */
var SamplerWrapType;
(function (SamplerWrapType) {
    /** 重复平铺. */
    SamplerWrapType[SamplerWrapType["Repeat"] = WebGL2RenderingContext.prototype.REPEAT] = "Repeat";
    /** 镜像平铺. */
    SamplerWrapType[SamplerWrapType["Mirror"] = WebGL2RenderingContext.prototype.MIRRORED_REPEAT] = "Mirror";
    /** 使用边缘平铺. */
    SamplerWrapType[SamplerWrapType["ClampToEdge"] = WebGL2RenderingContext.prototype.CLAMP_TO_EDGE] = "ClampToEdge";
})(SamplerWrapType || (exports.SamplerWrapType = SamplerWrapType = {}));
/** 默认的参数. */
const DefaultSamplerParameters = {
    filter: SamplerFilter.Nearest,
    wrapType: SamplerWrapType.Mirror,
    anisotropy: false,
};
/** 对应着一个采样器. */
class Sampler extends ff_1.Emitter {
    /** 采样器对应的唯一 id. */
    id = (0, util_1.generateUniqueID)();
    /** 原始纹理数据. 不同的采样器可能会共用同一个纹理数据. */
    data;
    /** 数据的宽度. */
    width;
    /** 数据的高度. */
    height;
    /** 采样设置信息. */
    params;
    /** 纹理数据上传之后获得的纹理对象. */
    texture;
    /** 如果为 -1, 代表该采样器未被安置到某个纹理单元, 需要再使用之前激活它. */
    unitIndex;
    context;
    /**
     * 用于在不同的采样器之间交换信息.
     * 这个类有点问题, 因为某些属性具体在此类设置还是管理类里面设置会让人困惑.
     * 稍后等到对于其理解更加完善之后再将这种难以预测的二义性去除.
     */
    manager;
    /** 当无引用时是否立即删除. */
    deleteAfterNoReference = true;
    /**
     * 对应的 gl 采样器.
     * 如果值为 null, 则意味着采样器对象已被删除.
     * 理论上, gl 采样器用于覆写纹理单元的采样方式, 应当只和纹理单元有关, 和具体的纹理无关.
     * 但是由于采样设置的重用是一件麻烦的事, 而 gl 采样器本身消耗极低, 所以我们将采样器放置到纹理数据之下.
     */
    glSampler;
    /** 用于对当前采样器进行引用计数. */
    counter;
    /**
     * 上传图片或者数据作为公用纹理. 如果上次之后未使用, 不会将其释放.
     * 需要注意的是 texImage2D 会解码图片为 binary image data 的形式, 对于 1080p 的图片可能会花费 50ms.
     */
    constructor(sw, data, params = {}) {
        super();
        this.context = sw.context;
        this.manager = sw.samplerManager;
        this.counter = sw.samplerReferenceCounter;
        this.data = data;
        let size = this.getDataSize(data);
        this.width = size.width;
        this.height = size.height;
        this.glSampler = this.context.createSampler();
        this.setupParameters(Object.assign({}, DefaultSamplerParameters, params));
        this.initialize();
    }
    /** 由于需要在子类中先初始化更多参数再调用, 所以由子类在 constructor 中调用. */
    initialize() {
        // 申请一个纹理单元并且激活它.
        this.manager.requestUnitIndex(this);
        // 申请一个纹理对象, 可能会重用已有的.
        let uploadState = this.manager.requestTexture(this);
        // 如果数据未被上传, 则上传数据.
        if (uploadState === sampler_manager_1.TextureUploadState.NotUploaded) {
            let { width, height } = this;
            // 只有当宽高存在时才会计时, 对于只是分配对象而不实际上传的情况不计时.
            if (width && height) {
                let timeEnd = debug_1.debug.timeStart(`${this.data ? 'Uploading' : 'Allocating'} ${this.constructor.name} ${this.id} in size "${width}x${height}"`);
                this.uploadData();
                timeEnd();
            }
            else {
                this.uploadData();
            }
        }
        // 确保生成 mipmap, 如果需要的话.
        this.manager.ensureMipmapIfNeeded(this);
        // 绑定采样设置.
        this.context.bindSampler(this.unitIndex, this.glSampler);
    }
    /** 设置采样器的参数. */
    setupParameters(params) {
        this.setupFilterParameter(params.filter);
        this.setupAnisotropyParameter(params.anisotropy);
        this.setupWrapTypeParameter(params.wrapType);
        this.params = params;
    }
    /** 设置采样器的过滤参数. */
    setupFilterParameter(filter) {
        let context = this.context;
        let glSampler = this.glSampler;
        switch (filter) {
            case SamplerFilter.MipmapLinearStatic:
            case SamplerFilter.MipmapLinear:
            case SamplerFilter.Linear:
                context.samplerParameteri(glSampler, context.TEXTURE_MAG_FILTER, context.LINEAR);
                break;
            default:
                context.samplerParameteri(glSampler, context.TEXTURE_MAG_FILTER, context.NEAREST);
        }
        context.samplerParameteri(glSampler, context.TEXTURE_MIN_FILTER, filter);
    }
    /** 设置采样器的各向异性过滤参数. */
    setupAnisotropyParameter(anisotropy) {
        let context = this.context;
        let glSampler = this.glSampler;
        if (anisotropy) {
            var ext = context.getExtension('EXT_texture_filter_anisotropic');
            if (ext) {
                var max = context.getParameter(ext.MAX_TEXTURE_MAX_ANISOTROPY_EXT);
                context.samplerParameterf(glSampler, ext.TEXTURE_MAX_ANISOTROPY_EXT, max);
            }
            context.samplerParameteri(glSampler, context.TEXTURE_MAG_FILTER, context.LINEAR);
            context.samplerParameteri(glSampler, context.TEXTURE_MIN_FILTER, context.LINEAR_MIPMAP_LINEAR);
        }
    }
    /** 设置采样器的重复参数. */
    setupWrapTypeParameter(wrapType) {
        let context = this.context;
        let glSampler = this.glSampler;
        context.samplerParameteri(glSampler, context.TEXTURE_WRAP_S, wrapType);
        context.samplerParameteri(glSampler, context.TEXTURE_WRAP_T, wrapType);
    }
    /** 对象是否正在被使用. */
    inUse() {
        return this.counter.isUsing(this);
    }
    /** 将纹理对象的引用次数加 1, 当 ToDraw 对象引用其时调用. */
    __use(by) {
        this.counter.use(this, by);
    }
    /** 将纹理对象的引用次数减 1, 当 ToDraw 对象引用其时调用. */
    __unuse(by) {
        this.counter.unuse(this, by);
    }
    /** 当纹理数据不再有引用时触发. */
    __onNoReference() {
        this.emit('noreference');
    }
    /** 当纹理数据不再有引用并且持续一段时间时触发. */
    __onNoReferenceForSeconds() {
        if (this.deleteAfterNoReference) {
            this.delete();
        }
    }
    /** 如果超过一段时间没有被引用, 抛出一个警告. */
    __onNoTouchForSeconds(seconds) {
        console.warn(`Sampler "${this.id}" has no reference for ${seconds} seconds after created`);
    }
    /** 为指定的纹理分配纹理单元, 如果 toDraw 对象指定的话, 不会覆盖其已使用的纹理单元. */
    active(toDraw = null) {
        if (this.unitIndex > -1) {
            return;
        }
        if (!this.glSampler) {
            throw new Error(`Sampler "${this.id}" has been deleted!`);
        }
        this.manager.requestUnitIndex(this, toDraw);
        this.context.bindSampler(this.unitIndex, this.glSampler);
        this.context.bindTexture(this.context.TEXTURE_2D, this.texture);
    }
    /** 激活并且设置为当前纹理单元, 以上传数据, 生成 mipmap 等. */
    activeAsCurrent() {
        if (this.unitIndex > -1) {
            this.context.activeTexture(this.context.TEXTURE0 + this.unitIndex);
            this.context.bindTexture(this.context.TEXTURE_2D, this.texture);
        }
        else {
            this.active();
        }
    }
    /** 更新采样器的采样参数. */
    updateParameters(params) {
        params = Object.assign({}, DefaultSamplerParameters, params);
        if ((0, ff_1.deepEqual)(params, this.params)) {
            return;
        }
        this.setupParameters(params);
        // 如果有必要, 确保纹理对象对应的 mipmap 生成, 但是不会重复生成.
        this.manager.ensureMipmapIfNeeded(this);
    }
    /** 如果采样器有 mipmap 设置的话, 则更新它. 当纹理的源数据更改之后调用. */
    updateMipmapIfNeed() {
        this.manager.generateMipmapIfNeeded(this);
    }
    /** 根据参数判断是否应当设置 mipmap. */
    shouldGenerateMipmap() {
        // 注意这里没有判断数据, 因为纹理缓存对象的采样器没有数据, 但是绘制之后同样要生成 mipmap.
        let filter = this.params.filter;
        let isMipmapFilter = [
            SamplerFilter.MipmapNearestStatic,
            SamplerFilter.MipmapLinearStatic,
            SamplerFilter.MipmapNearest,
            SamplerFilter.MipmapLinear,
        ].includes(filter);
        return isMipmapFilter;
    }
    /** 更新数据, 尺寸可能相同也可能不同. */
    updateData(data) {
        // 如果数据对应的纹理对象已经存在, 并且和之前的不同, 则替换为它.
        if (data !== this.data && this.manager.hasTextureForData(data)) {
            this.updateDataWithNewTexture(data);
        }
        let newSize = this.getDataSize(data);
        // 上传同尺寸的数据.
        if (newSize.width === this.width && newSize.height === this.height) {
            this.updateDataInSameSize(data);
        }
        // 重新分配纹理对象以上传不同尺寸的数据.
        else {
            this.updateDataWithNewTexture(data);
        }
    }
    /**
     * 更新相同尺寸的纹理数据, 用于例如更新视频帧. 如果有必要的话也会更新 Mipmap.
     * 由于不用重新分配显存所以其速度有优势, 但是一定要注意只能更新为和之前同样尺寸的纹理数据.
     */
    updateDataInSameSize(data) {
        // 替换之前的纹理数据的引用, 影响到所有共享此数据的对象.
        this.manager.replaceDataReference(this, data);
        this.data = data;
        this.activeAsCurrent();
        this.replaceData();
        this.context.bindSampler(this.unitIndex, this.glSampler);
        this.updateMipmapIfNeed();
    }
    /** 更新不同尺寸的纹理数据, 纹理对象将会被重建, 但是采样方式会被保留. */
    updateDataWithNewTexture(data) {
        this.manager.deleteUnitAndTexture(this);
        let newSize = this.getDataSize(data);
        this.width = newSize.width;
        this.height = newSize.height;
        this.data = data;
        this.initialize();
    }
    /** 跳过计数手动释放掉指定的纹理的引用, 触发 noreference 事件. */
    release() {
        this.__onNoReference();
    }
    /** 手动移除指定的纹理采样器. 一般只有供纹理缓存使用的采样器才有必要手动删除. */
    delete() {
        this.manager.deleteUnitAndTexture(this);
        this.counter.delete(this);
        this.context.deleteSampler(this.glSampler);
        this.glSampler = null;
        let { width, height } = this;
        debug_1.debug.verbose(`${this.constructor.name} ${this.id} in size "${width}x${height}" deleted`);
        this.emit('delete');
    }
}
exports.Sampler = Sampler;
/** RGBA 像素资源纹理采样器. */
class PixelSampler extends Sampler {
    /** 获得资源的像素尺寸, 也是最后会占用内存的尺寸. */
    getDataSize(data) {
        let width = 0;
        let height = 0;
        if (data instanceof HTMLVideoElement) {
            width = data.videoWidth;
            height = data.videoHeight;
        }
        else if (data instanceof HTMLImageElement) {
            width = data.naturalWidth;
            height = data.naturalHeight;
        }
        else if (data instanceof HTMLCanvasElement) {
            width = data.width;
            height = data.height;
        }
        else if (data) {
            width = data.width;
            height = data.height;
        }
        return { width, height };
    }
    /**
     * 上传图片或者数据作为纹理数据. 上传之后暂时不会将其释放. 直到一个 ToDraw 对象不再使用它, 并且没有其他 ToDraw 对象使用它.
     * 需要注意的是 texImage2D 会解码图片为 binary image data 的形式, 对于 1080p 的图片可能会花费 50ms.
     */
    uploadData() {
        if (!this.data) {
            return;
        }
        let isElement = this.data instanceof HTMLElement;
        if (isElement) {
            let data = this.data;
            this.context.texImage2D(this.context.TEXTURE_2D, 0, this.context.RGBA, this.context.RGBA, this.context.UNSIGNED_BYTE, data);
        }
        else {
            let { width, height, data } = this.data;
            // 由于解码数据非常大, 所以我们上传后就将其二进制数据移除.
            this.data.data = null;
            this.context.texImage2D(this.context.TEXTURE_2D, 0, this.context.RGBA, width, height, 0, this.context.RGBA, this.context.UNSIGNED_BYTE, data);
        }
    }
    /** 替换纹理数据. */
    replaceData() {
        if (!this.data) {
            return;
        }
        let isElement = this.data instanceof HTMLElement;
        if (isElement) {
            let data = this.data;
            this.context.texSubImage2D(this.context.TEXTURE_2D, 0, 0, 0, this.context.RGBA, this.context.UNSIGNED_BYTE, data);
        }
        else {
            let { width, height, data } = this.data;
            if (!data) {
                throw new Error(`Decoded image data has been released, please don't use it directly!`);
            }
            this.context.texSubImage2D(this.context.TEXTURE_2D, 0, 0, 0, width, height, this.context.RGBA, this.context.UNSIGNED_BYTE, data);
        }
    }
    shouldGenerateMipmap() {
        // 如果无数据, 则不应当设置 mipmap.
        if (!this.data) {
            return false;
        }
        return super.shouldGenerateMipmap();
    }
}
exports.PixelSampler = PixelSampler;
/** 二维浮点数据采样器. */
class FloatSampler extends Sampler {
    /** 获得资源的像素尺寸, 也是最后会占用内存的尺寸. */
    getDataSize(data) {
        let width = data.width;
        let height = data.height;
        return { width, height };
    }
    /**
     * 上传图片或者数据作为纹理数据. 上传之后暂时不会将其释放. 直到一个 ToDraw 对象不再使用它, 并且没有其他 ToDraw 对象使用它.
     * 需要注意的是 texImage2D 会解码图片为 binary image data 的形式, 对于 1080p 的图片可能会花费 50ms.
     */
    uploadData() {
        this.context.texImage2D(this.context.TEXTURE_2D, 0, this.context.R16F, this.width, this.height, 0, this.context.RED, this.context.FLOAT, this.data.data);
    }
    /** 替换纹理数据. */
    replaceData() {
        let width = this.width;
        let height = this.height;
        if (this.data) {
            this.context.texSubImage2D(this.context.TEXTURE_2D, 0, 0, 0, width, height, this.context.RGBA, this.context.UNSIGNED_BYTE, this.data.data);
        }
    }
}
exports.FloatSampler = FloatSampler;
/** 纹理缓存采样器, 用于输出纹理缓存的绘制内容. */
class TextureFrameSampler extends Sampler {
    /** 无引用之后不自动删除, 必须手动删除. */
    deleteAfterNoReference = false;
    /** 获得资源的像素尺寸, 也是最后会占用内存的尺寸. */
    getDataSize(data) {
        let width = data.width;
        let height = data.height;
        return { width, height };
    }
    /** 不实际上传资源, 只是分配显存. */
    uploadData() {
        this.context.texImage2D(this.context.TEXTURE_2D, 0, this.context.RGBA, this.width, this.height, 0, this.context.RGBA, this.context.UNSIGNED_BYTE, null);
    }
    /** 纹理数据. */
    updateData() {
        throw new Error(`Can't update data for "TextureFrameSampler"!`);
    }
    /** 替换纹理数据. */
    replaceData() {
        throw new Error(`Can't replace data for "TextureFrameSampler"!`);
    }
}
exports.TextureFrameSampler = TextureFrameSampler;


/***/ }),

/***/ "./src/libs/webgl/shader-program.ts":
/*!******************************************!*\
  !*** ./src/libs/webgl/shader-program.ts ***!
  \******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ShaderProgramManager = exports.ShaderProgram = void 0;
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
// 此模块对应了一个着色器程序, 它可以供切换.
// 提供了自动搜索所有的 uniform 绑定点并且自动判断应当使用的 uniform???.
// 此外该类支持同步所有的 uniform 参数, 这样方便做上下文切换.
// 注意代码没有重置默认 uniform 的行为, 所以应当为每个参数都设置值, 以防止上次设置的值因为这次未设置而无法重置.
class ShaderProgram {
    /** 着色器程序管理器, 用于共享着色程序. */
    manager;
    /** 顶点着色器代码. */
    vertCode;
    /** 片元着色器代码. */
    fragCode;
    /** 原始着色器程序. */
    webglProgram;
    context;
    /** 着色器变量地址信息. */
    uniformLocations = {};
    /** 着色器变量值. */
    uniformValues = {};
    /** 当前着色器程序是否被激活. */
    activated = false;
    // 如果多个 ToDraw 对象共享一个着色器程序, 则会大于 1.
    usedCount = 0;
    constructor(manager, vertCode, fragCode) {
        this.manager = manager;
        this.context = manager.context;
        this.vertCode = vertCode;
        this.fragCode = fragCode;
        this.webglProgram = this.createProgram();
        this.matchUniformLocations();
    }
    /** 创建着色器程序. */
    createProgram() {
        let vertexShader = this.initShader(this.vertCode, this.context.VERTEX_SHADER);
        let fragmentShader = this.initShader(this.fragCode, this.context.FRAGMENT_SHADER);
        let program = this.context.createProgram();
        if (!program) {
            throw new Error('Failed to create shader program!');
        }
        this.context.attachShader(program, vertexShader);
        this.context.attachShader(program, fragmentShader);
        this.context.linkProgram(program);
        if (!this.context.getProgramParameter(program, this.context.LINK_STATUS)) {
            throw this.context.getProgramInfoLog(program);
        }
        return program;
    }
    /** 编译着色器. */
    initShader(code, type) {
        let shader = this.context.createShader(type);
        if (!shader) {
            throw this.context.getError();
        }
        this.context.shaderSource(shader, code);
        this.context.compileShader(shader);
        let compiled = this.context.getShaderParameter(shader, this.context.COMPILE_STATUS);
        if (!compiled) {
            this.reportCompileError(code, shader);
        }
        return shader;
    }
    /** 通知编译错误. */
    reportCompileError(code, shader) {
        let error = this.context.getShaderInfoLog(shader);
        let lineNumber = Number((0, ff_1.firstMatch)(error, /0:(\d+)/));
        if (lineNumber) {
            let line = code.split(/\r?\n/)[lineNumber - 1].trim();
            throw '"' + line + '"\n' + error;
        }
        else {
            throw error;
        }
    }
    /** 匹配着色器代码中的 uniform 变量名称和类型. */
    matchUniformLocations() {
        this.matchUniformLocationsFromCode(this.vertCode);
        this.matchUniformLocationsFromCode(this.fragCode);
    }
    /** 匹配着色器代码中的 uniform 变量名称和类型. */
    matchUniformLocationsFromCode(code) {
        let uniforms = (0, ff_1.subMatches)(code, /uniform\s+(\w+)\s+(\w+)/g);
        for (let [type, name] of uniforms) {
            // 非常容易出现设置的参数实际未有使用的情况, 此时 location 为 null
            let location = this.context.getUniformLocation(this.webglProgram, name);
            if (location) {
                this.uniformLocations[name] = { type, location };
            }
        }
    }
    /** 激活当前着色器程序. */
    active() {
        this.context.useProgram(this.webglProgram);
        this.activated = true;
    }
    /** 不再激活当前着色器程序. */
    deactive() {
        this.activated = false;
    }
    /** 当前着色器程序引用次数增加. */
    use() {
        this.usedCount++;
    }
    /** 当前着色器程序引用次数减少. */
    unuse() {
        this.usedCount--;
        // 有可能着色器程序会先移除引用, 然后又马上引用, 所以这里应该创建一个延迟.
        // 使用 setTimeout 是因为一些绘制任务可能会在 Micro Task 中创建, 所以需要保证比这些任务更靠后.
        if (this.usedCount <= 0) {
            setTimeout(() => {
                if (this.usedCount <= 0) {
                    this.manager.delete(this);
                }
            }, 0);
        }
    }
    /** 取得着色器中的 uniform 变量的地址. */
    getUniformLocation(name) {
        return this.uniformLocations[name] ? this.uniformLocations[name].location : null;
    }
    /** 检查着色器中是否有设置指定的 uniform 变量. */
    hasUniform(name) {
        return !!this.uniformLocations[name];
    }
    /** 同步已设置的着色器变量对象. */
    syncUniform(values) {
        if (!this.activated) {
            throw new Error(`Shader must be in use when syncing uniform values`);
        }
        for (let [name, value] of Object.entries(values)) {
            if (this.uniformLocations[name] && !(0, ff_1.deepEqual)(this.uniformValues[name], value)) {
                this.doSettingUniformValue(name, value);
            }
        }
    }
    /** 同步已设置的着色器变量. */
    doSettingUniformValue(name, value) {
        let { type, location } = this.uniformLocations[name];
        // 单个值时转为数组, 从而统一通过矢量的形式设置.
        let isSingle = ['number', 'boolean'].includes(typeof value);
        if (isSingle) {
            value = [value];
        }
        switch (type) {
            case 'float':
            case 'double':
                this.context.uniform1fv(location, value);
                break;
            case 'int':
            case 'bool':
            case 'sampler2D':
                this.context.uniform1iv(location, value);
                break;
            case 'uint':
                this.context.uniform1uiv(location, value);
                break;
            case 'vec2':
            case 'dvec2':
                this.context.uniform2fv(location, value);
                break;
            case 'ivec2':
            case 'bvec2':
                this.context.uniform2iv(location, value);
                break;
            case 'uvec2':
                this.context.uniform2uiv(location, value);
                break;
            case 'vec3':
            case 'dvec3':
                this.context.uniform3fv(location, value);
                break;
            case 'ivec3':
            case 'bvec3':
                this.context.uniform3iv(location, value);
                break;
            case 'uvec3':
                this.context.uniform3uiv(location, value);
                break;
            case 'vec4':
            case 'dvec4':
                this.context.uniform4fv(location, value);
                break;
            case 'ivec4':
            case 'bvec4':
                this.context.uniform4iv(location, value);
                break;
            case 'uvec4':
                this.context.uniform4uiv(location, value);
                break;
            case 'mat2':
                this.context.uniformMatrix2fv(location, false, value);
                break;
            case 'mat3':
                this.context.uniformMatrix3fv(location, false, value);
                break;
            case 'mat4':
                this.context.uniformMatrix4fv(location, false, value);
                break;
            default:
                throw `Unmapped uniform data type "${type}"`;
        }
        this.uniformValues[name] = value;
    }
    /** 取得着色器程序中指定名称的顶点属性地址. */
    getAttributeLocation(name) {
        return this.context.getAttribLocation(this.webglProgram, name);
    }
}
exports.ShaderProgram = ShaderProgram;
/** 用于创建, 删除和缓存着色器程序, 同一个上下文, 同样的顶点和片元着色器将会重用用一个着色器程序. */
class ShaderProgramManager {
    context;
    // 关于这里为什么没有使用 vertexCode + fragmentCode 作为 key?
    // 原因和 V8 引擎处理字符串的方式有关: V8 在底层创建字符串时, 会自动为其计算一个 Hash,
    // 在之后再次创建相同的字符串时, 会直接根据 Hash 引用之前已创建的, 而不是重新分配内存.
    // 而当使用字符串作为索引时, 实际使用的仍然是 Hash.
    // 相比之下 vertexCode + fragmentCode 则会创建一个新的字符串并且为其分配内存, 这是很不划算的.
    map = {};
    constructor(context) {
        this.context = context;
    }
    /** 创建可被重用的着色器程序. */
    create(vertCode, fragCode) {
        let program = this.map[vertCode] ? this.map[vertCode][fragCode] : undefined;
        if (!program) {
            program = new ShaderProgram(this, vertCode, fragCode);
            this.map[vertCode] = this.map[vertCode] || {};
            this.map[vertCode][fragCode] = program;
        }
        program.use();
        return program;
    }
    /** 当着色器程序不再需要时将其删除. */
    delete(program) {
        this.context.deleteProgram(program.webglProgram);
        delete this.map[program.vertCode][program.fragCode];
    }
}
exports.ShaderProgramManager = ShaderProgramManager;


/***/ }),

/***/ "./src/libs/webgl/simple-webgl.ts":
/*!****************************************!*\
  !*** ./src/libs/webgl/simple-webgl.ts ***!
  \****************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SimpleWebGL = exports.SimpleWebGLBlendMode = void 0;
const shader_program_1 = __webpack_require__(/*! ./shader-program */ "./src/libs/webgl/shader-program.ts");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
const sampler_manager_1 = __webpack_require__(/*! ./sampler-manager */ "./src/libs/webgl/sampler-manager.ts");
const reference_counter_1 = __webpack_require__(/*! ./reference-counter */ "./src/libs/webgl/reference-counter.ts");
const texture_frame_manager_1 = __webpack_require__(/*! ./texture-frame-manager */ "./src/libs/webgl/texture-frame-manager.ts");
const matrix4_1 = __webpack_require__(/*! ../math/matrix4 */ "./src/libs/math/matrix4.ts");
const vector4_1 = __webpack_require__(/*! ../math/vector4 */ "./src/libs/math/vector4.ts");
const debug_1 = __webpack_require__(/*! ../util/debug */ "./src/libs/util/debug.ts");
/**
 * 混合模式.
 * 这个表只是一个列举, 目前只支持其中的一部分.
 * 要支持更多的混合模式, 需要通过着色对象进行着色.
 */
var SimpleWebGLBlendMode;
(function (SimpleWebGLBlendMode) {
    SimpleWebGLBlendMode[SimpleWebGLBlendMode["ADD"] = 0] = "ADD";
    SimpleWebGLBlendMode[SimpleWebGLBlendMode["ALPHA_ADD"] = 1] = "ALPHA_ADD";
    SimpleWebGLBlendMode[SimpleWebGLBlendMode["CLASSIC_COLOR_BURN"] = 2] = "CLASSIC_COLOR_BURN";
    SimpleWebGLBlendMode[SimpleWebGLBlendMode["CLASSIC_COLOR_DODGE"] = 3] = "CLASSIC_COLOR_DODGE";
    SimpleWebGLBlendMode[SimpleWebGLBlendMode["CLASSIC_DIFFERENCE"] = 4] = "CLASSIC_DIFFERENCE";
    SimpleWebGLBlendMode[SimpleWebGLBlendMode["COLOR"] = 5] = "COLOR";
    SimpleWebGLBlendMode[SimpleWebGLBlendMode["COLOR_BURN"] = 6] = "COLOR_BURN";
    SimpleWebGLBlendMode[SimpleWebGLBlendMode["COLOR_DODGE"] = 7] = "COLOR_DODGE";
    SimpleWebGLBlendMode[SimpleWebGLBlendMode["DANCING_DISSOLVE"] = 8] = "DANCING_DISSOLVE";
    SimpleWebGLBlendMode[SimpleWebGLBlendMode["DARKEN"] = 9] = "DARKEN";
    SimpleWebGLBlendMode[SimpleWebGLBlendMode["DARKER_COLOR"] = 10] = "DARKER_COLOR";
    SimpleWebGLBlendMode[SimpleWebGLBlendMode["DIFFERENCE"] = 11] = "DIFFERENCE";
    SimpleWebGLBlendMode[SimpleWebGLBlendMode["DISSOLVE"] = 12] = "DISSOLVE";
    SimpleWebGLBlendMode[SimpleWebGLBlendMode["EXCLUSION"] = 13] = "EXCLUSION";
    SimpleWebGLBlendMode[SimpleWebGLBlendMode["HARD_LIGHT"] = 14] = "HARD_LIGHT";
    SimpleWebGLBlendMode[SimpleWebGLBlendMode["HARD_MIX"] = 15] = "HARD_MIX";
    SimpleWebGLBlendMode[SimpleWebGLBlendMode["HUE"] = 16] = "HUE";
    SimpleWebGLBlendMode[SimpleWebGLBlendMode["LIGHTEN"] = 17] = "LIGHTEN";
    SimpleWebGLBlendMode[SimpleWebGLBlendMode["LIGHTER_COLOR"] = 18] = "LIGHTER_COLOR";
    SimpleWebGLBlendMode[SimpleWebGLBlendMode["LINEAR_BURN"] = 19] = "LINEAR_BURN";
    SimpleWebGLBlendMode[SimpleWebGLBlendMode["LINEAR_DODGE"] = 20] = "LINEAR_DODGE";
    SimpleWebGLBlendMode[SimpleWebGLBlendMode["LINEAR_LIGHT"] = 21] = "LINEAR_LIGHT";
    SimpleWebGLBlendMode[SimpleWebGLBlendMode["LUMINESCENT_PREMUL"] = 22] = "LUMINESCENT_PREMUL";
    SimpleWebGLBlendMode[SimpleWebGLBlendMode["LUMINOSITY"] = 23] = "LUMINOSITY";
    SimpleWebGLBlendMode[SimpleWebGLBlendMode["MULTIPLY"] = 24] = "MULTIPLY";
    SimpleWebGLBlendMode[SimpleWebGLBlendMode["NORMAL"] = 25] = "NORMAL";
    SimpleWebGLBlendMode[SimpleWebGLBlendMode["OVERLAY"] = 26] = "OVERLAY";
    SimpleWebGLBlendMode[SimpleWebGLBlendMode["PIN_LIGHT"] = 27] = "PIN_LIGHT";
    SimpleWebGLBlendMode[SimpleWebGLBlendMode["SATURATION"] = 28] = "SATURATION";
    SimpleWebGLBlendMode[SimpleWebGLBlendMode["SCREEN"] = 29] = "SCREEN";
    SimpleWebGLBlendMode[SimpleWebGLBlendMode["SILHOUETE_ALPHA"] = 30] = "SILHOUETE_ALPHA";
    SimpleWebGLBlendMode[SimpleWebGLBlendMode["SILHOUETTE_LUMA"] = 31] = "SILHOUETTE_LUMA";
    SimpleWebGLBlendMode[SimpleWebGLBlendMode["SOFT_LIGHT"] = 32] = "SOFT_LIGHT";
    SimpleWebGLBlendMode[SimpleWebGLBlendMode["STENCIL_ALPHA"] = 33] = "STENCIL_ALPHA";
    SimpleWebGLBlendMode[SimpleWebGLBlendMode["STENCIL_LUMA"] = 34] = "STENCIL_LUMA";
    SimpleWebGLBlendMode[SimpleWebGLBlendMode["VIVID_LIGHT"] = 35] = "VIVID_LIGHT";
})(SimpleWebGLBlendMode || (exports.SimpleWebGLBlendMode = SimpleWebGLBlendMode = {}));
/** SimpleWebGL 的默认配置. */
const SimpleWebGLDefaultOptions = {
    alpha: false,
    antialias: true,
    depth: true,
    premultipliedAlpha: true,
    stencil: false,
    flipY: true,
    clearColor: [0, 0, 0, 1],
    preserveDrawingBuffer: false,
};
class SimpleWebGL extends ff_1.Emitter {
    /** 是否可以直接使用源生混合函数来进行混合, 这些混合函数属于叠加顺序无关的线性叠加. */
    static supportsBlendMode(mode) {
        return [
            SimpleWebGLBlendMode.NORMAL,
            SimpleWebGLBlendMode.ADD,
        ].includes(mode);
    }
    /** 画布对象. */
    canvas;
    /** 画布像素宽度, 经过了设备像素分辨率校正. */
    width = 0;
    /** 画布像素高度, 经过了设备像素分辨率校正. */
    height = 0;
    /** 绘图上下文. */
    context;
    /**
     * 用于记录所有注册的 ToDraw 对象, 从而在动态激活纹理时可以释放私有的纹理单元占用.
     * 注意内部并不负责组织其绘制顺序, 这个需要开发时根据自己的需求去组织.
     */
    toDraws = new Set();
    /** 记录所有着色器程序共享的 uniform 变量. */
    uniforms = {};
    /** 用于跟踪顶点的使用情况. */
    verticesReferenceCounter;
    /** 用于管理采样器. 需要被 Sampler 类访问所以公开. */
    samplerManager;
    /** 用于跟踪采样器的使用情况. */
    samplerReferenceCounter;
    /** 用于申请纹理缓存. */
    textureFrameManager;
    /** 当前着色程序. */
    currentProgram;
    /** 是否开启了深度缓存. */
    enabledDepth = false;
    /** 是否开启了覆盖模板缓存. */
    enabledStencil = false;
    /** 是否开启了颜色混合. */
    enabledBlend = false;
    /** 是否开启了深度偏移. */
    enabledPolygonOffsetFill = false;
    /** 用于管理着色器程序. */
    shaderProgramManager;
    /** 手动指定的 viewport 区域. */
    viewport = null;
    constructor(canvas, partialOptions = {}) {
        super();
        this.canvas = canvas;
        let options = Object.assign({}, SimpleWebGLDefaultOptions, partialOptions);
        this.context = canvas.getContext('webgl2', options);
        // 设置清除色.
        this.context.clearColor(...options.clearColor);
        // 设置纹理是否进行 Y 方向倒置.
        this.context.pixelStorei(this.context.UNPACK_FLIP_Y_WEBGL, options.flipY ? 1 : 0);
        // 设置是否要对图片资源进行 Alpha 预乘. 注意它不影响到纹理缓存.
        this.context.pixelStorei(this.context.UNPACK_PREMULTIPLY_ALPHA_WEBGL, options.premultipliedAlpha);
        // 设置默认的融混方式.
        this.enableBlend();
        this.resetBlendMode();
        // 创建着色器程序管理类.
        this.shaderProgramManager = new shader_program_1.ShaderProgramManager(this.context);
        // 创建顶点引用计数器.
        this.verticesReferenceCounter = new reference_counter_1.ReferenceCounter();
        // 创建采样器管理器.
        this.samplerManager = new sampler_manager_1.SamplerManager(this.context);
        // 创建纹理引用计数器.
        this.samplerReferenceCounter = new reference_counter_1.ReferenceCounter();
        // 创建纹理缓存管理器.
        this.textureFrameManager = new texture_frame_manager_1.TextureFrameManager(this);
    }
    /** 开启颜色混合. */
    enableBlend() {
        if (!this.enabledBlend) {
            this.context.enable(this.context.BLEND);
            this.enabledBlend = true;
        }
    }
    /** 关闭颜色混合. */
    disableBlend() {
        if (this.enabledBlend) {
            this.context.disable(this.context.BLEND);
            this.enabledBlend = false;
        }
    }
    /** 开启深度测试. */
    enableDepth() {
        if (!this.enabledDepth) {
            this.context.enable(this.context.DEPTH_TEST);
            this.enabledDepth = true;
        }
    }
    /** 关闭深度测试. */
    disableDepth() {
        if (this.enabledDepth) {
            this.context.disable(this.context.DEPTH_TEST);
            this.enabledDepth = false;
        }
    }
    /** 开启覆盖模板缓冲. */
    enableStencil() {
        if (!this.enabledStencil) {
            this.context.enable(this.context.STENCIL_TEST);
            this.enabledStencil = true;
        }
    }
    /** 关闭覆盖模板缓冲. */
    disableStencil() {
        if (this.enabledStencil) {
            this.context.disable(this.context.STENCIL_TEST);
            this.enabledStencil = false;
        }
    }
    /** 开启覆盖模板缓冲. */
    enablePolygonOffsetFill() {
        if (!this.enabledPolygonOffsetFill) {
            this.context.enable(this.context.POLYGON_OFFSET_FILL);
            this.enabledPolygonOffsetFill = true;
        }
    }
    /** 关闭覆盖模板缓冲. */
    disablePolygonOffsetFill() {
        if (this.enabledPolygonOffsetFill) {
            this.context.disable(this.context.POLYGON_OFFSET_FILL);
            this.enabledPolygonOffsetFill = false;
        }
    }
    /** 设置清除色. */
    setClearColor(clearColor) {
        this.context.clearColor(...clearColor);
    }
    /** 设置混合模式, 输入颜色都已经经过了预乘. */
    setBlendMode(mode) {
        // destnation color: 即背景色.
        // source color: 即前景色.
        const { ONE, ONE_MINUS_SRC_ALPHA } = this.context;
        switch (mode) {
            // 普通叠加模式, 符合我们现实中对于两个半透明物体的叠加的感觉.
            // c = s + (1 - sA) * d
            case SimpleWebGLBlendMode.NORMAL:
                this.context.blendFunc(ONE, ONE_MINUS_SRC_ALPHA);
                break;
            // 将颜色值相加, 最后生成的颜色会更亮.
            // c = s + d
            case SimpleWebGLBlendMode.ADD:
                this.context.blendFunc(ONE, ONE);
                break;
            default:
                throw new Error(`Can't set blending type "${SimpleWebGLBlendMode[mode]}", try blend them by a "ToDraw" object!`);
        }
    }
    /** 还原混合模式为 Normal. */
    resetBlendMode() {
        this.setBlendMode(SimpleWebGLBlendMode.NORMAL);
    }
    /** 创建着色器程序. 仅供 ToDraw 对象调用. */
    __createProgram(vertexCode, fragmentCode) {
        return this.shaderProgramManager.create(vertexCode, fragmentCode);
    }
    /** 使用指定的着色器程序. */
    __useProgram(program) {
        if (program !== this.currentProgram) {
            if (this.currentProgram) {
                this.currentProgram.deactive();
            }
            program.active();
            this.currentProgram = program;
        }
    }
    /** 设置 uniform 变量数据. */
    // Because we will toggle programs, it's very hard to manage uniform for each shader program.
    // So we will sync uniform datas to each program just before drawing it.
    setUniform(name, value) {
        this.uniforms[name] = value;
    }
    /** 获取 uniform 变量数据. */
    getUniform(name) {
        return this.uniforms[name];
    }
    /** 当 toDraw 对象生成时调用.*/
    __registerToDraw(toDraw) {
        this.toDraws.add(toDraw);
    }
    /** 当 toDraw 对象移除时调用.*/
    __deleteToDraw(toDraw) {
        this.toDraws.delete(toDraw);
    }
    /** 清除画布. */
    clear() {
        let bit = this.context.COLOR_BUFFER_BIT;
        if (this.enabledDepth) {
            bit = bit | this.context.DEPTH_BUFFER_BIT;
        }
        this.context.clear(bit);
    }
    /** 预备绘制一个 ToDraw 对象之前的处理. */
    __prepareToDraw(toDraw) {
        let { program } = toDraw;
        this.__useProgram(program);
        program.syncUniform(this.uniforms);
    }
    /**
     * 按顺序绘制已注册的 ToDraw 对象.
     * 注意这只是一个简单的绘制所有注册对象的方法, 在调用它之前, 可能需要自己调整绘制顺序.
     * 一般还是建议手动调用 toDraw.draw.
     */
    drawAll() {
        for (let toDraw of this.toDraws) {
            toDraw.draw();
        }
    }
    /**
     * 设置 canvas 元素的尺寸, 内部会自动按照像素缩放比调整 viewport 的尺寸.
     * Canvas 元素内部的像素分辨率会根据 pixelRatio 做调整.
     */
    setCanvasSize(canvasWidth, canvasHeight, pixelRatio = devicePixelRatio) {
        // 确保至少有 1 像素, 否则一些绘制会出错.
        canvasWidth = Math.round(Math.max(canvasWidth, 1));
        canvasHeight = Math.round(Math.max(canvasHeight, 1));
        this.canvas.style.width = canvasWidth + 'px';
        this.canvas.style.height = canvasHeight + 'px';
        let width = Math.round(canvasWidth * pixelRatio);
        let height = Math.round(canvasHeight * pixelRatio);
        if (this.width !== width || this.height !== height) {
            this.setDefaultViewportFromSize(width, height);
        }
    }
    /** 设置 Viewport 尺寸. */
    setDefaultViewportFromSize(width, height) {
        this.canvas.width = width;
        this.canvas.height = height;
        this.context.viewport(0, 0, width, height);
        this.width = width;
        this.height = height;
        this.emit('resize');
    }
    /**
     * 设置绘制时的 viewport 从左下角开始的像素坐标和尺寸, 相对于当前可写入的像素坐标范围.
     * 或者说 -1~1 的 OpenGL 坐标所映射到像素区域相对于当前的像素区域的坐标和尺寸.
     * 一般仅用于帧缓存绘制, 以将一小块帧缓存区域映射到整个画布.
     */
    setViewport(x, y, w, h) {
        if (!(0, ff_1.deepEqual)([x, y, w, h], this.viewport)) {
            this.context.viewport(x, y, w, h);
            this.viewport = [x, y, w, h];
        }
    }
    /** 恢复原始的和画布对齐的 viewport. */
    resetViewport() {
        if (!(0, ff_1.deepEqual)([0, 0, this.width, this.height], this.viewport)) {
            this.context.viewport(0, 0, this.width, this.height);
            this.viewport = null;
        }
    }
    /**
     * 设置左下角开始的矩形裁剪区域, 绘制将只会作用于该区域. 四个参数都应当是整数.
     * 设置裁剪应该在绘制之前开始, 绘制之后关闭.
     */
    setScissor(x, y, w, h) {
        // 限制裁剪范围不超过可绘制范围.
        let x2 = Math.min(x + w, this.width);
        let y2 = Math.min(y + h, this.height);
        x = Math.max(x, 0);
        y = Math.max(y, 0);
        w = x2 - x;
        h = y2 - y;
        w = Math.max(0, w);
        h = Math.max(0, h);
        // 如果当前 viewport 被映射为局部区域,
        // 那么对应于原始的 [0, 0, w, h] 范围的裁剪坐标也要经过完全相同的映射.
        if (this.viewport) {
            let [vx, vy, vw, vh] = this.viewport;
            let from = matrix4_1.Matrix3.fromVectors(new vector4_1.Vector3(0, 0, 1), new vector4_1.Vector3(this.width, 0, 1), new vector4_1.Vector3(0, this.height, 1));
            let to = matrix4_1.Matrix3.fromVectors(new vector4_1.Vector3(vx, vy, 1), new vector4_1.Vector3(vx + vw, vy, 1), new vector4_1.Vector3(vx, vy + vh, 1));
            // M * F = T
            // M = T * F^-1
            let map = to.multiplySelf(from.inverseSelf());
            let xy = map.transfer2(new vector4_1.Vector2(x, y));
            let wh = map.transfer2(new vector4_1.Vector2(x + w, y + h)).minusSelf(xy);
            x = xy.x;
            y = xy.y;
            w = wh.x;
            h = wh.y;
        }
        this.context.enable(this.context.SCISSOR_TEST);
        this.context.scissor(x, y, w, h);
    }
    /** 清除矩形裁剪区域. */
    clearScissor() {
        this.context.disable(this.context.SCISSOR_TEST);
    }
    /**
     * 等待绘制完成, 以便于获取绘制结果.
     * 不应在预览时调用, 否则会大大有损绘制效率.
     */
    waitDrawingCompleted() {
        let context = this.context;
        let sync = context.fenceSync(context.SYNC_GPU_COMMANDS_COMPLETE, 0);
        let success = false;
        let signaled = context.getSyncParameter(sync, context.SYNC_STATUS);
        if (signaled == context.SIGNALED) {
            success = true;
        }
        else {
            let status = context.clientWaitSync(sync, 0, 0);
            if (status == context.CONDITION_SATISFIED) {
                success = true;
            }
        }
        context.deleteSync(sync);
        return success;
    }
    /** 强行移除上下文以及所有资源. */
    loseContext() {
        // 经过测试, 没有任何方法可以立刻释放 WebGL 上下文所占用的资源, 除了这个.
        let forLose = this.context.getExtension('WEBGL_lose_context');
        if (forLose) {
            forLose.loseContext();
        }
        this.textureFrameManager.clearAll();
    }
    /** 如果在应用端确信已经释放了所有的 ToDraw 对象, 调用此方法可以打印出意外未被释放的对象. */
    warnIfNotClean() {
        if (this.toDraws.size > 0 && debug_1.debug.development) {
            console.warn(`Following ToDraw objects are unexpected not been released:`, [...this.toDraws]);
        }
    }
}
exports.SimpleWebGL = SimpleWebGL;


/***/ }),

/***/ "./src/libs/webgl/texture-frame-draw-to-buffers.ts":
/*!*********************************************************!*\
  !*** ./src/libs/webgl/texture-frame-draw-to-buffers.ts ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.TextureFrameDrawToBuffers = void 0;
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
/**
 * 在绘制时用于进行写入的对象.
 * 自创建之后, 其状态切换全部交给 TextureFrame 对象.
 */
class TextureFrameDrawToBuffers extends ff_1.Emitter {
    /** 记录当前激活的 TextureFrameDrawToBuffers 对象. */
    static active = null;
    /** 记录了 TextureFrameDrawToBuffers 对象堆栈. */
    static stack = [];
    sw;
    /** 缓存的像素宽度. */
    width = 0;
    /** 缓存的像素高度. */
    height = 0;
    /**
     * 是否启用 MSAA 抗锯齿.
     * 在我的 MacBook 2014 款 1080p 下设置超级采样会降低大约 8 帧,
     * 所以其对于帧率的影响并不大.
     */
    antialias;
    /** 颜色帧缓存. 用于缓存绘制结果. */
    framebuffer;
    context;
    /** 当前绘制所对应的从左上角开始的 viewport 区域. */
    viewport;
    /** 颜色渲染缓存. 用于缓存绘制结果. */
    renderbuffer;
    /** 初始化用于写入绘制内容的帧缓存. */
    constructor(sw, width, height, antialias = false) {
        super();
        this.sw = sw;
        this.context = sw.context;
        this.width = width;
        this.height = height;
        this.antialias = antialias;
        let colorFramebuffer = this.context.createFramebuffer();
        let colorRenderbuffer = this.context.createRenderbuffer();
        this.context.bindFramebuffer(this.context.FRAMEBUFFER, colorFramebuffer);
        this.context.bindRenderbuffer(this.context.RENDERBUFFER, colorRenderbuffer);
        this.context.framebufferRenderbuffer(this.context.FRAMEBUFFER, this.context.COLOR_ATTACHMENT0, this.context.RENDERBUFFER, colorRenderbuffer);
        // 由于 MSAA 效果好, 开销又不大, 所以我们总是使用最高倍率.
        // 显存开销对于 1080P 8x 而言大概为 2M (pixels) * 8^2 / 8(bits) = 16M.
        if (this.antialias) {
            let maxMSAASamples = this.context.getParameter(this.context.MAX_SAMPLES);
            this.context.renderbufferStorageMultisample(this.context.RENDERBUFFER, maxMSAASamples, this.context.RGBA8, width, height);
        }
        else {
            this.context.renderbufferStorage(this.context.RENDERBUFFER, this.context.RGBA8, width, height);
        }
        this.framebuffer = colorFramebuffer;
        this.renderbuffer = colorRenderbuffer;
        // 取消绑定, 从而不影响现有的渲染, 稍后在需要时会通过 bind 再度绑定.
        this.context.bindFramebuffer(this.context.FRAMEBUFFER, null);
    }
    /**
     * 设置局部绘制的区域所对应的左上角像素坐标以及宽高.
     * 例如整个绘制作用于 0~100 坐标范围, 但是我们只需要 40~60 部分,
     * 我们申请一个 20x20 的帧缓存, 然后将整个绘制区域 100x100 的中心和这个帧缓存的中心对齐,
     * 100x100 在 20x20 的帧缓存区域的左下角坐标 (-40, -40) 和宽高 (100, 100) 即为 viewport.
     */
    setPartialRect(x, y, viewportWidth, viewportHeight, superSampling) {
        let vx = -x * superSampling;
        let vy = -(viewportHeight * superSampling - (y * superSampling + this.height));
        let vw = viewportWidth * superSampling;
        let vh = viewportHeight * superSampling;
        this.viewport = [vx, vy, vw, vh];
    }
    /** 应用局部绘制绘制时的 viewport. */
    applyViewport() {
        this.sw.setViewport(...this.viewport);
    }
    /** 将之后的绘制渲染到 texture 中, 直到调用 deactive., 在开始绘制到纹理之前调用. */
    active() {
        // 如果有激活的缓存, 则将其暂停.
        if (TextureFrameDrawToBuffers.active) {
            TextureFrameDrawToBuffers.active.pause();
            TextureFrameDrawToBuffers.stack.push(TextureFrameDrawToBuffers.active);
        }
        this.context.bindFramebuffer(this.context.FRAMEBUFFER, this.framebuffer);
        this.context.clearBufferfv(this.context.COLOR, 0, [0, 0, 0, 0]);
        this.applyViewport();
        TextureFrameDrawToBuffers.active = this;
    }
    /** 将数据从缓存区拷贝到纹理中并且取消绑定. 之后的绘制会画在画布或者上一级帧缓存中. */
    deactive() {
        if (TextureFrameDrawToBuffers.active !== this) {
            throw new Error(`TextureFrameDrawToBuffers must be deactived in the opposite order from been activated!`);
        }
        this.context.bindFramebuffer(this.context.FRAMEBUFFER, null);
        // 如果有队列的纹理缓存, 则将其继续.
        if (TextureFrameDrawToBuffers.stack.length > 0) {
            let previousTextureFrame = TextureFrameDrawToBuffers.stack.pop();
            previousTextureFrame.resume();
            TextureFrameDrawToBuffers.active = previousTextureFrame;
        }
        else {
            this.sw.resetViewport();
            TextureFrameDrawToBuffers.active = null;
        }
        this.emit('deactive');
    }
    /** 暂停缓存的使用, 以供其他缓存进行绘制. */
    pause() { }
    /** 当其他缓存完成绘制之后继续缓存的使用. */
    resume() {
        this.context.bindFramebuffer(this.context.FRAMEBUFFER, this.framebuffer);
        this.applyViewport();
    }
    /** 设置为读缓存对象. */
    setAsReadBuffer() {
        this.context.bindFramebuffer(this.context.READ_FRAMEBUFFER, this.framebuffer);
    }
    /** 删除对象并且释放内存. */
    delete() {
        this.context.deleteFramebuffer(this.framebuffer);
        this.context.deleteRenderbuffer(this.renderbuffer);
    }
}
exports.TextureFrameDrawToBuffers = TextureFrameDrawToBuffers;


/***/ }),

/***/ "./src/libs/webgl/texture-frame-manager.ts":
/*!*************************************************!*\
  !*** ./src/libs/webgl/texture-frame-manager.ts ***!
  \*************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.TextureFrameManager = void 0;
const texture_frame_1 = __webpack_require__(/*! ./texture-frame */ "./src/libs/webgl/texture-frame.ts");
const sampler_1 = __webpack_require__(/*! ./sampler */ "./src/libs/webgl/sampler.ts");
const rect_area_1 = __webpack_require__(/*! ../area/rect-area */ "./src/libs/area/rect-area.ts");
const texture_frame_draw_to_buffers_1 = __webpack_require__(/*! ./texture-frame-draw-to-buffers */ "./src/libs/webgl/texture-frame-draw-to-buffers.ts");
const texture_frame_result_buffers_1 = __webpack_require__(/*! ./texture-frame-result-buffers */ "./src/libs/webgl/texture-frame-result-buffers.ts");
const mapped_sampler_1 = __webpack_require__(/*! ./mapped-sampler */ "./src/libs/webgl/mapped-sampler.ts");
/**
 * 用于管理以及重用纹理缓存.
 * 纹理缓存是一种极其宝贵的资源, 如果每帧都申请和释放纹理缓存,
 * 那么帧率可能会从 60 帧降低到 20 帧.
 * 所以此类会最大程度地重用纹理缓存.
 */
class TextureFrameManager {
    sw;
    /** 这里将纹理缓存和采样器分别做管理, 是因为一般只需要一个纹理缓存, 而采样器则需要轮流使用, 并且同一时刻可能存在多个. */
    resultCacher;
    /** 这里存放可重用的用于写入的帧缓存和颜色缓存对象. */
    buffersCacher;
    /** 空的纹理, 用于在没有任何绘制的情况下填充纹理数据. */
    emptySampler = null;
    /**
     * maxIdleSeconds 指定动态分配的纹理缓存的最大存在时间. 大部分纹理缓存尺寸不大, 可以实时分配.
     * 但是实时分配仍然需要消耗时间, 所以我们假设尺寸总是会动态变化 (实际会和 256 对齐, 也就是很少变化),
     * 每次绘制分配 4M 显存, 那么每秒会分配 240M.
     * 此外, 就算性能再差的电脑, 应该至少也能达到 1s 绘制一帧, 所以最大的闲置时间最少也应当为 1s.
     * 这样暂停之后恢复播放时, 总是需要重新分配.
     * 此外为了尽量重用纹理缓存, 它的最大闲置时间应当设置为大概跨域两个场景, 大致为 10s.
     *
     * warnWhenCountExceeded 用于当忘记释放资源时弹出警告, 默认值为 30, 即超过 30 个纹理缓存时弹出警告.
     * 一般正常播放时不会超过 10 个, 不过快速拖动时可能会增长得比较快.
     */
    constructor(sw, maxIdleSeconds = 10, warnWhenCountExceeded = 50) {
        this.sw = sw;
        this.resultCacher = new TextureFrameResultBuffersCacher(sw, maxIdleSeconds, warnWhenCountExceeded);
        this.buffersCacher = new TextureFrameDrawToBuffersCacher(sw, maxIdleSeconds, warnWhenCountExceeded);
        this.sw.on('resize', this.clearIdle, this);
    }
    /**
     * 申请一个和当前上下文尺寸相同的纹理缓存.
     * 用于在提前不知道要绘制的尺寸的情况下,
     * 或者在绘制完可以很快丢弃纹理缓存以让他再继续循环使用的情况下.
     */
    requestFull(antialias = false, superSampling = 1, params = {}) {
        let area = new rect_area_1.RectArea(0, 0, this.sw.width, this.sw.height);
        return this.request(area, this.sw.width, this.sw.height, antialias, superSampling, params);
    }
    /**
     * 根据一个矩形区域对象申请一个纹理缓存用于进行局部绘制, 其尺寸会处理为和一些特定的位置对齐以尽量重用.
     * 用于已经确定绘制范围, 绘制内容不会被马上丢弃, 或者超采样情况下(申请全屏纹理缓存会占用很大的内存和显存).
     * 注意这里的矩形区域是经过栅格化的, 不是你当前使用的坐标系中的坐标或者尺寸.
     * 使用此 API 决定了你必须进行纹理坐标的重映射, 可以通过 textureFrame.getSamplingTransform 来完成,
     * 但是仍然无法避免一些时候的手工计算, 即先将 textureFrame 的矩形范围映射到栅格化的总尺寸范围 sw.width / height,
     * 然后再将这个比例带入原始坐标进行计算.
     * 如果你觉得这各处理过于复杂, 并且设备有足够的内存和显存, 可以使用 requestFull 代替, 其对于渲染性能影响不大.
     */
    requestPartial(area, antialias = false, superSampling = 1, params = {}) {
        // 将区域进行像素对齐.
        area = area.round();
        // 限制裁剪范围不超过可绘制范围.
        let { x1: x, y1: y, x2, y2 } = area;
        x = Math.max(x, 0);
        y = Math.max(y, 0);
        x2 = Math.min(x2, this.sw.width);
        y2 = Math.min(y2, this.sw.height);
        let w = x2 - x;
        let h = y2 - y;
        // 设置宽高的对齐方式, 其尽量贴近 960 和 540 的因数, 并且宽高稍微接近方形.
        // 如果设置的过小, 会产生比较多的碎片和分配次数, 设置的过大则会产生过大的显存和内存分配.
        let herizontalAlign = 240 * devicePixelRatio;
        let verticalAlign = 180 * devicePixelRatio;
        // 将尺寸和 256 对齐, 并且不超过原始画布尺寸.
        // 在 960p 绘制模式下, 最多可能产生 4 * 3 = 12 类
        if (w < this.sw.width || h < this.sw.height) {
            w = Math.ceil(w / herizontalAlign) * herizontalAlign;
            h = Math.ceil(h / verticalAlign) * verticalAlign;
        }
        // 申请的纹理缓存的尺寸不应当为0, 也不应当超过当前画布的尺寸.
        w = Math.max(w, herizontalAlign);
        h = Math.max(h, verticalAlign);
        w = Math.min(w, this.sw.width);
        h = Math.min(h, this.sw.height);
        area = new rect_area_1.RectArea(x, y, x + w, y + h);
        return this.request(area, this.sw.width, this.sw.height, antialias, superSampling, params);
    }
    /**
     * 申请一个纹理缓存对象.
     * area 指定纹理缓存所对应的在整个绘制窗口中的坐标区域.
     * viewportWidth 和 viewportHeight 指定总的绘制的像素尺寸,
     * 即 -1~1 的 OpenGL 坐标所映射到的像素范围, 默认等于当前窗口的像素尺寸.
     */
    request(area, viewportWidth, viewportHeight, antialias, superSampling, params) {
        // 将区域进行像素对齐.
        area = area.round();
        let { x1: x, y1: y, width: w, height: h } = area;
        let frame = new texture_frame_1.TextureFrame(this.sw, w, h);
        frame.setPartialOrigin(x, y);
        // 设置用于生成存储最终绘制结果的纹理缓存的函数.
        // 至于为何不立即生成此缓存, 是因为在绘制时经常启用多个纹理缓存,
        // 但是同时发生绘制的并不多.
        frame.setResultBuffersRequester(() => {
            return this.resultCacher.request(w, h, params);
        });
        // 设置用于生成存储绘制结果的颜色缓存的函数.
        frame.setDrawToBuffersRequester(() => {
            let buffers = this.buffersCacher.request(w * superSampling, h * superSampling, antialias);
            buffers.setPartialRect(x, y, viewportWidth, viewportHeight, superSampling);
            return buffers;
        });
        return frame;
    }
    /** 释放所有的闲置纹理缓存, 一般在画布更改尺寸之后调用. */
    clearIdle() {
        this.resultCacher.clearIdle();
        this.buffersCacher.clearIdle();
    }
    /** 释放所有的纹理缓存. */
    clearAll() {
        this.resultCacher.clearAll();
        this.buffersCacher.clearAll();
    }
    /** 生成一个空的纹理, 用于在没有任何绘制的情况下填充纹理数据. */
    getEmptySampler() {
        if (!this.emptySampler) {
            this.emptySampler = new sampler_1.TextureFrameSampler(this.sw, { width: 1, height: 1 });
        }
        return this.emptySampler;
    }
    /** 生成一个空的纹理, 用于在没有任何绘制的情况下填充纹理数据. */
    getEmptyMappedSampler() {
        return new mapped_sampler_1.MappedSampler(this.getEmptySampler());
    }
}
exports.TextureFrameManager = TextureFrameManager;
/** 用于缓存和重用具有同样的属性的资源. */
class ReuseableResourceCacher {
    using = new Set();
    idle = new Set();
    /**
     * 如果一个资源闲置超过这么多时间, 则会被释放.
     * 资源在绘制前申请, 绘制完成后即被释放. 所以如果设置了这个时间, 那么在画面暂停一段时间后也会被释放.
     */
    maxIdleSeconds;
    /** 当同时存在超过这个数目的副本时抛出警告, 以此来维持系统的稳定. */
    warnWhenCountExceeded;
    constructor(maxIdleSeconds, warnWhenCountExceeded) {
        this.maxIdleSeconds = maxIdleSeconds;
        this.warnWhenCountExceeded = warnWhenCountExceeded;
    }
    /** 根据参数申请一个资源. */
    request(...args) {
        let idleData = this.query(...args);
        // 重用.
        if (idleData) {
            let { timeoutId, resource } = idleData;
            clearTimeout(timeoutId);
            this.idle.delete(idleData);
            this.using.add(resource);
            this.update(resource, ...args);
            return resource;
        }
        // 新建.
        else {
            let resource = this.create(...args);
            this.using.add(resource);
            let totalSize = this.using.size + this.idle.size;
            if (totalSize >= this.warnWhenCountExceeded && totalSize % 10 === 0) {
                console.warn(`${totalSize} ${this.constructor.name.replace('Cacher', '')} instances exist at the same time, did you forget to release them?`);
            }
            return resource;
        }
    }
    /** 释放一个资源的使用. */
    release(resource) {
        if (!this.using.has(resource)) {
            return;
        }
        let timeoutId = setTimeout(() => {
            let deleted = this.delete(resource);
            if (deleted) {
                this.idle.delete(data);
            }
        }, this.maxIdleSeconds * 1000);
        let data = { resource, timeoutId };
        this.idle.add(data);
        this.using.delete(resource);
    }
    /** 清空所有的资源. */
    clearAll() {
        this.clearIdle();
        for (let resource of this.using) {
            this.delete(resource);
        }
        this.using = new Set();
    }
    /** 清空所有的闲置资源. */
    clearIdle() {
        for (let { resource, timeoutId } of this.idle) {
            clearTimeout(timeoutId);
            this.delete(resource);
        }
        this.idle = new Set();
    }
}
/** 用于缓存和重用纹理缓冲资源. */
class TextureFrameResultBuffersCacher extends ReuseableResourceCacher {
    sw;
    constructor(sw, maxIdleSeconds, warnWhenCountExceeded) {
        super(maxIdleSeconds, warnWhenCountExceeded);
        this.sw = sw;
    }
    /** 查询一个可重用的资源. */
    query(width, height) {
        // 查询有相同尺寸的, 不需要超采样倍率相同.
        let idleData = [...this.idle].find(({ resource: buffers }) => {
            return buffers.width === width
                && buffers.height === height
                // 必须不在使用中.
                // 有一种可能是回收之后立刻被再度使用.
                && !buffers.inUse();
        });
        return idleData;
    }
    /** 创建一个资源. */
    create(width, height, params) {
        let resultBuffers = new texture_frame_result_buffers_1.TextureFrameResultBuffers(this.sw, width, height, params);
        // 当纹理单元不被引用时自动回收.
        // 注意它可能被触发多次, 这是需要的, 因为可能第一次触发,
        // 倒计时后发现仍有引用. 那么之后触发才会正式将其删除.
        resultBuffers.sampler.on('noreference', () => {
            this.release(resultBuffers);
        });
        return resultBuffers;
    }
    /** 重用时更新资源属性. */
    update(resultBuffers, _width, _height, params) {
        resultBuffers.sampler.updateParameters(params);
    }
    /** 移除一个资源. */
    delete(resultBuffers) {
        if (!resultBuffers.inUse()) {
            resultBuffers.delete();
            return true;
        }
        else {
            return false;
        }
    }
}
/**
 * 用于缓存和重用绘制时写入的帧缓存和颜色缓存.
 * 很明显绘制完成后, 生成的纹理数据会被之后的绘制流程使用,
 * 但是之前用于写入的帧缓存对象还可以重用.
 */
class TextureFrameDrawToBuffersCacher extends ReuseableResourceCacher {
    sw;
    constructor(sw, maxIdleSeconds, warnWhenCountExceeded) {
        super(maxIdleSeconds, warnWhenCountExceeded);
        this.sw = sw;
    }
    /** 查询一个可重用的资源. */
    query(width, height, antialias) {
        // 查询有相同尺寸和抗锯齿类型的.
        let idleData = [...this.idle].find(({ resource: buffers }) => {
            return buffers.width === width
                && buffers.height === height
                && buffers.antialias === antialias;
        });
        return idleData;
    }
    /** 创建一个资源. */
    create(width, height, antialias) {
        let buffers = new texture_frame_draw_to_buffers_1.TextureFrameDrawToBuffers(this.sw, width, height, antialias);
        // 当纹理单元不被引用时自动回收.
        // 注意它可能被触发多次, 这是需要的, 因为可能第一次触发,
        // 倒计时后发现仍有引用. 那么之后触发才会正式将其删除.
        buffers.on('deactive', () => {
            this.release(buffers);
        });
        return buffers;
    }
    /** 重用时更新资源属性. */
    update() { }
    /** 移除一个资源. */
    delete(buffers) {
        buffers.delete();
        return true;
    }
}


/***/ }),

/***/ "./src/libs/webgl/texture-frame-result-buffers.ts":
/*!********************************************************!*\
  !*** ./src/libs/webgl/texture-frame-result-buffers.ts ***!
  \********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.TextureFrameResultBuffers = void 0;
const sampler_1 = __webpack_require__(/*! ./sampler */ "./src/libs/webgl/sampler.ts");
/** 相比 TextureFrameDrawToBuffers, 它对应着绘制完毕后写入到的纹理缓存. */
class TextureFrameResultBuffers {
    /** 纹理缓存的像素宽度. */
    width = 0;
    /** 纹理缓存的像素高度. */
    height = 0;
    /** 纹理采样参数设置. */
    samplerParams;
    /** 用于输出的纹理对应的采样器. */
    sampler;
    sw;
    context;
    /** 纹理数据关联的帧缓存. */
    framebuffer = null;
    constructor(sw, width, height, samplerParams) {
        this.sw = sw;
        this.context = sw.context;
        this.width = width;
        this.height = height;
        this.samplerParams = samplerParams;
        // 创建存储最终绘制结果的帧缓存, 它使用纹理对象作为附件.
        this.framebuffer = this.context.createFramebuffer();
        this.initializeSampler();
    }
    /** 初始化采样器. */
    initializeSampler() {
        // 在起初, 我们读写都在这个采样器关联的纹理上面,
        // 但是从 Chrome 83 开始, 不再允许一个附件同时进行读写.
        // 所以这里的纹理仅用于读, 而另一个用于绘制, 在绘制结束后将其拷贝过来.
        let sampler = new sampler_1.TextureFrameSampler(this.sw, { width: this.width, height: this.height }, this.samplerParams);
        this.context.bindFramebuffer(this.context.FRAMEBUFFER, this.framebuffer);
        this.context.framebufferTexture2D(this.context.FRAMEBUFFER, this.context.COLOR_ATTACHMENT0, this.context.TEXTURE_2D, sampler.texture, 0);
        this.sampler = sampler;
        // 取消绑定, 从而不影响现有的渲染, 稍后在需要时会通过 bind 再度绑定.
        this.context.bindFramebuffer(this.context.FRAMEBUFFER, null);
    }
    /** 是否正在使用. */
    inUse() {
        return this.sampler.inUse();
    }
    /** 设置为写入缓存. */
    setAsWriteBuffer() {
        this.context.bindFramebuffer(this.context.DRAW_FRAMEBUFFER, this.framebuffer);
    }
    /** 写入数据结束后来完成一些处理工作. */
    endWrite() {
        this.sampler.updateMipmapIfNeed();
    }
    /** 移除此对象和其资源. */
    delete() {
        this.sampler.delete();
    }
}
exports.TextureFrameResultBuffers = TextureFrameResultBuffers;


/***/ }),

/***/ "./src/libs/webgl/texture-frame.ts":
/*!*****************************************!*\
  !*** ./src/libs/webgl/texture-frame.ts ***!
  \*****************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.TextureFrame = void 0;
const matrix4_1 = __webpack_require__(/*! ../math/matrix4 */ "./src/libs/math/matrix4.ts");
const vector4_1 = __webpack_require__(/*! ../math/vector4 */ "./src/libs/math/vector4.ts");
const mapped_sampler_1 = __webpack_require__(/*! ./mapped-sampler */ "./src/libs/webgl/mapped-sampler.ts");
/**
 * 纹理缓存对象, 它指定一个帧缓存以供作为画布进行绘制,
 * 绘制完成之后输出一个纹理, 以便之后的绘制流程使用.
 */
class TextureFrame {
    /** 记录当前激活的 TextureFrame 对象. */
    static active = null;
    /** 记录了 TextureFrame 对象堆栈. */
    static stack = [];
    /** 确保当前纹理缓存已生成可存储绘制结果的颜色缓存. */
    static ensureCanDrawTo() {
        if (TextureFrame.active) {
            TextureFrame.active.ensureCanDrawTo();
        }
    }
    /** 指定当前帧缓存绘制范围在画布上的左上角坐标的 x 坐标, 应当为整型. */
    x = 0;
    /** 指定当前帧缓存绘制范围在画布上的左上角坐标的 y 坐标, 应当为整型. */
    y = 0;
    /** 纹理缓存的像素宽度. */
    width = 0;
    /** 纹理缓存的像素高度. */
    height = 0;
    sw;
    context;
    /** 用户存储最终绘制结果的纹理缓存. */
    resultBuffers = null;
    /** 用户存储绘制结果的颜色帧缓存. */
    drawToBuffers = null;
    /** 用于请求供存储最终绘制结果的纹理缓存. */
    resultBuffersRequester;
    /** 用于请求供存储绘制结果的颜色帧缓存. */
    drawToBuffersRequester;
    constructor(sw, width, height) {
        this.sw = sw;
        this.width = width;
        this.height = height;
        this.context = sw.context;
    }
    /**
     * 设置局部绘制的区域所对应的左上角坐标.
     * 如果设置此属性, 那么意味着我们使用了 "局部绘制",
     * 即将当前的纹理缓存的对应区域映射到一个画布的范围, 然后将绘制局限于其中,
     * 但是又不用改动做全局绘制时的顶点坐标和处理逻辑.
     * 但是需要注意所获得的纹理的采样坐标需要做针对调整.
     */
    setPartialOrigin(x, y) {
        this.x = x;
        this.y = y;
    }
    setResultBuffersRequester(requestBuffers) {
        this.resultBuffersRequester = requestBuffers;
    }
    /** 设置要绘制到的帧缓存对象. */
    setDrawToBuffersRequester(requestBuffers) {
        this.drawToBuffersRequester = requestBuffers;
    }
    /** 获得纹理采样器以及对应的采样变换矩阵, 用于将当前整个屏幕区域的采样坐标映射到实际绘制的区域的采样坐标. */
    getMappedSampler() {
        return new mapped_sampler_1.MappedSampler(this.getSampler(), this.getSamplingMapMatrix());
    }
    /** 获得纹理采样器. */
    getSampler() {
        return this.resultBuffers ? this.resultBuffers.sampler : this.sw.textureFrameManager.getEmptySampler();
    }
    /**
     * 对于只绘制在一个子区域的纹理缓存, 获得其纹理坐标的变换,
     * 以将之前基于全屏的纹理坐标转换为基于此区域的.
     */
    getSamplingMapMatrix() {
        // 像素之间的变换矩阵 Mp 满足 F * Mp = T.
        // 像素和采样坐标之间的变换矩阵 Ms 满足 Ms * F = S
        // 同时 Ms * T = S'.
        // 而最终的矩阵为 M 满足 M * S = S'
        // M * S = Ms * T = S * F^-1 * T
        // M = S * F^-1 * T * S^-1
        let fromVectorArray = [
            new vector4_1.Vector3(this.x, this.y, 1),
            new vector4_1.Vector3(this.x + this.width, this.y, 1),
            new vector4_1.Vector3(this.x, this.y + this.height, 1),
        ];
        let toVectorArray = [
            new vector4_1.Vector3(0, 0, 1),
            new vector4_1.Vector3(this.sw.width, 0, 1),
            new vector4_1.Vector3(0, this.sw.height, 1),
        ];
        let fromTextureVectorArray = [
            new vector4_1.Vector3(0, 1, 1),
            new vector4_1.Vector3(1, 1, 1),
            new vector4_1.Vector3(0, 0, 1),
        ];
        let fromCoords = matrix4_1.Matrix3.fromVectors(...fromVectorArray);
        let toCoords = matrix4_1.Matrix3.fromVectors(...toVectorArray);
        let fromTextureCoords = matrix4_1.Matrix3.fromVectors(...fromTextureVectorArray);
        let fromTextureInverse = fromTextureCoords.inverse();
        return matrix4_1.Matrix4.fromMatrix3(fromTextureCoords
            .multiplySelf(fromCoords.inverseSelf())
            .multiplySelf(toCoords)
            .multiplySelf(fromTextureInverse));
    }
    /** 将之后的绘制渲染到 texture 中, 直到调用 deactive. 在开始绘制到纹理之前调用. */
    active() {
        // 如果有激活的缓存, 则将其暂停.
        if (TextureFrame.active) {
            TextureFrame.stack.push(TextureFrame.active);
        }
        TextureFrame.active = this;
        if (this.drawToBuffers) {
            this.drawToBuffers.active();
        }
    }
    /** 确保可以写入, 此时才会分配写入缓存. */
    ensureCanDrawTo() {
        if (TextureFrame.active !== this) {
            throw new Error(`TextureFrame must be actived when calling "ensureCanDrawTo"!`);
        }
        if (!this.drawToBuffers) {
            this.drawToBuffers = this.drawToBuffersRequester();
            this.drawToBuffers.active();
        }
    }
    /** 将数据从缓存区拷贝到纹理中并且取消绑定. 之后的绘制会画在画布或者上一级帧缓存中. */
    deactive() {
        if (TextureFrame.active !== this) {
            throw new Error(`TextureFrame must be deactived in the opposite order from been activated!`);
        }
        // 如果有队列的纹理缓存, 则将其继续.
        if (TextureFrame.stack.length > 0) {
            TextureFrame.active = TextureFrame.stack.pop() || null;
        }
        else {
            TextureFrame.active = null;
        }
        // 如果没有任何绘制, 则可以不更新纹理对象.
        if (this.drawToBuffers) {
            this.ensureResultBuffers();
            this.copyToResultBuffers();
            this.drawToBuffers.deactive();
            this.drawToBuffers = null;
        }
    }
    /** 确保 resultBuffers 生成. */
    ensureResultBuffers() {
        if (!this.resultBuffers) {
            this.resultBuffers = this.resultBuffersRequester();
        }
    }
    /** 在抗锯齿模式下, 当绘制完成之后, 将数据从缓存区拷贝到纹理中. */
    copyToResultBuffers() {
        let { width, height } = this;
        let bufferWidth = this.drawToBuffers.width;
        let bufferHeight = this.drawToBuffers.height;
        let inSameSize = bufferWidth === this.width;
        let filterType = inSameSize ? this.context.NEAREST : this.context.LINEAR;
        this.drawToBuffers.setAsReadBuffer();
        this.resultBuffers.setAsWriteBuffer();
        this.context.clearBufferfv(this.context.COLOR, 0, [0, 0, 0, 0]);
        this.context.blitFramebuffer(0, 0, bufferWidth, bufferHeight, 0, 0, width, height, this.context.COLOR_BUFFER_BIT, filterType);
        this.resultBuffers.endWrite();
    }
}
exports.TextureFrame = TextureFrame;


/***/ }),

/***/ "./src/libs/webgl/todraw.ts":
/*!**********************************!*\
  !*** ./src/libs/webgl/todraw.ts ***!
  \**********************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ToDraw = exports.ToDrawType = void 0;
const vertices_1 = __webpack_require__(/*! ./vertices */ "./src/libs/webgl/vertices.ts");
const texture_frame_1 = __webpack_require__(/*! ./texture-frame */ "./src/libs/webgl/texture-frame.ts");
/** 绘制的多边形类型, 默认为 `TriangleStrip` */
var ToDrawType;
(function (ToDrawType) {
    ToDrawType[ToDrawType["Points"] = WebGL2RenderingContext.prototype.POINTS] = "Points";
    ToDrawType[ToDrawType["Lines"] = WebGL2RenderingContext.prototype.LINES] = "Lines";
    ToDrawType[ToDrawType["LineStrip"] = WebGL2RenderingContext.prototype.LINE_STRIP] = "LineStrip";
    ToDrawType[ToDrawType["LineLoop"] = WebGL2RenderingContext.prototype.LINE_LOOP] = "LineLoop";
    ToDrawType[ToDrawType["TriangleStrip"] = WebGL2RenderingContext.prototype.TRIANGLE_STRIP] = "TriangleStrip";
    ToDrawType[ToDrawType["Triangles"] = WebGL2RenderingContext.prototype.TRIANGLES] = "Triangles";
    ToDrawType[ToDrawType["TriangleFan"] = WebGL2RenderingContext.prototype.TRIANGLE_FAN] = "TriangleFan";
})(ToDrawType || (exports.ToDrawType = ToDrawType = {}));
/**
 * ToDraw 对象代表了一个需要被绘制的对象.
 * 它可以和其他的 `ToDraw` 对象共享 program, vertices,
 * 并且在切换 `ToDraw` 上下文时, 数据也会被尽量重用.
 * 一旦创建了 ToDraw 对象, 其依赖的顶点和纹理数据会马上上传到 GPU, 直到将其移除才会释放资源.
 */
class ToDraw {
    sw;
    /** 绘制类型, 默认为 TriangleStrip. */
    type = ToDrawType.TriangleStrip;
    /** 着色程序. */
    program;
    /** 顶点数据对象. */
    vertices;
    /** 按照名称组织的采样器对象. */
    samplers = {};
    uniforms = {};
    deleted = false;
    constructor(sw, options) {
        this.sw = sw;
        this.initializeOptions(options);
    }
    /** 初始化配置信息. */
    initializeOptions(options) {
        if (options.type !== undefined) {
            this.type = options.type;
        }
        this.program = this.sw.__createProgram(options.vertCode, options.fragCode);
        if (options.uniforms) {
            this.uniforms = options.uniforms;
        }
        if (options.vertices !== undefined) {
            this.initializeVertices(options.vertices);
        }
        if (options.samplers !== undefined) {
            this.initializeSampler(options.samplers);
        }
        this.sw.__registerToDraw(this);
    }
    /** 初始化顶点数据. */
    initializeVertices(vertices) {
        let { data, count, indices } = vertices;
        this.setVertices(data, count, indices);
    }
    /** 初始化纹理数据. */
    initializeSampler(textureObject) {
        for (let [name, samplers] of Object.entries(textureObject)) {
            let dataArray = Array.isArray(samplers) ? samplers : [samplers];
            this.useSampler(name, ...dataArray);
        }
    }
    /** 设置 uniform 变量. */
    setUniform(name, value) {
        this.uniforms[name] = value;
    }
    /** 设置指定的索引位置的 uniform 变量. */
    setSubUniform(name, index, value) {
        let values = this.uniforms[name] || (this.uniforms[name] = []);
        values[index] = value;
    }
    /** 检查是否已设置某个 uniform 变量. */
    hasUniform(name) {
        return this.uniforms.hasOwnProperty(name);
    }
    /** 上传并且使用顶点数据. 注意这个顶点数据是私有的. */
    setVertices(data, vertexCount, indices) {
        let vertices = new vertices_1.Vertices(this.sw, data, vertexCount, indices);
        this.useVertices(vertices);
    }
    /** 使用已上传的顶点数据. 由于顶点数据可能共享, 所以在此只使用已上传的数据. */
    useVertices(vertices) {
        if (vertices !== this.vertices) {
            if (this.vertices) {
                this.vertices.__unuse(this);
            }
            vertices.__useBy(this);
            this.vertices = vertices;
        }
    }
    /** 获得是否有设置指定名称的采样器. */
    hasSampler(name) {
        return !!this.samplers[name];
    }
    /** 获得是否有设置指定名称和索引位置的采样器. */
    hasSubSampler(name, index) {
        return !!(this.samplers[name] && this.samplers[name][index]);
    }
    /** 获得指定名称的采样器. */
    getSampler(name) {
        return this.samplers[name];
    }
    /** 获得指定名称和索引位置的采样器. */
    getSubSampler(name, index) {
        return this.samplers[name] ? this.samplers[name][index] || null : null;
    }
    /** 使用已上传的纹理单元数据, 如果没有必要, 即没有指定对应名称的着色器变量, 则不会使用它. */
    useSampler(name, ...samplers) {
        // 因为有时候我们可能会将一个公用的采样器送给所有 toDraw 对象使用, 所以在此判断是否有必要引用这个纹理单元.
        if (!this.program.hasUniform(name)) {
            return;
        }
        // 释放不再使用的采样器.
        let oldSamplers = this.samplers[name];
        let oldSamplerIds = oldSamplers ? oldSamplers.map(sampler => sampler.id) : [];
        let newSamplerIds = samplers.map(sampler => sampler.id);
        if (oldSamplers) {
            for (let sampler of oldSamplers) {
                if (!newSamplerIds.includes(sampler.id)) {
                    sampler.__unuse(this);
                }
            }
        }
        // 添加引用.
        for (let sampler of samplers) {
            if (!oldSamplerIds.includes(sampler.id)) {
                sampler.__use(this);
            }
        }
        this.samplers[name] = samplers;
    }
    /** 设置指定的索引位置的采样器. */
    useSubSampler(name, index, sampler) {
        let oldSamplers = this.samplers[name];
        let newSamplers = oldSamplers ? [...oldSamplers] : [];
        newSamplers[index] = sampler;
        this.useSampler(name, ...newSamplers);
    }
    /** 不再使用指定名称的采样器. */
    unuseSampler(name) {
        if (this.samplers[name]) {
            for (let sampler of this.samplers[name]) {
                sampler.__unuse(this);
            }
        }
        delete this.samplers[name];
    }
    /** 检查指定的纹理单元数据是否正被当前对象使用. */
    __isUsingSampler(sampler) {
        // 这里通过一个 set 结构来检查应当更好, 但是由于可能通过两个名称引用一个对象, 所以还应当做计数.
        // 另外由于一个绘制对象引用的纹理单元很少, 因此我们在此选择了循环比对已有的纹理单元数据.
        for (let samplers of Object.values(this.samplers)) {
            if (samplers.includes(sampler)) {
                return true;
            }
        }
        return false;
    }
    /** 进行绘制, 默认绘制所有的顶点. */
    draw(offset = 0, drawCount = -1) {
        this.beforeDraw();
        if (drawCount === -1) {
            drawCount = this.vertices.drawCount;
        }
        let { type, vertices } = this;
        let context = this.sw.context;
        this.sw.__prepareToDraw(this);
        vertices.active();
        this.activeSamplers();
        // 我们希望仅在需要时才同步, 然而由于 program 共享, 所以这里选择每次都同步.
        this.program.syncUniform(this.uniforms);
        // 索引绘制.
        if (vertices.hasIndices) {
            context.drawElements(type, drawCount, context.UNSIGNED_SHORT, offset);
        }
        // 数组绘制.
        else {
            context.drawArrays(type, offset, drawCount);
        }
        this.afterDraw();
    }
    /** 用于在绘制开始之后设置一些参数. */
    beforeDraw() {
        texture_frame_1.TextureFrame.ensureCanDrawTo();
    }
    /** 用于在绘制结束之后清理一些参数. */
    afterDraw() { }
    /**
     * 同步和激活需要使用的采样器.
     * 因为已激活的采样器其纹理单元可能会被再度占用, 所以必须每次绘制前做检查.
     */
    activeSamplers() {
        for (let [name, samplers] of Object.entries(this.samplers)) {
            for (let sampler of samplers) {
                sampler.active(this);
            }
            this.setUniform(name, samplers.map(v => v.unitIndex));
        }
    }
    /** 删除绘制对象, 并且移除对于顶点和纹理的引用. */
    // ToDraw 被删除之后, 无法重启再利用, 只能新建. 如果需要重启的话, 需要保留参数做重新初始化.
    delete() {
        // 防止因为多次删除而产生的 BUG.
        if (this.deleted) {
            return;
        }
        this.program.unuse();
        if (this.vertices) {
            this.vertices.__unuse(this);
        }
        this.unuseAllSamplers();
        this.sw.__deleteToDraw(this);
    }
    /** 移除所有的采样器. */
    unuseAllSamplers() {
        for (let samplers of Object.values(this.samplers)) {
            for (let sampler of samplers) {
                sampler.__unuse(this);
            }
        }
    }
}
exports.ToDraw = ToDraw;


/***/ }),

/***/ "./src/libs/webgl/util.ts":
/*!********************************!*\
  !*** ./src/libs/webgl/util.ts ***!
  \********************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.glslToVersion100 = exports.generateUniqueID = void 0;
let uniqueIdSeed = 1;
/** 获得一个不会重复的数字 id. */
function generateUniqueID() {
    return uniqueIdSeed++;
}
exports.generateUniqueID = generateUniqueID;
/** 将代码格式化为 100 版本, 暂未使用到. */
function glslToVersion100(code, isVertexCode) {
    if (/^\s*#version/.test(code)) {
        code = code.replace(/^\s*#version .+/, '#version 100');
    }
    else {
        code = code.replace(/^/, '#version 100\n');
    }
    code = code.replace(/\btexture\b/g, 'texture2D');
    if (isVertexCode) {
        code = code.replace(/\bin\b/g, 'attribute');
        code = code.replace(/\bout\b/g, 'varying');
    }
    else {
        code = code.replace(/\bin\b/g, 'varying');
        let outVariable = code.match(/out\s+vec4\s+(\w+)\s*;/)[1];
        code = code.replace(/out\s+vec4\s+(\w+)\s*;/, 'gl_FragColor = $1;');
        code = code.replace(new RegExp('\\b' + outVariable + '\\b'), 'gl_FragColor');
    }
    return code;
}
exports.glslToVersion100 = glslToVersion100;


/***/ }),

/***/ "./src/libs/webgl/vertices.ts":
/*!************************************!*\
  !*** ./src/libs/webgl/vertices.ts ***!
  \************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Vertices = void 0;
const util_1 = __webpack_require__(/*! ./util */ "./src/libs/webgl/util.ts");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
/** 用于记录顶点数据的类型. */
var VerticeDataRecordType;
(function (VerticeDataRecordType) {
    VerticeDataRecordType[VerticeDataRecordType["Float"] = WebGL2RenderingContext.prototype.FLOAT] = "Float";
    VerticeDataRecordType[VerticeDataRecordType["Int"] = WebGL2RenderingContext.prototype.INT] = "Int";
})(VerticeDataRecordType || (VerticeDataRecordType = {}));
/** 对应一份已上传的顶点数据, 可被多个着色程序使用. */
class Vertices extends ff_1.Emitter {
    /** 唯一数字 id. */
    id = (0, util_1.generateUniqueID)();
    /** 每次要绘制的顶点的数目, 或者要绘制的多边形的数目. */
    drawCount;
    /** 是否有设置绘制索引. */
    hasIndices = false;
    context;
    /**
     * 当前顶点绑定在的 VAO 对象, 可以通过切换它更换当前顶点.
     * 如果为 null, 则意味着数据已被删除.
     */
    vao;
    /** 当无引用时是否立即删除. */
    deleteAfterNoReference = true;
    /** 顶点的缓存数据对象. */
    records = {};
    /** 顶点数据的总数. */
    vertexCount;
    /** 用于对当前顶点对象进行引用计数. */
    counter;
    /**
     * 设置顶点数据. 设置之后顶点数据会进行引用计数, 如果无引用的话再将其移除.
     * @param datas 包含了由着色器端的 uniform 名称作为索引, 以及值作为数据的对象.
     * @param counts 顶点数据的分组数目, 所有的顶点数据的数目都应当能整除它.
     * @param indices 绘制索引数据, 用于处理索引绘制时.
     */
    constructor(sw, datas, vertexCount, indices) {
        super();
        this.context = sw.context;
        this.counter = sw.verticesReferenceCounter;
        this.vertexCount = vertexCount;
        this.vao = this.context.createVertexArray();
        this.context.bindVertexArray(this.vao);
        // 绑定数据.
        for (let name of Object.keys(datas)) {
            this.bufferData(name, datas[name]);
        }
        // 设置顶点索引数据.
        if (indices) {
            this.setIndicesOnVAOActivated(indices);
        }
        // 这里一定要注意, 在进行索引绘制时, 绘制的数目是索引的长度, 而不是顶点数目.
        this.drawCount = indices ? indices.length : vertexCount;
    }
    /** 将多个顶点数据进行打包. */
    bufferData(name, data) {
        let dataArray = Array.isArray(data) ? new Float32Array(data) : data;
        let buffer = this.context.createBuffer();
        this.createDataRecord(name, dataArray, buffer);
        this.context.bindBuffer(this.context.ARRAY_BUFFER, buffer);
        this.context.bufferData(this.context.ARRAY_BUFFER, dataArray, this.context.STATIC_DRAW);
    }
    /** 创建一条顶点数据记录. */
    createDataRecord(name, dataArray, buffer) {
        if (dataArray.length % this.vertexCount !== 0) {
            throw new Error(`Data count must exactly divide vertex count`);
        }
        let size = dataArray.length / this.vertexCount;
        let bytesPerElement = dataArray.BYTES_PER_ELEMENT;
        let type = dataArray instanceof Float64Array || dataArray instanceof Float32Array ? VerticeDataRecordType.Float : VerticeDataRecordType.Int;
        this.records[name] = {
            type,
            buffer,
            size,
            bytesPerElement,
        };
    }
    /** 设置或者更新顶点索引数据. */
    setIndices(indices) {
        this.active();
        if (indices) {
            this.setIndicesOnVAOActivated(indices);
        }
        else {
            this.context.bindBuffer(this.context.ELEMENT_ARRAY_BUFFER, null);
            this.hasIndices = false;
        }
    }
    /** 设置顶点索引数据, 会自动绑定到当前的 vao 上面. */
    setIndicesOnVAOActivated(indices) {
        let buffer = this.context.createBuffer();
        let intIndices = new Uint16Array(indices);
        this.context.bindBuffer(this.context.ELEMENT_ARRAY_BUFFER, buffer);
        this.context.bufferData(this.context.ELEMENT_ARRAY_BUFFER, intIndices, this.context.STATIC_DRAW);
        this.hasIndices = true;
    }
    /** 更新顶点数据, 请务必确保其格式和数量与最初设置的顶点数据移植. */
    updateData(datas) {
        this.active();
        for (let name of Object.keys(datas)) {
            let data = datas[name];
            let dataArray = Array.isArray(data) ? new Float32Array(data) : data;
            let record = this.records[name];
            if (!record) {
                throw new Error(`Vertex data "${name}" must be set when initializing`);
            }
            this.context.bindBuffer(this.context.ARRAY_BUFFER, record.buffer);
            this.context.bufferSubData(this.context.ARRAY_BUFFER, 0, dataArray);
        }
    }
    /**
     * 让 ToDraw 对象使用已上传的顶点数据.
     * 由于顶点数据不和着色程序相关, 所以多个 ToDraw 对象可以使用同一个顶点数据, 必须在此设置内存布局结构.
     */
    __useBy(toDraw) {
        this.active();
        for (let name of Object.keys(this.records)) {
            let { type, size, buffer, bytesPerElement } = this.records[name];
            let location = toDraw.program.getAttributeLocation(name);
            this.context.bindBuffer(this.context.ARRAY_BUFFER, buffer);
            // 设置 size 大于 4 的内存布局, 例如矩阵数据.
            if (size > 4) {
                let loop = size / 4;
                let stride = size * bytesPerElement;
                for (let i = 0; i < loop; i++) {
                    this.context.enableVertexAttribArray(location + i);
                    this.context.vertexAttribPointer(location + i, 4, type, false, stride, i * 4 * bytesPerElement);
                }
            }
            else {
                this.context.enableVertexAttribArray(location);
                this.context.vertexAttribPointer(location, size, type, false, 0, 0);
            }
        }
        this.counter.use(this, toDraw);
    }
    /** 激活顶点数据对象, 在需要为指定的着色器程序设置内存布局, 或者即将绘制时需要激活对应的顶点数据对象. */
    active() {
        if (!this.vao) {
            throw new Error(`Vertex data ${this.id} has been deleted!`);
        }
        this.context.bindVertexArray(this.vao);
    }
    /** 对象是否正在被使用. */
    inUse() {
        return this.counter.isUsing(this);
    }
    /** 当 ToDraw 对象不再使用某个顶点数据时调用. */
    __unuse(by) {
        this.counter.unuse(this, by);
    }
    /** 当顶点数据不再有引用时触发. */
    __onNoReference() {
        this.emit('noreference');
    }
    /** 当顶点数据不再有引用时触发. */
    __onNoReferenceForSeconds() {
        if (this.deleteAfterNoReference) {
            this.delete();
        }
    }
    /** 如果超过一段时间没有被引用, 抛出一个警告. */
    __onNoTouchForSeconds(seconds) {
        console.warn(`Vertices "${this.id}" has no reference for ${seconds} seconds after created`);
    }
    /** 移除顶点索引对象, ToDraw 对象释放时会自动调用此方法. */
    delete() {
        this.context.deleteVertexArray(this.vao);
        this.vao = null;
    }
}
exports.Vertices = Vertices;


/***/ }),

/***/ "./src/tools/fix-video-black-surrounding-blend.frag":
/*!**********************************************************!*\
  !*** ./src/tools/fix-video-black-surrounding-blend.frag ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ("#version 300 es\n#ifdef GL_ES\nprecision mediump float;\n#endif\nin vec2 fTextureCoord;\nout vec4 fragColor;\nuniform vec2 iResolution;\nuniform sampler2D iChannel[2];\nuniform int maxSearchingFgRadius;\nuniform int maxMaskErrorPixels;\nvec4 guessForegroundColor(vec4 color, vec4 bgColor) {\nvec4 fgColor = vec4(0);\nfloat fgTargetValue = 0.0;\nfor (int i = -maxSearchingFgRadius; i <= maxSearchingFgRadius; i++) {\nfor (int j = -maxSearchingFgRadius; j <= maxSearchingFgRadius; j++) {\nvec2 pixelCoord = fTextureCoord + vec2(i, j) / iResolution;\nvec4 pixelFgColor = texture(iChannel[0], pixelCoord);\nvec4 pixelMaskColor = texture(iChannel[1], fTextureCoord);\nfloat pixelMaskAlpha = pixelMaskColor.r * 0.333 + pixelMaskColor.g * 0.333 + pixelMaskColor.b * 0.334;\nfloat pixelAlpha = dot(color.rgb - bgColor.rgb, pixelFgColor.rgb - bgColor.rgb)\n/ pow(length(pixelFgColor.rgb - bgColor.rgb), 2.0);\npixelAlpha = clamp(pixelAlpha, 0.0, 1.0);\nfloat beFrontPriority = pow((pixelMaskAlpha + 1.0) / 2.0, 24.0);\nfloat distancePriority = float(maxSearchingFgRadius) / float(maxSearchingFgRadius + abs(i) + abs(j));\nfloat colorDecompressionPriority = pow(1.0 / (0.5 + distance(color, pixelFgColor * pixelAlpha + (1.0 - pixelAlpha) * bgColor)), 2.0);\nfloat farFromBgPriority = pow(distance(pixelFgColor, bgColor) + 0.5, 3.0);\nfloat targetValue = beFrontPriority\n* distancePriority\n* farFromBgPriority\n* colorDecompressionPriority;\nif (targetValue > fgTargetValue) {\nfgColor = pixelFgColor;\nfgTargetValue = targetValue;\n}\n}\n}\nfgColor /= fgColor.a;\nreturn fgColor;\n}\nfloat getAverageMaskAlpha() {\nfloat alphaTotal = 0.0;\nfloat pixelCount = pow(float(maxMaskErrorPixels * 2 + 1), 2.0);\nfor (int i = -maxMaskErrorPixels; i <= maxMaskErrorPixels; i++) {\nfor (int j = -maxMaskErrorPixels; j <= maxMaskErrorPixels; j++) {\nvec2 pixelCoord = fTextureCoord + vec2(i, j) / iResolution;\nvec4 pixelMaskColor = texture(iChannel[1], pixelCoord);\nfloat pixelMaskAlpha = pixelMaskColor.r * 0.333 + pixelMaskColor.g * 0.333 + pixelMaskColor.b * 0.334;\nalphaTotal += pixelMaskAlpha;\n}\n}\nreturn alphaTotal / pixelCount;\n}\nvec4 getFragColor() {\nvec4 color = texture(iChannel[0], fTextureCoord);\nvec4 bgColor = vec4(0, 0, 0, 1);\nvec4 fgColor = guessForegroundColor(color, bgColor);\nfloat averageMaskAlpha = getAverageMaskAlpha();\nfloat alpha = dot(color.rgb - bgColor.rgb, fgColor.rgb - bgColor.rgb)\n/ pow(length(fgColor.rgb - bgColor.rgb), 2.0);\nalpha = clamp(alpha, 0.0, 1.0);\nif (averageMaskAlpha > 0.99) {\nreturn color;\n}\nelse {\nreturn fgColor;\n}\n}\nvoid main() {\nfragColor = getFragColor();\n}\n");

/***/ }),

/***/ "./src/tools/fix-video-black-surrounding-smooth.frag":
/*!***********************************************************!*\
  !*** ./src/tools/fix-video-black-surrounding-smooth.frag ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ("#version 300 es\n#ifdef GL_ES\nprecision mediump float;\n#endif\nin vec2 fTextureCoord;\nout vec4 fragColor;\nuniform vec2 iResolution;\nuniform sampler2D iChannel[1];\nuniform float blurRadius;\nuniform float luminanceRadius;\nfloat getLuminance(vec4 color) {\nreturn (color.r + color.g + color.b) / 3.0;\n}\nvec4 getFragColor() {\nvec4 totalColor;\nfloat totalPriority;\nfloat coreLuminance = getLuminance(texture(iChannel[0], fTextureCoord));\nfor (float i = -blurRadius; i <= blurRadius; i++) {\nfor (float j = -blurRadius; j <= blurRadius; j++) {\nvec2 pixelCoord = fTextureCoord + vec2(i, j) / iResolution;\nvec4 pixelColor = texture(iChannel[0], pixelCoord);\nfloat luminance = getLuminance(pixelColor);\nfloat distancePriority = exp(- (i * i + j * j) / (2.0 * blurRadius * blurRadius));\nfloat luminanceDiff = luminance - coreLuminance;\nfloat luminancePriority = exp(- luminanceDiff * luminanceDiff / (2.0 * luminanceRadius * luminanceRadius));\nfloat priority = distancePriority * luminancePriority;\ntotalColor += pixelColor * priority;\ntotalPriority += priority;\n}\n}\nreturn totalColor / totalPriority;\n}\nvoid main() {\nfragColor = getFragColor();\n}\n");

/***/ }),

/***/ "./src/tools/fix-video-black-surrounding.ts":
/*!**************************************************!*\
  !*** ./src/tools/fix-video-black-surrounding.ts ***!
  \**************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.FixVideoBlackSurrounding = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
const flit_ui_1 = __webpack_require__(/*! @pucelle/flit-ui */ "./node_modules/@pucelle/flit-ui/out/index.js");
const ffmpeg_1 = __webpack_require__(/*! ../libs/ffmpeg/ffmpeg */ "./src/libs/ffmpeg/ffmpeg.ts");
const video_frames_extractor_1 = __webpack_require__(/*! ../aegl/helpers/video-frames-extractor */ "./src/aegl/helpers/video-frames-extractor.ts");
const simple_webgl_1 = __webpack_require__(/*! ../libs/webgl/simple-webgl */ "./src/libs/webgl/simple-webgl.ts");
const todraw_1 = __webpack_require__(/*! ../libs/webgl/todraw */ "./src/libs/webgl/todraw.ts");
const sampler_1 = __webpack_require__(/*! ../libs/webgl/sampler */ "./src/libs/webgl/sampler.ts");
const media_1 = __webpack_require__(/*! ../aegl/helpers/media */ "./src/aegl/helpers/media.ts");
const file_1 = __webpack_require__(/*! ../libs/util/file */ "./src/libs/util/file.ts");
const fix_video_black_surrounding_blend_frag_1 = __webpack_require__(/*! ./fix-video-black-surrounding-blend.frag */ "./src/tools/fix-video-black-surrounding-blend.frag");
const fix_video_black_surrounding_smooth_frag_1 = __webpack_require__(/*! ./fix-video-black-surrounding-smooth.frag */ "./src/tools/fix-video-black-surrounding-smooth.frag");
const preload_1 = __webpack_require__(/*! ../libs/util/preload */ "./src/libs/util/preload.ts");
let FixVideoBlackSurrounding = class FixVideoBlackSurrounding extends flit_1.Component {
    processing = false;
    drawProgress = 0;
    encodingProgress = 0;
    videoFiles = null;
    toDraws;
    video;
    mask;
    time = 0;
    render() {
        return (0, flit_1.html) `
		<canvas :show=${this.videoFiles} :ref="canvas" />

		<div :show=${this.videoFiles}>
			<f-slider style="width: 300px;" .min=${0} .max=${this.video ? this.video.duration : 0} .step=${0.04}
				.value=${this.time} @change=${(time) => this.drawFrameAtTime(time)}
			/>
		</div>

		<div style="margin-top: 10px"><button @click=${this.selectVideos}>选择视频和蒙版视频</button></div>

		<div style="margin-top: 10px" :show=${this.videoFiles}><button @click=${this.process}>开始处理</button></div>
		<div style="font-size: 20px; margin-top: 30px" :show=${this.processing}>绘制进度: ${(0, ff_1.toDecimal)(this.drawProgress * 100, 0)}%</div>
		<div style="font-size: 20px; margin-top: 10px" :show=${this.processing}>编码进度: ${(0, ff_1.toDecimal)(this.encodingProgress * 100, 0)}%</div>
		`;
    }
    onReady() {
        this.showTestVideo();
    }
    async showTestVideo() {
        let videoURL = 'videos/1008-loop-720p-1.mp4';
        let maskURL = 'videos/1008-loop-720p-1-mask.mp4';
        let videoFile = await (0, file_1.getFilefromURL)(videoURL);
        let maskFile = await (0, file_1.getFilefromURL)(maskURL);
        this.videoFiles = [videoFile, maskFile];
        await this.preparePrviewVideo();
        await this.drawFrameAtTime(0.8);
    }
    async selectVideos() {
        let files = await (0, ff_1.selectMultipleFile)('video/mp4');
        if (!files) {
            return;
        }
        if (files.length !== 2) {
            flit_ui_1.notification.error(`请选择两个文件, 其中之一为原视频, 另一个为名称中包含 "mask" 的蒙版视频.`);
            return;
        }
        let maskFile = files.find(file => file.name.includes('mask'));
        if (!maskFile) {
            flit_ui_1.notification.error(`请选择两个文件, 其中之一为原视频, 另一个为名称中包含 "mask" 的蒙版视频.`);
            return;
        }
        let videoFile = files.find(file => file !== maskFile);
        this.videoFiles = [videoFile, maskFile];
        await this.preparePrviewVideo();
        await this.drawFrameAtTime(0);
    }
    async preparePrviewVideo() {
        let [videoFile, maskFile] = this.videoFiles;
        let videoURL = URL.createObjectURL(videoFile);
        let maskURL = URL.createObjectURL(maskFile);
        this.video = await (0, preload_1.preloadVideo)(videoURL);
        this.mask = await (0, preload_1.preloadVideo)(maskURL);
        let canvas = this.refs.canvas;
        let width = this.video.videoWidth;
        let height = this.video.videoHeight;
        if (width > 960) {
            height = Math.round(960 / width * height);
            width = 960;
        }
        this.toDraws = this.createToDraws(canvas, width, height);
        let [toDrawBlend] = this.toDraws;
        let videoSampler = new sampler_1.PixelSampler(toDrawBlend.sw, this.video, { filter: sampler_1.SamplerFilter.Linear });
        let maskSampler = new sampler_1.PixelSampler(toDrawBlend.sw, this.mask, { filter: sampler_1.SamplerFilter.Linear });
        toDrawBlend.useSampler('iChannel', videoSampler, maskSampler);
    }
    async drawFrameAtTime(time) {
        this.time = time;
        let [toDrawBlend, toDrawSmooth] = this.toDraws;
        let sw = toDrawBlend.sw;
        this.video.currentTime = time;
        this.mask.currentTime = time;
        await (0, media_1.waitForVideoDecoded)(this.video);
        await (0, media_1.waitForVideoDecoded)(this.mask);
        let textureFrame = sw.textureFrameManager.requestFull();
        toDrawBlend.getSubSampler('iChannel', 0).updateData(this.video);
        toDrawBlend.getSubSampler('iChannel', 1).updateData(this.mask);
        textureFrame.active();
        toDrawBlend.draw();
        textureFrame.deactive();
        sw.clear();
        toDrawSmooth.useSampler('iChannel', textureFrame.getSampler());
        toDrawSmooth.draw();
        toDrawSmooth.unuseSampler('iChannel');
    }
    async process() {
        let [videoFile, maskFile] = this.videoFiles;
        this.processing = true;
        this.drawProgress = 0;
        this.encodingProgress = 0;
        let videoURL = URL.createObjectURL(videoFile);
        let maskURL = URL.createObjectURL(maskFile);
        let videoExtractor = new video_frames_extractor_1.VideoFramesExtractor(videoURL, 'png', false);
        let maskExtractor = new video_frames_extractor_1.VideoFramesExtractor(maskURL, 'png', false);
        await videoExtractor.ready;
        await maskExtractor.ready;
        let frameCount = videoExtractor.totalFrameCount;
        let frameRate = videoExtractor.mediaInfo.video.frameRate;
        let canvas = document.createElement('canvas');
        let width = videoExtractor.mediaInfo.video.width;
        let height = videoExtractor.mediaInfo.video.height;
        let [toDrawBlend, toDrawSmooth] = this.createToDraws(canvas, width, height);
        let sw = toDrawBlend.sw;
        let videoFrames = [];
        let maskFrames = [];
        let videoSampler = new sampler_1.PixelSampler(sw, (await videoExtractor.getFrameAtIndex(0)).image);
        let maskSampler = new sampler_1.PixelSampler(sw, (await maskExtractor.getFrameAtIndex(0)).image);
        toDrawBlend.useSampler('iChannel', videoSampler, maskSampler);
        for (let i = 0; i < frameCount; i++) {
            let videoFrame = (await videoExtractor.getFrameAtIndex(i)).image;
            let maskFrame = (await maskExtractor.getFrameAtIndex(i)).image;
            let textureFrame = toDrawBlend.sw.textureFrameManager.requestFull();
            if (i > 0) {
                videoSampler.updateData(videoFrame);
                maskSampler.updateData(maskFrame);
            }
            textureFrame.active();
            toDrawBlend.draw();
            textureFrame.deactive();
            sw.clear();
            toDrawSmooth.useSampler('iChannel', textureFrame.getSampler());
            toDrawSmooth.draw();
            toDrawSmooth.unuseSampler('iChannel');
            sw.waitDrawingCompleted();
            let pngBlob = await (0, media_1.readCanvasAsImage)(sw.canvas, 'png', 1);
            let arrayBuffer = await (0, file_1.readBlobAsArrayBuffer)(pngBlob);
            videoFrames.push(arrayBuffer);
            let maskBlob = (await maskExtractor.getBlobsAtIndex(i))[0];
            maskFrames.push(await (0, file_1.readBlobAsArrayBuffer)(maskBlob));
            this.drawProgress = (i + 1) / frameCount;
        }
        let files = videoFrames.map((data, index) => {
            return {
                name: String(index).padStart(5, '0') + '.png',
                data,
            };
        });
        let args = [
            '-hide_banner',
            '-framerate', frameRate,
            '-i', '%05d.png',
            '-an',
            '-c:v', 'libx264',
            '-pix_fmt', 'yuv420p',
            '-crf', 18,
            '-vf', 'scale=out_color_matrix=bt709',
            '-color_primaries', 'bt709',
            '-color_trc', 'bt709',
            '-colorspace', 'bt709',
            videoFile.name,
        ];
        let outFiles = await ffmpeg_1.ffmpeg.execWithProgress(files, args, (loaded) => {
            this.encodingProgress = loaded / frameCount / 2;
        });
        ffmpeg_1.ffmpeg.downloadFile(outFiles[0]);
        await this.processMask(maskFrames, maskFile, frameRate);
        this.processing = false;
    }
    async processMask(maskFrames, maskFile, frameRate) {
        let files = maskFrames.map((data, index) => {
            return {
                name: String(index).padStart(5, '0') + '.png',
                data,
            };
        });
        let args = [
            '-hide_banner',
            '-framerate', frameRate,
            '-i', '%05d.png',
            '-an',
            '-c:v', 'libx264',
            '-crf', 18,
            '-pix_fmt', 'yuv420p',
            '-vf', 'scale=out_color_matrix=bt709',
            '-color_primaries', 'bt709',
            '-color_trc', 'bt709',
            '-colorspace', 'bt709',
            maskFile.name,
        ];
        let outFiles = await ffmpeg_1.ffmpeg.execWithProgress(files, args, (loaded) => {
            this.encodingProgress = 0.5 + loaded / maskFrames.length / 2;
        });
        ffmpeg_1.ffmpeg.downloadFile(outFiles[0]);
    }
    createToDraws(canvas, width, height) {
        let sw = new simple_webgl_1.SimpleWebGL(canvas, { alpha: true });
        let vertCode = this.getVertexCode();
        sw.setCanvasSize(width, height, 1);
        sw.setClearColor([0, 0, 0, 0]);
        let toDrawBlend = new todraw_1.ToDraw(sw, {
            vertCode,
            fragCode: fix_video_black_surrounding_blend_frag_1.default,
            vertices: {
                data: this.getVerticesData(),
                count: 4,
            },
        });
        toDrawBlend.setUniform('maxSearchingFgRadius', 10);
        toDrawBlend.setUniform('maxMaskErrorPixels', 2);
        toDrawBlend.setUniform('iResolution', [width, height]);
        let toDrawSmooth = new todraw_1.ToDraw(sw, {
            vertCode,
            fragCode: fix_video_black_surrounding_smooth_frag_1.default,
            vertices: {
                data: this.getVerticesData(),
                count: 4,
            },
        });
        toDrawSmooth.setUniform('blurRadius', 5);
        toDrawSmooth.setUniform('luminanceRadius', 0.05);
        toDrawSmooth.setUniform('iResolution', [width, height]);
        return [toDrawBlend, toDrawSmooth];
    }
    getVertexCode() {
        return `#version 300 es
		precision mediump float;
		in vec4 vPosition;
		out vec2 fTextureCoord;
		void main() {
			gl_Position = vPosition;
			fTextureCoord = vPosition.xy / 2.0 + 0.5;
		}
		`;
    }
    getVerticesData() {
        return {
            vPosition: [
                -1, 1,
                -1, -1,
                1, 1,
                1, -1,
            ]
        };
    }
};
exports.FixVideoBlackSurrounding = FixVideoBlackSurrounding;
exports.FixVideoBlackSurrounding = FixVideoBlackSurrounding = __decorate([
    (0, flit_1.define)('fix-video-black-surrounding')
], FixVideoBlackSurrounding);


/***/ }),

/***/ "./src/transition-samples/alternate.ts":
/*!*********************************************!*\
  !*** ./src/transition-samples/alternate.ts ***!
  \*********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
const transition_processor_1 = __webpack_require__(/*! ../transitions/transition-processor */ "./src/transitions/transition-processor.ts");
const sampler_1 = __webpack_require__(/*! ../libs/webgl/sampler */ "./src/libs/webgl/sampler.ts");
const matrix4_1 = __webpack_require__(/*! ../libs/math/matrix4 */ "./src/libs/math/matrix4.ts");
(0, transition_processor_1.extendTransitions)({
    'alternate-from-left': {
        sourceParams: { filter: sampler_1.SamplerFilter.Linear },
        targetParams: { filter: sampler_1.SamplerFilter.Linear },
        steps: [
            {
                useTexture: transition_processor_1.TextureReference.Source,
                transform: (x) => {
                    return new matrix4_1.Matrix4().translateSelf(4 * -x);
                },
            },
            {
                useTexture: transition_processor_1.TextureReference.Target,
                transform: (x) => {
                    return new matrix4_1.Matrix4().translateSelf(4 * (x - 1));
                },
            },
        ]
    },
    'alternate-from-right': {
        sourceParams: { filter: sampler_1.SamplerFilter.Linear },
        targetParams: { filter: sampler_1.SamplerFilter.Linear },
        steps: [
            {
                useTexture: transition_processor_1.TextureReference.Source,
                transform: (x) => {
                    return new matrix4_1.Matrix4().translateSelf(4 * x);
                },
            },
            {
                useTexture: transition_processor_1.TextureReference.Target,
                transform: (x) => {
                    return new matrix4_1.Matrix4().translateSelf(4 * (1 - x));
                },
            },
        ]
    },
    'alternate-from-top': {
        sourceParams: { filter: sampler_1.SamplerFilter.Linear },
        targetParams: { filter: sampler_1.SamplerFilter.Linear },
        steps: [
            {
                useTexture: transition_processor_1.TextureReference.Source,
                transform: (x) => {
                    return new matrix4_1.Matrix4().translateSelf(0, 4 * x);
                },
            },
            {
                useTexture: transition_processor_1.TextureReference.Target,
                transform: (x) => {
                    return new matrix4_1.Matrix4().translateSelf(0, 4 * (1 - x));
                },
            },
        ]
    },
    'alternate-from-bottom': {
        sourceParams: { filter: sampler_1.SamplerFilter.Linear },
        targetParams: { filter: sampler_1.SamplerFilter.Linear },
        steps: [
            {
                useTexture: transition_processor_1.TextureReference.Source,
                transform: (x) => {
                    return new matrix4_1.Matrix4().translateSelf(0, 4 * -x);
                },
            },
            {
                useTexture: transition_processor_1.TextureReference.Target,
                transform: (x) => {
                    return new matrix4_1.Matrix4().translateSelf(0, 4 * (x - 1));
                },
            }
        ]
    },
});


/***/ }),

/***/ "./src/transition-samples/blur.ts":
/*!****************************************!*\
  !*** ./src/transition-samples/blur.ts ***!
  \****************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
const transition_processor_1 = __webpack_require__(/*! ../transitions/transition-processor */ "./src/transitions/transition-processor.ts");
const zoomBlurUniformSlides = [
    {
        name: 'maxBlurRadiusRate',
        desc: 'Max Blur Radius Rate',
        min: 0,
        max: 1,
        step: 0.01,
        value: 0.2,
    },
];
const motionBlurUniformSlides = [
    {
        name: 'movesCount',
        desc: 'Moves Count',
        min: 6,
        max: 100,
        step: 2,
        value: 24,
    }
];
(0, transition_processor_1.extendTransitions)({
    'zoom-blur': {
        uniformSlides: zoomBlurUniformSlides,
        steps: [
            {
                fragShaderName: 'zoom-blur'
            }
        ]
    },
    'motion-blur-to-top': {
        uniformSlides: motionBlurUniformSlides,
        uniformValues: {
            directionAngle: 90,
        },
        steps: [
            {
                fragShaderName: 'motion-blur'
            }
        ]
    },
    'motion-blur-to-bottom': {
        uniformSlides: motionBlurUniformSlides,
        uniformValues: {
            directionAngle: -90,
        },
        steps: [
            {
                fragShaderName: 'motion-blur'
            }
        ]
    },
    'motion-blur-to-left': {
        uniformSlides: motionBlurUniformSlides,
        uniformValues: {
            directionAngle: 180,
        },
        steps: [
            {
                fragShaderName: 'motion-blur'
            }
        ]
    },
    'motion-blur-to-right': {
        uniformSlides: motionBlurUniformSlides,
        uniformValues: {
            directionAngle: 0,
        },
        steps: [
            {
                fragShaderName: 'motion-blur'
            }
        ]
    },
    'motion-blur-to-top-left': {
        uniformSlides: motionBlurUniformSlides,
        uniformValues: {
            directionAngle: 135,
        },
        steps: [
            {
                fragShaderName: 'motion-blur'
            }
        ]
    },
    'motion-blur-to-top-right': {
        uniformSlides: motionBlurUniformSlides,
        uniformValues: {
            directionAngle: 45,
        },
        steps: [
            {
                fragShaderName: 'motion-blur'
            }
        ]
    },
    'motion-blur-to-bottom-left': {
        uniformSlides: motionBlurUniformSlides,
        uniformValues: {
            directionAngle: -135,
        },
        steps: [
            {
                fragShaderName: 'motion-blur'
            }
        ]
    },
    'motion-blur-to-bottom-right': {
        uniformSlides: motionBlurUniformSlides,
        uniformValues: {
            directionAngle: -45,
        },
        steps: [
            {
                fragShaderName: 'motion-blur'
            }
        ]
    },
});


/***/ }),

/***/ "./src/transition-samples/cube.ts":
/*!****************************************!*\
  !*** ./src/transition-samples/cube.ts ***!
  \****************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
const transition_processor_1 = __webpack_require__(/*! ../transitions/transition-processor */ "./src/transitions/transition-processor.ts");
const sampler_1 = __webpack_require__(/*! ../libs/webgl/sampler */ "./src/libs/webgl/sampler.ts");
const vector4_1 = __webpack_require__(/*! ../libs/math/vector4 */ "./src/libs/math/vector4.ts");
const matrix4_1 = __webpack_require__(/*! ../libs/math/matrix4 */ "./src/libs/math/matrix4.ts");
const frontVertices = [
    -1, 1, 1,
    -1, -1, 1,
    1, 1, 1,
    1, -1, 1,
];
const rightVertices = [
    1, 1, 1,
    1, -1, 1,
    1, 1, -1,
    1, -1, -1,
];
const leftVertices = [
    -1, 1, -1,
    -1, -1, -1,
    -1, 1, 1,
    -1, -1, 1,
];
const textureCoords = [
    0, 1,
    0, 0,
    1, 1,
    1, 0,
];
const topVertices = [
    -1, 1, -1,
    -1, 1, 1,
    1, 1, -1,
    1, 1, 1,
];
const bottomVertices = [
    -1, -1, 1,
    -1, -1, -1,
    1, -1, 1,
    1, -1, -1,
];
// deep 代表着摄影机到投影屏幕的距离.
function getRotationTransform(x, direction, deep) {
    let rotateZX = direction === 'left' ? -1 : direction === 'right' ? 1 : 0;
    let rotateYZ = direction === 'bottom' ? 1 : direction === 'top' ? -1 : 0;
    let transform = new matrix4_1.Matrix4();
    transform.rotate3DSelf(rotateYZ * x * Math.PI / 2, rotateZX * x * Math.PI / 2, 0);
    transform.translateSelf(0, 0, -1 * (1 - Math.pow(2 * x - 1, 2)));
    // 代表着摄影机到 box 中心点的距离.
    let camera = deep + 1;
    let lookAt = matrix4_1.Matrix4.lookAt(new vector4_1.Vector3(0, 0, camera), new vector4_1.Vector3(0, 0, 0));
    let projection = matrix4_1.Matrix4.perspective(2, 2, deep);
    let final = projection.multiplySelf(lookAt).multiplySelf(transform);
    return final;
}
function getRotationRightTransform(x, uniforms) {
    return getRotationTransform(x, 'right', uniforms.perspective);
}
function getRotationLeftTransform(x, uniforms) {
    return getRotationTransform(x, 'left', uniforms.perspective);
}
function getRotationTopTransform(x, uniforms) {
    return getRotationTransform(x, 'top', uniforms.perspective);
}
function getRotationBottomTransform(x, uniforms) {
    return getRotationTransform(x, 'bottom', uniforms.perspective);
}
const uniformSlides = [
    {
        name: 'perspective',
        desc: 'Perspective',
        min: 1.1,
        max: 10,
        step: 0.1,
        value: 3,
    }
];
(0, transition_processor_1.extendTransitions)({
    'cube-from-right': {
        sourceParams: { filter: sampler_1.SamplerFilter.MipmapLinear, anisotropy: true },
        targetParams: { filter: sampler_1.SamplerFilter.MipmapLinear, anisotropy: true },
        threeD: true,
        uniformSlides,
        steps: [
            {
                useTexture: transition_processor_1.TextureReference.Source,
                vertices: frontVertices,
                transform: getRotationLeftTransform,
                fragShaderName: 'cube-source',
            },
            {
                useTexture: transition_processor_1.TextureReference.Target,
                vertices: rightVertices,
                textureCoords: textureCoords,
                transform: getRotationLeftTransform,
                fragShaderName: 'cube-target',
            }
        ]
    },
    'cube-from-left': {
        sourceParams: { filter: sampler_1.SamplerFilter.MipmapLinear, anisotropy: true },
        targetParams: { filter: sampler_1.SamplerFilter.MipmapLinear, anisotropy: true },
        threeD: true,
        uniformSlides,
        steps: [
            {
                useTexture: transition_processor_1.TextureReference.Source,
                vertices: frontVertices,
                transform: getRotationRightTransform,
                fragShaderName: 'cube-source',
            },
            {
                useTexture: transition_processor_1.TextureReference.Target,
                vertices: leftVertices,
                textureCoords,
                transform: getRotationRightTransform,
                fragShaderName: 'cube-target',
            }
        ]
    },
    'cube-from-top': {
        sourceParams: { filter: sampler_1.SamplerFilter.MipmapLinear, anisotropy: true },
        targetParams: { filter: sampler_1.SamplerFilter.MipmapLinear, anisotropy: true },
        threeD: true,
        uniformSlides,
        steps: [
            {
                useTexture: transition_processor_1.TextureReference.Source,
                vertices: frontVertices,
                transform: getRotationBottomTransform,
                fragShaderName: 'cube-source',
            },
            {
                useTexture: transition_processor_1.TextureReference.Target,
                vertices: topVertices,
                textureCoords,
                transform: getRotationBottomTransform,
                fragShaderName: 'cube-target',
            }
        ]
    },
    'cube-from-bottom': {
        sourceParams: { filter: sampler_1.SamplerFilter.MipmapLinear, anisotropy: true },
        targetParams: { filter: sampler_1.SamplerFilter.MipmapLinear, anisotropy: true },
        threeD: true,
        uniformSlides,
        steps: [
            {
                useTexture: transition_processor_1.TextureReference.Source,
                vertices: frontVertices,
                transform: getRotationTopTransform,
                fragShaderName: 'cube-source',
            },
            {
                useTexture: transition_processor_1.TextureReference.Target,
                vertices: bottomVertices,
                textureCoords,
                transform: getRotationTopTransform,
                fragShaderName: 'cube-target',
            }
        ]
    },
});


/***/ }),

/***/ "./src/transition-samples/distortion.ts":
/*!**********************************************!*\
  !*** ./src/transition-samples/distortion.ts ***!
  \**********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
const transition_processor_1 = __webpack_require__(/*! ../transitions/transition-processor */ "./src/transitions/transition-processor.ts");
const uniformSlides = [
    {
        name: 'offsetRadius',
        desc: 'Offset Radius',
        min: 0,
        max: 1,
        step: 0.01,
        value: 0.1,
    },
];
(0, transition_processor_1.extendTransitions)({
    'morph': {
        uniformSlides,
        steps: [
            {
                fragShaderName: 'morph'
            }
        ]
    },
    'color-offset': {
        uniformSlides,
        steps: [
            {
                fragShaderName: 'color-offset'
            }
        ]
    },
    'fly-eye': {
        uniformSlides: [
            {
                name: 'offsetRadius',
                desc: 'Offset Radius',
                min: 0,
                max: 1,
                step: 0.01,
                value: 0.03,
            },
            {
                name: 'offsetPeriod',
                desc: 'Offset Period',
                min: 0,
                max: 1,
                step: 0.01,
                value: 0.1,
            },
            {
                name: 'colorSeparation',
                desc: 'Color Separation',
                min: 0,
                max: 1,
                step: 0.1,
                value: 0.1,
            },
        ],
        steps: [
            {
                fragShaderName: 'fly-eye'
            }
        ]
    },
});


/***/ }),

/***/ "./src/transition-samples/enlarge.ts":
/*!*******************************************!*\
  !*** ./src/transition-samples/enlarge.ts ***!
  \*******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
const transition_processor_1 = __webpack_require__(/*! ../transitions/transition-processor */ "./src/transitions/transition-processor.ts");
const sampler_1 = __webpack_require__(/*! ../libs/webgl/sampler */ "./src/libs/webgl/sampler.ts");
const matrix4_1 = __webpack_require__(/*! ../libs/math/matrix4 */ "./src/libs/math/matrix4.ts");
(0, transition_processor_1.extendTransitions)({
    'central-in': {
        targetParams: { filter: sampler_1.SamplerFilter.MipmapLinear },
        steps: [
            {
                useTexture: transition_processor_1.TextureReference.Source,
            },
            {
                useTexture: transition_processor_1.TextureReference.Target,
                transform: (x) => {
                    return new matrix4_1.Matrix4().scaleSelf(x, x);
                },
            },
        ]
    },
    'left-top-in': {
        targetParams: { filter: sampler_1.SamplerFilter.MipmapLinear },
        steps: [
            {
                useTexture: transition_processor_1.TextureReference.Source,
            },
            {
                useTexture: transition_processor_1.TextureReference.Target,
                transform: (x) => {
                    return new matrix4_1.Matrix4().scaleSelf(x, x).translateSelf(-(1 - x), 1 - x);
                }
            },
        ]
    },
    'right-top-in': {
        targetParams: { filter: sampler_1.SamplerFilter.MipmapLinear },
        steps: [
            {
                useTexture: transition_processor_1.TextureReference.Source,
            },
            {
                useTexture: transition_processor_1.TextureReference.Target,
                transform: (x) => {
                    return new matrix4_1.Matrix4().scaleSelf(x, x).translateSelf(1 - x, 1 - x);
                },
            },
        ]
    },
    'left-bottom-in': {
        targetParams: { filter: sampler_1.SamplerFilter.MipmapLinear },
        steps: [
            {
                useTexture: transition_processor_1.TextureReference.Source,
            },
            {
                useTexture: transition_processor_1.TextureReference.Target,
                transform: (x) => {
                    return new matrix4_1.Matrix4().scaleSelf(x, x).translateSelf(-(1 - x), -(1 - x));
                },
            },
        ]
    },
    'right-bottom-in': {
        targetParams: { filter: sampler_1.SamplerFilter.MipmapLinear },
        steps: [
            {
                useTexture: transition_processor_1.TextureReference.Source,
            },
            {
                useTexture: transition_processor_1.TextureReference.Target,
                transform: (x) => {
                    return new matrix4_1.Matrix4().scaleSelf(x, x).translateSelf(1 - x, -(1 - x));
                },
            },
        ]
    },
});
// 用于演示不同的采样方式
let steps = [
    {
        useTexture: transition_processor_1.TextureReference.Source,
    },
    {
        useTexture: transition_processor_1.TextureReference.Target,
        transform: (x) => {
            return new matrix4_1.Matrix4().scaleSelf(x, x);
        },
    },
];
(0, transition_processor_1.extendTransitions)({
    'NEAREAST': {
        targetParams: { filter: sampler_1.SamplerFilter.Nearest },
        steps,
    },
    'LINEAR': {
        targetParams: { filter: sampler_1.SamplerFilter.Linear },
        steps,
    },
    'NEAREST_MIPMAP_NEAREST': {
        targetParams: { filter: sampler_1.SamplerFilter.MipmapNearestStatic },
        steps,
    },
    'NEAREST_MIPMAP_LINEAR': {
        targetParams: { filter: sampler_1.SamplerFilter.MipmapNearest },
        steps,
    },
    'LINEAR_MIPMAP_NEAREST': {
        targetParams: { filter: sampler_1.SamplerFilter.MipmapLinearStatic },
        steps,
    },
    'LINEAR_MIPMAP_LINEAR': {
        targetParams: { filter: sampler_1.SamplerFilter.MipmapLinear },
        steps,
    },
});


/***/ }),

/***/ "./src/transition-samples/face-transform.ts":
/*!**************************************************!*\
  !*** ./src/transition-samples/face-transform.ts ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
const transition_processor_1 = __webpack_require__(/*! ../transitions/transition-processor */ "./src/transitions/transition-processor.ts");
const todraw_1 = __webpack_require__(/*! ../libs/webgl/todraw */ "./src/libs/webgl/todraw.ts");
const sampler_1 = __webpack_require__(/*! ../libs/webgl/sampler */ "./src/libs/webgl/sampler.ts");
(0, transition_processor_1.extendTransitions)({
    'face-transform': {
        sourceParams: { filter: sampler_1.SamplerFilter.MipmapLinear },
        targetParams: { filter: sampler_1.SamplerFilter.MipmapLinear },
        steps: [
            // 绘制原图到画布.
            {
                useTexture: transition_processor_1.TextureReference.Source,
                drawType: todraw_1.ToDrawType.Triangles,
                vertShaderName: 'face-transform-source',
            },
            // 将新图绘制在一个纹理上, 然后在下一步引用.
            {
                useTexture: transition_processor_1.TextureReference.Target,
                drawType: todraw_1.ToDrawType.Triangles,
                vertShaderName: 'face-transform-target',
            },
            // 将上面的纹理设置透明度后再绘制到画布.
            {
                useTexture: transition_processor_1.TextureReference.None,
                fragShaderName: 'face-transform-target',
            }
        ],
    },
});


/***/ }),

/***/ "./src/transition-samples/fade.ts":
/*!****************************************!*\
  !*** ./src/transition-samples/fade.ts ***!
  \****************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
const transition_processor_1 = __webpack_require__(/*! ../transitions/transition-processor */ "./src/transitions/transition-processor.ts");
(0, transition_processor_1.extendTransitions)({
    'fade': {
        steps: [
            {
                fragShaderName: 'fade',
            }
        ]
    },
    'fade-black': {
        uniformValues: {
            fadeToColor: [0, 0, 0],
        },
        steps: [
            {
                fragShaderName: 'fade-color'
            }
        ]
    },
    'fade-white': {
        uniformValues: {
            fadeToColor: [1, 1, 1],
        },
        steps: [
            {
                fragShaderName: 'fade-color'
            }
        ]
    },
});


/***/ }),

/***/ "./src/transition-samples/flash.ts":
/*!*****************************************!*\
  !*** ./src/transition-samples/flash.ts ***!
  \*****************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
const transition_processor_1 = __webpack_require__(/*! ../transitions/transition-processor */ "./src/transitions/transition-processor.ts");
(0, transition_processor_1.extendTransitions)({
    'flash-white': {
        uniformValues: {
            flashToColor: [1, 1, 1],
        },
        steps: [
            {
                fragShaderName: 'flash'
            }
        ]
    },
    'flash-black': {
        uniformValues: {
            flashToColor: [0, 0, 0],
        },
        steps: [
            {
                fragShaderName: 'flash'
            }
        ]
    },
    'flash-brown': {
        uniformValues: {
            flashToColor: [0.9, 0.4, 0.2],
        },
        steps: [
            {
                fragShaderName: 'flash'
            }
        ]
    },
});


/***/ }),

/***/ "./src/transition-samples/grid-zoom.ts":
/*!*********************************************!*\
  !*** ./src/transition-samples/grid-zoom.ts ***!
  \*********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
const transition_processor_1 = __webpack_require__(/*! ../transitions/transition-processor */ "./src/transitions/transition-processor.ts");
const uniformSlides = [
    {
        name: 'cellSizeRate',
        desc: 'Cell Size Rate',
        min: 0.01,
        max: 1,
        step: 0.01,
        value: 0.1,
    },
];
(0, transition_processor_1.extendTransitions)({
    'grid-zoom-in': {
        uniformSlides,
        uniformValues: {
            beZoomOut: false,
            cellZoomOrigin: [0.5, 0.5],
        },
        steps: [
            {
                fragShaderName: 'grid-zoom'
            }
        ]
    },
    'grid-zoom-out': {
        uniformSlides,
        uniformValues: {
            beZoomOut: true,
            cellZoomOrigin: [0.5, 0.5],
        },
        steps: [
            {
                fragShaderName: 'grid-zoom'
            }
        ]
    },
    'grid-zoom-in-from-top-left': {
        uniformSlides,
        uniformValues: {
            beZoomOut: false,
            cellZoomOrigin: [0, 1],
        },
        steps: [
            {
                fragShaderName: 'grid-zoom'
            }
        ]
    },
    'grid-zoom-out-from-top-left': {
        uniformSlides,
        uniformValues: {
            beZoomOut: true,
            cellZoomOrigin: [1, 0],
        },
        steps: [
            {
                fragShaderName: 'grid-zoom'
            }
        ]
    },
});


/***/ }),

/***/ "./src/transition-samples/index.ts":
/*!*****************************************!*\
  !*** ./src/transition-samples/index.ts ***!
  \*****************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
__webpack_require__(/*! ./alternate */ "./src/transition-samples/alternate.ts");
__webpack_require__(/*! ./enlarge */ "./src/transition-samples/enlarge.ts");
__webpack_require__(/*! ./push */ "./src/transition-samples/push.ts");
__webpack_require__(/*! ./shuffle */ "./src/transition-samples/shuffle.ts");
__webpack_require__(/*! ./wipe */ "./src/transition-samples/wipe.ts");
__webpack_require__(/*! ./split */ "./src/transition-samples/split.ts");
__webpack_require__(/*! ./stripe-merge */ "./src/transition-samples/stripe-merge.ts");
__webpack_require__(/*! ./wave */ "./src/transition-samples/wave.ts");
__webpack_require__(/*! ./page-curl */ "./src/transition-samples/page-curl.ts");
__webpack_require__(/*! ./slant-wipe */ "./src/transition-samples/slant-wipe.ts");
__webpack_require__(/*! ./fade */ "./src/transition-samples/fade.ts");
__webpack_require__(/*! ./radar */ "./src/transition-samples/radar.ts");
__webpack_require__(/*! ./rays */ "./src/transition-samples/rays.ts");
__webpack_require__(/*! ./flash */ "./src/transition-samples/flash.ts");
__webpack_require__(/*! ./mask */ "./src/transition-samples/mask.ts");
__webpack_require__(/*! ./mask-fade */ "./src/transition-samples/mask-fade.ts");
__webpack_require__(/*! ./mask-of-polar-sampling */ "./src/transition-samples/mask-of-polar-sampling.ts");
__webpack_require__(/*! ./mask-of-shape */ "./src/transition-samples/mask-of-shape.ts");
__webpack_require__(/*! ./face-transform */ "./src/transition-samples/face-transform.ts");
__webpack_require__(/*! ./pixelate */ "./src/transition-samples/pixelate.ts");
__webpack_require__(/*! ./distortion */ "./src/transition-samples/distortion.ts");
__webpack_require__(/*! ./blur */ "./src/transition-samples/blur.ts");
__webpack_require__(/*! ./grid-zoom */ "./src/transition-samples/grid-zoom.ts");
__webpack_require__(/*! ./shutter */ "./src/transition-samples/shutter.ts");
__webpack_require__(/*! ./cube */ "./src/transition-samples/cube.ts");
__webpack_require__(/*! ./others */ "./src/transition-samples/others.ts");


/***/ }),

/***/ "./src/transition-samples/mask-fade.ts":
/*!*********************************************!*\
  !*** ./src/transition-samples/mask-fade.ts ***!
  \*********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
const transition_processor_1 = __webpack_require__(/*! ../transitions/transition-processor */ "./src/transitions/transition-processor.ts");
const uniformSlides = [
    {
        name: 'smoothRange',
        desc: 'Smooth Range',
        min: 0,
        max: 1,
        step: 0.01,
        value: 0.1,
    },
];
(0, transition_processor_1.extendTransitions)({
    'mask-evaporate-painted-lines': {
        uniformSlides,
        mask: 'evaporate-painted-lines',
        steps: [
            {
                fragShaderName: 'mask-fade'
            }
        ]
    },
    'mask-evaporate-ripple': {
        uniformSlides,
        mask: 'evaporate-ripple',
        steps: [
            {
                fragShaderName: 'mask-fade'
            }
        ]
    },
});


/***/ }),

/***/ "./src/transition-samples/mask-of-polar-sampling.ts":
/*!**********************************************************!*\
  !*** ./src/transition-samples/mask-of-polar-sampling.ts ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
const transition_processor_1 = __webpack_require__(/*! ../transitions/transition-processor */ "./src/transitions/transition-processor.ts");
const uniformSlides = [
    {
        name: 'blurRadius',
        desc: 'Blur Radius',
        min: 0,
        max: 0.5,
        step: 0.01,
        value: 0.01,
    }
];
(0, transition_processor_1.extendTransitions)({
    'heart': {
        polarSamplingData: [0.678, 0.6842, 0.6905, 0.6968, 0.7031, 0.7095, 0.7159, 0.7224, 0.7288, 0.7351, 0.7415, 0.7477, 0.7539, 0.76, 0.766, 0.7719, 0.7776, 0.7831, 0.7885, 0.7937, 0.7987, 0.8034, 0.8078, 0.8119, 0.8158, 0.8193, 0.8226, 0.8256, 0.8283, 0.8307, 0.8328, 0.8346, 0.8361, 0.8373, 0.8383, 0.8389, 0.8393, 0.8393, 0.8391, 0.8386, 0.8378, 0.8368, 0.8354, 0.8338, 0.8319, 0.8297, 0.8272, 0.8244, 0.8214, 0.818, 0.8144, 0.8105, 0.8063, 0.8018, 0.797, 0.7919, 0.7865, 0.7809, 0.7749, 0.7687, 0.7622, 0.7554, 0.7484, 0.7411, 0.7335, 0.7256, 0.7175, 0.7091, 0.7004, 0.6915, 0.6822, 0.6727, 0.6629, 0.6527, 0.6423, 0.6316, 0.6206, 0.6093, 0.5977, 0.5858, 0.5735, 0.561, 0.5481, 0.535, 0.5215, 0.5077, 0.4939, 0.481, 0.4689, 0.4575, 0.4468, 0.4575, 0.4689, 0.481, 0.4939, 0.5077, 0.5216, 0.5351, 0.5483, 0.5612, 0.5738, 0.586, 0.5979, 0.6096, 0.6209, 0.6319, 0.6426, 0.653, 0.6631, 0.6729, 0.6824, 0.6916, 0.7005, 0.7092, 0.7176, 0.7257, 0.7335, 0.7411, 0.7484, 0.7554, 0.7622, 0.7687, 0.7749, 0.7809, 0.7865, 0.7919, 0.797, 0.8018, 0.8063, 0.8105, 0.8144, 0.818, 0.8214, 0.8244, 0.8272, 0.8297, 0.8319, 0.8338, 0.8354, 0.8368, 0.8378, 0.8386, 0.8391, 0.8393, 0.8393, 0.8389, 0.8383, 0.8373, 0.8361, 0.8346, 0.8328, 0.8307, 0.8283, 0.8256, 0.8226, 0.8193, 0.8158, 0.8119, 0.8078, 0.8034, 0.7987, 0.7937, 0.7885, 0.7831, 0.7776, 0.7719, 0.766, 0.76, 0.7539, 0.7477, 0.7415, 0.7351, 0.7288, 0.7224, 0.7159, 0.7095, 0.7031, 0.6968, 0.6905, 0.6842, 0.678, 0.6719, 0.6659, 0.6599, 0.6541, 0.6484, 0.6428, 0.6373, 0.6319, 0.6267, 0.6216, 0.6166, 0.6118, 0.6071, 0.6025, 0.5981, 0.5938, 0.5896, 0.5856, 0.5818, 0.578, 0.5745, 0.571, 0.5677, 0.5645, 0.5615, 0.5586, 0.5558, 0.5532, 0.5507, 0.5483, 0.5461, 0.544, 0.542, 0.5402, 0.5385, 0.5369, 0.5354, 0.5341, 0.5328, 0.5318, 0.5308, 0.5299, 0.5292, 0.5286, 0.5281, 0.5278, 0.5276, 0.5275, 0.5275, 0.5277, 0.5279, 0.5283, 0.5289, 0.5295, 0.5303, 0.5312, 0.5323, 0.5335, 0.5348, 0.5363, 0.5379, 0.5396, 0.5415, 0.5435, 0.5457, 0.548, 0.5505, 0.5531, 0.556, 0.5589, 0.5621, 0.5654, 0.5688, 0.5725, 0.5764, 0.5804, 0.5846, 0.5891, 0.5937, 0.5986, 0.6037, 0.609, 0.6146, 0.6204, 0.6264, 0.6327, 0.6393, 0.6462, 0.6534, 0.6608, 0.6534, 0.6462, 0.6394, 0.6328, 0.6265, 0.6205, 0.6147, 0.6091, 0.6038, 0.5987, 0.5939, 0.5892, 0.5848, 0.5805, 0.5765, 0.5726, 0.569, 0.5655, 0.5622, 0.559, 0.5561, 0.5533, 0.5506, 0.5481, 0.5458, 0.5436, 0.5416, 0.5397, 0.5379, 0.5363, 0.5349, 0.5336, 0.5324, 0.5313, 0.5304, 0.5296, 0.5289, 0.5284, 0.528, 0.5277, 0.5275, 0.5275, 0.5276, 0.5278, 0.5282, 0.5286, 0.5292, 0.53, 0.5308, 0.5318, 0.5329, 0.5341, 0.5354, 0.5369, 0.5385, 0.5402, 0.542, 0.544, 0.5461, 0.5483, 0.5507, 0.5532, 0.5558, 0.5586, 0.5615, 0.5645, 0.5677, 0.571, 0.5745, 0.578, 0.5818, 0.5856, 0.5896, 0.5938, 0.5981, 0.6025, 0.6071, 0.6118, 0.6166, 0.6216, 0.6267, 0.6319, 0.6373, 0.6428, 0.6484, 0.6541, 0.6599, 0.6659, 0.6719],
        uniformSlides,
        steps: [
            {
                fragShaderName: 'mask-of-polar-sampling'
            }
        ],
    },
    'star': {
        polarSamplingData: [0.6907, 0.6971, 0.7029, 0.7082, 0.7128, 0.7169, 0.7205, 0.7235, 0.726, 0.728, 0.7295, 0.7306, 0.7311, 0.7312, 0.7308, 0.7299, 0.7286, 0.7268, 0.7245, 0.7217, 0.7183, 0.7145, 0.7102, 0.7052, 0.6998, 0.6937, 0.6869, 0.6796, 0.6715, 0.6627, 0.6531, 0.6427, 0.6313, 0.6191, 0.6071, 0.5958, 0.585, 0.5748, 0.5651, 0.5559, 0.5471, 0.5395, 0.5329, 0.5273, 0.5226, 0.5185, 0.5151, 0.5124, 0.5102, 0.5085, 0.5074, 0.5068, 0.5066, 0.507, 0.5079, 0.5092, 0.5111, 0.5136, 0.5167, 0.5203, 0.5247, 0.5299, 0.5359, 0.5427, 0.5499, 0.5575, 0.5654, 0.5738, 0.5826, 0.5918, 0.6016, 0.6115, 0.6207, 0.6293, 0.6373, 0.6447, 0.6515, 0.6578, 0.6635, 0.6687, 0.6734, 0.6775, 0.6812, 0.6845, 0.6873, 0.6896, 0.6915, 0.693, 0.6941, 0.6947, 0.6949, 0.6947, 0.6941, 0.6931, 0.6916, 0.6897, 0.6874, 0.6847, 0.6814, 0.6778, 0.6736, 0.6689, 0.6638, 0.6581, 0.6518, 0.645, 0.6376, 0.6296, 0.6209, 0.6117, 0.6017, 0.592, 0.5827, 0.5739, 0.5656, 0.5576, 0.5501, 0.5428, 0.536, 0.5299, 0.5247, 0.5203, 0.5165, 0.5135, 0.511, 0.5091, 0.5077, 0.5068, 0.5065, 0.5066, 0.5072, 0.5084, 0.51, 0.5123, 0.515, 0.5184, 0.5225, 0.5273, 0.5329, 0.5395, 0.5472, 0.5559, 0.5651, 0.5748, 0.585, 0.5958, 0.6072, 0.6192, 0.6313, 0.6426, 0.6529, 0.6625, 0.6713, 0.6793, 0.6867, 0.6934, 0.6994, 0.7049, 0.7098, 0.7142, 0.718, 0.7213, 0.7242, 0.7265, 0.7283, 0.7297, 0.7306, 0.731, 0.731, 0.7305, 0.7295, 0.728, 0.726, 0.7235, 0.7205, 0.717, 0.713, 0.7083, 0.7031, 0.6973, 0.6909, 0.6838, 0.6761, 0.6677, 0.6586, 0.6489, 0.6394, 0.6304, 0.6218, 0.6137, 0.6059, 0.5985, 0.5915, 0.585, 0.5794, 0.5748, 0.571, 0.5679, 0.5655, 0.5637, 0.5626, 0.562, 0.5621, 0.5627, 0.564, 0.5658, 0.5684, 0.5716, 0.5755, 0.5803, 0.586, 0.5928, 0.6008, 0.6102, 0.6203, 0.631, 0.6422, 0.654, 0.6665, 0.6796, 0.6925, 0.7043, 0.715, 0.7247, 0.7336, 0.7415, 0.7487, 0.7552, 0.7609, 0.7659, 0.7703, 0.7741, 0.7772, 0.7798, 0.7818, 0.7832, 0.784, 0.7843, 0.784, 0.7832, 0.7817, 0.7798, 0.7772, 0.774, 0.7702, 0.7657, 0.7606, 0.7548, 0.7482, 0.7409, 0.7328, 0.7239, 0.7141, 0.7034, 0.6918, 0.6805, 0.6698, 0.6596, 0.6499, 0.6407, 0.6319, 0.6239, 0.617, 0.6113, 0.6065, 0.6026, 0.5995, 0.5972, 0.5955, 0.5945, 0.5942, 0.5945, 0.5955, 0.5972, 0.5995, 0.6026, 0.6066, 0.6113, 0.6171, 0.6239, 0.632, 0.6408, 0.65, 0.6597, 0.6699, 0.6806, 0.6919, 0.7035, 0.7142, 0.724, 0.7329, 0.741, 0.7482, 0.7548, 0.7606, 0.7657, 0.7701, 0.7739, 0.7771, 0.7797, 0.7817, 0.7831, 0.7839, 0.7842, 0.7839, 0.7831, 0.7817, 0.7797, 0.7771, 0.774, 0.7702, 0.7658, 0.7608, 0.755, 0.7486, 0.7414, 0.7334, 0.7246, 0.7148, 0.7041, 0.6923, 0.6795, 0.6663, 0.6538, 0.642, 0.6308, 0.6202, 0.6101, 0.6007, 0.5928, 0.5861, 0.5804, 0.5756, 0.5717, 0.5685, 0.5659, 0.564, 0.5628, 0.5621, 0.5621, 0.5626, 0.5637, 0.5655, 0.5678, 0.5709, 0.5747, 0.5793, 0.5849, 0.5913, 0.5984, 0.6058, 0.6136, 0.6217, 0.6303, 0.6393, 0.6488, 0.6585, 0.6676, 0.6759, 0.6836],
        uniformSlides,
        steps: [
            {
                fragShaderName: 'mask-of-polar-sampling'
            }
        ],
    }
});


/***/ }),

/***/ "./src/transition-samples/mask-of-shape.ts":
/*!*************************************************!*\
  !*** ./src/transition-samples/mask-of-shape.ts ***!
  \*************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
const transition_processor_1 = __webpack_require__(/*! ../transitions/transition-processor */ "./src/transitions/transition-processor.ts");
(0, transition_processor_1.extendTransitions)({
    'spade': {
        uniformValues: {
            maxMaskExtandRate: 3.1,
        },
        mask: 'spade',
        steps: [
            {
                fragShaderName: 'mask-of-shape'
            }
        ],
    },
    'club': {
        uniformValues: {
            maxMaskExtandRate: 4.1,
        },
        mask: 'club',
        steps: [
            {
                fragShaderName: 'mask-of-shape'
            }
        ],
    }
});


/***/ }),

/***/ "./src/transition-samples/mask.ts":
/*!****************************************!*\
  !*** ./src/transition-samples/mask.ts ***!
  \****************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
const transition_processor_1 = __webpack_require__(/*! ../transitions/transition-processor */ "./src/transitions/transition-processor.ts");
const uniformSlides = [
    {
        name: 'smoothRange',
        desc: 'Smooth Range',
        min: 0,
        max: 1,
        step: 0.01,
        value: 0.1,
    },
];
(0, transition_processor_1.extendTransitions)({
    'mask-black-first': {
        uniformSlides,
        steps: [
            {
                fragShaderName: 'mask-black-first'
            }
        ]
    },
    'mask-white-first': {
        uniformSlides,
        steps: [
            {
                fragShaderName: 'mask-white-first'
            }
        ]
    },
    'mask-perlin': {
        uniformSlides: [...uniformSlides,
            {
                name: 'noiseRadius',
                desc: 'Noise Radius',
                min: 0,
                max: 1,
                step: 0.01,
                value: 0.1,
            },
            {
                name: 'noiseOffset',
                desc: 'Noise Offset',
                min: 0,
                max: 100,
                step: 1,
                value: 0,
            },
        ],
        steps: [
            {
                fragShaderName: 'mask-perlin'
            }
        ]
    },
});


/***/ }),

/***/ "./src/transition-samples/others.ts":
/*!******************************************!*\
  !*** ./src/transition-samples/others.ts ***!
  \******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
const transition_processor_1 = __webpack_require__(/*! ../transitions/transition-processor */ "./src/transitions/transition-processor.ts");
(0, transition_processor_1.extendTransitions)({});


/***/ }),

/***/ "./src/transition-samples/page-curl.ts":
/*!*********************************************!*\
  !*** ./src/transition-samples/page-curl.ts ***!
  \*********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
const transition_processor_1 = __webpack_require__(/*! ../transitions/transition-processor */ "./src/transitions/transition-processor.ts");
const uniformSlides = [
    {
        name: 'curlRadius',
        desc: 'Curl Radius',
        min: 0.01,
        max: 0.5,
        step: 0.01,
        value: 0.05,
    },
    {
        name: 'shadowBlurRadius',
        desc: 'Shadow Blur Radius',
        min: 0,
        max: 0.1,
        step: 0.01,
        value: 0.02,
    },
    {
        name: 'shadowAlphaRate',
        desc: 'Shadow Alpha Rate',
        min: 0,
        max: 1,
        step: 0.1,
        value: 0.2,
    },
    {
        name: 'backfaceOpacity',
        desc: 'Backface Opacity ',
        min: 0,
        max: 1,
        step: 0.1,
        value: 0.2,
    },
];
(0, transition_processor_1.extendTransitions)({
    'page-curl-to-right': {
        uniformSlides,
        uniformValues: {
            directionAngle: 0
        },
        steps: [
            {
                fragShaderName: 'page-curl'
            }
        ]
    },
    'page-curl-to-left': {
        uniformSlides,
        uniformValues: {
            directionAngle: -180
        },
        steps: [
            {
                fragShaderName: 'page-curl'
            }
        ]
    },
    'page-curl-to-top': {
        uniformSlides,
        uniformValues: {
            directionAngle: 180 / 2
        },
        steps: [
            {
                fragShaderName: 'page-curl'
            }
        ]
    },
    'page-curl-to-bottom': {
        uniformSlides,
        uniformValues: {
            directionAngle: -90
        },
        steps: [
            {
                fragShaderName: 'page-curl'
            }
        ]
    },
    'page-curl-to-top-right': {
        uniformSlides,
        uniformValues: {
            directionAngle: 45
        },
        steps: [
            {
                fragShaderName: 'page-curl'
            }
        ]
    },
    'page-curl-to-top-left': {
        uniformSlides,
        uniformValues: {
            directionAngle: 135
        },
        steps: [
            {
                fragShaderName: 'page-curl'
            }
        ]
    },
    'page-curl-to-bottom-right': {
        uniformSlides,
        uniformValues: {
            directionAngle: -45
        },
        steps: [
            {
                fragShaderName: 'page-curl'
            }
        ]
    },
    'page-curl-to-bottom-left': {
        uniformSlides,
        uniformValues: {
            directionAngle: -135
        },
        steps: [
            {
                fragShaderName: 'page-curl'
            }
        ]
    },
});


/***/ }),

/***/ "./src/transition-samples/pixelate.ts":
/*!********************************************!*\
  !*** ./src/transition-samples/pixelate.ts ***!
  \********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
const transition_processor_1 = __webpack_require__(/*! ../transitions/transition-processor */ "./src/transitions/transition-processor.ts");
const sampler_1 = __webpack_require__(/*! ../libs/webgl/sampler */ "./src/libs/webgl/sampler.ts");
const uniformSlides = [
    {
        name: 'maxPixelSizeRate',
        desc: 'Max Pixel Size Rate',
        min: 0.01,
        max: 1,
        step: 0.01,
        value: 0.1,
    },
];
(0, transition_processor_1.extendTransitions)({
    'cube-pixelate': {
        uniformSlides,
        uniformValues: {
            rotatedAngle: 0,
            glassMode: false,
        },
        sourceParams: { filter: sampler_1.SamplerFilter.MipmapLinear },
        targetParams: { filter: sampler_1.SamplerFilter.MipmapLinear },
        steps: [
            {
                fragShaderName: 'cube-pixelate',
            }
        ]
    },
    'slant-cube-pixelate': {
        uniformSlides,
        uniformValues: {
            rotatedAngle: 45,
            glassMode: false,
        },
        sourceParams: { filter: sampler_1.SamplerFilter.MipmapLinear },
        targetParams: { filter: sampler_1.SamplerFilter.MipmapLinear },
        steps: [
            {
                fragShaderName: 'cube-pixelate',
            }
        ]
    },
    'glass-pixelate': {
        uniformSlides,
        uniformValues: {
            rotatedAngle: 45,
            glassMode: true,
        },
        sourceParams: { filter: sampler_1.SamplerFilter.MipmapLinear },
        targetParams: { filter: sampler_1.SamplerFilter.MipmapLinear },
        steps: [
            {
                fragShaderName: 'cube-pixelate',
            }
        ]
    },
    'cube-pixelate-noise': {
        uniformSlides,
        uniformValues: {
            rotatedAngle: 0,
        },
        steps: [
            {
                fragShaderName: 'cube-pixelate-noise',
            }
        ]
    },
    'slant-cube-pixelate-noise': {
        uniformSlides,
        uniformValues: {
            rotatedAngle: 45,
        },
        steps: [
            {
                fragShaderName: 'cube-pixelate-noise',
            }
        ]
    },
    'hexagon-pixelate-herizontal': {
        uniformSlides,
        uniformValues: {
            rotatedAngle: 0,
        },
        sourceParams: { filter: sampler_1.SamplerFilter.MipmapLinear },
        targetParams: { filter: sampler_1.SamplerFilter.MipmapLinear },
        steps: [
            {
                fragShaderName: 'hexagon-pixelate',
            }
        ]
    },
    'hexagon-pixelate-vertical': {
        uniformSlides,
        uniformValues: {
            rotatedAngle: 30,
        },
        sourceParams: { filter: sampler_1.SamplerFilter.MipmapLinear },
        targetParams: { filter: sampler_1.SamplerFilter.MipmapLinear },
        steps: [
            {
                fragShaderName: 'hexagon-pixelate',
            }
        ]
    },
    'hexagon-pixelate-noise-herizontal': {
        uniformSlides,
        uniformValues: {
            rotatedAngle: 0,
        },
        steps: [
            {
                fragShaderName: 'hexagon-pixelate-noise',
            }
        ]
    },
    'hexagon-pixelate-noise-vertical': {
        uniformSlides,
        uniformValues: {
            rotatedAngle: 30,
        },
        steps: [
            {
                fragShaderName: 'hexagon-pixelate-noise',
            }
        ]
    },
});


/***/ }),

/***/ "./src/transition-samples/push.ts":
/*!****************************************!*\
  !*** ./src/transition-samples/push.ts ***!
  \****************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
const transition_processor_1 = __webpack_require__(/*! ../transitions/transition-processor */ "./src/transitions/transition-processor.ts");
const sampler_1 = __webpack_require__(/*! ../libs/webgl/sampler */ "./src/libs/webgl/sampler.ts");
const matrix4_1 = __webpack_require__(/*! ../libs/math/matrix4 */ "./src/libs/math/matrix4.ts");
(0, transition_processor_1.extendTransitions)({
    'push-left': {
        sourceParams: { filter: sampler_1.SamplerFilter.Linear },
        targetParams: { filter: sampler_1.SamplerFilter.Linear },
        steps: [
            {
                useTexture: transition_processor_1.TextureReference.Source,
                transform: (x) => {
                    return new matrix4_1.Matrix4().translateSelf(-2 * x);
                },
            },
            {
                useTexture: transition_processor_1.TextureReference.Target,
                transform: (x) => {
                    return new matrix4_1.Matrix4().translateSelf(2 * (1 - x));
                },
            }
        ]
    },
    'push-right': {
        sourceParams: { filter: sampler_1.SamplerFilter.Linear },
        targetParams: { filter: sampler_1.SamplerFilter.Linear },
        steps: [
            {
                useTexture: transition_processor_1.TextureReference.Source,
                transform: (x) => {
                    return new matrix4_1.Matrix4().translateSelf(2 * x);
                },
            },
            {
                useTexture: transition_processor_1.TextureReference.Target,
                transform: (x) => {
                    return new matrix4_1.Matrix4().translateSelf(2 * (x - 1));
                },
            }
        ]
    },
    'push-top': {
        sourceParams: { filter: sampler_1.SamplerFilter.Linear },
        targetParams: { filter: sampler_1.SamplerFilter.Linear },
        steps: [
            {
                useTexture: transition_processor_1.TextureReference.Source,
                transform: (x) => {
                    return new matrix4_1.Matrix4().translateSelf(0, 2 * x);
                },
            },
            {
                useTexture: transition_processor_1.TextureReference.Target,
                transform: (x) => {
                    return new matrix4_1.Matrix4().translateSelf(0, 2 * (x - 1));
                },
            }
        ]
    },
    'push-bottom': {
        sourceParams: { filter: sampler_1.SamplerFilter.Linear },
        targetParams: { filter: sampler_1.SamplerFilter.Linear },
        steps: [
            {
                useTexture: transition_processor_1.TextureReference.Source,
                transform: (x) => {
                    return new matrix4_1.Matrix4().translateSelf(0, 2 * -x);
                },
            },
            {
                useTexture: transition_processor_1.TextureReference.Target,
                transform: (x) => {
                    return new matrix4_1.Matrix4().translateSelf(0, 2 * (1 - x));
                },
            }
        ]
    },
});


/***/ }),

/***/ "./src/transition-samples/radar.ts":
/*!*****************************************!*\
  !*** ./src/transition-samples/radar.ts ***!
  \*****************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
const transition_processor_1 = __webpack_require__(/*! ../transitions/transition-processor */ "./src/transitions/transition-processor.ts");
const uniformSlides = [
    {
        name: 'blurAngle',
        desc: 'Blur Angle',
        min: 0,
        max: 90,
        step: 1,
        value: 10,
    },
];
(0, transition_processor_1.extendTransitions)({
    'radar-clockwise': {
        uniformSlides,
        uniformValues: {
            startDirectionAngle: 90,
            moveDirection: 1,
        },
        steps: [
            {
                fragShaderName: 'radar'
            }
        ]
    },
    'radar-anticlockwise': {
        uniformSlides,
        uniformValues: {
            startDirectionAngle: 90,
            moveDirection: 0,
        },
        steps: [
            {
                fragShaderName: 'radar'
            }
        ]
    },
});


/***/ }),

/***/ "./src/transition-samples/rays.ts":
/*!****************************************!*\
  !*** ./src/transition-samples/rays.ts ***!
  \****************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
const transition_processor_1 = __webpack_require__(/*! ../transitions/transition-processor */ "./src/transitions/transition-processor.ts");
const uniformSlides = [
    {
        name: 'raysCount',
        desc: 'Rays Count',
        min: 1,
        max: 50,
        step: 1,
        value: 10,
    },
    {
        name: 'blurRate',
        desc: 'Blur Rate',
        min: 0,
        max: 0.5,
        step: 0.01,
        value: 0,
    },
];
(0, transition_processor_1.extendTransitions)({
    'rays-clockwise': {
        uniformSlides,
        uniformValues: {
            startDirectionAngle: 90,
            moveDirection: 1,
        },
        steps: [
            {
                fragShaderName: 'rays'
            }
        ]
    },
    'rays-anticlockwise': {
        uniformSlides,
        uniformValues: {
            startDirectionAngle: 90,
            moveDirection: 0,
        },
        steps: [
            {
                fragShaderName: 'rays'
            }
        ]
    },
});


/***/ }),

/***/ "./src/transition-samples/shuffle.ts":
/*!*******************************************!*\
  !*** ./src/transition-samples/shuffle.ts ***!
  \*******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
const transition_processor_1 = __webpack_require__(/*! ../transitions/transition-processor */ "./src/transitions/transition-processor.ts");
const sampler_1 = __webpack_require__(/*! ../libs/webgl/sampler */ "./src/libs/webgl/sampler.ts");
const matrix4_1 = __webpack_require__(/*! ../libs/math/matrix4 */ "./src/libs/math/matrix4.ts");
(0, transition_processor_1.extendTransitions)({
    'shuffle-left': {
        threeD: true,
        sourceParams: { filter: sampler_1.SamplerFilter.Linear },
        targetParams: { filter: sampler_1.SamplerFilter.Linear },
        steps: [
            {
                useTexture: transition_processor_1.TextureReference.Source,
                transform: (x) => {
                    let left = Math.abs(x - 0.5) - 0.5;
                    let z = x < 0.5 ? -0.1 : 0.1;
                    return new matrix4_1.Matrix4().translateSelf(2 * left, 0, 2 * z);
                },
            },
            {
                useTexture: transition_processor_1.TextureReference.Target,
                transform: (x) => {
                    let left = 0.5 - Math.abs(x - 0.5);
                    return new matrix4_1.Matrix4().translateSelf(2 * left);
                },
            },
        ]
    },
    'shuffle-right': {
        threeD: true,
        sourceParams: { filter: sampler_1.SamplerFilter.Linear },
        targetParams: { filter: sampler_1.SamplerFilter.Linear },
        steps: [
            {
                useTexture: transition_processor_1.TextureReference.Source,
                transform: (x) => {
                    let left = 0.5 - Math.abs(x - 0.5);
                    let z = x < 0.5 ? -0.1 : 0.1;
                    return new matrix4_1.Matrix4().translateSelf(2 * left, 0, 2 * z);
                },
            },
            {
                useTexture: transition_processor_1.TextureReference.Target,
                transform: (x) => {
                    let left = Math.abs(x - 0.5) - 0.5;
                    return new matrix4_1.Matrix4().translateSelf(2 * left);
                },
            },
        ]
    },
    'shuffle-top': {
        threeD: true,
        sourceParams: { filter: sampler_1.SamplerFilter.Linear },
        targetParams: { filter: sampler_1.SamplerFilter.Linear },
        steps: [
            {
                useTexture: transition_processor_1.TextureReference.Source,
                transform: (x) => {
                    let top = 0.5 - Math.abs(x - 0.5);
                    let z = x < 0.5 ? -0.1 : 0.1;
                    return new matrix4_1.Matrix4().translateSelf(0, 2 * top, 2 * z);
                },
            },
            {
                useTexture: transition_processor_1.TextureReference.Target,
                transform: (x) => {
                    let top = Math.abs(x - 0.5) - 0.5;
                    return new matrix4_1.Matrix4().translateSelf(0, 2 * top);
                },
            },
        ]
    },
    'shuffle-bottom': {
        threeD: true,
        sourceParams: { filter: sampler_1.SamplerFilter.Linear },
        targetParams: { filter: sampler_1.SamplerFilter.Linear },
        steps: [
            {
                useTexture: transition_processor_1.TextureReference.Source,
                transform: (x) => {
                    let top = Math.abs(x - 0.5) - 0.5;
                    let z = x < 0.5 ? -0.1 : 0.1;
                    return new matrix4_1.Matrix4().translateSelf(0, 2 * top, 2 * z);
                },
            },
            {
                useTexture: transition_processor_1.TextureReference.Target,
                transform: (x) => {
                    let top = 0.5 - Math.abs(x - 0.5);
                    return new matrix4_1.Matrix4().translateSelf(0, 2 * top);
                },
            },
        ]
    },
});


/***/ }),

/***/ "./src/transition-samples/shutter.ts":
/*!*******************************************!*\
  !*** ./src/transition-samples/shutter.ts ***!
  \*******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
const transition_processor_1 = __webpack_require__(/*! ../transitions/transition-processor */ "./src/transitions/transition-processor.ts");
const uniformSlides = [
    {
        name: 'shutterSizeRate',
        desc: 'Shutter Size Rate',
        min: 0.01,
        max: 1,
        step: 0.01,
        value: 0.1,
    },
];
(0, transition_processor_1.extendTransitions)({
    'shutter-herizontal': {
        uniformSlides,
        uniformValues: {
            shutterSlideOrigin: 0.5,
            beVertical: false,
        },
        steps: [
            {
                fragShaderName: 'shutter'
            }
        ]
    },
    'shutter-herizontal-to-top': {
        uniformSlides,
        uniformValues: {
            shutterSlideOrigin: 0,
            beVertical: false,
        },
        steps: [
            {
                fragShaderName: 'shutter'
            }
        ]
    },
    'shutter-herizontal-to-bottom': {
        uniformSlides,
        uniformValues: {
            shutterSlideOrigin: 1,
            beVertical: false,
        },
        steps: [
            {
                fragShaderName: 'shutter'
            }
        ]
    },
    'shutter-vertical': {
        uniformSlides,
        uniformValues: {
            shutterSlideOrigin: 0.5,
            beVertical: true,
        },
        steps: [
            {
                fragShaderName: 'shutter'
            }
        ]
    },
    'shutter-vertical-to-right': {
        uniformSlides,
        uniformValues: {
            shutterSlideOrigin: 0,
            beVertical: true,
        },
        steps: [
            {
                fragShaderName: 'shutter'
            }
        ]
    },
    'shutter-vertical-to-left': {
        uniformSlides,
        uniformValues: {
            shutterSlideOrigin: 1,
            beVertical: true,
        },
        steps: [
            {
                fragShaderName: 'shutter'
            }
        ]
    },
});


/***/ }),

/***/ "./src/transition-samples/slant-wipe.ts":
/*!**********************************************!*\
  !*** ./src/transition-samples/slant-wipe.ts ***!
  \**********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
const transition_processor_1 = __webpack_require__(/*! ../transitions/transition-processor */ "./src/transitions/transition-processor.ts");
const uniformSlides = [
    {
        name: 'wipeBlurRate',
        desc: 'Wipe Blur Rate',
        min: 0,
        max: 1,
        step: 0.01,
        value: 0,
    },
];
(0, transition_processor_1.extendTransitions)({
    'slant-wipe-to-top-right': {
        uniformSlides,
        uniformValues: {
            directionAngle: 45,
        },
        steps: [
            {
                fragShaderName: 'wipe'
            }
        ]
    },
    'slant-wipe-to-top-left': {
        uniformSlides,
        uniformValues: {
            directionAngle: 135
        },
        steps: [
            {
                fragShaderName: 'wipe'
            }
        ]
    },
    'slant-wipe-to-bottom-left': {
        uniformSlides,
        uniformValues: {
            directionAngle: -135
        },
        steps: [
            {
                fragShaderName: 'wipe'
            }
        ]
    },
    'slant-wipe-to-bottom-right': {
        uniformSlides,
        uniformValues: {
            directionAngle: -45
        },
        steps: [
            {
                fragShaderName: 'wipe'
            }
        ]
    },
});


/***/ }),

/***/ "./src/transition-samples/split.ts":
/*!*****************************************!*\
  !*** ./src/transition-samples/split.ts ***!
  \*****************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
const transition_processor_1 = __webpack_require__(/*! ../transitions/transition-processor */ "./src/transitions/transition-processor.ts");
const sampler_1 = __webpack_require__(/*! ../libs/webgl/sampler */ "./src/libs/webgl/sampler.ts");
const matrix4_1 = __webpack_require__(/*! ../libs/math/matrix4 */ "./src/libs/math/matrix4.ts");
const leftVertices = [
    -1, 1, 0,
    -1, -1, 0,
    0, 1, 0,
    0, -1, 0,
];
const rightVertices = [
    0, 1, 0,
    0, -1, 0,
    1, 1, 0,
    1, -1, 0,
];
const topVertices = [
    -1, 1, 0,
    -1, 0, 0,
    1, 1, 0,
    1, 0, 0,
];
const bottomVertices = [
    -1, 0, 0,
    -1, -1, 0,
    1, 0, 0,
    1, -1, 0,
];
(0, transition_processor_1.extendTransitions)({
    'split-herizontal': {
        sourceParams: { filter: sampler_1.SamplerFilter.Linear },
        steps: [
            {
                useTexture: transition_processor_1.TextureReference.Target,
            },
            {
                useTexture: transition_processor_1.TextureReference.Source,
                vertices: leftVertices,
                transform: (x) => {
                    return new matrix4_1.Matrix4().translateSelf(-x);
                },
            },
            {
                useTexture: transition_processor_1.TextureReference.Source,
                vertices: rightVertices,
                transform: (x) => {
                    return new matrix4_1.Matrix4().translateSelf(x);
                },
            }
        ],
    },
    'split-vertical': {
        sourceParams: { filter: sampler_1.SamplerFilter.Linear },
        steps: [
            {
                useTexture: transition_processor_1.TextureReference.Target,
            },
            {
                useTexture: transition_processor_1.TextureReference.Source,
                vertices: topVertices,
                transform: (x) => {
                    return new matrix4_1.Matrix4().translateSelf(0, x);
                },
            },
            {
                useTexture: transition_processor_1.TextureReference.Source,
                vertices: bottomVertices,
                transform: (x) => {
                    return new matrix4_1.Matrix4().translateSelf(0, -x);
                },
            }
        ],
    },
    'split-herizontal-fade': {
        sourceParams: { filter: sampler_1.SamplerFilter.Linear },
        steps: [
            {
                useTexture: transition_processor_1.TextureReference.Target,
            },
            {
                useTexture: transition_processor_1.TextureReference.Source,
                vertices: leftVertices,
                transform: (x) => {
                    return new matrix4_1.Matrix4().translateSelf(-x);
                },
                fragShaderName: 'split-fade',
            },
            {
                useTexture: transition_processor_1.TextureReference.Source,
                vertices: rightVertices,
                transform: (x) => {
                    return new matrix4_1.Matrix4().translateSelf(x);
                },
                fragShaderName: 'split-fade',
            }
        ],
    },
    'split-vertical-fade': {
        sourceParams: { filter: sampler_1.SamplerFilter.Linear },
        steps: [
            {
                useTexture: transition_processor_1.TextureReference.Target,
            },
            {
                useTexture: transition_processor_1.TextureReference.Source,
                vertices: topVertices,
                transform: (x) => {
                    return new matrix4_1.Matrix4().translateSelf(0, x);
                },
                fragShaderName: 'split-fade',
            },
            {
                useTexture: transition_processor_1.TextureReference.Source,
                vertices: bottomVertices,
                transform: (x) => {
                    return new matrix4_1.Matrix4().translateSelf(0, -x);
                },
                fragShaderName: 'split-fade',
            }
        ],
    },
    'split-herizontal-fade-black': {
        sourceParams: { filter: sampler_1.SamplerFilter.Linear },
        steps: [
            {
                useTexture: transition_processor_1.TextureReference.Target,
            },
            {
                useTexture: transition_processor_1.TextureReference.Source,
                vertices: leftVertices,
                transform: (x) => {
                    return new matrix4_1.Matrix4().translateSelf(-x);
                },
                fragShaderName: 'split-fade-black',
            },
            {
                useTexture: transition_processor_1.TextureReference.Source,
                vertices: rightVertices,
                transform: (x) => {
                    return new matrix4_1.Matrix4().translateSelf(x);
                },
                fragShaderName: 'split-fade-black',
            }
        ],
    },
    'split-vertical-fade-black': {
        sourceParams: { filter: sampler_1.SamplerFilter.Linear },
        steps: [
            {
                useTexture: transition_processor_1.TextureReference.Target,
            },
            {
                useTexture: transition_processor_1.TextureReference.Source,
                vertices: topVertices,
                transform: (x) => {
                    return new matrix4_1.Matrix4().translateSelf(0, x);
                },
                fragShaderName: 'split-fade-black',
            },
            {
                useTexture: transition_processor_1.TextureReference.Source,
                vertices: bottomVertices,
                transform: (x) => {
                    return new matrix4_1.Matrix4().translateSelf(0, -x);
                },
                fragShaderName: 'split-fade-black',
            }
        ],
    },
    'split-herizontal-cross': {
        sourceParams: { filter: sampler_1.SamplerFilter.Linear },
        steps: [
            {
                useTexture: transition_processor_1.TextureReference.Target,
            },
            {
                useTexture: transition_processor_1.TextureReference.Source,
                vertices: leftVertices,
                transform: (x) => {
                    return new matrix4_1.Matrix4().translateSelf(0, 2 * -x);
                },
                fragShaderName: 'split-fade',
            },
            {
                vertices: rightVertices,
                transform: (x) => {
                    return new matrix4_1.Matrix4().translateSelf(0, 2 * x);
                },
                fragShaderName: 'split-fade',
            }
        ],
    },
    'split-vertical-cross': {
        sourceParams: { filter: sampler_1.SamplerFilter.Linear },
        steps: [
            {
                useTexture: transition_processor_1.TextureReference.Target,
            },
            {
                useTexture: transition_processor_1.TextureReference.Source,
                vertices: topVertices,
                transform: (x) => {
                    return new matrix4_1.Matrix4().translateSelf(2 * x);
                },
                fragShaderName: 'split-fade',
            },
            {
                vertices: bottomVertices,
                transform: (x) => {
                    return new matrix4_1.Matrix4().translateSelf(2 * -x);
                },
                fragShaderName: 'split-fade',
            }
        ],
    },
});


/***/ }),

/***/ "./src/transition-samples/stripe-merge.ts":
/*!************************************************!*\
  !*** ./src/transition-samples/stripe-merge.ts ***!
  \************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
const transition_processor_1 = __webpack_require__(/*! ../transitions/transition-processor */ "./src/transitions/transition-processor.ts");
(0, transition_processor_1.extendTransitions)({
    'stripe-merge': {
        uniformSlides: [
            {
                name: 'stripeHeight',
                desc: 'Stripe Height',
                min: 1,
                max: 10,
                step: 1,
                value: 2,
            },
            {
                name: 'maxStripeLoopHeight',
                desc: 'Stripe Loop Height',
                min: 10,
                max: 200,
                step: 1,
                value: 60,
            },
            {
                name: 'fixedYPosition',
                desc: 'Fixed Y Position',
                min: 0,
                max: 1,
                step: 0.1,
                value: 0,
            }
        ],
        steps: [
            {
                fragShaderName: 'stripe-merge'
            }
        ],
    },
});


/***/ }),

/***/ "./src/transition-samples/wave.ts":
/*!****************************************!*\
  !*** ./src/transition-samples/wave.ts ***!
  \****************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
const transition_processor_1 = __webpack_require__(/*! ../transitions/transition-processor */ "./src/transitions/transition-processor.ts");
(0, transition_processor_1.extendTransitions)({
    'wave': {
        uniformSlides: [
            {
                name: 'waveRadius',
                desc: 'Wave Radius',
                min: 0.01,
                max: 1,
                step: 0.01,
                value: 0.1,
            },
            {
                name: 'waveStrength',
                desc: 'Wave Strength',
                min: 0.1,
                max: 1,
                step: 0.1,
                value: 0.5,
            },
            {
                name: 'photoDeep',
                desc: 'Photo Deep',
                min: 0.01,
                max: 1,
                step: 0.01,
                value: 0.1,
            },
            {
                name: 'blurRadius',
                desc: 'Blur Radius',
                min: 0.01,
                max: 1,
                step: 0.01,
                value: 0.1,
            },
        ],
        steps: [
            {
                fragShaderName: 'wave',
            }
        ]
    },
});


/***/ }),

/***/ "./src/transition-samples/wipe.ts":
/*!****************************************!*\
  !*** ./src/transition-samples/wipe.ts ***!
  \****************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
const transition_processor_1 = __webpack_require__(/*! ../transitions/transition-processor */ "./src/transitions/transition-processor.ts");
const uniformSlides = [
    {
        name: 'wipeBlurRate',
        desc: 'Wipe Blur Rate',
        min: 0,
        max: 1,
        step: 0.01,
        value: 0,
    },
];
(0, transition_processor_1.extendTransitions)({
    'wipe-left': {
        uniformSlides,
        uniformValues: {
            directionAngle: -180,
        },
        steps: [
            {
                fragShaderName: 'wipe'
            }
        ]
    },
    'wipe-right': {
        uniformSlides,
        uniformValues: {
            directionAngle: 180,
        },
        steps: [
            {
                fragShaderName: 'wipe'
            }
        ]
    },
    'wipe-top': {
        uniformSlides,
        uniformValues: {
            directionAngle: 90,
        },
        steps: [
            {
                fragShaderName: 'wipe'
            }
        ]
    },
    'wipe-bottom': {
        uniformSlides,
        uniformValues: {
            directionAngle: -90,
        },
        steps: [
            {
                fragShaderName: 'wipe'
            }
        ]
    },
});


/***/ }),

/***/ "./src/transitions/face-libs/face-transform.ts":
/*!*****************************************************!*\
  !*** ./src/transitions/face-libs/face-transform.ts ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.TriangleTransformProcesser = exports.FaceTransform = void 0;
const vector4_1 = __webpack_require__(/*! ../../libs/math/vector4 */ "./src/libs/math/vector4.ts");
const matrix4_1 = __webpack_require__(/*! ../../libs/math/matrix4 */ "./src/libs/math/matrix4.ts");
const triangulate_1 = __webpack_require__(/*! ./triangulate */ "./src/transitions/face-libs/triangulate.ts");
const frontal_face_points_1 = __webpack_require__(/*! ./frontal-face-points */ "./src/transitions/face-libs/frontal-face-points.ts");
// 坐标计算均基于 -1~1 范围.
class FaceTransform {
    transformProcesser;
    fromCoords;
    toCoords;
    translates;
    fromTriangleIndices;
    toTriangleIndices;
    constructor(fromCoords, toCoords) {
        this.fromCoords = fromCoords;
        this.toCoords = toCoords;
        // 计算脸部的整体变换矩阵.
        let fromTriangle = this.getEyesAndMouseTriangle(fromCoords);
        let toTriangle = this.getEyesAndMouseTriangle(toCoords);
        this.transformProcesser = new TriangleTransformProcesser(fromTriangle, toTriangle);
        // 计算脸部坐标在整体变换矩阵基础上需要附加的仿射变换偏移.
        this.translates = this.generateLandmarkCoordTranslates();
        let environmentCoords = this.getEnvironmentCoords();
        fromCoords.push(...environmentCoords);
        toCoords.push(...environmentCoords);
        // 计算环境三角形网格索引, 然后和预设的脸部网格索引组合成最终索引.
        this.fromTriangleIndices = this.generateTriangleIndices(fromCoords);
        this.toTriangleIndices = this.generateTriangleIndices(toCoords);
    }
    // 用于决定脸部的大小, 旋转位置的三个点, 分别为眼睛和嘴巴位置.
    // 这三个点会让前后两张照片进行对照, 然后决定整个照片变换时的旋转和缩放, 位移.
    getEyesAndMouseTriangle(coords) {
        let eyes1 = [coords[38], coords[39], coords[41], coords[42]];
        let eyes2 = [coords[44], coords[45], coords[47], coords[42]];
        let eye1Coord = new vector4_1.Vector2(0, 0);
        let eye2Coord = new vector4_1.Vector2(0, 0);
        for (let i = 0; i < 4; i++) {
            eye1Coord.x += eyes1[i].x / 4;
            eye1Coord.y += eyes1[i].y / 4;
            eye2Coord.x += eyes2[i].x / 4;
            eye2Coord.y += eyes2[i].y / 4;
        }
        let mouseCoord = new vector4_1.Vector2((coords[63].x + coords[67].x) / 2, (coords[63].y + coords[67].y) / 2);
        return [eye1Coord, eye2Coord, mouseCoord];
    }
    // 为了使得脸部的每个坐标点在整个变换过程中重叠,
    // 我们首先计算出一个原图坐标经过变换之后, 和目标坐标的距离构成的向量, 设置为 T.
    // 然后目标坐标减去 T, 以达到和原图的最终坐标对齐, 然后再应用变换矩阵的逆矩阵以和原图坐标对齐.
    // 然后在变换过程中, 原图和经过逆变换的目标坐标经过变换后, 都再继续移动 T * progress.
    // 另一种方式:
    // 计算出一个原图坐标和目标坐标经过逆变换坐标的距离构成的向量, 设置为 T'.
    // 然后目标应用变换矩阵的逆矩阵, 再减去 T' 以和原图坐标对齐.
    // 然后在变换过程中, 原图和经过逆变换的目标坐标都先移动 T' * progress, 再应用变换矩阵.
    // 两种方式其实完全相同, 关联是 T = TransformMatrix * T'.
    // 在此我们选择第一种.
    generateLandmarkCoordTranslates() {
        let translates = [];
        for (let i = 0; i < this.fromCoords.length; i++) {
            let fromCoord = this.fromCoords[i];
            let toCoord = this.toCoords[i];
            let fromCoordTransformed = this.transformProcesser.transform.transfer2(fromCoord);
            let x = toCoord.x - fromCoordTransformed.x;
            let y = toCoord.y - fromCoordTransformed.y;
            translates.push(new vector4_1.Vector2(x, y));
        }
        // 为环境顶点添加 0 偏移向量, 以进行一致的计算.
        for (let i = 0; i < 8; i++) {
            translates.push(new vector4_1.Vector2(0, 0));
        }
        return translates;
    }
    // 返回四角加四边的中点的 8 个环境顶点.
    getEnvironmentCoords() {
        return [
            [-1, -1],
            [-1, 0],
            [-1, 1],
            [0, -1],
            [0, 1],
            [1, -1],
            [1, 0],
            [1, 1],
        ].map(([x, y]) => new vector4_1.Vector2(x, y));
    }
    // 三角形网络会受到不同的照片脸部的旋转的影响, 即不同的照片, 某个脸部的顶点连接的 8 个照片顶点之一的顶点是不同的,
    // 所以需要根据照片进行计算, 不能提前预设.
    // 但是侧脸如果不做预设的话, 转为正脸时由于三角形网格截然不同, 会产生很大的扭曲.
    // 所以在此我们先生成一个脸部预设网格, 然后在其基础上二次添加环境顶点.
    generateTriangleIndices(coords) {
        // 生成正脸修复的顶点坐标.
        let fixedCoords = this.getFrontalFixedCoords(coords);
        // 生成三角形网格.
        let points = fixedCoords.map(({ x, y }, index) => new triangulate_1.Point(x, y, index));
        let triangulate = new triangulate_1.Triangulate(points);
        let indices = triangulate.outputIndices();
        return indices;
    }
    // 由于正脸转场侧脸或者侧脸转向正脸时, 网格的变化比较大而产生扭曲.
    // 所以我们将侧脸的坐标大致做一个变换处理来变换为类似正脸的结构.
    // 其具体方法时通过脸部轮廓的三个点确定一个变换矩阵, 然后用一张预设的正脸来替换脸内部的点.
    getFrontalFixedCoords(coords) {
        let faceOutlineIndices = [0, 8, 16];
        // z 分量作为位移分量, 固定为 1.
        let fromCoords = faceOutlineIndices.map(index => {
            return new vector4_1.Vector3(...frontal_face_points_1.FrontalFacePoints[index], 1);
        });
        let toNumCoords = faceOutlineIndices.map(index => {
            return new vector4_1.Vector3(...coords[index].xy, 1);
        });
        // 3x3 坐标矩阵, 每一列是一个坐标.
        let fromCoordsMatrix = matrix4_1.Matrix3.fromVectors(...fromCoords);
        let toCoordsMatrix = matrix4_1.Matrix3.fromVectors(...toNumCoords);
        // 计算 from 到 to 的变换矩阵.
        let transform = toCoordsMatrix.multiply(fromCoordsMatrix.inverse());
        // 拷贝脸部轮廓顶点.
        let fixedCoords = coords.slice(0, 17);
        // 将脸部内侧的点通过预设的正脸顶点替换.
        for (let i = 17; i < frontal_face_points_1.FrontalFacePoints.length; i++) {
            fixedCoords.push(transform.transfer2(new vector4_1.Vector2(...frontal_face_points_1.FrontalFacePoints[i])));
        }
        // 拷贝环境顶点.
        fixedCoords.push(...coords.slice(frontal_face_points_1.FrontalFacePoints.length));
        return fixedCoords;
    }
    getTransformMatrixesByProgress(progress) {
        return this.transformProcesser.getTransformsByProgress(progress);
    }
}
exports.FaceTransform = FaceTransform;
// 用于计算从一个三角形到另一个三角形的变换矩阵,
// 然后将矩阵分离为平移, 缩放, 旋转, 斜切, 再对每个矩阵的参数做动画.
// 越靠近前面的, 动画越容易被观察到. 所以斜切一定放在最后. 平移一定放在最前因为这样方便分解.
class TriangleTransformProcesser {
    // 存储变换矩阵, 用于将 from 变换到 to.
    transform;
    // 变换矩阵的逆矩阵, 用于将 to 变换到 from.
    transformInverse;
    rotationRadians = 0;
    scaleX = 0;
    scaleY = 0;
    skewX = 0;
    translateX = 0;
    translateY = 0;
    // 坐标处理基于 [-1, 1] 范围.
    constructor(fromCoords, toCoords) {
        // z 分量固定为 1.
        let fromCoords3 = fromCoords.map(({ x, y }) => {
            return new vector4_1.Vector3(x, y, 1);
        });
        let toNumCoords = toCoords.map(({ x, y }) => {
            return new vector4_1.Vector3(x, y, 1);
        });
        // 3x3 坐标矩阵, 每一列是一个坐标.
        let fromCoordsMatrix = matrix4_1.Matrix3.fromVectors(...fromCoords3);
        let toCoordsMatrix = matrix4_1.Matrix3.fromVectors(...toNumCoords);
        // 计算 from 到 to 的变换矩阵, 提取用于二维变换的 6 个参数.
        let transform = toCoordsMatrix.multiply(fromCoordsMatrix.inverse());
        let [a, c, e, b, d, f] = transform.flatten();
        this.transform = matrix4_1.Matrix4.fromMatrix3(transform);
        this.transformInverse = this.transform.inverse();
        /*
        矩阵分解, 基于以下数学运算:

            [a c e] = [1 0 e] × [a c 0]
            [b d f]   [0 1 f]   [b d 0]
            [0 0 1]   [0 0 1]   [0 0 1]

            [a c] = Rotate(θ) × Scale(x, y) × SkewX(s)
            [b d]

            θ = atan2(b, a)
            x = sqrt(a^2 + b^2)
            y = (ad - bc) / x
            s = (ac + bd) / x^2
        */
        let abSquareSum = a * a + b * b;
        this.rotationRadians = Math.atan2(b, a);
        this.scaleX = Math.sqrt(abSquareSum);
        this.scaleY = (a * d - b * c) / this.scaleX;
        this.skewX = Math.atan((a * c + b * d) / abSquareSum);
        this.translateX = e;
        this.translateY = f;
    }
    getTransformsByProgress(progress) {
        let fromTransform = new matrix4_1.Matrix4()
            .skewSelf(this.skewX * progress)
            .scaleSelf(1 + (this.scaleX - 1) * progress, 1 + (this.scaleY - 1) * progress)
            .rotateSelf(this.rotationRadians * progress)
            .translateSelf(this.translateX * progress, this.translateY * progress);
        let toTransform = fromTransform.multiply(this.transformInverse);
        return {
            from: fromTransform,
            to: toTransform,
        };
    }
}
exports.TriangleTransformProcesser = TriangleTransformProcesser;


/***/ }),

/***/ "./src/transitions/face-libs/frontal-face-points.ts":
/*!**********************************************************!*\
  !*** ./src/transitions/face-libs/frontal-face-points.ts ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.FrontalFacePoints = void 0;
// 来自于 Vicky 的某一张正脸数据.
// 用于辅助进行生成一个标准的脸部三角形网格.
exports.FrontalFacePoints = [
    [0.19, 0.506],
    [0.2, 0.596],
    [0.216, 0.684],
    [0.244, 0.766],
    [0.284, 0.842],
    [0.338, 0.912],
    [0.398, 0.974],
    [0.466, 1.024],
    [0.546, 1.032],
    [0.622, 1.014],
    [0.69, 0.956],
    [0.746, 0.888],
    [0.792, 0.81],
    [0.82, 0.728],
    [0.836, 0.642],
    [0.842, 0.556],
    [0.842, 0.466],
    [0.228, 0.432],
    [0.262, 0.388],
    [0.318, 0.372],
    [0.38, 0.376],
    [0.438, 0.398],
    [0.564, 0.388],
    [0.62, 0.36],
    [0.68, 0.352],
    [0.738, 0.362],
    [0.776, 0.4],
    [0.51, 0.488],
    [0.514, 0.548],
    [0.514, 0.608],
    [0.516, 0.668],
    [0.446, 0.712],
    [0.482, 0.722],
    [0.52, 0.73],
    [0.556, 0.72],
    [0.59, 0.708],
    [0.3, 0.506],
    [0.332, 0.486],
    [0.376, 0.486],
    [0.414, 0.514],
    [0.376, 0.522],
    [0.334, 0.522],
    [0.6, 0.506],
    [0.636, 0.476],
    [0.678, 0.47],
    [0.716, 0.488],
    [0.686, 0.506],
    [0.644, 0.512],
    [0.392, 0.812],
    [0.44, 0.79],
    [0.488, 0.778],
    [0.52, 0.786],
    [0.556, 0.778],
    [0.606, 0.788],
    [0.656, 0.806],
    [0.612, 0.864],
    [0.564, 0.89],
    [0.524, 0.894],
    [0.488, 0.89],
    [0.44, 0.866],
    [0.412, 0.816],
    [0.488, 0.804],
    [0.52, 0.808],
    [0.56, 0.804],
    [0.632, 0.81],
    [0.56, 0.842],
    [0.522, 0.846],
    [0.488, 0.844],
];


/***/ }),

/***/ "./src/transitions/face-libs/triangulate.ts":
/*!**************************************************!*\
  !*** ./src/transitions/face-libs/triangulate.ts ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Triangulate = exports.Point = void 0;
// 参考了 https://travellermap.com/tmp/delaunay.htm
// 对由多个点组成的点集进行三角形剖分, 满足德劳内三角化:
// https://en.wikipedia.org/wiki/Delaunay_triangulation
// 即通过外接圆检测尽量减少尖锐的三角形.
// 不过这个算法是一个简单的 O(n^2) 的实现, 在之后我又查询到了 O(nlogn) 的实现.
// 具体参考 <<计算几何第三版>> 第九章, 之后再有需要时会实现.
const EPSILON = 1.0e-9;
// 表示一个顶点.
class Point {
    x;
    y;
    id;
    constructor(x, y, id = -Infinity) {
        this.x = x;
        this.y = y;
        this.id = id;
    }
    minus(p) {
        return new Vector(this.x - p.x, this.y - p.y);
    }
    isBoundingPoint() {
        return this.id < 0;
    }
    clone() {
        return new Point(this.x, this.y, this.id);
    }
}
exports.Point = Point;
// 辅助进行向量运算.
class Vector {
    x;
    y;
    constructor(x, y) {
        this.x = x;
        this.y = y;
    }
    // 计算向量点积.
    dot(v) {
        return this.x * v.x + this.y * v.y;
    }
    // 计算向量叉积. 它相当于围成的平行四边形面积, 并且当前向量到 v 的旋转角小于 180° 时为正.
    cross(v) {
        return this.x * v.y - this.y * v.x;
    }
}
// 三个点组成的三角形.
class Triangle {
    p0;
    p1;
    p2;
    center;
    radiusSquared;
    constructor(v0, v1, v2) {
        this.p0 = v0;
        this.p1 = v1;
        this.p2 = v2;
        this.calcCircumcircle();
    }
    // 计算三角形的外接圆.
    // 其基本思路为圆心到三个点的距离相等而列出关于中心坐标的两个线性方程, 然后通过克拉默法则求解.
    // 还有一种方法是边中点加一个法向量乘以变量得到圆心坐标, 从而列出两个线性方程, 解法类似.
    calcCircumcircle() {
        let { p0: v0, p1: v1, p2: v2 } = this;
        let A = v1.x - v0.x;
        let B = v1.y - v0.y;
        let C = v2.x - v0.x;
        let D = v2.y - v0.y;
        let E = A * (v0.x + v1.x) + B * (v0.y + v1.y);
        let F = C * (v0.x + v2.x) + D * (v0.y + v2.y);
        let G = 2.0 * (A * (v2.y - v1.y) - B * (v2.x - v1.x));
        let dx, dy;
        // 在一条直线上, 圆心由其连线组成的线段作为直径来确定.
        if (Math.abs(G) < EPSILON) {
            let minx = Math.min(v0.x, v1.x, v2.x);
            let miny = Math.min(v0.y, v1.y, v2.y);
            let maxx = Math.max(v0.x, v1.x, v2.x);
            let maxy = Math.max(v0.y, v1.y, v2.y);
            this.center = new Point((minx + maxx) / 2, (miny + maxy) / 2);
            dx = this.center.x - minx;
            dy = this.center.y - miny;
        }
        else {
            let cx = (D * E - B * F) / G;
            let cy = (A * F - C * E) / G;
            this.center = new Point(cx, cy);
            dx = this.center.x - v0.x;
            dy = this.center.y - v0.y;
        }
        this.radiusSquared = dx * dx + dy * dy;
    }
    isBoundingTriangle() {
        return this.p0.isBoundingPoint() || this.p1.isBoundingPoint() || this.p2.isBoundingPoint();
    }
    // 检查点包含于三角形的外接圆内.
    // 如果是的话, 需要将三角形拆开再全部连接到这个点.
    isPointInsideCircumcircle(p) {
        let dx = this.center.x - p.x;
        let dy = this.center.y - p.y;
        let dSquared = dx * dx + dy * dy;
        return dSquared <= this.radiusSquared;
    }
    // 逆时针输出三个顶点的 id.
    outputAnticlockwiseIndices() {
        let v1 = this.p1.minus(this.p0);
        let v2 = this.p2.minus(this.p0);
        let crossValue = v1.cross(v2);
        if (crossValue >= 0) {
            return [this.p0.id, this.p1.id, this.p2.id];
        }
        else {
            return [this.p0.id, this.p2.id, this.p1.id];
        }
    }
}
// 两点组成的边.
class Edge {
    p0;
    p1;
    id;
    constructor(v0, v1) {
        this.p0 = v0;
        this.p1 = v1;
        this.id = v0.id < v1.id ? v0.id + '_' + v1.id : v1.id + '_' + v0.id;
    }
}
// 用于进行三角形剖分的类.
// 使用此类是因为有时候需要一个中间结果做进一步运算, 例如实现预设脸部网格的情况下做动态环境网格划分.
class Triangulate {
    points = [];
    triangles = [];
    constructor(points) {
        if (points) {
            this.triangles.push(this.createBoundingTriangle(points));
            for (let point of points) {
                this.addPoint(point);
            }
        }
    }
    // 创建一个包含所有顶点的三角形的三角形.
    createBoundingTriangle(points) {
        let xs = points.map(v => v.x);
        let ys = points.map(v => v.y);
        let minx = Math.min(...xs);
        let maxx = Math.max(...xs);
        let miny = Math.min(...ys);
        let maxy = Math.max(...ys);
        // 所有的顶点都被包含于一个矩形中.
        // 由于我们可能稍后还会加入新的顶点, 考虑 OpenGL 的默认坐标范围 -1~1, 所以确保最小值为 2.
        // 如果一个本来构成三角形的三个点 ABC, 因为包含顶点 S 在其外接圆内,
        // 结果 ABC 被拆除产生了 SA, SB, SC 三个边.
        // 之后再移除包含顶点 S 之后, 三角形 ABC 会产生缺失.
        // 所以我们需要确保即使需要再连接 ABC, 构成的三角形因为太小而变得没有意义, 例如高小于 1px.
        // 可以通过数学计算得到需要的半径大概为 1 * 1000 (大致的像素) = 1000
        // 在 <<计算几何>> 中, 介绍了生成初始包围三角形的更完善的方法, 即在最初生成这些包含三角形顶点时,
        // 即避免包含三角形顶点被任何一个内部点的凸多边形的某个边作为一边的三角形的外接圆包含,
        // 换句话说, 包含三角形的顶点和这个凸多边形的边的外接圆不应当包含其他的任何顶点.
        // 而在选择其他的包含三角形顶点时, 也同样需要考虑不包含之前已生成的包含三角形顶点.
        let w = Math.max(maxx - minx, 2) * 1000;
        let h = Math.max(maxy - miny, 2) * 1000;
        // 构建一个包含所有顶点的三角形.
        let stv0 = new Point(minx - 3 * w, miny - h, -1);
        let stv1 = new Point(maxx + 3 * w, miny - h, -2);
        let stv2 = new Point((minx + maxx) / 2, maxy + 3 * h, -3);
        return new Triangle(stv0, stv1, stv2);
    }
    // 注意这是一个 O(n^2) 的算法. 可以将顶点分组以对不可能形成三角形的顶点不进行比对.
    // 由于我们的顶点一般都不会超过 100 个, 所以暂时不对其优化.
    addPoint(point) {
        let edges = [];
        // 当我们发现一个三角形的外接圆包含了一个顶点时, 我们暂时将其移除然后生成三个边.
        this.triangles = this.triangles.filter(triangle => {
            if (triangle.isPointInsideCircumcircle(point)) {
                edges.push(new Edge(triangle.p0, triangle.p1));
                edges.push(new Edge(triangle.p1, triangle.p2));
                edges.push(new Edge(triangle.p2, triangle.p0));
                return false;
            }
            return true;
        });
        edges = this.uniqueEdges(edges);
        this.points.push(point);
        // 将这些边和顶点连接起来形成新的三角形.
        for (let edge of edges) {
            this.triangles.push(new Triangle(edge.p0, edge.p1, point));
        }
    }
    // 移除所有共同的边, 即如果出现超过一次则全部移除.
    uniqueEdges(edges) {
        let edgeIds = new Set();
        let uniqueEdgeIds = new Set();
        for (let { id } of edges) {
            if (edgeIds.has(id)) {
                uniqueEdgeIds.delete(id);
            }
            else {
                edgeIds.add(id);
                uniqueEdgeIds.add(id);
            }
        }
        return edges.filter(({ id }) => uniqueEdgeIds.has(id));
    }
    // 输出三角形索引. 输出的顶点索引是逆时针排列的.
    outputIndices() {
        return this.trianglesToIndices(this.removeBoundingTriangle());
    }
    // 获得三角形索引.
    trianglesToIndices(triangles) {
        return triangles.map(triangle => triangle.outputAnticlockwiseIndices());
    }
    // 移除和包含三角形共享顶点的所有三角形.
    removeBoundingTriangle() {
        return this.triangles.filter(triangle => !triangle.isBoundingTriangle());
    }
}
exports.Triangulate = Triangulate;


/***/ }),

/***/ "./src/transitions/face-transform-preview.ts":
/*!***************************************************!*\
  !*** ./src/transitions/face-transform-preview.ts ***!
  \***************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.FaceTransformPreview = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const transition_preview_1 = __webpack_require__(/*! ./transition-preview */ "./src/transitions/transition-preview.ts");
const vector4_1 = __webpack_require__(/*! ../libs/math/vector4 */ "./src/libs/math/vector4.ts");
const face_transform_1 = __webpack_require__(/*! ./face-libs/face-transform */ "./src/transitions/face-libs/face-transform.ts");
let FaceTransformPreview = class FaceTransformPreview extends transition_preview_1.TransitionPreview {
    names = ['face-transform'];
    transitionTimePercent = 1;
    images = [
        '7.jpg',
        '8.jpg',
        '11.jpg',
        '12.jpg',
    ];
    imageDirectory = 'face-transform';
    facePictureSize = [1920, 1080];
    faceTransform;
    // 在两张照片开始过渡前进行的准备工作.
    async onChangeImage() {
        // 生成 -1~1 的坐标点.
        let lastIndex = (this.toImageIndex - 1 + this.images.length) % this.images.length;
        let fromCoords = await this.getFaceLandmarkCoords(lastIndex);
        let toCoords = await this.getFaceLandmarkCoords(this.toImageIndex);
        this.setFaceTransform(new face_transform_1.FaceTransform(fromCoords, toCoords));
    }
    // 从预生成的文件读取人脸数据.
    async getFaceLandmarkCoords(index) {
        let [w, h] = this.facePictureSize;
        let imageURL = `pictures/${this.imageDirectory}/${this.images[index]}`;
        // 人脸数据保存在图片同目录的无后缀文件中.
        let dataURL = imageURL.replace(/.jpg$/, '');
        let text = await (await fetch(dataURL)).text();
        let points = text.trim().split(/\r?\n/g).slice(1).map(line => line.split(',').map(s => Number(s)));
        return points.map(([x, y]) => new vector4_1.Vector2(x / w * 2 - 1, (1 - y / h) * 2 - 1));
    }
    setFaceTransform(faceTransform) {
        this.faceTransform = faceTransform;
        let { fromCoords, toCoords, translates } = faceTransform;
        // 生成顶点数据.
        let fromArray = fromCoords.map(c => [c.x, c.y]).flat();
        let toArray = toCoords.map(c => [c.x, c.y]).flat();
        let translateArray = translates.map(c => [c.x, c.y]).flat();
        // 生成索引绘制数据.
        let fromIndices = faceTransform.fromTriangleIndices.flat();
        let toIndices = faceTransform.toTriangleIndices.flat();
        // 由于两份数据实际上共享 translate 部分, 所以这里我们也可以设置每组 6 条数据,
        // 将数据上传后分别激活两个 VAO, VAO 划分的数据结构分别对应 0~1, 4~5, 以及 2~3, 4~5.
        // 因为数据量很小, 所以这里不做这个优化.
        let toDraws = [...this.sw.toDraws];
        let fromTextureCoord = map2DTextureCoordsFromVerticesData(fromArray);
        let toTextureCoord = map2DTextureCoordsFromVerticesData(toArray);
        toDraws[0].setVertices({ vPosition: fromArray, vTextureCoord: fromTextureCoord, translate: translateArray }, fromCoords.length, fromIndices);
        toDraws[1].setVertices({ vPosition: toArray, vTextureCoord: toTextureCoord, translate: translateArray }, toCoords.length, toIndices);
    }
    drawAll() {
        this.processor.updateProgress(this.progress);
        this.sw.clear();
        // 设置变换矩阵.
        this.setTransformUniforms();
        // 绘制原图.
        let toDraws = [...this.sw.toDraws];
        toDraws[0].draw();
        let textureFrame = this.sw.textureFrameManager.requestFull(true);
        // 绘制新图作为一个帧缓冲纹理.
        textureFrame.active();
        toDraws[1].draw();
        textureFrame.deactive();
        // 将第三步绘制需要的纹理单元设置为帧缓冲纹理对应的单元.
        toDraws[2].useSampler('iChannel', textureFrame.getSampler());
        // 将上面的纹理加上透明度后再度绘制到画布.
        toDraws[2].draw();
    }
    // 设置场景变换矩阵.
    setTransformUniforms() {
        let toDraws = [...this.sw.toDraws];
        let { from, to } = this.faceTransform.getTransformMatrixesByProgress(this.progress);
        toDraws[0].setUniform('iTransform', from.toFloat32Array());
        toDraws[1].setUniform('iTransform', to.toFloat32Array());
    }
};
exports.FaceTransformPreview = FaceTransformPreview;
exports.FaceTransformPreview = FaceTransformPreview = __decorate([
    (0, flit_1.define)('face-transform-preview')
], FaceTransformPreview);
/** 从 2d 顶点数据获得纹理的映射数据. */
function map2DTextureCoordsFromVerticesData(verticesData) {
    let coords = [];
    for (let i = 0; i < verticesData.length; i += 2) {
        coords.push(verticesData[i] / 2 + 0.5);
        coords.push(verticesData[i + 1] / 2 + 0.5);
    }
    return coords;
}


/***/ }),

/***/ "./src/transitions/transition-preview.ts":
/*!***********************************************!*\
  !*** ./src/transitions/transition-preview.ts ***!
  \***********************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {


var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.TransitionPreview = void 0;
const flit_1 = __webpack_require__(/*! @pucelle/flit */ "./node_modules/@pucelle/flit/out/index.js");
const ff_1 = __webpack_require__(/*! @pucelle/ff */ "./node_modules/@pucelle/ff/out/index.js");
const preload_1 = __webpack_require__(/*! ../libs/util/preload */ "./src/libs/util/preload.ts");
const simple_webgl_1 = __webpack_require__(/*! ../libs/webgl/simple-webgl */ "./src/libs/webgl/simple-webgl.ts");
const transition_processor_1 = __webpack_require__(/*! ./transition-processor */ "./src/transitions/transition-processor.ts");
const sampler_1 = __webpack_require__(/*! ../libs/webgl/sampler */ "./src/libs/webgl/sampler.ts");
let TransitionPreview = class TransitionPreview extends flit_1.Component {
    names = [];
    toImageIndex = 1;
    transitionName = '';
    sw;
    intervalSeconds = ff_1.storage.get('transitionIntervalTime', 5);
    imageNaturalSize = [0, 0];
    endPlaying = () => { };
    paused = false;
    easing = ff_1.storage.get('transitionEasing', 'ease-in-out');
    uniforms;
    uniformValues;
    linearProgress = 0;
    transitionTimePercent = 0.9;
    progress = 0;
    processor;
    easingData = [
        { value: 'linear', text: 'linear' },
        { value: 'ease-in-out', text: 'ease in out' },
        { value: 'ease-in-out-quad', text: 'ease in out quad' },
        { value: 'ease-in-out-cubic', text: 'ease in out cubic' },
        { value: 'ease-in-out-quart', text: 'ease in out quart' },
        { value: 'ease-in-out-quint', text: 'ease in out quint' },
        { value: 'ease-in-out-sine', text: 'ease in out sine' },
        { value: 'ease-in-out-expo', text: 'ease in out expo' },
        { value: 'ease-in-out-circ', text: 'ease in out circ' },
        { value: 'ease-in-out-back', text: 'ease in out back' },
        { value: 'ease-in', text: 'ease in' },
        { value: 'ease-in-quad', text: 'ease in quad' },
        { value: 'ease-in-cubic', text: 'ease in cubic' },
        { value: 'ease-in-quart', text: 'ease in quart' },
        { value: 'ease-in-quint', text: 'ease in quint' },
        { value: 'ease-in-sine', text: 'ease in sine' },
        { value: 'ease-in-expo', text: 'ease in expo' },
        { value: 'ease-in-circ', text: 'ease in circ' },
        { value: 'ease-in-back', text: 'ease in back' },
        { value: 'ease-out', text: 'ease out' },
        { value: 'ease-out-quad', text: 'ease out quad' },
        { value: 'ease-out-cubic', text: 'ease out cubic' },
        { value: 'ease-out-quart', text: 'ease out quart' },
        { value: 'ease-out-quint', text: 'ease out quint' },
        { value: 'ease-out-sine', text: 'ease out sine' },
        { value: 'ease-out-expo', text: 'ease out expo' },
        { value: 'ease-out-circ', text: 'ease out circ' },
        { value: 'ease-out-back', text: 'ease out back' },
    ];
    images = [
        'allef-vinicius-pa0vicn6dwe-unsplash.jpg',
        'allef-vinicius-ttusgz8ulkk-unsplash.jpg',
        'allef-vinicius-_ugpeypqiuc-unsplash.jpg',
        'anastasia-dulgier-kokszzy9wsa-unsplash.jpg',
        'anthony-tran-mehojxixkdq-unsplash.jpg',
        'deanna-alys-6lbbowkpzyq-unsplash.jpg',
        'erol-ahmed-aiyfr0vbadk-unsplash.jpg',
        'floriane-vita-fyd3owbuxny-unsplash.jpg',
        'icons8-team-7lnatqymzm4-unsplash.jpg',
        'jessica-weiller-so4efi-d1nc-unsplash.jpg',
        'newborn-1328454.jpg',
        'quan-nguyen-sghnxezeo-q-unsplash.jpg',
        'scott-webb--udznjsczse-unsplash.jpg',
    ];
    imageDirectory = 'color-correction';
    render() {
        return (0, flit_1.html) `
		<template class="preview">
			${this.renderTransitionNames()}
			${this.renderToolbar()}
			${this.renderImages()}
			${this.renderAdditionalToolbar()}
		</template>
		`;
    }
    renderTransitionNames() {
        if (this.names.length < 2) {
            return '';
        }
        return (0, flit_1.html) `
		<div class="preview-names">
			${this.names.map((name) => (0, flit_1.html) `
				<div
					:class.active=${name === this.transitionName}
					@click=${() => this.onClickTransitionName(name)}
				>
					${name}
				</div>
			`)}
		</div>
		`;
    }
    renderToolbar() {
        return (0, flit_1.html) `
		<table class="preview-toolbar">
		<tbody>
			<tr>
				<td>
					Duration: <span class="preview-slide-value">${this.intervalSeconds}s</span>
				</td>
				<td>
					<f-slider class="preview-slider" .min="1" .max="30" .step="1" .value=${this.intervalSeconds} @change=${this.changeIntervalTime} />
					<button class="preview-slider-button" @click=${this.togglePaused}>${this.paused ? 'Play' : 'Pause'}</button>
					<f-select class="preview-easing-select" .value=${this.easing} .data=${this.easingData} @change=${this.onChangeEasing} />
				</td>
			</tr>

			${this.uniforms.map(({ name, desc, min, max, step, value: defaultValue }, index) => {
            let currentValue = this.uniformValues[index];
            return (0, flit_1.html) `
				<tr>
					<td>
						${desc}: <span class="preview-slide-value">${currentValue}</span>
					</td>
					<td>
						<f-slider class="preview-slider" .min=${min} .max=${max} .step=${step} .value=${currentValue}
							@change=${(value) => this.changeSliderValue(name, index, value)}
						/>
						<button class="preview-slider-button" @click=${() => this.changeSliderValue(name, index, defaultValue)}>Reset</button>
					</td>
				</tr>
				`;
        })}
		</tbody>
		</table>
		`;
    }
    renderImages() {
        return (0, flit_1.html) `
			<div class="preview-nav">
			${this.images.map((name, index) => (0, flit_1.html) `
				<div class="preview-nav-item"
					:class.active=${index === this.toImageIndex}
					@click=${() => this.onClickImageInIndex(index)}
				>
					<img src="pictures/${this.imageDirectory}/${name}">
				</div>
			`)}
			</div>

			<div class="preview-canvas" :ref="canvasContainer">
				<canvas :ref="canvas" />
			</div>
		`;
    }
    renderAdditionalToolbar() {
        return (0, flit_1.html) `
		<div class="preview-additional-toolbar">
			<f-slider class="preview-progress" :ref="slider" .min="0" .max="1" .step="0.01" .value=${this.linearProgress}
				.renderTooltipValue=${() => (0, flit_1.html) `<div style="min-width: 40px; text-align: center;">${Math.round(this.linearProgress * 100)}%`}
				@dragstart=${this.startChangingProgress}
				@dragend=${this.endChangingProgress}
				@change=${this.changeProgress}
			/>
			<button class="preview-slider-button" @click=${this.toFullscreen}>Fullscreen</button>
		</div>
		`;
    }
    changeIntervalTime(value) {
        this.intervalSeconds = value;
        ff_1.storage.set('transitionIntervalTime', value);
    }
    changeSliderValue(name, index, value) {
        this.sw.setUniform(name, value);
        this.uniformValues[index] = value;
        this.drawAll();
    }
    startChangingProgress() {
        this.endPlaying();
    }
    endChangingProgress() {
        if (!this.paused) {
            this.startPlaying();
        }
    }
    changeProgress(value) {
        this.updateProgress(value);
    }
    onCreated() {
        this.transitionName = this.names[0];
        this.uniforms = (0, transition_processor_1.getUniformSlides)(this.transitionName) || [];
        this.uniformValues = this.uniforms.map(uniform => uniform.value);
    }
    async onReady() {
        this.initGL();
        for (let i = 0; i < this.uniforms.length; i++) {
            let { name, value } = this.uniforms[i];
            this.sw.setUniform(name, value);
        }
        await this.setTransitionName(this.transitionName);
        await this.setToImageIndex(this.toImageIndex);
        if (!this.paused) {
            this.startPlaying();
        }
    }
    initGL() {
        let canvas = this.refs.canvas;
        this.sw = new simple_webgl_1.SimpleWebGL(canvas);
    }
    onConnected() {
        (0, flit_1.on)(window, 'resize', this.onResize, this);
        (0, flit_1.on)(document, 'keydown.space.prevent', this.togglePaused, this);
    }
    onDisconnected() {
        this.endPlaying();
        (0, flit_1.off)(window, 'resize', this.onResize, this);
        (0, flit_1.off)(document, 'keydown', this.togglePaused, this);
    }
    onResize() {
        if (this.imageNaturalSize[0] > 0) {
            this.adjustSize();
            this.drawAll();
        }
    }
    adjustSize() {
        let [iw, ih] = this.imageNaturalSize;
        let w = this.refs.canvasContainer.offsetWidth;
        let h = Math.round(ih / iw * w);
        if (w > iw) {
            w = iw;
            h = ih;
        }
        this.sw.setCanvasSize(w, h);
        this.sw.setUniform('iResolution', [w, h]);
    }
    togglePaused() {
        this.paused = !this.paused;
        if (this.paused) {
            this.endPlaying();
        }
        else {
            this.startPlaying();
        }
    }
    toFullscreen() {
        this.refs.canvasContainer.requestFullscreen();
        this.adjustSize();
    }
    onChangeEasing(value) {
        this.easing = value;
        ff_1.storage.set('transitionEasing', value);
    }
    async onClickImageInIndex(index) {
        await this.setToImageIndex(index);
        this.restartPlaying();
    }
    async setToImageIndex(index) {
        this.toImageIndex = index;
        // 加载图片.
        let fromIndex = (index + this.images.length - 1) % this.images.length;
        let fromImageURL = `pictures/${this.imageDirectory}/${this.images[fromIndex]}`;
        let toImageURL = `pictures/${this.imageDirectory}/${this.images[index]}`;
        // 此处可以缓存图片, 这样采样器不会重复上传纹理.
        // 由于这只是一个临时的演示, 之后再考虑优化.
        let fromImage = await (0, preload_1.preloadImage)(fromImageURL);
        let toImage = await (0, preload_1.preloadImage)(toImageURL);
        this.imageNaturalSize = [fromImage.naturalWidth, fromImage.naturalHeight];
        this.adjustSize();
        // 上传纹理和设置纹理单元.
        let sourceSampler = new sampler_1.PixelSampler(this.sw, fromImage, this.processor.getSourceParams());
        let targetSampler = new sampler_1.PixelSampler(this.sw, toImage, this.processor.getTargetParams());
        this.processor.useSamplers(sourceSampler, targetSampler);
        // 调用图片更改之后的扩展处理.
        await this.onChangeImage();
    }
    /** 从头开始播放转场. */
    restartPlaying() {
        this.linearProgress = 0;
        this.progress = 0;
        this.startPlaying();
    }
    async onChangeImage() { }
    startPlaying() {
        this.endPlaying();
        if (this.paused) {
            this.drawAll();
            return;
        }
        let startTime = performance.now();
        let pastTime = 0;
        let frameId = 0;
        let playedOut = false;
        let ended = false;
        if (this.progress > 0) {
            startTime -= this.getDuration() * this.linearProgress;
        }
        let drawFrame = async () => {
            pastTime = performance.now() - startTime;
            if (pastTime > this.intervalSeconds * 1000) {
                await this.setToImageIndex((this.toImageIndex + 1) % this.images.length);
                this.restartPlaying();
                return;
            }
            // 由于上面有一个 await, 期间如果 endTransition, 这里会无法结束动画, 所以需要判断 ended.
            if (ended) {
                return;
            }
            if (pastTime < this.getDuration()) {
                this.updateProgress(pastTime / this.getDuration());
            }
            else if (!playedOut) {
                this.updateProgress(1);
                playedOut = true;
            }
            frameId = requestAnimationFrame(drawFrame);
        };
        drawFrame();
        this.endPlaying = () => {
            cancelAnimationFrame(frameId);
            ended = true;
        };
    }
    getDuration() {
        return this.transitionTimePercent * this.intervalSeconds * 1000;
    }
    updateProgress(linearProgress) {
        this.linearProgress = linearProgress;
        this.progress = (0, ff_1.getEasingFunction)(this.easing)(linearProgress);
        this.sw.setUniform('iProgress', this.progress);
        this.drawAll();
    }
    drawAll() {
        this.processor.updateProgress(this.progress);
        this.sw.clear();
        this.sw.drawAll();
    }
    async onClickTransitionName(name) {
        await this.setTransitionName(name);
        await this.setToImageIndex(this.toImageIndex);
        if (this.paused) {
            this.startPlaying();
        }
        else {
            this.restartPlaying();
        }
    }
    async setTransitionName(name) {
        this.transitionName = name;
        this.endPlaying();
        // 重置转场处理器.
        await this.prepareProcessor();
    }
    async prepareProcessor() {
        if (this.processor) {
            this.processor.delete();
        }
        this.processor = new transition_processor_1.TransitionProcessor(this.transitionName, this.sw);
        await this.processor.ready;
    }
};
exports.TransitionPreview = TransitionPreview;
exports.TransitionPreview = TransitionPreview = __decorate([
    (0, flit_1.define)('transition-preview')
], TransitionPreview);


/***/ }),

/***/ "./src/transitions/transition-processor.ts":
/*!*************************************************!*\
  !*** ./src/transitions/transition-processor.ts ***!
  \*************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.getUniformSlides = exports.TransitionProcessor = exports.extendTransitions = exports.DefinedTransitions = exports.TextureReference = void 0;
const preload_1 = __webpack_require__(/*! ../libs/util/preload */ "./src/libs/util/preload.ts");
const todraw_1 = __webpack_require__(/*! ../libs/webgl/todraw */ "./src/libs/webgl/todraw.ts");
const sampler_1 = __webpack_require__(/*! ../libs/webgl/sampler */ "./src/libs/webgl/sampler.ts");
const matrix4_1 = __webpack_require__(/*! ../libs/math/matrix4 */ "./src/libs/math/matrix4.ts");
var TextureReference;
(function (TextureReference) {
    /** 不使用任何纹理. */
    TextureReference[TextureReference["None"] = 0] = "None";
    /** 仅使用 source 纹理, 即原图. */
    TextureReference[TextureReference["Source"] = 1] = "Source";
    /** 仅使用 target 纹理, 即新图. */
    TextureReference[TextureReference["Target"] = 2] = "Target";
    /** 使用两个纹理. 默认. */
    TextureReference[TextureReference["Both"] = 3] = "Both";
})(TextureReference || (exports.TextureReference = TextureReference = {}));
exports.DefinedTransitions = {};
function extendTransitions(transforms) {
    Object.assign(exports.DefinedTransitions, transforms);
}
exports.extendTransitions = extendTransitions;
// 用于根据一个指定名称的 Transition 进行转场绘制的类, 一个 webgl 上下文在切换 Transition 时会切换此类.
// 此类只负责更新参数和进行单次绘制, 如果需要控制播放和暂停以及时间轴, 请在外层实现.
class TransitionProcessor {
    /** 等待初始化完成的 promise. */
    ready;
    transitionName;
    sw;
    options;
    toDraw;
    constructor(transitionName, sw) {
        this.transitionName = transitionName;
        this.options = exports.DefinedTransitions[this.transitionName];
        this.sw = sw;
        this.ready = this.initialize();
    }
    async initialize() {
        let options = this.options;
        // 确定是否需要开启 3D.
        if (options.threeD) {
            this.sw.enableDepth();
        }
        else {
            this.sw.disableDepth();
        }
        // 处理预设参数.
        if (options.uniformValues) {
            for (let [name, value] of Object.entries(options.uniformValues)) {
                this.sw.setUniform(name, value);
            }
        }
        // 初始化绘制步骤以及对应的 ToDraw 对象.
        await this.initializeSteps();
        // 上传极坐标采样数据.
        if (options.polarSamplingData) {
            let sampler = new sampler_1.FloatSampler(this.sw, {
                data: new Float32Array(options.polarSamplingData),
                width: options.polarSamplingData.length,
                height: 1,
            }, { filter: sampler_1.SamplerFilter.Linear, wrapType: sampler_1.SamplerWrapType.Repeat });
            this.sw.setUniform('minimalPolarRadius', Math.min(...options.polarSamplingData));
            this.toDraw.useSampler('polarSampler', sampler);
        }
        // 上传蒙版数据.
        if (options.mask) {
            let image = await (0, preload_1.preloadImage)(`textures/${options.mask}.png`);
            let sampler = new sampler_1.PixelSampler(this.sw, image, { filter: sampler_1.SamplerFilter.Linear });
            this.toDraw.useSampler('mask', sampler);
        }
    }
    async initializeSteps() {
        for (let step of this.options.steps) {
            await this.createToDraw(step);
        }
    }
    async createToDraw(step) {
        let vertCode = await this.getVertexCode(step);
        let fragCode = await this.getFragmentCode(step);
        let vPosition = this.getVerticesData(step);
        let vTextureCoord = step.textureCoords || map3DTextureCoordsFromVerticesData(vPosition);
        let vertices = { data: { vPosition, vTextureCoord }, count: vPosition.length / 3 };
        let uniforms = {};
        if (!step || !step.transform) {
            uniforms.iTransform = matrix4_1.Matrix4.I.toFloat32Array();
        }
        this.toDraw = new todraw_1.ToDraw(this.sw, {
            type: step.drawType,
            vertCode,
            fragCode,
            vertices,
            uniforms
        });
    }
    async getVertexCode(step) {
        if (step && step.vertShaderName) {
            return await (await fetch(`shaders/transitions/out/${step.vertShaderName}.vert`)).text();
        }
        return `#version 300 es
			precision mediump float;
			layout (location = 0) in vec4 vPosition;
			layout (location = 1) in vec2 vTextureCoord;
			uniform mat4 iTransform;
			out vec2 fTextureCoord;
			void main() {
				gl_Position = iTransform * vPosition;
				fTextureCoord = vTextureCoord;
			}
		`;
    }
    async getFragmentCode(step) {
        if (step && step.fragShaderName) {
            return await (await fetch(`shaders/transitions/out/${step.fragShaderName}.frag`)).text();
        }
        return `#version 300 es
			precision mediump float; 
			uniform sampler2D iChannel[1];
			in vec2 fTextureCoord;
			out vec4 color;
			void main() {
				color = texture(iChannel[0], fTextureCoord);
			}
		`;
    }
    // 这里使用的是单向顶点数据, 只有一个 position 字段.
    getVerticesData(step) {
        if (step.vertices) {
            return step.vertices;
        }
        return [
            -1, 1, 0,
            -1, -1, 0,
            1, 1, 0,
            1, -1, 0,
        ];
    }
    /** 绘制. */
    updateProgress(progress) {
        let { width, height } = this.sw;
        let index = 0;
        for (let toDraw of this.sw.toDraws) {
            let step = this.options.steps[index];
            if (step.transform) {
                let matrixData = step.transform(progress, this.sw.uniforms, [width, height]);
                toDraw.setUniform('iTransform', matrixData.toFloat32Array());
            }
            index++;
        }
    }
    /** 获得原图的线性过滤设置. */
    getSourceParams() {
        return this.options.sourceParams;
    }
    /** 获得新图的线性过滤设置. */
    getTargetParams() {
        return this.options.targetParams;
    }
    /** 设置纹理单元. */
    useSamplers(sourceSampler, targetSampler) {
        let toDraws = [...this.sw.toDraws];
        for (let i = 0; i < toDraws.length; i++) {
            let step = this.options.steps[i];
            let toDraw = toDraws[i];
            if (step.useTexture === TextureReference.Source) {
                toDraw.useSampler('iChannel', sourceSampler);
            }
            else if (step.useTexture === TextureReference.Target) {
                toDraw.useSampler('iChannel', targetSampler);
            }
            else if (step.useTexture !== TextureReference.None) {
                toDraw.useSampler('iChannel', sourceSampler, targetSampler);
            }
        }
    }
    /** 删除 ToDraw 对象. */
    delete() {
        for (let toDraw of [...this.sw.toDraws]) {
            toDraw.delete();
        }
    }
}
exports.TransitionProcessor = TransitionProcessor;
/** 获取指定的 transition 配置中的滑动配置. */
function getUniformSlides(transitionName) {
    let obj = exports.DefinedTransitions[transitionName];
    if (obj) {
        return obj.uniformSlides;
    }
    return undefined;
}
exports.getUniformSlides = getUniformSlides;
/** 从 3d 顶点数据获得纹理的映射数据. */
function map3DTextureCoordsFromVerticesData(verticesData) {
    let coords = [];
    for (let i = 0; i < verticesData.length; i += 3) {
        coords.push(verticesData[i] / 2 + 0.5);
        coords.push(verticesData[i + 1] / 2 + 0.5);
    }
    return coords;
}


/***/ })

/******/ 	});
/************************************************************************/
/******/ 	// The module cache
/******/ 	var __webpack_module_cache__ = {};
/******/ 	
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/ 		// Check if module is in cache
/******/ 		var cachedModule = __webpack_module_cache__[moduleId];
/******/ 		if (cachedModule !== undefined) {
/******/ 			return cachedModule.exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = __webpack_module_cache__[moduleId] = {
/******/ 			// no module.id needed
/******/ 			// no module.loaded needed
/******/ 			exports: {}
/******/ 		};
/******/ 	
/******/ 		// Execute the module function
/******/ 		__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/ 	
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/ 	
/************************************************************************/
/******/ 	/* webpack/runtime/define property getters */
/******/ 	(() => {
/******/ 		// define getter functions for harmony exports
/******/ 		__webpack_require__.d = (exports, definition) => {
/******/ 			for(var key in definition) {
/******/ 				if(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {
/******/ 					Object.defineProperty(exports, key, { enumerable: true, get: definition[key] });
/******/ 				}
/******/ 			}
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/hasOwnProperty shorthand */
/******/ 	(() => {
/******/ 		__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/make namespace object */
/******/ 	(() => {
/******/ 		// define __esModule on exports
/******/ 		__webpack_require__.r = (exports) => {
/******/ 			if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 				Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 			}
/******/ 			Object.defineProperty(exports, '__esModule', { value: true });
/******/ 		};
/******/ 	})();
/******/ 	
/************************************************************************/
/******/ 	
/******/ 	// startup
/******/ 	// Load entry module and return exports
/******/ 	// This entry module is referenced by other modules so it can't be inlined
/******/ 	var __webpack_exports__ = __webpack_require__("./src/index.ts");
/******/ 	
/******/ })()
;
//# sourceMappingURL=bundle.js.map